<!DOCTYPE html><html domain=".com" lang="en"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="default-src 'self';object-src 'none';script-src 'self' 'unsafe-inline' https://cdnjs.cloudflare.com/ https://gist.github.com/ https://www.googletagmanager.com/ https://www.google-analytics.com;connect-src 'self' https://www.google-analytics.com https://api.github.com;style-src 'self' https://fonts.googleapis.com/ https://use.fontawesome.com/ 'unsafe-inline' https://github.githubassets.com/ https://cdn.jsdelivr.net;img-src 'self' data:;font-src 'self' https://fonts.gstatic.com/ https://use.fontawesome.com/ https://cdn.jsdelivr.net" http-equiv="Content-Security-Policy"><link href="/favicon.svg" rel="icon" type="image/svg+xml"><meta content="#f9c412" name="theme-color"><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name="robots"><title>Docker + GPUs</title><meta content="Docker + GPUs" property="og:title"><meta content="ðŸ‘‰ Note: Docker 101 ðŸ‘‰ Note: Wordpress Docker ðŸ‘‰ Note: Airflow + Kubernetes 101 ðŸ‘‰ Note: Tensorflow extra WSL + Windows # ðŸ‘‰ Note: WSL +..." name="description"><meta content="ðŸ‘‰ Note: Docker 101 ðŸ‘‰ Note: Wordpress Docker ðŸ‘‰ Note: Airflow + Kubernetes 101 ðŸ‘‰ Note: Tensorflow extra WSL + Windows # ðŸ‘‰ Note: WSL +..." property="og:description"><meta content="summary_large_image" name="twitter:card"><meta content="@dinhanhthi" name="twitter:site"><meta content="@dinhanhthi" name="twitter:creator"><meta content="https://dinhanhthi.com/img/remote/19UVif.svg" property="og:image"><meta content="article" property="og:type"><link href="https://dinhanhthi.com/docker-gpu/" rel="canonical"><meta content="https://dinhanhthi.com/docker-gpu/" property="og:url"><meta content="no-referrer-when-downgrade" name="referrer"><link href="/feed/feed.xml" rel="alternate" type="application/atom+xml" title="ðŸ”¥ Anh-Thi DINH"><link href="/" rel="preconnect" crossorigin=""><link href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css" rel="stylesheet"><script csp-hash="sha256-1krv3Gb414NWjc9OVes7p1DsVGXMgyXL7klj8V8OQJE=">if (/Mac OS X/.test(navigator.userAgent))
			document
				.documentElement
				.classList
				.add('apple')</script><style>@charset "UTF-8";@font-face{font-display:swap;font-family:"Poppins";font-style:normal;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-regular.eot);src:local("Poppins Regular"),local("Poppins-Regular"),url(/fonts/poppins/poppins-v15-latin-regular.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-regular.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-regular.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-regular.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-regular.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:"Poppins";font-style:italic;font-weight:400;src:url(/fonts/poppins/poppins-v15-latin-italic.eot);src:local("Poppins Italic"),local("Poppins-Italic"),url(/fonts/poppins/poppins-v15-latin-italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:normal;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600.eot);src:local("Poppins SemiBold"),local("Poppins-SemiBold"),url(/fonts/poppins/poppins-v15-latin-600.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Poppins';font-style:italic;font-weight:600;src:url(/fonts/poppins/poppins-v15-latin-600italic.eot);src:local("Poppins SemiBold Italic"),local("Poppins-SemiBoldItalic"),url(/fonts/poppins/poppins-v15-latin-600italic.eot?#iefix) format("embedded-opentype"),url(/fonts/poppins/poppins-v15-latin-600italic.woff2) format("woff2"),url(/fonts/poppins/poppins-v15-latin-600italic.woff) format("woff"),url(/fonts/poppins/poppins-v15-latin-600italic.ttf) format("truetype"),url(/fonts/poppins/poppins-v15-latin-600italic.svg#Poppins) format("svg")}@font-face{font-display:swap;font-family:'Recoleta';src:url(/fonts/recoleta/Recoleta-Bold.woff2) format("woff2"),url(/fonts/recoleta/Recoleta-Bold.woff) format("woff"),url(/fonts/poppins/Recoleta-Bold.ttf) format("truetype");font-weight:700;font-style:bold}*{border:0;box-sizing:border-box}:root{font-size:16.5px}main img{content-visibility:auto}::-webkit-scrollbar{height:10px;width:10px}::-webkit-scrollbar-thumb{background:#3e466b;border-radius:6px}::-webkit-scrollbar-thumb:hover{background:#aaa;cursor:pointer}::-webkit-scrollbar-track{background:#363948}::-webkit-scrollbar-corner{background:#282a36}body,html{font-family:"Poppins",Arial,Helvetica,sans-serif;font-size:16.5px}html{-webkit-text-size-adjust:100%}@supports (font-variation-settings:normal){html{font-family:"Poppins" var alt,Arial,Helvetica,sans-serif}}body{background:#282a36;color:#eee;margin:0;counter-reset:h2counter}strong{font-weight:600;color:#8cc8ff}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}mark{color:inherit;padding:0;background-color:transparent;box-shadow:inset 0 -4px 0 0 #ffd479}a,a:hover{text-decoration:none}a:hover{border-bottom:2px solid #ffd479}a.no-effect:hover{border-bottom:none}.page-note h3:hover a:hover,.page-note>h2:hover a:hover,a,a strong{color:#ffd479}.intro a,a strong:hover,a:hover{color:#fff}img{max-width:100%}main{margin:0 auto}.page-note h3,.page-note>h2,h1,h2,h3{font-family:"Recoleta",Arial,Helvetica,sans-serif}h1{font-size:29.7px}h2{font-size:24.75px}h3{font-size:21.5325px}.page-note h3,.page-note>h2{color:#eee}.page-note h3:hover .direct-link,.page-note>h2:hover .direct-link{display:inline-block}.page-note>h2{font-size:24.75px;margin:37.125px 0 19.8px}.page-note p+ol,.page-note p+ul,.page-note>h2+h3{margin-top:-.5rem}.page-note>h3{font-size:21.5325px;margin-bottom:19.8px}.page-note .direct-link{display:none;color:#777;border-bottom:none;margin-left:3px}.page-note pre+h2,.page-note pre+h3,.page-note>h3{margin-top:37.125px}.page-note h1{counter-reset:h2counter}.page-note h2{counter-reset:h3counter}.page-note h3{counter-reset:h4counter}.page-note h3:before{opacity:.5;content:counter(h2counter) "." counter(h3counter) ".Â Â ";counter-increment:h3counter}.page-note h2:before{content:counter(h2counter) ".Â Â ";counter-increment:h2counter;color:#8cc8ff}.container,header{width:100%;margin:0 auto}.normal{padding:0 16.5px;width:100%}@media (min-width:916.5px){.normal{width:900px}}.mt-2{margin-top:2rem}.page-index .container{padding:2rem 1rem 0}.page-index .main-cats{flex:0 1 calc(100% - 280px);padding-right:1rem}.page-index .main-cats>.category-wrapper{padding-bottom:1.5rem}.page-index .main-cats>.category-wrapper>.category{border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:2rem 1.5rem 1.5rem}.page-index .toc-index{border:1px solid #404040;border-radius:7px;height:fit-content;background:#35373c;flex:0 1 280px;position:sticky;top:60px;padding:1rem 1.1rem}.page-index .toc-index h3{padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 10px;font-size:1.3rem}.page-index .toc-index ul{padding-left:20px;margin:0}.page-index .toc-index p{font-style:italic;color:#999;padding-top:0;margin-bottom:0;font-size:.95rem;margin-top:10px}.page-index .toc-index p a{color:#999;border-bottom:2px solid #999}.page-index .toc-index p a:hover{border-bottom:2px solid #ffd479}@media (max-width:991px){.page-index .main-cats{flex:1 1 100%;order:2;padding-right:0}.page-index .toc-index{flex:1 1 100%;order:1;position:inherit;margin-bottom:1.5rem}.page-index .toc-index ul{column-count:3;-webkit-column-count:3;-moz-column-count:3}}@media (max-width:767px){.page-index .toc-index ul{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (max-width:575px){.page-index .toc-index ul{column-count:1;-webkit-column-count:1;-moz-column-count:1}}.category{width:100%}.category h2,header h1{font-size:1.55rem;margin-top:0}.category h2 img{float:left;margin-right:7px}.category .list-homepage{list-style:none;padding-left:0;margin-bottom:0;column-count:1;-webkit-column-count:1;-moz-column-count:1}@media (min-width:768px){.category .list-homepage{column-count:2;-webkit-column-count:2;-moz-column-count:2}}@media (min-width:992px){.category .list-homepage{column-count:3;-webkit-column-count:3;-moz-column-count:3}}.category .list-homepage li{padding-left:25px;margin-bottom:10px;width:100%}.category .list-homepage li a{color:#ddd;border-bottom:2px solid rgba(255,255,255,.14);border-style:dotted}.category .list-homepage li img{width:20px;height:auto;margin-bottom:-5px;margin-left:-25px;opacity:.9}.category .list-homepage li:hover{cursor:pointer}.category .list-homepage li:hover a{border-color:#ffd479;color:#fff}.category .list-homepage li:hover::before{opacity:1}.page-index header{padding-top:5em;padding-bottom:0}.page-index header .header-logo{height:80px;width:auto}header nav{z-index:10}#nav{z-index:2;position:relative}header{padding:5.5rem 1.5rem 1rem;width:900px;text-align:center;max-width:100%;display:flex;align-items:center;flex-direction:column}header h1{font-size:2.2rem;margin-bottom:0}header p{margin-top:1rem}header .header-logo{width:55px;height:55px;margin-bottom:1rem}header .header-logo img{width:100%;height:100%}header .social{margin-top:.5rem}header #more-info #note-tag>a,header .social a{margin-right:10px}header .social a:last-child,p.contact a:last-child{margin-right:0}@media (min-width:992px){header .social a{margin-right:20px}}header .social a img{border-radius:50%}header #more-info{padding:1rem}header #more-info #note-tag{padding-bottom:10px;border-bottom:1px solid #444}header #more-info #note-tag>a::before{content:"#"}header #more-info #last-modified{padding-top:10px;font-style:italic}#reading-progress,nav{top:0;left:0;width:100vw}#reading-progress{z-index:3;border-bottom:1px solid #ffd479;position:absolute;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}.intro,.job span{font-size:1.02rem}.intro b,.intro strong{color:#ffd479;font-weight:400}.job span{background:#ffd479;color:#000;padding:3px 20px;border-radius:15px}p.contact{width:100%;text-align:center;margin-bottom:4rem}p.contact a{margin-right:10px;margin-bottom:10px}nav{position:fixed;padding:0 1.5rem;background:#35373c}nav nav #nav .nav-search .nav-search__input{padding-right:1.5rem}@media (max-width:992px){nav{padding:0 1rem}nav nav #nav .nav-search .nav-search__input{padding-right:1rem}}@media (max-width:576px){nav{padding:0 .5em}nav nav #nav .nav-search .nav-search__input{padding-right:.5rem}}nav #nav{display:-ms-flexbox;-ms-flex-align:center;align-items:center}nav #nav a{color:#ccc;margin-right:15px;align-items:center;padding:0 .5rem;font-size:1.1rem;white-space:nowrap}nav #nav a img{margin-right:5px}nav #nav a:hover{color:#fff;cursor:pointer;text-decoration:none}nav #nav .nav-item{text-align:left;margin-right:5px}@media (min-width:421px){nav #nav .nav-item{padding-left:0!important}}@media (max-width:575px){nav #nav .nav-item{width:unset!important}nav #nav .nav-item span{display:none}}@media (min-width:576px){nav #nav .nav-item{margin-right:15px}}nav #nav .nav-github{text-align:right;padding-right:0!important;margin-right:0!important}nav #nav .nav-github:hover img{filter:invert(.4)}nav #nav .nav-search{display:block;background-image:linear-gradient(to right,#3d4251,#3b3f4c,#393d46,#373a41,#35373c);width:100%;position:relative}nav #nav,nav #nav .nav-search form,nav #nav a{display:flex}nav #nav .nav-search .nav-search__input{border:0;background:0 0;color:#ddd;font-size:1.05rem;padding:.65rem .5rem;width:100%}nav #nav .nav-search .nav-search__input:focus{outline:0;border:0}nav #nav .nav-search #nav-search__result-container{position:absolute;max-height:80vh;overflow:auto;width:100%;background:#35373c;border-bottom-right-radius:5px;border-bottom-left-radius:5px;padding:0;filter:drop-shadow(2px 4px 6px #000)}@media (max-width:767px){nav #nav .nav-search #nav-search__result-container{position:fixed;left:0;right:0;border-radius:0}}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul{padding:0;margin:0;list-style:none}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li{display:flex;padding:10px;align-items:center;justify-content:space-between;overflow:hidden}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li .item__icon{width:20px}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li .item__content{padding:0 10px;width:100%;overflow:hidden;text-overflow:ellipsis}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li .item__content h3{margin:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li .item__content h3 a{color:#efb232;padding:0;text-align:left;font-weight:400;font-size:16.5px;line-height:1.5;margin:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;display:block}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li .item__content h3 a:hover{border-bottom:none;color:#8cc8ff}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li .item__content p{text-align:left;margin:0;line-height:1.5;font-size:.95rem;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li .enter{width:20px;display:none}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li.selected{background:#282a36}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul li.selected .enter{display:block}nav #nav .nav-search #nav-search__result-container ul#nav-search__ul mark{background:0 0;color:inherit;box-shadow:inset 0 -3px 0 0 #fff}nav #nav .nav-search #nav-search__result-container #nav-search__no-result{padding:0 10px}nav #nav .nav-search #nav-search__result-container #nav-search__no-result p{text-align:left}footer{font-size:1rem;background:#35373c;padding:.75rem 1rem;text-align:center;margin-top:3rem}footer a{color:#ccc}footer a:hover{color:#fff}.danger,.info,.warning{position:relative;padding:16.5px;margin-bottom:24.75px;border:1px solid transparent;border-radius:.25rem;color:#eee;border-left-width:15px}.danger :last-child,.info :last-child,.warning :last-child{margin-bottom:0}.info{border-color:#8cc8ff}.danger{border-color:#f55}.warning{border-color:#ffd479}@media (min-width:768px){.col-2-equal{display:flex;align-items:stretch;flex-wrap:wrap}.col-2-equal>*{flex:0 0 50%;max-width:50%;overflow:auto}.col-2-equal>:nth-child(even){padding-left:5px}.col-2-equal>:nth-child(odd){padding-right:5px}.col-2-equal>*>code{height:100%}.col-2-equal+h2,.col-2-equal+h3{margin-top:12.375px}}.hsbox{margin-bottom:24.75px;border:1px solid #969696;padding:1rem;border-radius:3px}.hsbox .hs__title{cursor:pointer}.hsbox .hs__title::before{content:" ";display:inline-block;border-top:7px solid transparent;border-bottom:7px solid transparent;border-left:7px solid currentColor;vertical-align:middle;margin-right:.7rem;transform:translateY(-2px);transition:transform .2s ease-out}.hsbox .hs__title.show{padding-bottom:15px;border-bottom:.5px solid #666;margin-bottom:1rem}.hsbox .hs__title.show+.hs__content{display:block;opacity:1;padding:5px 0;transition:all .25s 0s cubic-bezier(.4,0,.2,1)}.hsbox .hs__title.show::before{transform:rotate(90deg) translateX(-3px)}.hsbox .hs__content{display:none;transition:all .2s 0s ease}.hsbox .hs__content>:last-child{margin-bottom:0}blockquote{margin:0;margin-bottom:1.5rem;padding-left:1rem;border-left:5px solid #aaa}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration,input[type=search]::-webkit-search-results-button,input[type=search]::-webkit-search-results-decoration{display:none}.page-note .text-center{text-align:center}.page-note ol,.page-note p,.page-note ul{margin-top:0;margin-bottom:24.75px}.page-note ol li,.page-note ul li,div.toc ol li{margin-bottom:5px}.page-note ol li ol,.page-note ol li ul,.page-note ul li ol,.page-note ul li ul{margin-bottom:5px;padding-left:20px}.page-note ol li>:not(span),.page-note ul li>:not(span){margin-bottom:10px}.page-note p.noindent{display:none;padding-left:20px}.page-note p.noindent+ol,.page-note p.noindent+ul{padding-left:20px;margin-top:0}.page-note p.indent{display:none;padding-left:40px}.page-note ol.indent,.page-note p.indent+ol,.page-note p.indent+ul,.page-note ul.indent{padding-left:40px}.page-note ol.noindent,.page-note ul.noindent{padding-left:20px}.page-note hr{border-bottom:1px solid #676767;margin-bottom:24.75px}.page-note p.katex-block{overflow-x:auto;overflow-y:hidden}.page-note p.katex-block .katex-display{margin:0!important}#reading-list .item .author{font-style:italic}#reading-list .item .intro{color:#999}code[class*=language-],pre[class*=language-]{color:#eee;font-size:16px;text-shadow:none;font-family:Menlo,Monaco,Consolas,"Andale Mono","Ubuntu Mono","Courier New",monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#75a7ca}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}.token.comment{color:#6a9955}.token.punctuation{color:#eee}.token.inserted,.token.number{color:#b5cea8}.token.builtin,.token.string{color:#ce9178}.token.operator{color:#eee}.token.atrule{color:#ce9178}.token.atrule .token.url{color:#9cdcfe}.token.atrule .token.url .token.function{color:#efefac}.token.atrule .token.url .token.punctuation{color:#eee}.token.keyword{color:#90cdff}.token.function{color:#efefac}.token.constant{color:#9cdcfe}.token.class-name{color:#4ec9b0}.token.property,.token.variable{color:#9cdcfe}.token.tag{color:#90cdff}.token.tag .token.punctuation{color:gray}pre[class*=language-]>code[class*=language-]{position:relative;z-index:1}code,pre{font-family:Consolas,Menlo,Monaco,"Andale Mono WT","Andale Mono","Lucida Console","Lucida Sans Typewriter","DejaVu Sans Mono","Bitstream Vera Sans Mono","Liberation Mono","Nimbus Mono L","Courier New",Courier,monospace;line-height:1.5}h2>code{font-size:21.78px!important}h3>code{font-size:18.9486px!important}:not(pre)>code{border:1px solid #444;background:#6b444245;padding:2px 4px;margin:0 1px;border-radius:3px;font-size:.9rem;color:#fff;word-break:break-word}h2>code,h3>code{color:#ddd;padding-right:6px}a>code{color:#ffd479}a:hover>code{color:#ccc}pre,pre[class*=language-]{margin:0 0 27.225px;overflow:auto}pre>code,pre[class*=language-]>code{display:block;padding:14.5px 16.5px 16.5px;background:#2f3240;border:.5px solid #3b3e54;overflow:auto;border-radius:3px;max-height:450px}div.toc{margin-bottom:24.75px;border:1px solid #3b3e54;border-radius:7px;height:fit-content;background:#2f3240;padding:15px 15px 10px 0}div.toc>ol::before{content:"In this note";display:block;padding-bottom:5px;border-bottom:1px solid #555;margin:0 0 15px;font-size:1.18rem;font-family:"Recoleta",Arial,Helvetica,sans-serif}div.toc ol{padding-left:20px;font-size:14.85px;margin-bottom:0}div.toc ol li code{font-size:.85rem;background:#ececec;padding:0 4px 2px}div.toc ol li ol{padding-left:10px;margin-top:7px}div.toc ol,div.toc ol ol{counter-reset:item;list-style-type:none}div.toc ol li::before{content:counters(item,".") ". ";counter-increment:item}div.toc>ol>li ol>li::before{opacity:.7}div.toc>ol>li::before{color:#8cc8ff}@media (min-width:1300px){div.toc{float:right;margin-right:-280px;border-left:none;width:250px;position:-webkit-sticky;position:sticky;top:60px;max-height:70vh;overflow:auto}div.toc ol{margin-top:0;margin-bottom:0}}@media (min-width:1500px){div.toc{margin-right:-310px;width:280px}}.toc-active>a{color:#fff!important}.toc-active::before{opacity:1!important}.page-note img{height:auto;width:100%}.page-note p>img+br{display:none}</style></head><body><header><nav><div id="nav"><a href="/" class="nav-item no-effect"><img alt="home" height="18" src="/img/nav/home.svg" width="18"> <span>Thi</span> </a><a href="/about/" class="nav-item no-effect"><img alt="about" height="15" src="/img/nav/about.svg" width="15"> <span>About</span></a><div class="nav-search" id="nav-search"><form><input aria-label="search notes (press &quot;/&quot; to focus &amp; &quot;ESC&quot; to lose)" class="nav-search__input" id="nav-search__input" onfocusin="inFocus(this)" placeholder="search notes (press &quot;/&quot; to focus &amp; &quot;ESC&quot; to lose)" type="search"></form><div id="nav-search__result-container" style="display: none;"><ul id="nav-search__ul"></ul><div id="nav-search__no-result" style="display: none;"><p>No results found.</p></div></div></div><a href="https://github.com/dinhanhthi" class="nav-item no-effect nav-github" target="_blank"><img alt="github" height="20" src="/img/nav/github.svg" width="20"></a></div><div id="reading-progress" aria-hidden="true"></div></nav><script src="/js/search.js?hash=1aae822ef9" async="" defer=""></script><div class="header-logo"><img alt="Docker + GPUs" height="512" src="/img/header/docker.svg" width="512"></div><h1>Docker + GPUs</h1><div id="more-info"><div id="note-tag"><a href="/tags/mlops">MLOps</a> <a href="/tags/docker">Docker</a></div><div id="last-modified">16-01-2021 / <a href="https://github.com/dinhanhthi/dinhanhthi.com/edit/dev/./posts/deploy-run/2020-10-22-docker-gpu.md">Edit on Github</a></div></div></header><main><article><div class="container mt-2 normal page-note"><div class="toc"><ol><li><a href="#wsl-%2B-windows">WSL + Windows</a></li><li><a href="#with-tensorflow-or-pytorch">With Tensorflow or PyTorch</a></li><li><a href="#basic-installation">Basic installation</a></li><li><a href="#check-info">Check info</a></li><li><a href="#install-nvidia-docker2">Install nvidia-docker2</a></li><li><a href="#difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime">Difference: nvidia-container-toolkit vs nvidia-container-runtime</a></li><li><a href="#using-docker-compose%3F">Using docker-compose?</a></li><li><a href="#check-usage-of-gpu">Check usage of GPU</a><ol><li><a href="#kill-process">Kill process</a></li></ol></li><li><a href="#reset-gpu">Reset GPU</a></li><li><a href="#errors-with-gpu">Errors with GPU</a></li><li><a href="#make-nvidia-work-in-docker-(linux)">Make NVIDIA work in docker (Linux)</a></li><li><a href="#references">References</a></li></ol></div><p>ðŸ‘‰ Note: <a href="/docker">Docker 101</a><br>ðŸ‘‰ Note: <a href="/wordpress-docker">Wordpress Docker</a><br>ðŸ‘‰ Note: <a href="/airflow-k8s-101">Airflow + Kubernetes 101</a><br>ðŸ‘‰ Note: <a href="/tensorflow">Tensorflow extra</a></p><h2 id="wsl-%2B-windows">WSL + Windows <a href="#wsl-%2B-windows" class="direct-link">#</a></h2><p>ðŸ‘‰ Note: <a href="/docker-wsl2-windows/#wsl-%2B-windows">WSL + Windows</a></p><h2 id="with-tensorflow-or-pytorch">With Tensorflow or PyTorch <a href="#with-tensorflow-or-pytorch" class="direct-link">#</a></h2><p>ðŸ‘‰ <a href="https://www.tensorflow.org/install/docker">Official doc for TF + docker</a><br>ðŸ‘‰ Note: <a href="/tensorflow#installation-with-docker">Docker + TF</a>.<br>ðŸ‘‰ <a href="https://github.com/dinhanhthi/git_dataswati/tree/master/docker-thi">An example of docker pytorch with gpu support</a>.</p><h2 id="basic-installation">Basic installation <a href="#basic-installation" class="direct-link">#</a></h2><div class="warning"><p>You have to install (successfully) GPU driver on your (linux) machine before continuing the steps in this note. Go to "<a href="#check-info">Check info</a>" section to check the availability of your drivers.</p></div><p>It works perfectly on Pop!_OS 20.04,</p><pre class="language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update<br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-container-runtime<br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-container-toolkit<br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-cuda-toolkit<br><span class="token comment"># restard required</span></code></pre><h2 id="check-info">Check info <a href="#check-info" class="direct-link">#</a></h2><pre class="language-bash"><code class="language-bash"><span class="token comment"># verify that your computer has a graphic card</span><br>lspci -nn <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'\[03'</span></code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># First, install drivers and check</span><br>nvidia-smi<br><span class="token comment"># output: NVIDIA-SMI 450.80.02 Driver Version: 450.80.02    CUDA Version: 11.0</span><br><span class="token comment"># it's maximum CUDA version that your driver supports</span></code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># check current version of cuda</span><br>nvcc --version<br><span class="token comment"># If there is not nvcc, it may be in /usr/local/cuda/bin/</span><br><span class="token comment"># Add this location to PATH</span><br><span class="token comment"># modify ~/.zshrc or ~/.bashrc</span><br><span class="token builtin class-name">export</span> <span class="token variable assign-left"><span class="token constant environment">PATH</span></span><span class="token operator">=</span>/usr/local/cuda/bin:<span class="token constant environment">$PATH</span><br><br><span class="token comment"># You may need to install</span><br><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> -y nvidia-cuda-toolkit</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># install and check nvidia-docker</span><br>dpkg -l <span class="token operator">|</span> <span class="token function">grep</span> nvidia-docker<br><span class="token comment"># or</span><br>nvidia-docker version</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># Verifying â€“gpus option under docker run</span><br>docker run --help <span class="token operator">|</span> <span class="token function">grep</span> -i gpus<br><span class="token comment"># output: --gpus gpu-request GPU devices to add to the container ('all' to pass all GPUs)</span></code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># Listing out GPU devices</span><br>docker run -it --rm --gpus all ubuntu nvidia-smi -L<br><span class="token comment"># output: GPU 0: GeForce GTX 1650 (...)</span></code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># Verifying again with nvidia-smi</span><br>docker run -it --rm --gpus all ubuntu nvidia-smi</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># test a working setup container-toolkit</span><br>docker run --rm --gpus all nvidia/cuda nvidia-smi</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># test a working setup container-runtime</span><br>docker run --runtime<span class="token operator">=</span>nvidia --rm nvidia/cuda nvidia-smi<br><br><span class="token comment"># Error response from daemon: Unknown runtime specified nvidia.</span><br><span class="token comment"># Search below for "/etc/docker/daemon.json"</span><br><span class="token comment"># Maybe it helps.</span></code></pre><h2 id="install-nvidia-docker2">Install <code>nvidia-docker2</code> <a href="#install-nvidia-docker2" class="direct-link">#</a></h2><div class="hsbox"><div class="hs__title">More information (<a href="https://github.com/NVIDIA/nvidia-docker/issues/1268">ref</a>)</div><div class="hs__content"><blockquote><p>This package is the only docker-specific package of any of them. It takes the script associated with the <code>nvidia-container-runtime</code> and installs it into docker's <code>/etc/docker/daemon.json</code> file for you. This then allows you to run (for example) <code>docker run --runtime=nvidia ...</code> to automatically add GPU support to your containers. It also installs a wrapper script around the native docker CLI called <code>nvidia-docker</code> which lets you invoke docker without needing to specify <code>--runtime=nvidia</code> every single time. It also lets you set an environment variable on the host (NV_GPU) to specify which GPUs should be injected into a container.</p></blockquote></div></div><p>ðŸ‘‰ <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker">Officicial guide to install</a>.</p><pre class="language-bash"><code class="language-bash"><span class="token variable assign-left">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span><br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -<br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/<span class="token variable">$distribution</span>/nvidia-docker.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-docker.list<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> update<br><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y nvidia-docker2<br><br><span class="token comment"># restart docker</span><br><span class="token function">sudo</span> systemctl restart docker</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># check version</span><br>nvidia-docker version</code></pre><h2 id="difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime">Difference: <code>nvidia-container-toolkit</code> vs <code>nvidia-container-runtime</code> <a href="#difference%3A-nvidia-container-toolkit-vs-nvidia-container-runtime" class="direct-link">#</a></h2><p>ðŸ‘‰ <a href="https://github.com/NVIDIA/nvidia-docker/issues/1268">What's the difference between the lastest nvidia-docker and nvidia container runtimeï¼Ÿ</a></p><blockquote><p>In this note, with Docker 19.03+ (<code>docker --version</code>), he says that <code>nvidia-container-toolkit</code> is used for <code>--gpus</code> (in <code>docker run ...</code>), <code>nvidia-container-runtime</code> is used for <code>--runtime=nvidia</code> (can also be used in <code>docker-compose</code> file).</p></blockquote><blockquote><p>However, <mark markdown="span">if you want to use Kubernetes with Docker 19.03, you actually <strong>need to continue using nvidia-docker2</strong></mark> because Kubernetes doesn't support passing GPU information down to docker through the <code>--gpus</code> flag yet. It still relies on the nvidia-container-runtime to pass GPU information down the stack via a set of environment variables.</p></blockquote><p>ðŸ‘‰ <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker">Installation Guide â€” NVIDIA Cloud Native Technologies documentation</a></p><h2 id="using-docker-compose%3F">Using docker-compose? <a href="#using-docker-compose%3F" class="direct-link">#</a></h2><p>Purpose?</p><div class="col-2-equal"><pre class="language-bash"><code class="language-bash"><span class="token comment"># instead of using</span><br>docker run <span class="token punctuation">\</span><br>    --gpus all<span class="token punctuation">\</span><br>    --name docker_thi_test<span class="token punctuation">\</span><br>    --rm<span class="token punctuation">\</span><br>    -v abc:abc<span class="token punctuation">\</span><br>    -p <span class="token number">8888</span>:8888</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># we use this with docker-compose.yml</span><br>docker-compose up</code></pre></div><pre class="language-bash"><code class="language-bash"><span class="token comment"># check version of docker-compose</span><br>docker-compose --version</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># If "version" in docker-compose.yml &lt; 2.3</span><br><span class="token comment"># Modify: /etc/docker/daemon.json</span><br><span class="token punctuation">{</span><br>    <span class="token string">"default-runtime"</span><span class="token builtin class-name">:</span> <span class="token string">"nvidia"</span>,<br>    <span class="token string">"runtimes"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><br>        <span class="token string">"nvidia"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><br>            <span class="token string">"path"</span><span class="token builtin class-name">:</span> <span class="token string">"nvidia-container-runtime"</span>,<br>            <span class="token string">"runtimeArgs"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><br>        <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># restart our docker daemon</span><br><span class="token function">sudo</span> <span class="token function">pkill</span> -SIGHUP dockerd</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># If "version" in docker-compose.yml &gt;=2.3</span><br><span class="token comment"># docker-compose.yml =&gt; able to use "runtime"</span><br>version: <span class="token string">'2.3'</span> <span class="token comment"># MUST BE &gt;=2.3 AND &lt;3</span><br>services:<br>  testing:<br>    ports:<br>      - <span class="token string">"8000:8000"</span><br>    runtime: nvidia<br>    volumes:<br>      - ./object_detection:/object_detection</code></pre><p>ðŸ‘‰ Check more in my repo <a href="https://github.com/dinhanhthi/my-dockerfiles">my-dockerfiles</a> on Github.</p><p>Run the test,</p><pre class="language-bash"><code class="language-bash">docker pull tensorflow/tensorflow:latest-gpu-jupyter<br><span class="token function">mkdir</span> ~/Downloads/test/notebooks</code></pre><p>Without using <code>docker-compose.yml</code> (tensorflow) (cf. <a href="/tensorflow#without-docker-compose">this note</a> for more)</p><pre class="language-bash"><code class="language-bash">docker run --name docker_thi_test -it --rm -v <span class="token variable"><span class="token variable">$(</span>realpath ~/Downloads/test/notebooks<span class="token variable">)</span></span>:/tf/notebooks -p <span class="token number">8888</span>:8888 tensorflow/tensorflow:latest-gpu-jupyter</code></pre><p>With <code>docker-compose.yml</code>?</p><pre class="language-bash"><code class="language-bash"><span class="token comment"># ~/Download/test/Dockerfile</span><br>FROM tensorflow/tensorflow:latest-gpu-jupyter</code></pre><pre class="language-yaml"><code class="language-yaml"><span class="token comment"># ~/Download/test/docker-compose.yml</span><br><span class="token atrule key">version</span><span class="token punctuation">:</span> <span class="token string">'2'</span><br><span class="token atrule key">services</span><span class="token punctuation">:</span><br>  <span class="token atrule key">jupyter</span><span class="token punctuation">:</span><br>    <span class="token atrule key">container_name</span><span class="token punctuation">:</span> <span class="token string">'docker_thi_test'</span><br>    <span class="token atrule key">build</span><span class="token punctuation">:</span> .<br>    <span class="token atrule key">volumes</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> ./notebooks<span class="token punctuation">:</span>/tf/notebooks <span class="token comment"># notebook directory</span><br>    <span class="token atrule key">ports</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> 8888<span class="token punctuation">:</span><span class="token number">8888</span> <span class="token comment"># exposed port for jupyter</span><br>    <span class="token atrule key">environment</span><span class="token punctuation">:</span><br>        <span class="token punctuation">-</span> NVIDIA_VISIBLE_DEVICES=0 <span class="token comment"># which gpu do you want to use for this container</span><br>        <span class="token punctuation">-</span> PASSWORD=12345</code></pre><p>Then run,</p><pre class="language-bash"><code class="language-bash">docker-compose run --rm jupyter</code></pre><h2 id="check-usage-of-gpu">Check usage of GPU <a href="#check-usage-of-gpu" class="direct-link">#</a></h2><pre class="language-bash"><code class="language-bash"><span class="token comment"># Linux only</span><br>nvidia-smi<br><br><span class="token comment"># |===============================+======================+======================|</span><br><span class="token comment"># |   0  GeForce GTX 1650    Off  | 00000000:01:00.0 Off |                  N/A |</span><br><span class="token comment"># | N/A   53C    P8     2W /  N/A |   3861MiB /  3914MiB |      2%      Default |</span><br><span class="token comment"># |                               |                      |                  N/A |</span><br><span class="token comment"># +-------------------------------+----------------------+----------------------+</span><br><br><span class="token comment"># =&gt; 3861MB / 3914MB is used!</span><br><br><span class="token comment"># +-----------------------------------------------------------------------------+</span><br><span class="token comment"># | Processes:                                                       GPU Memory |</span><br><span class="token comment"># |  GPU       PID   Type   Process name                             Usage      |</span><br><span class="token comment"># |=============================================================================|</span><br><span class="token comment"># |    0      3019      C   ...e/scarter/anaconda3/envs/tf1/bin/python  3812MiB |</span><br><span class="token comment"># +-----------------------------------------------------------------------------+</span><br><br><span class="token comment"># =&gt; Process 3019 is using the GPU</span></code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># All processes that use GPU</span><br><span class="token function">sudo</span> <span class="token function">fuser</span> -v /dev/nvidia*</code></pre><h3 id="kill-process">Kill process <a href="#kill-process" class="direct-link">#</a></h3><pre class="language-bash"><code class="language-bash"><span class="token comment"># Kill a single process</span><br><span class="token function">sudo</span> <span class="token function">kill</span> -9 <span class="token number">3019</span></code></pre><h2 id="reset-gpu">Reset GPU <a href="#reset-gpu" class="direct-link">#</a></h2><div class="col-2-equal"><pre class="language-bash"><code class="language-bash"><span class="token comment"># all</span><br><span class="token function">sudo</span> nvidia-smi --gpu-reset</code></pre><pre class="language-bash"><code class="language-bash"><span class="token comment"># single</span><br><span class="token function">sudo</span> nvidia-smi --gpu-reset -i <span class="token number">0</span></code></pre></div><h2 id="errors-with-gpu">Errors with GPU <a href="#errors-with-gpu" class="direct-link">#</a></h2><pre class="language-bash"><code class="language-bash"><span class="token comment"># Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.</span><br><span class="token comment"># Function call stack:</span><br><span class="token comment"># train_function</span></code></pre><p>Check <a href="https://stackoverflow.com/a/56511889/1323473">this answer</a> as a reference!</p><h2 id="make-nvidia-work-in-docker-(linux)">Make NVIDIA work in docker (Linux) <a href="#make-nvidia-work-in-docker-(linux)" class="direct-link">#</a></h2><div class="danger"><p>This section is still working (on 26-Oct-2020) but it's old for newer methods.</p></div><p><strong>Idea</strong>: Using NVIDIA driver of the base machine, don't install anything in docker!</p><div class="hsbox"><div class="hs__title">Detail of steps</div><div class="hs__content"><p class="noindent"></p><ol><li><p>First, <a href="/pytorch#installation">maker sure</a> your base machine has an NVIDIA driver.</p><pre class="language-bash"><code class="language-bash"><span class="token comment"># list all gpus</span><br>lspci -nn <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'\[03'</span><br><br><span class="token comment"># check nvidia &amp; cuda versions</span><br>nvidia-smi</code></pre></li><li><p>Install <a href="https://github.com/NVIDIA/nvidia-container-runtime"><code>nvidia-container-runtime</code></a></p><pre class="language-bash"><code class="language-bash"><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -<br><span class="token variable assign-left">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span><br><br><span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-container-runtime/<span class="token variable">$distribution</span>/nvidia-container-runtime.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-container-runtime.list<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> update<br><br><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nvidia-container-runtime</code></pre></li><li><p>Note that, <mark markdown="span">we cannot use <code>docker-compose.yml</code> in this case!!!</mark></p></li><li><p>Create an image <code>img_datas</code> with <code>Dockerfile</code> is</p><pre class="language-docker"><code class="language-docker"><span class="token keyword">FROM</span> nvidia/cuda<span class="token punctuation">:</span>10.2<span class="token punctuation">-</span>base<br><br><span class="token keyword">RUN</span> apt<span class="token punctuation">-</span>get update &amp;&amp; \<br>	apt<span class="token punctuation">-</span>get <span class="token punctuation">-</span>y upgrade &amp;&amp; \<br>	apt<span class="token punctuation">-</span>get install <span class="token punctuation">-</span>y python3<span class="token punctuation">-</span>pip python3<span class="token punctuation">-</span>dev locales git<br><br><span class="token comment"># install dependencies</span><br><span class="token keyword">COPY</span> requirements.txt requirements.txt<br><span class="token keyword">RUN</span> python3 <span class="token punctuation">-</span>m pip install <span class="token punctuation">-</span><span class="token punctuation">-</span>upgrade pip &amp;&amp; \<br>	python3 <span class="token punctuation">-</span>m pip install <span class="token punctuation">-</span>r requirements.txt<br><span class="token keyword">COPY</span> . .<br><br><span class="token comment"># default command</span><br><span class="token keyword">CMD</span> <span class="token punctuation">[</span> <span class="token string">"jupyter"</span><span class="token punctuation">,</span> <span class="token string">"lab"</span><span class="token punctuation">,</span> <span class="token string">"--no-browser"</span><span class="token punctuation">,</span> <span class="token string">"--allow-root"</span><span class="token punctuation">,</span> <span class="token string">"--ip=0.0.0.0"</span>  <span class="token punctuation">]</span></code></pre></li><li><p>Create a container,</p><pre class="language-bash"><code class="language-bash">docker run --name docker_thi --gpus all -v /home/thi/folder_1/:/srv/folder_1/ -v /home/thi/folder_1/git/:/srv/folder_2 -dp <span class="token number">8888</span>:8888 -w<span class="token operator">=</span><span class="token string">"/srv"</span> -it img_datas<br><br><span class="token comment"># -v: volumes</span><br><span class="token comment"># -w: working dir</span><br><span class="token comment"># --gpus all: using all gpus on base machine</span></code></pre></li></ol><p><a href="https://towardsdatascience.com/how-to-properly-use-the-gpu-within-a-docker-container-4c699c78c6d1">This article</a> is also very interesting and helpful in some cases.</p></div></div><h2 id="references">References <a href="#references" class="direct-link">#</a></h2><ol><li><a href="https://github.com/NVIDIA/nvidia-docker/wiki/CUDA">Difference between <code>base</code>, <code>runtime</code> and <code>devel</code> in <code>Dockerfile</code> of CUDA</a>.</li><li><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles/dockerfiles">Dockerfile on Github</a> of Tensorflow.</li></ol></div><script type="application/ld+json">{
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "Docker + GPUs",
        "image": [],
        "author": "Anh-Thi DINH",
        "genre": "Insert a schema.org genre",
        "url": "https://dinhanhthi.com/docker-gpu/",
        "mainEntityOfPage": "https://dinhanhthi.com/docker-gpu/",
        "datePublished": "21-10-2020",
        "dateModified": "16-01-2021",
        "description": "ðŸ‘‰ Note: Docker 101 ðŸ‘‰ Note: Wordpress Docker ðŸ‘‰ Note: Airflow + Kubernetes 101 ðŸ‘‰ Note: Tensorflow extra WSL + Windows # ðŸ‘‰ Note: WSL +..."
      }</script></article></main><footer><a href="/" target="_blank">Thi &nbsp;Â©&nbsp; 2021 </a>&nbsp;â€¢&nbsp; <a href="/about-the-notes/">About the notes </a>&nbsp;â€¢&nbsp; <a href="/about/">About me </a>&nbsp;â€¢&nbsp; <a href="https://photos.app.goo.gl/9OVEkdTjmtRPg7vC3" target="_blank">My sketches </a>&nbsp;â€¢&nbsp; <a href="https://goo.gl/photos/yQXdQws1LLS16x5v5" target="_blank">My cooking </a>&nbsp;â€¢&nbsp; <a href="/for-me-only/">For me only </a>&nbsp;â€¢&nbsp; <a href="/donate/">Support Thi</a></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/elasticlunr/0.9.6/elasticlunr.min.js"></script><script src="https://www.googletagmanager.com/gtag/js?id=G-K3YRSB918B" async=""></script><script>window.dataLayer = window.dataLayer || [];
		function gtag() {
			dataLayer.push(arguments);
		}
		gtag('js', new Date());
		gtag('config', 'G-K3YRSB918B');</script><script src="/js/min.js?hash=410580648a" async="" defer=""></script></body></html>