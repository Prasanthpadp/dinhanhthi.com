{"version":"0.9.5","fields":["title","keywords","tags"],"ref":"id","documentStore":{"docs":{"/css-tips/":{"id":"/css-tips/","title":"CSS extra","keywords":"for loop in css scss sass tool flat ui color space gradient contrast different compass watch folder convert wordpress fontawesome font awesome css free version 5 CSS Pseudo-elements html character reference style.css style.css wordpress auto convert watch gulp ruby compass difference px pixel em rem percentage % numberfing heading scss mixin function loop programming with css","tags":["posts","Web Dev"],"cat":"/img/cats/web-dev.svg","content":"Tools #\n\nFlat UI Color: Choose different contrast colors\nColor Space: make gradient colors.\nCSS Gradient: make gradient background.\n\npx vs em vs rem vs % #\n\npx: not responsive.\nem: flexible + scalable + translated to px.\n\nRelative to element on which it's used.\n1em = 16px (default font-size Google Chrome)\nUsed for: headings, paragraphs, texts, elements related to typography (padding, margin).\n\n\nrem: flexible + scalable + translated to px.\n\nRelative to root HTML's font size.\nChange root font size -&gt; change the hold project.\n\n\n%: relative to another component.\n\nUsed for height, width properties.\n\n\n\nAutomatically watch and convert scss to css #\nEasy: if you use VSC #\n\n\nInstall extension Live Sass Compiler\n\n\nOpen settings and add following,\n\"liveSassCompile.settings.formats\": [ { \"format\": \"expanded\", \"extensionName\": \".css\", \"savePath\": \"/\", }],\n\n\nClick on &quot;Watch Sass&quot; at the bottom line of VSC.\n\n\nEverytime you save or make some changes on /sass/style.scss, /style.css will be automatically updated.\n\n\nAny scss file to css file #\nUsing gulp,\nnpm install gulp-cli -gnpm install gulp -Dnpx -p touch nodetouch gulpfile.jsgulp --help# then usesass --watch &lt;scss folder>:&lt;css folder>\nstyle.scss to style.css #\n\n\nInstall ruby.\n\n\nUpdate ruby (if you installed it before) and install compass,\ngem update --systemgem install compass\n\n\ncd to the current working theme.\n\n\nCreate a folder named sass in the root of this theme.\n\n\nCreate a file config.rb which contains below codes, this file is for compass\nhttp_path = \"/\" #root level target pathcss_dir = \".\" #targets our default style.css file at the root level of our themesass_dir = \"sass\" #targets our sass directoryimages_dir = \"images\" #targets our pre existing image directoryjavascripts_dir = \"js\" #targets our JavaScript directory## You can select your preferred output style here (can be overridden via the command line):# output_style = :expanded or :nested or :compact or :compressed## To enable relative paths to assets via compass helper functions.# note: this is important in wordpress themes for sprites#relative_assets = true\n\n\nInside folder sass, create a folder named _partials, all partial scss files will be located in this folder. For example, we use _font.scss to store all styles relating to font for the theme.\n\n\nInside folder sass, create a file named style.scss, after every modification, this file will be generated by compass and overwirte the style.css file in the root theme folder. In the content of this file, you place,\n@import \"compass\";@import \"_partials/font\";\n\n\nUse terminal and run following command (suppose that you are already in the theme folder). From this step, everytime you modify style.scss or files in _partials folder, the compass will automatically update the changes and overwrite to the style.css file in root theme folder.\ncompass watch\n\n\nUsing FontAwesome 5 in CSS #\n👉 Official doc.\n.login::before { content: \"\\f007\"; font-family: \"Font Awesome 5 Free\"; font-weight: 900;}\nHeading numbering #\n// don't count h1, from h2 onlybody{counter-reset: h2counter;}.post-content{ h1 {counter-reset: h2counter;} h2 {counter-reset: h3counter;} h3 {counter-reset: h4counter;} h2:before { content: counter(h2counter) \".\\0000a0\\0000a0\"; counter-increment: h2counter;} h3:before { content: counter(h2counter) \".\" counter(h3counter) \".\\0000a0\\0000a0\"; counter-increment: h3counter;} h4:before { content: counter(h2counter) \".\" counter(h3counter) \".\" counter(h4counter) \".\\0000a0\\0000a0\"; counter-increment: h4counter;}}\nTOC numbering #\n.post-content{ counter-reset: item; list-style-type: none; ol { counter-reset: item; list-style-type: none;} li { &amp;::before { content: counters(item, \".\") \". \"; counter-increment: item;}}}\nSCSS / SASS #\n👉 Official references.\nLoop #\n$imgage-sizes: 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100;@each $size in $imgage-sizes{ .img-full-#{$size}{ width: $size/100*100%; }}\nMixin (function) #\n\n@mixin column-count($ncol) {\tcolumn-count: $ncol;\t-webkit-column-count: $ncol;\t-moz-column-count: $ncol;\t-moz-column-count: $ncol;}\n// usage.custom{ @include column-count(3);}\n\n"},"/good-repositories/":{"id":"/good-repositories/","title":"Favorite Github repositories","keywords":"repository github git","tags":["posts","Others","Collection"],"cat":"/img/cats/others.svg","content":"\nThis note will always be updated.\n\nMachine Learning #\n\nhomemade-machine-learning -- If you don't wanna apply tools and understand nothing, you can write &quot;again&quot; from scratch with this repository.\n100-Days-Of-ML-Code -- Learn ML day by day.\n\nData Science #\n\nfaker -- Faker is a Python package that generates fake data for you.\nawesome-datascience -- An awesome Data Science repository to learn and apply for real world problems.\nData Cheatsheets -- List of Data Science Cheatsheets to rule the world.\n\nWeb Development #\n\nnodebestpractices -- The largest Node.js best practices list.\njavascript-algorithms -- Algorithms and data structures implemented in JavaScript with explanations and links to further readings.\n\nCoding #\n\n30-seconds-of-code -- A curated collection of useful JavaScript snippets that you can understand in 30 seconds or less.\n30-seconds -- The team behind 30-seconds-of-code and official 30-seconds projects.\nLearn to Code -- Resources to help people learn to code.\nThe Algorithms - Python -- All Algorithms implemented in Python (for education).\ngitignore -- A collection of useful .gitignore templates.\n\nOthers #\n\ninterviews -- Everything you need to know to get the job.\ntech-interview-handbook -- Algorithms study materials, behavioral content and tips for rocking your coding interview.\nawesome-interview-questions -- A curated awesome list of lists of interview questions!\n120-Data-Science-Interview-Questions -- Answers to 120 commonly asked data science interview questions.\nawesome -- Awesome lists about all kinds of interesting topics.\n\n"},"/setting-up-a-cafe-in-hcmc/":{"id":"/setting-up-a-cafe-in-hcmc/","title":"Setting up a café in Ho Chi Minh City","keywords":"IBM applied data science capstone Coursera List of Ho Chi Minh City administrative units coordinates (latitude, longitude) housing price coffee json file Housing Sales Price Index hcmc OpenStreetMap geopy.geocoders.Nominatim folium district data preprocessing K-Mean clustering elbow method","tags":["posts","Project-based Learning"],"cat":"/img/cats/project.svg","content":"This is the final project for the course &quot;Applied Data Science Capstone&quot; given by IBM on Coursera. We will explore the venues in Pdifferent districts of Ho Chi Minh City to find the best place to set up our business.\nhtml file -- open in colab -- full report\n\nData presentation #\nIn order to explore the previous questions, we need to use the following data in the research.\n\n\nList of Ho Chi Minh City administrative units from Wikipedia.\nList of the coordinates (latitude, longitude) of all urban districts in HCMC. This list can be generated based on the name of each district and package geopy.geocoders.Nominatim.\nList of average housing prices per m2m^2m2 in HCMC.\nA .json file contains all coordinates where we use it to create a choropleth map of Housing Sales Price Index of HCMC. I create this file by myself using OpenStreetMap.\n\nMethodology (TL;DR;) #\n\nGet the data:\n\nScrape the data from a website using requests and bs4.BeautifulSoup: data of districts (df_hcm) and data of housing price (df_housing_price).\nUsing geopy.geocoders.Nominatim to find coordinates (longitude, latitude) of districts based on their name.\n\n\nUsing folium to plot the map.\nUsing Foursquare API to find the venues of each district.\nExplore the venues in each district:\n\nList of unique categories.\nNumber of venues in each district.\nNumber of venues in each category.\nNumber of categories in each district.\n\n\nData preprocessing:\n\nRemove all , in a number.\nCreate new feature called Density which is the population over area.\nRemove word District and only keep the name of that district.\nRemove Vietnamese accents.\nMerge 2 dataframes into 1 df.\nUsing pd.get_dummies() to convert categorical features into dummy ones (one-hot encoding).\n\n\nUsing groupby to find the top 10 venue categories for each district.\nUsing K-Means clustering to cluster districts by category. We try with different values of k and use the &quot;elbow&quot; method to choose the best k for the K-Means.\nNext, we examine the range of Average Housing Price (AHP): low, medium, high and very high.\nFinally, based on the map, we can choose the best district to set up our business: the one in which there are a lot of people living there (high density), there are not many already-working café and the average housing price is low.\n\n"},"/confusion-matrix-and-f1-score/":{"id":"/confusion-matrix-and-f1-score/","title":"Confusion matrix & f1-score","keywords":"true false negative positive type i type ii error precision recall f1 score email spam bank transaction is fraudulent skewed class accuracy specificity prediction support ROC curve machine learning crash course google developers Koo Ping Shung Marco Altini Salma Ghoneim Towards Data Science NLP blog Sensitivity precision recall curve ROC curve receiver operating characteristic","tags":["posts","Machine Learning"],"cat":"/img/cats/ml.svg","content":"Confusion matrix #\n\n\n\n\nactual (yes)\nactual (no)\n\n\n\n\npredict (yes)\nTP\nFP\n\n\npredict (no)\nFN\nTN\n\n\n\n\n\n\nTrue Positive (TP): what we predict Positive is really Positive.\nTrue Negative (FN): what we predict Negative is really Negative.\nFalse Negative (FN): what we predict Negative is actually Positive.\nFalse Positive (FP): what we predict Positive is actually Negative.\n\n\n\nThis guy is pregnant?\n\nHow to remember? #\n\nTrue/False indicates what we predicted is right/wrong.\nPositive/Negative is what we predicted (yes or no).\n\nType I / Type II errors #\n\nFP = Type I error = rejection of true null hypothesis = negative results are predicted wrongly = what we predict positive is actually negative.\nFN = Type II error = non-rejection of a false null hypothesis = positive results are predicted wrongly = what we predict negative are actually positive.\n\nWhy CM is important? #\nGive a general view about our model, &quot;is it really good?&quot; thanks to precision and recall!\nPrecision &amp; Recall #\n\n\n\n\n\nactual (yes)\nactual (no)\n\n\n\n\n\npredict (yes)\nTP\nFP\nPrecision\n\n\npredict (no)\nFN\nTN\n\n\n\n\nRecall\n\n\n\n\n\n\n\nPrecision: How many of our positive predictions are really true? (Check the accuracy of our positive predictions).\nprecision=true positivepositively predicted results=TPTP+FP.\\mathrm {precision}= \\dfrac{\\mathrm{true\\, positive}}{\\mathrm{positively\\, predicted\\, results}}= \\dfrac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}.\nprecision=positivelypredictedresultstruepositive​=TP+FPTP​.\n\n\nRecall: How many of positive results belong to our predictions? (Do we miss some negative predictions?)\nrecall=true positivepositively actual results=TPTP+FN.\\mathrm {recall}= \\dfrac{\\mathrm{true\\, positive}}{\\mathrm{positively\\, actual\\, results}}= \\dfrac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}.\nrecall=positivelyactualresultstruepositive​=TP+FNTP​.\n\n\n\nRecognizing number 5. Figure taken from this book.\nWhen to use? #\n\nPrecision is importantly used when the &quot;wrongly predicted yes&quot; (FP) influences much (e.g. This email is spam? -- results yes but actually no and we lost important emails!).\nRecall (Sensitivity) is importantly used when the &quot;wrongly predicted no&quot; (FN) influences much (e.g. In the banking industry, this transaction is fraudulent? -- results no but actually yes and we lost money!).\n\nPrecision / Recall curve #\nWith thresholds, we can use precision_recall_curve() to compute precision and recall for all possible thresholds,\n\nAn example of Precision/Recall curve with many thresholds. Figure taken from this book.\nTrace-off: Higher precision, lower recall and vice versa.\nfrom sklearn.metrics import precision_recall_curveprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")plt.show()\nF1-Score #\nHigh precision and low recall or vice versa? F1-Score gives us a balance between precision and recall.\nf1=(recall−1+precision−12)−1=2×precision⋅recallprecision+recall.f_1 = \\left({\\frac {\\mathrm {recall} ^{-1}+\\mathrm {precision} ^{-1}}{2}}\\right)^{-1}=2\\times {\\frac {\\mathrm {precision} \\cdot \\mathrm {recall} }{\\mathrm {precision} +\\mathrm {recall} }}.\nf1​=(2recall−1+precision−1​)−1=2×precision+recallprecision⋅recall​.\nF1-score depends on how we label the class &quot;positive&quot;. This email is spam? is very different from This email is not spam?\nWhen to use F1-Score? #\n\nWhen you need a balance between precision and recall.\nWhen we have a &quot;skewed class&quot; problem (uneven class distribution, too many &quot;yes&quot; and very few &quot;no&quot;, for example).\nOne of precision and recall is improved but the other changes too much, then f1-score will be very small!\n\nHow to choose f1-score value? #\nNormally, f1∈(0,1]f_1\\in (0,1]f1​∈(0,1] and it gets the higher values, the better our model is.\n\nThe best one (f1=1f_1=1f1​=1), both precision and recall get 100%100\\%100%.\nOne of precision and recall gets very small value (close to 0), f1f_1f1​ is very small, our model is not good!\n\nWhat if we prefer one of precision and recall than the other? We consider fβf_{\\beta}fβ​[ref]\nfβ=(1+β2)precision⋅recallβ2⋅precision+recallf_{\\beta} = ( 1 + \\beta^2)\\frac{\\text{precision}\\cdot\\text{recall}}{\\beta^2\\cdot\\text{precision} + \\text{recall}}\nfβ​=(1+β2)β2⋅precision+recallprecision⋅recall​\nf1f_1f1​ is a special case of fβf_{\\beta}fβ​ when β=1\\beta=1β=1:\n\nWhen precision is more important than recall, we choose β&lt;1\\beta &lt; 1β&lt;1 (usually choose β=0.5\\beta=0.5β=0.5).\nWhen recall is more important than precision, we choose β&gt;1\\beta &gt; 1β&gt;1 (usually choose β=2\\beta=2β=2).\n\nAccuracy / Specificity #\n\n\nAccuracy: How accurate our predictions to the whole predictions?\naccuracy=TP+TNTP+TN+FP+FN\\mathrm{accuracy} = \\dfrac{TP + TN}{TP + TN + FP + FN}\naccuracy=TP+TN+FP+FNTP+TN​\n\n\nSpecificity: How many negative results belong to our predictions?\nspecificity=TNFP+TN\\mathrm{specificity} = \\dfrac{TN}{FP + TN}\nspecificity=FP+TNTN​\n\n\nWhen to use? #\n\nAccuaracy is used when we have symmetric datasets.\nSpecificity is used when we care about TN values and don't want to make false alarms of the FP values (e.g. drug test).\n\nThe ROC Curve #\n\nROC = Receiver operating characteristic.\nA common tool used with binary classifier.\nDiffrent from precision/recall curve, ROC plots the true positive rate (recall) against the false positive rate (1 - specificity).\n\n\nThis ROC curve plots FPR vs TPR for all possible thresholds. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that lines as possible (toward the top-left corner). Figure taken from this book.\nTrade-off: the higher recall, the more FPR (predict wrong) the classifier produces.\nfrom sklearn.metrics import roc_curveimport matplotlib.pyplot as plt%matplotlib inlinefpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)# create plotplt.plot(fpr, tpr, label='ROC curve')plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonalplt.show()\nThe AUC #\n\nAUC = Area under the curve.\nPerfect classifier will have AUC = 1 (fix the rectangle).\nThe purely random classifier (dotted line) will have AUC = 0.5.\n\nConfusion Matrix &amp; F1-Score with Scikit-learn #\nfrom sklearn.metrics import confusion_matrixn_classes = target.shape[0]confusion_matrix(y_true, y_pred, labels=range(n_classes))\nPrecision / Reacall / f1-score / support\nfrom sklearn.metrics import classification_reportclassification_report(y_test, y_pred)\nReferences #\n\nClassification: Precision and Recall - Google Developers, Machine Learning Crash Course.\nClassification: Check Your Understanding (Accuracy, Precision, Recall) - Google Developers, Machine Learning Crash Course.\nF-measure versus Accuracy - NLP blog.\nAccuracy, Precision, Recall or F1? - Koo Ping Shung, Towards Data Science.\nDealing with Imbalanced data: undersampling, oversampling and proper cross-validation - Marco Altini.\nAccuracy, Recall, Precision, F-Score &amp; Specificity, which to optimize on? - Salma Ghoneim, Towards Data Science.\n\n"},"/js-tips/":{"id":"/js-tips/","title":"JavaScript extra","keywords":"automatically reload page mathjax anchor link fixed navigation header hover links back to top button zoom enlarge photo js prevent default event keyboard arrow","tags":["posts","JavaScript"],"cat":"/img/cats/js.svg","content":"Automatically reload page if js file changes #\n\nInstall nodejs.\nInstall live-server using nodejs: npm install -g live-server.\ncd to the project folder.\nrun live-server (accept all networks notification)\nBrowse: http://127.0.0.1:8080\nEnjoy!\n\n\nIt may not reload the browser (it only detects the changes)!\n\nAdd MathJax to website #\n👉 Check the codes.\nAnchor links hidden by fixed navigation #\nIf you use table of content for posts in which links starting with # link to headings. After jumping, headings are usually hidden by the fixed navigation. Adding below script before &lt;/body&gt; tag can solve the problem (change value 100 to change where the page jump).[ref]\n👉 Check the codes.\nHeading hover anchor links #\n👉 Check the codes.[ref]\nBack to top button #\nClick and go back to the top of the page using javascript with smooth effect.\n👉 Check the codes.\nHide / Show box #\nAuto hide / show the next div of the current clicked div.\n👉 Check the codes.\nAdvantage: We don't need the id of content div, this method requires that div.hs__content comes right after div.hs__title, otherwise it won't work!\nClick to enlarge photo #\nIf some photos on your page are too small and you wanna add a function in that users can click on the photo to enlarge it. This technique requires Bootstrap 4.\n👉 Check the codes.\nPrevent default event #\nStop arrow key acts as usual,\nwindow.addEventListener(\"keydown\", function(e) {\t// space and arrow keys\tif([32, 37, 38, 39, 40].indexOf(e.keyCode) > -1) {\t\te.preventDefault();\t}}, false);\nIf div_1 inside div_2, prevent actions in div_2 when performs on div_1 (check this example), use e.stopPropagation().\nSearch + result + navigation #\n\nAuto close the result if losing focus.\nCicling the result items with arrow up/down keys.\nAuto focus to the a tag of the title.\n\n👉 Check the codes.\n"},"/random-forest/":{"id":"/random-forest/","title":"Random Forest","keywords":"decision tree ensemble learning votes from the trees relatively uncorrelated bagging Feature randomness entropy imbalanced classes feature importance Tony Yiu The Yhat Blog Chris Albon fast.ai","tags":["posts","Machine Learning"],"cat":"/img/cats/ml.svg","content":"What's the idea of Random Forest? #\nRandom forest consists a (large) number of decision trees operating together (ensemble learning). The class with the most votes from the trees will be chosen as the final result of the RF's prediction. These decision tree models are relatively uncorrelated so that they can protect each other from their individual errors.\n\nAn illustration of the random forest's idea.\nWhat is Ensemble Learning?Ensemble learning involves the combination of several models to solve a single prediction problem. It works by generating multiple classifiers/models which learn and make predictions independently. Those predictions are then combined into a single (mega) prediction that should be as good or better than the prediction made by any one classifer.[ref]\n\n❓ How (decision) trees are chosen? RF ensures that the chosen trees are not too correlated to the others.\n\nBagging: From a sample of size N, trees are chosen so that they also have size N with replacement. For example, if our training data was [1, 2, 3, 4, 5] (size 5), then we might give one of our tree the list [1, 2, 2, 5, 5] (with replacement).\nFeature randomness: The features in the original dataset are chosen randomly. There may be some trees that are lacking in some features.\n\nSo in our random forest, we end up with trees that are not only trained on different sets of data (thanks to bagging) but also use different features to make decisions[ref].\nFor each tree, we can use decision tree classifier or decision tree regression depending on the type our problem (classification or regression).\nWhen we use Random Forest? #\n\nDecision tree algorithms easily lead to overfitting problems. Random forest algorithm can overcome this.\nCapable of both regression and classification problems.\nHandle a large number of features.\nEstimating which features are important in the underlying data being modeled[ref].\nRandom forest is capable of learning without carefully crafted data transformations[ref].\nOutput probabilities for classification problems.\n\nUsing RF with Scikit-learn #\nRandom forest classifier #\nLoad the library,\nfrom sklearn.ensemble import RandomForestClassifier\nA sample dataset:\niris = datasets.load_iris() # iris flowersX = iris.datay = iris.target\nCreate RF classifier(other parameters),\nclf = RandomForestClassifier(criterion='entropy', # default is 'gini' n_estimators=8, # number of trees (default=10) n_jobs=-1) # number of processors being used (\"-1\" means \"all\")\n\nIf a problem has imbalanced classes, use class_weight=&quot;balanced&quot;.[ref]\n\nTraining &amp; predict (other methods),\nmodel = clf.fit(X, y)model.predict([[ 5, 4, 3, 2]]) # returns: array([1])model.predict_proba([[ 5, 4, 3, 2]]) # predict class probabilities\nRandom forest regression #\n# load librariesfrom sklearn.ensemble import RandomForestRegressorfrom sklearn import datasets\n# sample: Boston Housing Databoston = datasets.load_boston()X = boston.data[:,0:2]y = boston.target\n# trainregr = RandomForestRegressor(random_state=0, n_jobs=-1)model = regr.fit(X, y)\n# predictmodel.predict(&lt;something>)\nSelect important features in Random Forest #\nSome premilinaries,\nfrom sklearn.ensemble import RandomForestClassifier# Load datairis = datasets.load_iris()X = iris.datay = iris.target# create a RF classifierclf = RandomForestClassifier(random_state=0, n_jobs=-1)\nSelect feature importance[ref],\n# Train modelmodel = clf.fit(X, y)# Calculate feature importancesimportances = model.feature_importances_# load additional packagesimport numpy as npimport matplotlib.pyplot as plt\nVisualize,\n\n# Sort feature importances in descending orderindices = np.argsort(importances)[::-1]# Rearrange feature names so they match the sorted feature importancesnames = [iris.feature_names[i] for i in indices]plt.figure()plt.title(\"Feature Importance\")plt.bar(range(X.shape[1]), importances[indices])plt.xticks(range(X.shape[1]), names, rotation=90)plt.show()\n\n\nSelect features with importance greater than a threshold,[ref]\nfrom sklearn.feature_selection import SelectFromModel# Create object that selects features with importance greater than or equal to a thresholdselector = SelectFromModel(clf, threshold=0.3)# Feature new feature matrix using selectorX_important = selector.fit_transform(X, y)# Train random forest using most important featuresmodel = clf.fit(X_important, y)\nReferences #\n\nTony Yiu -- Understanding Random Forest.\nScikit-learn -- Random Forest CLassifier official doc.\nScikit-learn -- Random Forest Regression official doc.\nChris Albon -- Titanic Competition With Random Forest.\nThe Yhat Blog -- Random Forests in Python.\nfast.ai -- Introduction to Random Forest and a solution to &quot;Bull Book for Bulldozers&quot; problem on Kaggle.\n\n"},"/decision-tree-classifier/":{"id":"/decision-tree-classifier/","title":"Decision Tree Classifier","keywords":"classification regression outlook temperature huminity windy play golf Iterative Dichotomiser (ID3) CART (Classification And Regression Tree) information gain entropy Gini impurity root node branch child node internal node splitting pruning parent node sub nodes stopping condition gini gain Highly interpretable irrelevant features Non-parametric tuning unbalanced Graphviz Saed Sayad Tiep Vu Brian Ambielli Aurélien Géron","tags":["posts","Machine Learning","Classification"],"cat":"/img/cats/ml.svg","content":"What's the idea of Decision Tree Classifier? #\nThe basic intuition behind a decision tree is to map out all possible decision paths in the form of a tree. It can be used for classification and regression (note). In this post, let's try to understand the classifier.\nSuppose that we have a dataset SSS like in the figure below[ref, Table 1.2],\n\n\nAn example of dataset SSS.\n\nA decision tree we want.\n\nThere are many algorithms which can help us make a tree like above, in Machine Learning, we usually use:\n\n\nID3 (Iterative Dichotomiser): uses information gain / entropy.\nCART (Classification And Regression Tree): uses Gini impurity.\n\nSome basic concepts #\n\n\nSplitting: It is a process of dividing a node into two or more sub-nodes.\nPruning: When we remove sub-nodes of a decision node, this process is called pruning.\nParent node and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node.\n\nID3 algorithm #\nID3 algorithm (TL;DR;)\n\nTo check the disorder at current node (let's say SSS, parent node), we calculate its entropy with,\nH(S)=−∑i=12pS,ilog⁡2pS,i,H(S) = -\\sum_{i=1}^{2} p_{S,i} \\log_2 p_{S,i},\nH(S)=−i=1∑2​pS,i​log2​pS,i​,\nwhere i∈i \\ini∈ the number of classes and pS,ip_{S,i}pS,i​ is the probability of class iii in SSS.\n\n\nIf entropy at this node is pure (there is only 1 class or the majority is 1 class) or it meets the stopping conditions, we stop splitting at this node. Otherwise, go to the next step.\n\n\nCalculate the information gain (IG) after splitting node SSS on each attribute (for example, consider attribute OOO). The attribute w.r.t. the biggest IG will be chosen!\nIG(S,O)⏟information gain=H(S)⏟entropy before split−∑jP(Oj∣S)×H(S,Oj)⏟weighted entropy after split\\underbrace{IG(S,O)}_{\\text{information gain}} = \\underbrace{H(S)}_{\\text{entropy before split}} - \\underbrace{\\sum_j P(O_j | S) \\times H(S,O_j)}_{\\text{weighted entropy after split}}\ninformation gainIG(S,O)​​=entropy before splitH(S)​​−weighted entropy after splitj∑​P(Oj​∣S)×H(S,Oj​)​​\nwhere j∈j \\inj∈ number of different properties in OOO and P(Oj)P(O_j)P(Oj​) is the propability of property OjO_jOj​ in OOO.\n\n\nAfter splitting, we have new child nodes. Each of them becomes a new parent node in the next step. Go back to step 1.\n\n\n\nID3 algorithm in detailHow we know we can split the dataset SSS base on the Outlook attribute instead of the others (Temperature, Humidity, Windy)? ⇒\\Rightarrow⇒ We calculate the information gain after splitting SSS on each attribute. It’s the information which can increase the level of certainty after splitting. The highest one will be chosen (after this section, you will see that the Outlook attribute has the highest information gain).\nIn order to calculate the information gain, we need &quot;entropy&quot; which is the amount of information disorder or the amount of randomness in the data.\ninformation gain=entropy before split−weighted entropy after split\\text{information gain} = \\text{entropy before split} - \\text{weighted entropy after split}\ninformation gain=entropy before split−weighted entropy after split\nAt the beginning, entropy before split (H(S)H(S)H(S)) shows us the disorder status of the whole dataset SSS. If SSS contains only Yes, SSS has no disorder or it's pure (H(S)=0)H(S)=0)H(S)=0). If the amount of Yes and No in SSS is equal, SSS has the highest disorder (H(S)=1H(S)=1H(S)=1).\n\nAn illustration of entropy with different proportions of Yes/No in SSS.\nAt each node, we need to calculate again its entropy (corresponding to the number of Yes and No in this node.). We prefer the lowest entropy, of course! How can we calculate entropy of each node? More specifically, how to calculate H(S)H(S)H(S)?\nH(S)=−∑i=12pS,ilog⁡2pS,i,H(S) = -\\sum_{i=1}^{2} p_{S,i} \\log_2 p_{S,i},\nH(S)=−i=1∑2​pS,i​log2​pS,i​,\nwhere i∈i \\ini∈ the number of classes (node SSS has 2 classes, Yes and No), pS,ip_{S,i}pS,i​ is the probability of class iii in SSS.\n\nGraph of H(p)H(p)H(p) in the case of 2 classes. Max is 1.\n\nIn this case we use log⁡2\\log_2log2​ (binary logarithm) to obtain the maximum H(S)=1H(S)=1H(S)=1 and we also use a convention in which 0×log⁡2(0)=00\\times\\log_2(0)=00×log2​(0)=0. There are other documents using log⁡\\loglog (natural logarithm) instead.\n\n\n\nOn node SSS , we have,\nH(S)=H([9,5])=−914×log⁡2(914)−514×log⁡2(514)=0.94.\\begin{aligned}\nH(S) &amp;= H([9,5]) \\\\\n&amp;= -\\frac{9}{14} \\times \\log_2(\\frac{9}{14}) - \\frac{5}{14}\\times\\log_2(\\frac{5}{14})\\\\\n&amp;= 0.94.\n\\end{aligned}\nH(S)​=H([9,5])=−149​×log2​(149​)−145​×log2​(145​)=0.94.​\nWe see that, SSS is not pure but it's also not totally disordered.\n\n\nThe frequency of classes in S.\n\nBecause we are considering to split SSS on OOO (Outlook) and OOO has 3 different properties which are Sunny, Overcast and Rainy. Corresponding to these properties, we have different sizes of Yes/No (Different nodes having different sizes of data but their total is equal to the size of SSS which is their &quot;parent&quot; node.). That's why we need to calculate the weighted entropy (weighted entropy after split).\n∑j=13P(Oj)×H(S,Oj),\\sum_{j=1}^3 P(O_j) \\times H(S,O_j),\nj=1∑3​P(Oj​)×H(S,Oj​),\nwhere j∈j \\inj∈ number of different properties in OOO and P(Oj)P(O_j)P(Oj​) is the propability of property OjO_jOj​ in OOO. Therefore, the information gain if split SSS on OOO is,\nIG(S,O)=H(S)−∑j=13P(Oj)×H(S,Oj).IG(S,O) = H(S) - \\sum_{j=1}^3 P(O_j) \\times H(S,O_j).\nIG(S,O)=H(S)−j=1∑3​P(Oj​)×H(S,Oj​).\n\nIf we split S on Outlook (O), there will be 3 branches.\nFor example, we consider branch O1O_1O1​ (Sunny), it has P(O1)=514P(O_1)=\\frac{5}{14}P(O1​)=145​ and entropy at this node, H(S,O1)H(S,O_1)H(S,O1​) is calculated as\n\nH(S,O1)=H([2,3])=−25×log⁡2(25)−35×log⁡2(35)=0.97.\\begin{aligned}\nH(S,O_1) &amp;= H([2,3]) \\\\\n&amp;= -\\frac{2}{5} \\times \\log_2(\\frac{2}{5}) - \\frac{3}{5}\\times\\log_2(\\frac{3}{5})\\\\\n&amp;= 0.97.\n\\end{aligned}\nH(S,O1​)​=H([2,3])=−52​×log2​(52​)−53​×log2​(53​)=0.97.​\n\nOnly consider branch Sunny (O1O_1O1​).\n\nThus, the information gain after splitting SSS on OOO is,\nIG(S,O)=H(S)−∑j=13P(Oj)×H(S,Oj)=0.94−(514×0.971+414×0+514×0.971)=0.94−0.693=0.247.\\begin{aligned}\nIG(S,O) &amp;= H(S) - \\sum_{j=1}^3 P(O_j) \\times H(S,O_j) \\\\\n&amp;= 0.94 - (\\frac{5}{14}\\times 0.971 + \\frac{4}{14}\\times 0 + \\frac{5}{14}\\times 0.971) \\\\\n&amp;= 0.94 - 0.693 = 0.247.\n\\end{aligned}\nIG(S,O)​=H(S)−j=1∑3​P(Oj​)×H(S,Oj​)=0.94−(145​×0.971+144​×0+145​×0.971)=0.94−0.693=0.247.​\nWith the same method, we can calculate the information gain after splitting SSS on other attributes (Temperature, Windy, Humidity) and get,\n\nDataset is split into different ways.\nWe can see that, the winner is Outlook with the highest information gain. We split SSS on that attribute first!\n\nDataset is split on Outlook.\nHow about 3 others remaining attributes (Temperature, Humidity, Windy), which one to be chosen next? Especially on branches Suuny and Humidity because on branch Overcast, this node is pure (all are Yes), we don't need to split any more.\n\nThere are remaining Temperature, Humidity, Windy. Which attribute will be chosen next?\nWe repeat the steps again, for example, on the branch O1O_1O1​ (Sunny), we calculate IG after splitting O1O_1O1​ on each attribute Temperature (T), Humidity (H) or Windy (W). Other words, we need to calculate IG(O1,T)IG(O_1,T)IG(O1​,T), IG(O1,H)IG(O_1, H)IG(O1​,H) and IG(O1,W)IG(O_1, W)IG(O1​,W) and then compare them to find the best one. Let's consider HHH (Humidity) as an example,\n\n\nIG(O1,H)=H(O1)−∑j=12P(Hj∣O1)×H(O1,Hj)=H(S,O1)−35×0−25×0=0.971.\\begin{aligned}\nIG(O_1,H) &amp;= H(O_1) - \\sum_{j=1}^2 P(H_j|O_1) \\times H(O_1,H_j) \\\\\n&amp;= H(S,O_1) - \\frac{3}{5}\\times 0 - \\frac{2}{5} \\times 0 \\\\\n&amp;= 0.971.\n\\end{aligned}\nIG(O1​,H)​=H(O1​)−j=1∑2​P(Hj​∣O1​)×H(O1​,Hj​)=H(S,O1​)−53​×0−52​×0=0.971.​\nNodes W1W_1W1​ and W2W_2W2​ are pure, that's why their entropy are 000.\n\n\nConsider branch O1O_1O1​ and attribute Windy (W).\n\nSimilarly, we calculate IG(O1,T)IG(O_1,T)IG(O1​,T), IG(O1,H)IG(O_1,H)IG(O1​,H) and we see that IG(O1,W)IG(O_1,W)IG(O1​,W) is the biggest one! So we choose WWW (Windy) to split at node O1O_1O1​. On the branch O3O_3O3​ (Rainy), the biggest information gain after splitting is on HHH (Humidity).\n\nFrom now, if we have a new input which contains information about Outlook, Temperature, Humidity and Windy, we go from the top of the tree and choose an appropriate branch to get the decision Yes or No.\n\nCART algorithm #\nCART algorithm (TL;DR;)\nThe difference between two algorithms is the difference between H(S)H(S)H(S) and IG(S)I_G(S)IG​(S).\n\n\n\nTo check the disorder at current node (let's say SSS, parent node), we calculate its Giny Impurity with,\nIG(S)=∑i=12pS,i(1−pS,i),I_G(S) = \\sum_{i=1}^{2} p_{S,i}(1-p_{S,i}),\nIG​(S)=i=1∑2​pS,i​(1−pS,i​),\nwhere i∈i \\ini∈ the number of classes in SSS and pS,ip_{S,i}pS,i​ is the probability of class iii in SSS.\n\n\nIf entropy at this node is pure (there is only 1 class or the majority is 1 class) or it meets the stopping conditions, we stop splitting at this node. Otherwise, go to the next step.\n\n\nCalculate the Gini Gain (GG) after splitting node SSS on each attribute (for example, consider attribute OOO). The attribute w.r.t. the biggest GG will be chosen!\nGG(S,O)⏟gini gain=IG(S)⏟gini impurity before split−∑jP(Oj∣S)×IG(S,Oj)⏟weighted gini impurity after split\\underbrace{GG(S,O)}_{\\text{gini gain}} = \\underbrace{I_G(S)}_{\\text{gini impurity before split}} - \\underbrace{\\sum_j P(O_j | S) \\times I_G(S,O_j)}_{\\text{weighted gini impurity after split}}\ngini gainGG(S,O)​​=gini impurity before splitIG​(S)​​−weighted gini impurity after splitj∑​P(Oj​∣S)×IG​(S,Oj​)​​\nwhere j∈j \\inj∈ number of different properties in OOO and P(Oj)P(O_j)P(Oj​) is the propability of property OjO_jOj​ in OOO.\n\n\nAfter splitting, we have new child nodes. Each of them becomes a new parent node in the next step. Go back to step 1.\n\n\n\nCART algorithm in detailIt's quite the same to the ID3 algorithm except a truth that it's based on the definition of Gini impurity instead of Entropy. Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset.\nAt every nonleaf node (which isn't pure), we have to answer a question &quot;Which attribute we should choose to split that node?&quot; We calculate the Gini gain for each split based on the attribute we are going to use. This Gini gain is quite the same as Information gain. The highest one will be chosen.\ngini gain=gini impurity before split−weighted gini impurity after split\\text{gini gain} = \\text{gini impurity before split} - \\text{weighted gini impurity after split}\ngini gain=gini impurity before split−weighted gini impurity after split\nThe Gini Impurity at node SSS is calculated as,\nIG(S)=∑i=12pS,i(1−pS,i),I_G(S) = \\sum_{i=1}^2p_{S,i}(1-p_{S,i}),\nIG​(S)=i=1∑2​pS,i​(1−pS,i​),\nwhere i∈i\\ini∈ the number of classes in SSS, pS,ip_{S,i}pS,i​ is the probability of class iii in SSS. IG=0I_G=0IG​=0 will be the best!\n\n\nOn node SSS, we have,\nIG(S)=IG([9,5])=914×514+514×914=0.459.\\begin{aligned}\nI_G(S) &amp;= I_G([9,5]) \\\\\n&amp;= \\frac{9}{14} \\times \\frac{5}{14} + \\frac{5}{14} \\times \\frac{9}{14}\\\\\n&amp;= 0.459.\n\\end{aligned}\nIG​(S)​=IG​([9,5])=149​×145​+145​×149​=0.459.​\n\n\nThe frequency of classes in S.\n\nSimilarly to the information gain, we can calculate Gini Gain (GGGGGG) after splitting SSS on the property OOO with,\nGG(S,O)=IG(S)−∑j=13P(Oj)×IG(S,Oj),GG(S,O) = I_G(S) - \\sum_{j=1}^3 P(O_j) \\times I_G(S,O_j),\nGG(S,O)=IG​(S)−j=1∑3​P(Oj​)×IG​(S,Oj​),\nwhere j∈j \\inj∈ number of different properties in OOO and P(Oj)P(O_j)P(Oj​) is the propability of property OjO_jOj​ in OOO.\n\nIf we split S on Outlook (O), there will be 3 branches.\nApply above equation, we calculate all GG if splitting SSS on each property and get,\nGG(S,O)=IG([9,5])−(514×IG([2,3])+414×IG([4,0])+514×IG([3,2]))=…\\begin{aligned}\nGG(S,O) &amp;= I_G([9,5]) - ( \\frac{5}{14}\\times I_G([2,3]) + \\frac{4}{14}\\times I_G([4,0]) + \\frac{5}{14}\\times I_G([3,2])) \\\\\n&amp;= \\ldots\n\\end{aligned}\nGG(S,O)​=IG​([9,5])−(145​×IG​([2,3])+144​×IG​([4,0])+145​×IG​([3,2]))=…​\nThe same for GG(S,H)GG(S,H)GG(S,H) (Humidity), GG(S,T)GG(S,T)GG(S,T) (Temperature) and GG(S,W)GG(S,W)GG(S,W) (Windy). Keep going the same arguments as in the section ID3 in detail, we will get the final tree. The difference between two algorithms is the difference between H(S)H(S)H(S) and IG(S)I_G(S)IG​(S).\n\nGini Impurity or Entropy? #\nSome points:[ref]\n\n\nMost of the time, they lead to similar trees.[ref]\nGini impurity is slightly faster.[ref]\nGini impurity tends to isolate the most frequent class in its own branch of the tree, while entropy tends to produce slightly more balanced trees.\n\nGood / Bad of Decision Tree? #\nSome highlight advantages of Decision Tree Classifier:[ref]\n\n\nCan be used for regression or classification.\nCan be displayed graphically.\nHighly interpretable.\nCan be specified as a series of rules, and more closely approximate human decision-making than other models.\nPrediction is fast.\nFeatures don't need scaling.\nAutomatically learns feature interactions.\nTends to ignore irrelevant features.\nNon-parametric (will outperform linear models if relationship between features and response is highly non-linear).\n\nIts disadvantages:\n\n\nPerformance is (generally) not competitive with the best supervised learning methods.\nCan easily overfit the training data (tuning is required).\nSmall variations in the data can result in a completely different tree (high variance).\nRecursive binary splitting makes &quot;locally optimal&quot; decisions that may not result in a globally optimal tree.\nDoesn't tend to work well if the classes are highly unbalanced.\nDoesn't tend to work well with very small datasets.\n\nWhen to stop? #\nIf the number of features are too large, we'll have a very large tree! Even, it easily leads to an overfitting problem. How to avoid them?\n\n\nPruning: removing the branches that make use of features having low importance.\nSet a minimum number of training input to use on each leaf. If it doesn't satisfy, we remove this leaf. In scikit-learn, use min_samples_split.\nSet the maximum depth of the tree. In scikit-learn, use max_depth.\n\nWhen we need to use Decision Tree? #\n\nWhen explainability between variable is prioritised over accuracy. Otherwise, we tend to use Random Forest.\nWhen the data is more non-parametric in nature.\nWhen we want a simple model.\nWhen entire dataset and features can be used\nWhen we have limited computational power\nWhen we are not worried about accuracy on future datasets.\nWhen we are not worried about accuracy on future datasets.\n\nUsing Decision Tree Classifier with Scikit-learn #\nLoad and create #\nLoad the library,\nfrom sklearn.tree import DecisionTreeClassifier\nCreate a decision tree (other parameters):\n# The Gini impurity (default)clf = DecisionTreeClassifier() # criterion='gini'# The information gain (ID3)clf = DecisionTreeClassifier(criterion='entropy')\nAn example,\n\nfrom sklearn import treeX = [[0, 0], [1, 1]]Y = [0, 1]clf = tree.DecisionTreeClassifier()clf = clf.fit(X, Y)# predictclf.predict([[2., 2.]])# probability of each classclf.predict_proba([[2., 2.]])\narray([1])\narray([[0., 1.]])\n\n\nPlot and Save plots #\nPlot the tree (You may need to install Graphviz first. Don't forget to add its installed folder to $path),\n\nfrom IPython.display import Imageimport pydotplusdot_data = tree.export_graphviz(clf, out_file=None, rounded=True, filled=True)graph = pydotplus.graph_from_dot_data(dot_data)Image(graph.create_png())\n\n\nSave the tree (follows the codes in &quot;plot the tree&quot;)\ngraph.write_pdf(\"tree.pdf\") # to pdfgraph.write_png(\"thi.png\") # to png\nReferences #\n\nScikit-learn. Decision Tree CLassifier official doc.\nSaed Sayad. Decision Tree - Classification.\nTiep Vu. Bài 34: Decision Trees (1): Iterative Dichotomiser 3.\nBrian Ambielli. Information Entropy and Information Gain.\nBrian Ambielli. Gini Impurity (With Examples).\nAurélien Géron. Hands-on Machine Learning with Scikit-Learn and TensorFlow, chapter 6.\n\n"},"/decision-tree-regression/":{"id":"/decision-tree-regression/","title":"Decision Tree Regression","keywords":"classification regression MSE Mean Square Error MAE Mean Absolute Error stopping conditions Standard Deviation Reduction SDR Graphviz example Saed Sayad","tags":["posts","Machine Learning"],"cat":"/img/cats/ml.svg","content":"What's the idea of Decision Tree Regression? #\nThe basic intuition behind a decision tree is to map out all possible decision paths in the form of a tree. It can be used for classification (note) and regression. In this post, let's try to understand the regression.\nDT Regression is similar to DT Classification, however we use Mean Square Error (MSE, default) or Mean Absolute Error (MAE) instead of cross-entropy or Gini impurity to determine splits.\nMSE=1n∑i=1n(yi−yˉi)2,MAE=1n∑i=1n∣yi−yˉi∣.\\begin{aligned}\n\\text{MSE} &amp;= \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y}_i)^2, \\\\\n\\text{MAE} &amp;= \\frac{1}{n}\\sum_{i=1}^n \\vert y_i - \\bar{y}_i \\vert.\n\\end{aligned}\nMSEMAE​=n1​i=1∑n​(yi​−yˉ​i​)2,=n1​i=1∑n​∣yi​−yˉ​i​∣.​\nSuppose that we have a dataset SSS like in the figure below,\n\n\nAn example of dataset SSS.\n\nA decision tree we want.\n\nSome basic concepts #\n\n\nSplitting: It is a process of dividing a node into two or more sub-nodes.\nPruning: When we remove sub-nodes of a decision node, this process is called pruning.\nParent node and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node.\n\n\nOther aspects of decision tree algorithm, check this note.\n\n\nLooking for an example like in the post of decision tree classifier? Check this! Below are a short algorithm,\n\n\n\nCalculate the Standard Deviation (SDSDSD) of the current node (let's say SSS, parent node) by using MSE or MAE,\nSD(S)=1n∑i=1n(yi−yˉi)2,or SD(S)=1n∑i=1n∣yi−yˉi∣,\\begin{aligned}SD(S) &amp;= \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y}_i)^2, \\\\\\text{or } SD(S) &amp;= \\frac{1}{n}\\sum_{i=1}^n \\vert y_i - \\bar{y}_i \\vert,\\end{aligned}\nSD(S)or SD(S)​=n1​i=1∑n​(yi​−yˉ​i​)2,=n1​i=1∑n​∣yi​−yˉ​i​∣,​\nwhere yi∈y_i\\inyi​∈ the target values (Hours Played in the above example), yˉ=Σyn\\bar{y}=\\frac{\\Sigma y}{n}yˉ​=nΣy​ is the mean value and nnn is the number of examples in this node.\n\n\nCheck the stopping conditions (we don't need to make any split at this node) to stop the split and this node becomes a leaf node. Otherwise, go to step 3.\n\nThe minimum number of samples required to split an internal node, use min_samples_split in scikit-learn.\nThe maximum depth of the tree, use max_depth in scikit-learn.\nA node will be split if this split induces a decrease of the impurity greater than or equal to this value, use min_impurity_decrease in scikit-learn.\nIts coefficient of variation (SD(S)yˉ\\frac{SD(S)}{\\bar{y}}yˉ​SD(S)​) is less than a certain threshold.\n\n\n\nCalculate the Standard Deviation Reduction (SDR) after splitting node SSS on each attribute (for example, consider attribute OOO). The attribute w.r.t. the biggest SDR will be chosen!\nSDR(S,O)⏟Standard Deviation Reduction=SD(S)⏟SD before split−∑jP(Oj∣S)×SD(S,Oj)⏟weighted SD after split\\underbrace{SDR(S,O)}_{\\text{Standard Deviation Reduction}}= \\underbrace{SD(S)}_{\\text{SD before split}}- \\underbrace{\\sum_j P(O_j | S) \\times SD(S,O_j)}_{\\text{weighted SD after split}}\nStandard Deviation ReductionSDR(S,O)​​=SD before splitSD(S)​​−weighted SD after splitj∑​P(Oj​∣S)×SD(S,Oj​)​​\nwhere j∈j \\inj∈ number of different properties in OOO and P(Oj)P(O_j)P(Oj​) is the propability of property OjO_jOj​ in OOO. Note that, SD(S,Oj)SD(S,O_j)SD(S,Oj​) means the SD of node OjO_jOj​ which is also a child of node SSS.\n\n\nAfter splitting, we have new child nodes. Each of them becomes a new parent node in the next step. Go back to step 1.\n\n\nUsing Decision Tree Regression with Scikit-learn #\nLoad and create #\nLoad the library,\nfrom sklearn.tree import DecisionTreeRegressor\nCreate a decision tree (other parameters):\n# mean squared error (default)reg = DecisionTreeRegressor() # criterion='mse'# mean absolute errorreg = DecisionTreeRegressor(criterion='mae')\nAn example,\n\nfrom sklearn import treeX = [[0, 0], [2, 2]]y = [0.5, 2.5]reg = tree.DecisionTreeRegressor()reg = reg.fit(X, y) # train\narray([0.5])\n\n\nPlot and save plots #\nPlot the tree (You may need to install Graphviz first. Don't forget to add its installed folder to $path),\n\nfrom IPython.display import Imageimport pydotplusdot_data = tree.export_graphviz(reg, out_file=None, rounded=True, filled=True)graph = pydotplus.graph_from_dot_data(dot_data)Image(graph.create_png())\n\n\nSave the tree (follows the codes in &quot;plot the tree&quot;)\ngraph.write_pdf(\"tree.pdf\") # to pdfgraph.write_png(\"thi.png\") # to png\nReferences #\n\nSkikit-learn. Decision Tree Regressor official doc.\nSaed Sayad. Decision Tree - Regression.\n\n"},"/computer-and-internet-tips/":{"id":"/computer-and-internet-tips/","title":"Computer & Internet tips","keywords":"download flash video browser extension video url google video download manager videoplay developer tools exclude files folders search technique skills patterns preference settings confige configure options remove apps google apps bit.ly cortana uses chrome instead of edge default browser windows 10 change default directory powershell cmder","tags":["posts","Others"],"cat":"/img/cats/others.svg","content":"General #\nApplications #\n🔅 Change default directory in cmder\n\nGo to settings\nThen, Startup &gt; Tasks\nChoose {cmd::Cmder}\nChoose the below-right box, let the cursor at the end of the text\nClick on &quot;Startup dir…&quot;\nChoose your desired directory &gt; OK\nRemove the current line with the new appearing one (new_console:d:%USERPROFILE%)\nClick on Save settings\n\nWindows #\nCortana uses Chrome instead of Edge #\n\nDownload and install this app (reinstall it after every update of Windows).\nChoose EdgeDeflector as the default web browser if it asks.\nInstall this extension in Chrome to force to redirect from Bing to Google Search Engine.\n\nChange default directory in PowerShell #\n\nCreate a folder in your Documents folder called WindowsPowerShell\nCreate a file called profile.ps1 inside this folder\nAdd following command Set-Location c:\\abc\nEvery time you launch PowerShell, the profile script will be executed\n\nInternet #\n🔅 Remove apps permission from Google Apps (Youtube, Google Play Music, …) ⇾ here.\nProblem of hsts #\nCannot open a page with security problem.\n\nGo to chrome://net-internals/#hsts\n&quot;Query HSTS/PKP domain&quot;, fill domain, e.g. gitlab.powerop.io.\n&quot;Delete domain security policies&quot;, fill domain and click on Delete.\nTry again &gt; Click on &quot;Advanced&quot; &gt; Click on ...unsafe....\n\nDownload flash video #\nIn most case, you can use Flash Video Downloader (for Chrome) or other extensions to detect the video url.\nIn the case browser extensions cannot capture the url, you can open the Developer Tools (in Chrome, press F12) &gt; Reload the page and click to play again the video &gt; Network tab &gt; Media tab &gt; click on any sources on the left column (videoplayback?expire...) &gt; On the right column, in tab Headers &gt; General &gt; Copy the content in Request URL, something like below,\nhttps://r4---sn-25ge7ns7.googlevideo.com/videoplayback?expire=1568040368&amp;ei=kEl2Xb...f_cW7qE=\n\nOpen a new tab in your browser, Ctrl + S to save the video. You can also open the Downloads manager in your browser (Ctrl + J) to copy the download link and use other Download Manager tools to download this video without using the browser!\nGithub README.md on localhost #\nIn stall grip.\n# go to the file's directorygrip # if file is README.mdgrip file.md\n"},"/pep-8/":{"id":"/pep-8/","title":"Python PEP 8 : Style Guide","keywords":"pep 8 python style naming style code layout indentation tab or space whitespace recommendation pep8 PEP8 PEP 8 formatting beautifier beautiful python codes 80 characters","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"What's PEP 8? #\nIt contains some conventions in coding with Python. They make the codes clearer and more beautiful. Read the full doc here. Below are just some of them in my choice.\nNaming styles #\n\n\nPackage &amp; module names &amp; function &amp; variable: all_lower_case or short with underscore.\n\n\nClass names: use CapWords.\n\n\nConstant: ALL_CAPITAL_LETTERS.\n\n\nAvoid these:\nl = 1 # lowercase letter elO = 1 # uppercase letter ohI = 1 # uppercase letter eyeCapitalized_Words_With_Underscores = 1 # ugly\n\n\nCode layout #\nIndentation #\nUse 4 spaces per indentation level. Note that, in this site, for a better view, I use 2 spaces for the code highlight.\n\n# YESdef func(...): commands # 4 spaces\n# NOdef func(...): commands # 2 spaces\n\nVertical align when break a continuous line:\n\n# YESfoo = long_function_name(var_one, var_two, var_three, var_four)\n# NOfoo = long_function_name(var_one, var_two, var_three, var_four)\n\nDistinguish arguments from the rest:\n\n# YESdef long_function_name( var_one, var_two, var_three, var_four): print(var_one)\n# NOdef long_function_name( var_one, var_two, var_three, var_four): print(var_one)\n\nTabs or spaces? #\nSpaces are preferred. Don't mix tabs and spaces (not allowed in Python 3).\nMax line lenght #\nMax of 79 characters.\nLine break with operator #\nOperators should go with operands\n\n# YESincome = (salary + sale)\n# NOincome = (salary + sale)\n\nImport #\nImports should usually be on separate lines:\n\n# YESimport osimport sys\n# NOimport os, sys\n# But yesfrom subprocess import Popen, PIPE\n\nWhitespace #\nAvoid extraneous whitespace:\n\n# YESspam(ham[1], {eggs: 2})foo = (0,)if x == 4: print x, y; x, y = y, x\n# NOspam( ham[ 1 ], { eggs: 2 } )bar = (0, )if x == 4 : print x , y ; x , y = y , x\n\nFor slices\n\n# YESham[1:9], ham[1:9:3], ham[:9:3], ham[1::3], ham[1:9:]ham[lower:upper], ham[lower:upper:], ham[lower::step]ham[lower+offset : upper+offset]ham[: upper_fn(x) : step_fn(x)], ham[:: step_fn(x)]ham[lower + offset : upper + offset]\n# NOham[lower + offset:upper + offset]ham[1: 9], ham[1 :9], ham[1:9 :3]ham[lower : : upper]ham[ : upper]\n\nAdd open parenthesis/bracket right after:\n\n# YESspam(1)dct['key'] = lst[index]\n# NOspam (1)dct ['key'] = lst [index]\n\nNo need to have verticle alignment:\n\n# YESx = 1y = 2long_variable = 3\n# NOx = 1y = 2long_variable = 3\n\nWith operators:\n\n# YESi = i + 1submitted += 1x = x*2 - 1hypot2 = x*x + y*yc = (a+b) * (a-b)\n# NOi=i+1submitted +=1x = x * 2 - 1hypot2 = x * x + y * yc = (a + b) * (a - b)\n\nDef of a function:\n\n# YESdef complex(real, imag=0.0): return magic(r=real, i=imag)\n# NOdef complex(real, imag = 0.0): return magic(r = real, i = imag)\n\nProgramming Recommendations #\nUsing not inside if:\n\n# YESif foo is not None:\n# NOif not foo is None:\n\nUsing Use .startswith() and .endswith() instead of string slicing:\n\n# YESif foo.startswith('bar'):\n# NOif foo[:3] == 'bar':\n\nFor sequences, (strings, lists, tuples), use the fact that empty sequences are false:\n\n# YESif not seq:if seq:\n# NOif len(seq):if not len(seq):\n\nDon't compare boolean values to True or False using ==:\n\n# YESif greeting:\n# NOif greeting == True:\n# Worseif greeting is True:\n\n"},"/python-classes-objects/":{"id":"/python-classes-objects/","title":"Python Classes & Objects","keywords":"classes vs objects methods instances blueprint attributes import local class empty file __init__.py ValueError: attempted relative import beyond top-level package same folder subfolder another folder from incldue get and access attributes of a class abstract class method super father child son Syntactic sugar easier to read why self Syntactic sugar","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Classes vs Objects vs Instances vs Methods #\n\nClass is a blueprint/template of an object.\n\nEach class has its own attributes (its states) and methods (its behaviors).\n\n\nObject is a bundle of related attributes and methods.\nInstance is a single and unique unit of a class.\n\nMany instances may have the same class. They have attributes and methods defined in the class.\n\n\n\nAn exampleA class student represents (a template of) an object student with:\n\nAttributes: name, marks and\nMethods: take_exams(), graduate().\n\nInstances john_doe and jane_doe defined from class student will have:\n\nTheir names: john_doe.name and jane_doe.name.\nTheir marks: john_doe.marks and jane_doe.marks.\nTheir behaviors: john_doe.take_exams() and jane_doe.graduate(), ...\n\nSyntactic sugar &amp; self #\nSyntactic sugar is syntax within a programming language that is designed to make things easier to read or to express. For example, we use arr[i,j] but behind the scene, it's get_element(arr, vector(i,j)).\nclass MyClass() def method(arg): print(arg)my_object = MyClass()my_object.method('foo')# TypeError: method() takes exactly 1 positional argument (2 given)\nmy_object.method('foo') means MyClass.method(my_object, 'foo'). That's why we need self or a decorator,\n\nclass MyClass(): def method(self, arg): print(arg)\n# DON'T NEED `self`class MyClass(): @staticmethod def method(self, arg): print(arg)\n\nGet all attributes of a class #\n# CHECK THERE IS AN ATTRIBUTEgetattr(MyClass, 'report', None)# if there is a class, it return this class' detail# if not, return None\ndef props(cls): return [i for i in cls.__dict__.keys() if i[:1] != '_']# access these attributesproperties = props(MyClass)for att in properties: print(getattr(MyClass, att))\n# Get dictionaries of all attributes &amp; their valuesMyClass.__dict__\nImport local class #\nSuppose that we have a folders/files structure like below,\n\n# ORIGINAL STRUCTUREpopai/ processings/ a.py # contains class ABC test/ b.py lib/ c.py # contains class XYZ\n# UPDATED STRUCTUREpopai/ __init__.py processings/ __init__.py a.py # contains class ABC test/ __init__.py b.py lib/ c.py # contains class XYZ\n\nWe want import both classes ABC and XYZ,\n\n# b.pyfrom popai.processings.a import ABC\n# a.pyfrom popai.lib.c import XYZ\n\nJust add __init__.py like in the right box above.\nSome errors may occur,\nValueError: attempted relative import beyond top-level package\nFather and Son #\n\n# FATHERclass father_class(): def __init__(self): self.abc = 1\n# SONclass son_class(father_class): def __init__(self): # son_class has attribute `abc` super().__init__() self.xyz = 2\n\nIf you want son takes all parameters of father and use additional parameters,\nclass Shape: def __init__(self, shapename): self.shapename = shapenameclass ColoredShape(Shape): def __init__(self, color, **kwargs): super().__init__(**kwargs) self.color = colorcs = ColoredShape(color='red', shapename='circle')\nAbstract Base Classes (ABC) #\nfrom abc import ABC, abstractmethod\n\n# FATHER CLASSclass BaseModel(ABC): def __init__(self): pass # child class must have @abstractmethod def fit(self, X): pass # child class must have @abstractmethod def predit(self, X): pass # children class don't need to have # but they can call def fit_predict(self, X): pass\n# CHILD CLASSclass LinearModel(BaseModel) def __init__(self): pass # must-have def fit(self, X): pass # must-have def predict(self, X): pass # this call can use .fix_predict() # from its father!\n\n"},"/python-docs-refs/":{"id":"/python-docs-refs/","title":"Python references","keywords":"references documentation material courses practice python newsletter platform","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"For checking #\n\nGoogle, of course!\nprogramiz.com\nPython Reference on iOS.\n\nCourses #\n\nPython 3 tutorial on TutorialsPoint.\nPython Tutorial on W3School.\nPython Tutorials by Corey Schafer on Youtube.\nPython 3 on Codecademy (paid).\nPython fundamentals on PluralSight (paid).\n\nBooks #\nPractice #\n\nHackerrank.\nExercism.\nCodeSignal.\nCodeChef.\n\nOthers #\n\nNewsletter for python news.\nTime complexity (Big O) of various operators in CPython.\n\n"},"/python-functions/":{"id":"/python-functions/","title":"Python Functions","keywords":"function def Unpacking a function Functions with stars kwargs args rargs lambda function check input verify raise error should we check the arguments type decorators @ notation at wrapper","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Facts #\n\nIn python, function is the first-class object. It's can be used as an argument.\nFunction can be used as a return value.\n\nreturn func1: reference to func1.\nreturn func1(): results of evaluating func().\n\n\nShould we check the argument/input?: No! The responsibility is on the caller! Your function should be well-documented, that's it![ref]\n\nCreate a normal function #\nIf a function doesn't return any value, it returns None.\n\n# without argumentsdef func_name(): pass\n# with argumentsdef func_name(&lt;args>): pass\n# returndef func_name(&lt;args>): return &lt;some_thing>\n# call a functionfunc_name(&lt;args>)\n\nUnpacking a function #\n\ndef sum_and_div(num1, num2): sum_nums = num1 + num2 div_nums = num1 / num2 return sum_nums, div_nums # multiple returnssum, div = sum_and_div(18, 9)print(sum, div)\n27 2.0\n\n\nFunctions with stars (*args and **kwargs) #\nThe *args will give you all function parameters as a tuple:[ref]\n\ndef foo(*args): print(args) for a in args: print(a)foo(1)foo(2, 3, 4)\n(1,)\n1\n(2, 3, 4)\n2\n3\n4\n\n\n\ndef foo(rarg1, rarg2): print(rarg1, rarg2)lst = [1, 2]foo(*lst)tpl = (3, 4)foo(*tpl)\n1 2\n3 4\n\n\nIf you wanna use &quot;keywords arguments&quot;, use **args:\n\ndef kwfunc(**kwargs): print(type(kwargs)) print(kwargs)kwfunc()kwfunc(kw1=\"thi\", kw2=\"dinh\")\n&lt;class 'dict'&gt;\n{}\n&lt;class 'dict'&gt;\n{'kw1': 'thi', 'kw2': 'dinh'}\n\n\nUse a dictionary as an input,\n\ndef kwfunc(**kwargs): # must have ** print(kwargs)kwargs = {'kw1': \"thi\", 'kw2': \"dinh\"}kwfunc(**kwargs) # must have **\n{'kw1': 'thi', 'kw2': 'dinh'}\n\n\n\ndef kwfunc(kw1=\"john\", kw2=\"doe\"): print(kw1, kw2)kwargs = {'kw1': \"thi\", 'kw2': \"dinh\"}kwfunc()kwfunc(kwargs) # goes to kw1kwfunc(**kwargs) # goes to both kw1 &amp; kw2\njohn doe\n{'kw1': 'thi', 'kw2': 'dinh'} doe\nthi dinh\n\n\nCoupling rargs, *args and **kwargs:\n\nRequired positional arguments: rarg1, rarg2, ...\nOptional positional arguments: *args.\nOptional key-values arguments: **kwargs.\n\n\ndef kwfunc(rarg1=0, rarg2=0, *args, **kwargs): print(\"required args: \", rarg1, rarg2) if args: print(\"*args: \", args) if kwargs: print(\"**kwargs: \", kwargs) print(\"\\n\")kwfunc()kwfunc(1, 2)kwfunc(3, 4, 5, 6)kwfunc(kw1=\"thi\", kw2=\"dinh\")\nrequired args: 0 0\n\nrequired args: 1 2\n\nrequired args: 3 4\n*args: (5, 6)\n\nrequired args: 0 0\n**kwargs: {'kw1': 'thi', 'kw2': 'dinh'}\n\n\nAll arguments after * must be key-value arguments,\n\ndef func(rarg1, rarg2, *, kwarg1, kwarg2): print(\"required args: \", rarg1, rarg2) print(\"kwarg*: \", kwarg1, kwarg2)# func(1, 2, 3, 4) # error!func(1, 2, kwarg1=3, kwarg2=4)\nrequired args: 1 2\nkwarg*: 3 4\n\n\nLambda function #\nIt's convenient but don't use it regularly, use def (in 1 line) instead.\n\nx = lambda a : a + 10print(x(5))# you can use thisdef x(a): return a + 10\n15\n\n\n# if else with lambda functionlambda row: 'good' if (row>=80) else ('bad' if row&lt;80 else '')\nCheck input &amp; raise error #\nSomething like that,\nif par1 is None: msg = \"par1 must be in type `int`\" raise TypeError(msg)\nYou can check other exceptions here.\nDecorators #\n\ndef my_decorator(func): def wrapper(): print(\"Before func called.\") func() print(\"After func called.\") return wrapperdef say_whee(): print(\"Whee!\")say_whee = my_decorator(say_whee)say_whee()\nSomething is happening before the function is called.\nWhee!\nSomething is happening after the function is called.\n\n\nIn a class (note that, there is no self parameter in _deco),\n\nclass test_class(): def _deco(func): def wrapper(self, name): print('before func called') func(self, name) print('after func called') return wrapper @_deco def fit(self, name): print('Hello, ', name)a = test_class()a.fit('thi')\nbefore func called\nHello, thi\nafter func called\n\n\n"},"/python-input-output/":{"id":"/python-input-output/","title":"Python: Input & Output","keywords":"print string display long strings long texts break the line word wrap multi lines multilines display decimal numbers display dataframes log logging warning info error alert docstring comment multiline comments documentation class definition sample structure example","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Input #\n# Get input from user and display (input's type is `string`)age = input(\"Your age? \") # python 3, raw_input for python 2print(\"Your age:\", age) # don't need space after \"age\"\n# Get the input and store to numbers listnumbers = list(map(int, input().split()))\n# Get multi inputs on 1 linex, y, z, n = (int(input()) for _ in range(4))\nComment #\nUsing # on each line.\n\n# print(\"This is not showed.\")print(\"This is showed.)\nThis is showed.\n\n\nPrint / Display #\n\n# Print normallyprint(\"Hello!\") # python 3print \"Hello!\" # python 2\nHello!\nHello!\n\n\n\n# print with `format`print(\"Hello {} and {}.\".format(\"A\", \"B\"))\nHello A and B.\n\n\n\n# change orderprint(\"Hello {2} and {1}.\".format(\"A\", \"B\"))\nHello B and A.\n\n\n\n# Directly insert (python 3.6 or above)b = \"B\"print(f'Hello {\"A\"} and {b}.')\nHello A and B.\n\n\n\n# long stringsprint('This is a part of sentence.' 'This is other part.')\nThis is a part of sentence. This is other part.\n\n\n\n# print decimalsprint(\"{:.6f}\".format(number))\n# print decimals\n1.000000\n\n\n\n# print multiplesprint(\"1\", 5, \"thi\") # there are spaces\n# print multiples\n1 5 thi\n\n\n# first 20 characters, second 10 charactersprint( '{:&lt;20s} {:&lt;10s}'.format(string_one, string_two) )\nDisplay separated results (like in executing multiple code cells),\ndisplay(df_1)display(df_2)\nLogging #\nCheck more here.\nimport logginglog = logging.getLogger(__name__)# order of increasing severitylog.debug('something')log.info('something')log.warning('something')log.error('something')logger.critical('something')# by default, the logging module logs the messages with a severity level of WARNING or above# thus: debug and info aren't show by default\nIf the log.info() doesn't work, set below[ref],\nlogging.getLogger().setLevel(logging.INFO) # show all except \"debug\"# orlogging.basicConfig(level=logging.DEBUG) # show all\n# in the classimport logginglog = logging.getLogger(__name__)log.info(\"abc\")log.debug(\"xyz\")log.info(\"abc: %s\", abc)log.debug(\"xyz: {}\".format(xyz))\n# in the jupyter notebookimport logginglog = logging.getLogger(__name__)logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"DEBUG\"))\n"},"/python-installation/":{"id":"/python-installation/","title":"Python Installation","keywords":"windows linux mac anaconda pip jupyter notebook activate base ubuntu install new packages conda env environement revision ImportError ssl error ssh module _ssl TLS/SSL check version update pip upgrade pip AttributeError: 'NoneType' object UnicodeDecodeError: 'ascii' codec conda: The following packages are not available from current channels freetype (from matplotlib) dtaidistance: C-library is not available","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Windows #\nUpdate 11/Sep/20: Install python on WSL2 using Miniconda.\nOther options (directly install)Download and install Anaconda or smaller version Miniconda.\n# default installed dirC:\\ProgramData\\Anaconda3\nAdd to System Environment Variables:\nC:\\ProgramData\\Anaconda3C:\\ProgramData\\Anaconda3\\Scripts\nIf you don't wanna use Anaconda and install it by yourself, add this:\nC:\\Users\\&lt;user>\\AppData\\Roaming\\Python\\Python36\\Scripts\n(You can find C:\\...\\Roaming by typing %appdata% in the Windows Explorer's navigation bar)\nApp to run: cmder (use this setting file).\nJupyer Notebook #\n👉 Jupyter notebook note.\nAnaconda contains JN in it, no need to install it again. cd to the folder you wanna work on and run\n\n# RUN (after installing Anaconda)python -m notebook\n# If `ImportError: DLL load failed`active base # active env \"base\" in anacondajupyter notebook\n\nThe -m option allows you to execute a module or package as a script[ref].\n# If `import _ssl`, `ImportError`set CONDA_DLL_SEARCH_MODIFICATION_ENABLE=1python -m notebook\nMacOS #\nBy default, Python 2 is already installed on MacOS, you can check this by\npython --version# to be sure, check if python3 is installed?python3 --version\nLinux (Ubuntu) #\nPython is already installed on Ubuntu. You would like to install Anaconda, download and install it.\nWanna install Miniconda instead? 👉 Download .sh file and install inside Linux environement (including WSL2).\n# ADD CONDA TO $PATHnano ~/.profile# find where conda is installed and thenexport PATH=/home/&lt;user>/anaconda3/bin:$PATHsource ~/.profile# checkwhich python# should return: /home/&lt;user>/anaconda3/bin/python# check versionconda --version\nMake right version #\nalias python=python3alias pip=pip3# for ubuntu >=20.04sudo apt install python-is-python3# prevent Python 2 from being installed as a dependency of somethingsudo apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\nCheck GPU #\n👉 Read more on note of pytorch.\n# with pytorchimport torchprint('cuda is available? ', torch.cuda.is_available())print('device_count: ', torch.cuda.device_count())print('current device: ', torch.cuda.current_device())print('device name: ', torch.cuda.get_device_name(0))\n# with tensorflowimport tensorflow as tfprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\npip #\nUpdate pip #\n\n# Check pip versionpip -V\n# update pipeasy_install -U pip\n\n\nIf you meet AttributeError: 'NoneType' object has no attribute 'bytes' when updating pip, check the version and make sure that there is only 1 pip on your computer and then use easy_install -U pip (don't forget to activate )\nIf there is a problem with python -m pip install --upgrade pip, use easy_install!\n\nInstall packages with pip #\nInstall pip (It's actually installed with Anaconda). If you wanna upgrade it to the latest version:\npython -m pip install --user --upgrade pip # install for current user onlypython -m pip install --upgrade pip # need to run cmder as administrator\nAttributeError: 'NoneType' objectFirst, activate &lt;env&gt; and then using easy_install -U pip. You can check the version of pip by pip -V.\n\n# LIST ALL INSTALLED PACKAGESpip freeze\n# INSTALL A PACKAGEpip install &lt;package> # admin &lt;-- SHOULDN'T!!!pip install --user &lt;package> # current user only\n# REMOVEpip uninstall &lt;package>pip uninstall --user &lt;package>\n# CHECK VERSION OF A PACKAGEpip show &lt;package>\n\nIf install packages with pip, they are installed in which environment of conda? Where pip is executed from.\n\nwhich pythonwhich pipconda info --envs# or# conda env list\n/c/ProgramData/Anaconda3/python\n/c/ProgramData/Anaconda3/Scripts/pip\n\n# conda environments:\nbase * C:\\ProgramData\\Anaconda3\nfastai C:\\Users\\thi\\.conda\\envs\\fastai\n\n\nInstall packages with requirement file,\npip install -r requirements.txt\nAn example of requirement file,\ngeopandas==0.4.1grpcio==1.27.1grpcio-tools==1.27.1h5py==2.10.0isodate==0.6.0PyYAML==5.3.1\nInstall a package from a git repository,\npip install git+https://github.com/TimeSynth/TimeSynth.git\n# version &lt;=pip3 install -U \"pillow&lt;7\"\npip vs conda? #\nDifferences:[ref]\n\npip installs python packages in any environment.\nconda installs any package in conda environments.\n\nWhich one to be used?[ref]\n\nIf you installed Python using Anaconda or Miniconda, then use conda to install Python packages. If conda tells you the package you want doesn't exist, then use pip (or try conda-forge, which has more packages available than the default conda channel).\nIf you installed Python any other way (from source, using pyenv, virtualenv, etc.), then use pip to install Python packages\n\nPython virtual environnement #\nMain guide is here.\nsudo apt-get install python3-venv# cd to &lt;DIR> where python venv storedpython3 -m venv &lt;DIR># activatetutorial-env\\Scripts\\activate.bat # windowssource &lt;DIR>/bin/activate # linux# deactivatedeactivate\nTo detele, just remove the corresponding folder, i.e., &lt;DIR&gt;.\nConda #\nInstall / Update conda #\n# INSTALL CONDA BY PIP (without Anaconda)pip install conda\n# UPDATE CONDAconda update -n base -c defaults conda\nIf there is an error TypeError: LoadLibrary() argument 1 must be str, not None at the end of the log, try to activate the environment base before running above line.\nactivate base # on Windowssource activate base # on MacOS\nInstall packages with conda #\n# INSTALLactivate &lt;env> # you need to activate an environment firstconda install &lt;package> # install for &lt;env> only\n# UPDATEacctivate &lt;env> # choose an env firstconda update &lt;package> # ud package in that env\n# LIST ALL INSTALLED PACKAGESconda list\n# Update packages listed in an env file to current env,conda env update -n &lt;env> -f /path/to/&lt;file>.yml\n# example of yml filename: statsdependencies: - python=3.6 - geopandas==0.4.1\n# install packages with requirements.txtconda install --file requirements.txt\nEnvironment #\nCheck an official doc here or this useful post.\nCreate a new environment with python version 3.7:\nconda create -n &lt;env-name> python=3.7 anaconda\n# The same python version with current shell's Python interpreterconda create -n &lt;env-name> python\n# with addtional packages (python will be automatically installed)conda create -n &lt;env-name> &lt;package1> &lt;package2># with versionconda create -n &lt;env-name> &lt;package1>=1.16 &lt;package2>\n# in different directoryconda create --prefix /path/to/&lt;env-name>\n# create from file &lt;file>.ymlconda env create -n &lt;env> -f /path/to/&lt;file>.yml\n# Clone from another envconda create --name &lt;cloned-env> --clone &lt;env>\n\nMost of below commands are assumed to be run in an environment named env which is already activated. If you don't activate any environment before, use an alternative instead. For example,\nconda update pandas # &lt;env> activatedconda update -n &lt;env> pandas # &lt;env> isn't activatedconda update -p /path/to/&lt;env> # &lt;env> isn't in the default directory of conda\nconda env export -f &lt;file>.yml # &lt;env> activated &amp; current folderconda env export -n &lt;env> -f /path/to/&lt;file>.yml # &lt;env> isn't activated &amp; different folderconda update -p /path/to/&lt;env> -f /path/to/&lt;file>.yml # &lt;env> isn't in the default directory of conda &amp; different folder\n\n\n# Activate an envactivate &lt;env> # windowssource activate &lt;env> # linux / macos\n# DEACTIVE AN ENVconda deactivate # Linuxdeactivate # Windowssource deactivate # MacOS\n# REMOVE AN ENVconda remove -n &lt;env> --all\n# SHOW LIST OF CURRENT ENVconda info --envs# orconda env list\n# EXPORT TO A ENV FILEconda env export -f &lt;file>.yml\n\n# Update packages listed in an env file to current env,conda env update -n &lt;env> -f /path/to/&lt;file>.yml --prune\nKernel 2 &amp; 3 for Jupyter Notebook #\nCheck if nb_conda_kernels is installed by conda list. If not, install it by:\nconda install nb_conda_kernels\nIf you are using Python 2 and you wanna separate Python 3,\nconda create -n py37 python=3.7 ipykernel # \"py37\" is a custom name\nIf you are using Python 3 and you wanna separate Python 2,\nconda create -n py27 python=2.7 ipykernel # \"py37\" is a custom name\nRestart the Jupyter Notebook, the list of kernels is available under New.\nConda Revisions #\n\n# Check revisionsconda list --revisions\n# Go back to revision `1`,conda install --revision 1\n\nError? #\n# UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 975: ordinal not# solution: instead ofpip3 install sesd# useLC_ALL=C.UTF-8 pip3 install sesd\n# conda: The following packages are not available from current channels:# Solution 1: One can use pip in this case (the same env with conda)# Solution 2:conda install -c anaconda &lt;package>\n# The following required packages can not be built: * freetype (from matplotlib)# try to use conda to install matplotlibconda install matplotlib# it actually install the same thing as pip does on the same env\n# dtaidistance: C-library is not availablepip install -vvv --upgrade --force-reinstall dtaidistance\n# zsh: command not found: conda# Make sure your installation folder is already# in the $PATHexport PATH=\"/home/thi/miniconda3/bin:$PATH\"\n"},"/python-list/":{"id":"/python-list/","title":"Python List","keywords":"python list Mutable Create a list copy Access elements Nested list get length add more slices remove element pop clear coupling 2 lists sort arrange reverse map a function to each element index count len repeat a list random number int intersection","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"General #\n\nIndex starts with 0.\nSlice: x[1:4] gives elements from x[1] to x[3] inclusive (takes 1, not 4).\nx[:3] + x[3:] gives exactly x.\n\nProperties #\nOrdered (different order, different list):\n\nx = [1, 2]y = [1, 2]z = [2, 1]x == yx == z\nTrue\nFalse\n\n\nMutable (we can change elements in list),\n\nx = [1, 2, 3]x[1] = 5print(x)# change mutiple elementsy = [1, 2, 3, 4, 5]y[1:3] = [20, 30]print(y)\n[1, 5, 3]\n[1, 20, 30, 4, 5]\n\n\nCreate #\nDirectly,\n\nx = [1, \"Thi\", 3] # mixed datatypesy = [[1, 2, 3], [4, 5, 6]] # nested listz = [] # empty listprint(x)print(y)print(z)\n[1, 'Thi', 3]\n[[1, 2, 3], [4, 5, 6]]\n[]\n\n\nFrom other types,\n\na = (1, 2, 3) # tuplex = list(a)print(a)print(x)\n(1, 2, 3)\n[1, 2, 3]\n\n\nWith for (List comprehensions),\n\nx = [i for i in range(4)]print(x)\n[0, 1, 2, 3]\n\n\n# list comprehension with if[e for e in lst if e>0]# list comprehension with if else[x+1 if x >= 45 else x+5 for x in l]\n# 2 fors in list comprehension[(x,y) for x in seq_x for y in seq_y][entry for tag in tags for entry in entries if tag in entry]a = [[1,2], [3,4]]{i for e in a for i in e}# {1, 2, 3, 4}\nCreate a list from range,\n\n[*range(10, 21, 1)]\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n\n\nA list of random int numbers,\nrandom.sample(range(10, 30), 5)# [16, 19, 13, 18, 15]\nCopy #\nDon't use y = x directly!\n\nx = [1, 2, 3]y = xz = x.copy()t = x[:]u = list(x)x[2] = 30 # x changesprint(x)print(y) # y changes with xprint(z) # z doesn't changeprint(t) # t doesn't changeprint(u) # u doesn't change\n[1, 2, 30]\n[1, 2, 30]\n[1, 2, 3]\n[1, 2, 3]\n[1, 2, 3]\n\n\nAccess elements #\nNormal list (1 dimensional),\n\nx = [1, 2, 3, 4]print(x[0]) # single indexprint(x[:2]) # sliceprint(x[-2]) # negative index\n1\n[1, 2]\n3\n\n\nNested list,\n\ny = [[1, 2, 3], [4, 5, 6]]print(y[0][1]) # single elementprint(y[1]) # row 1print([row[1] for row in y]) # column 1\n2\n[4, 5, 6]\n[2, 5]\n\n\nGet length #\n\nx = [1, 2, 3, 4]y = [[1, 2, 3], [4, 5, 6]]print(len(x))print(len(y)) # number of rowsprint(len(y[0])) # number of columnsimport numpy as npnp.shape(y)\n4\n2\n3\n\n(3,4)\n\n\nAdd more elements #\n\nx = [1, 2, 3]x.append(4) # single elementprint(x)x.extend([5, 6]) # another listprint(x)\n[1, 2, 3, 4]\n[1, 2, 3, 4, 5, 6]\n\n\nAdd to desired positions,\n\nx = [1, 2]x.insert(30, 3) # at 30th position --> add to the lastprint(x)y = [1, 2]y.insert(1, 3)print(y)\n[1, 2, 3]\n[1, 3, 2]\n\n\nWith slices (it likes the intersection between indexes of the current list with indexes indicated in the slice):\n\nx = [1, 2]x[5:7] = [3, 4]print(x)y = [1, 2]y[2:2] = [3, 4, 5]print(y)\n[1, 2, 3, 4]\n[1, 2, 3, 4, 5]\n\n\nRemove elements #\nUsing the keyword del:\n\nx = [1, 2, 3, 4, 5]print(x)del x[1]print(x)del x[:2]print(x)del x # delete entire listprint(x)\n[1, 2, 3, 4, 5]\n[1, 3, 4, 5]\n[4, 5]\nNameError: name 'x' is not defined\n\n\nUsing .remove() to remove a value in list (it removes the first found value):\n\nx = [1, 2, 3, 4, 3]x.remove(3) # remove the first found value \"3\"print(x)\n[1, 2, 4, 3]\n\n\nIf you wanna remove all specific value from a list:\n\nx = [1, 2, 3, 4, 3]x = [i for i in x if i != 3]print(x)\n[1, 2, 4]\n\n\nUsing .pop() to remove and return the deleted element.\n\nx = [1, 2, 3, 4]y = x.pop(2) # delete at 2nd positionprint(x)print(y)z = x.pop() # delete the last elementprint(x)print(z)\n[1, 2, 4]\n3\n[1, 2]\n4\n\n\nUsing .clear() to empty a list:\n\nx = [1, 2, 3]x.clear()print(x)\n[]\n\n\nSpecial case, using a empty list:\n\nx = [1, 2, 3, 4]x[1:3] = []print(x)\n[1, 4]\n\n\n2 lists #\nIntersection #\nlist(set(a) &amp; set(b))\nCoupling 2 lists #\nUsing + and * (repeat),\n\nx = [1, 2, 3]print(x + [4, 5, 6])print([\"re\"] * 3)\n[1, 2, 3, 4, 5, 6]\n['re', 're', 're']\n\n\nSort a list #\nReturn a sorted list but not change the list:\n\nx = [1, 5, 3, 2, 4]print(sorted(x)) # ASCprint(sorted(x, reverse=True)) # DESCprint(x) # x doesn't change\n[1, 2, 3, 4, 5]\n[5, 4, 3, 2, 1]\n[1, 5, 3, 2, 4]\n\n\nSort and change a list:\n\nx = [1, 5, 3, 2, 4]x.sort() # return None, ASCprint(x) # x does changex.sort(reverse=True) # DESCprint(x)\n[1, 2, 3, 4, 5]\n[5, 4, 3, 2, 1]\n\n\nReverse a list #\n\nx = [1, 2, 3, 4]y = x[::-1] # x doesn't changeprint(x)print(y)x.reverse() # x changesprint(x)\n[1, 2, 3, 4]\n[4, 3, 2, 1]\n[4, 3, 2, 1]\n\n\nMap a function to each element #\nIf you wanna apply a function to each element in an iterable:\n\nsquare = lambda x: x * 2x = [1, 2, 3, 4] # can be tuple or other iterabley = map(square, x) # return a map objectprint(list(y))\n[1, 4, 9, 16]\n\n\nGet indexes #\nGet indexes with for #\n\ncourses = ['a', 'b', 'c']for idx, val in enumerate(courses, start=1): print(idx, val)\n1 a\n2 b\n3 c\n\n\nGet index of some element #\nlst.index(&lt;e>) # Returns the index of the first matched itemlst.index(max(lst)) # get the index of the max in list\nOther methods #\n\n.count(&lt;e&gt;): Returns the number of item &lt;e&gt; in list.\n\n"},"/python-tips/":{"id":"/python-tips/","title":"Python extra","keywords":"python tips swap 2 variables huyen chip clear variable __name__ __main__ __future__ reset del delete variable system reset confirmation elif else if inside lambda function","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Miscellaneous #\n\n\n; is not used, use spaces instead!\n\n\nIf you wanna 2 or more commands in 1 line, you can use ; to separate them.\n\n\nTab size usually is 4.\n\n\nLines can be broken with just an Enter, you also use \\ between the lines if you want.\n\n\nFrom Python 3.6, you can use 1_000_000 for the number 1000000.\n\n\nfrom __future__ import &lt;package&gt; allows current version of python to use &lt;package&gt; which is only available in the &quot;future&quot; version of python.\n\n\nif __name__ == &quot;__main__&quot;: determines the main running file of codes. The codes inside this command only run if the file containing it is the main executed file! [read more]\n\n\nIf we don't need to mention some variable, use _:\n\nfor _ in range(2): print(\"Thi\")\nThi\nThi\n\n\n\n\nSwap 2 variables #\na, b = b, a\nClear variables #\n# Clear (without confirmation) a variable from workspacedel &lt;var>%reset_selective &lt;var>\n# Check if available and then deleteif '&lt;var>' in globals(): del &lt;var># use locals() inside a def\n# Clear all variables%reset # with confirmation%reset -f # without confirmation\nReferences #\n\nHuyền Chip -- A gentle guide to Python features that I didn't know exist or was too afraid to use.\n\n"},"/git/":{"id":"/git/","title":"Git","keywords":"github git gitlab branches merge remove clone github desktop gitkraken push pull commit discard changes repository staged alias git gui gitk reset checkout ssh clone to local key rename branch local remote restore commit stash pull push -m -d -b master remote checkout -- . : -s ours FETCH HEAD comparelog -1 --prep status checkout gui graphic repository repo config credential.helper store --global git cheatsheet quit vim exit vim editor upstream corresponding local remote branches repo template notetheme notetheme2 fatal: Authentication failed for two factor authentication fast-forward fast forward git submodule sub module change remote","tags":["posts","Skills"],"cat":"/img/cats/skills.svg","content":"Quick references for basic tasks with git.\n👉 Note about Github.\nInstallation &amp; Tools #\n\nDownload and install (to use command lines): git's homepage.\nGit client tools: Github Desktop (Windows and MacOS, Linux), GitKraken (Windows, Linux, MacOS).\nRead html files in repository on Github: use this tool.\n\nRules to be more effective #\n\nDo commit early and often.[ref]\nDo make useful commit messages.\nCreate a new branch for every new feature.\nUse pull requests to merge code to master.[ref]\nFor temporary branches, name them starting with _.\n\nSettings on local machine #\n\n# SET GLOBAL INFOgit config --global user.name \"Anh-Thi DINH\"git config --global user.email \"dinhanhthi@gmail.com\"\n# SPECIFIC REPOgit config user.name \"Thi\"git config user.email \"thi@abc.com\"\n# Verify your configurationcat .git/config\n# IF: `Could not resolve host: github.com`git config --global --unset http.proxygit config --global --unset https.proxy\n\n# SAVE GITHUB AS DEFAULT# (don't need to log in again every time we use)git config credential.helper storegit pull\n# FORMATTING DISPLAYgit config color.ui true # add colors to the resultsgit config format.pretty oneline # disply only one line of each commit\nCheck the status #\n\n# CHECK STATUSgit statusgit status -s # modified files\n# Get remote listgit remote -v\n\n# WITH COLORSgit log --oneline --graph --color --all --decorate# --graph: draw text-based branches# --decorate: display names and tags\nCheck some commit:\ngit log -- &lt;file> # check commits containing &lt;file>git log --prep='abc' # look for commits containing \"abc\" in their namegit log &lt;from>..&lt;to> # display commints from &lt;from> to &lt;to> (commit's id, branch's name,...)\nCheck current HEAD\ngit log -1# something likes HEAD -> &lt;branch-name>\nCheck the change of some file,\ngit diff file_name.abc\nCheck the list of files in the last commit,\n# get the last commit idgit log --format=\"%H\" -n 1# list of filesgit diff-tree --no-commit-id --name-only -r &lt;commit_id>\nGit ignore #\nCreate a file .gitignore.\n\n# ignore.jekyll-cache.git__pycache__/\n__pycache__/# ignore all except/*# whitelist!.gitignore!/docker/\n\nIgnore local changes on some files from pull/push,\n# they are assumed to be unchangedgit update-index --assume-unchanged file_1 file_2# undogit update-index --no-assume-unchanged file_1 file_2# To get a list of dir's/files that are assume-unchangedgit ls-files -v|grep '^h'\nRepositories #\n\n# CREATE REPOgit init &lt;repo-name>\n# CLONE REPO (using https or ssh)git clone &lt;repo-link>\n\nGit GUI #\ngit guigitk\nStaged &amp; Commits &amp; Push &amp; Pull #\nStaged #\n# ADD MODIFICATION (1 FILE)git add * # add all the changesgit add &lt;file-name> # only add the &lt;file-name> to the staged\n\n# UNSTAGE A FILEgit reset HEAD &lt;file>\n# UNSTAGED EVERYTHINGgit reset\n\nCommit &amp; Push #\n\n# MAKE COMMIT (FROM STAGED)git commit -m '&lt;comment-for-this-commit>'git commit -a # commit any files\n# UNCOMMIT (back to before commit)git reset --soft HEAD~1\n\n# PUSH TO REMOTEgit push origin &lt;branch-name> # push only &lt;branch-name>git push --all origin # push all branches\n\n# CHECK &amp; TEST A COMMITgit checkout &lt;commit-id># after testinggit checkout &lt;current-branch>\n# Commit current dategit commit -m \"`date`\" # Wed Aug 28 10:22:06 CST 2019git commit -m \"`date +'%Y-%m-%d'`\" # 2019-08-28git commit -m \"Updated: `date +'%Y-%m-%d %H:%M:%S'`\" # Updated: 2019-08-28 10:22:06\n\nPull #\n\n# LIST ALL REMOTE REPOSgit remote -v\n# UPDATE REMOTE -> LOCALgit pull origin &lt;branch-on-remote>\n# Pull (fetch) a branch from remotegit checkout --track origin/&lt;branch>\n# COPY A COPY FROM REMOTEgit fetch origin &lt;branch-on-remote># compare current branch to this copygit diff --stat FETCH_HEAD\n\nDifference between git pull --rebase and git pull --ff-only[ref],\n\n--rebase: remote changes (C) will be applied before local changes (D) resulting in the following tree\n\nA -- B -- C -- D\n\n--ff-only: fail if there are conflicts, otherwise, it will work!\n\nBranches #\nCreate #\n# CREATE A BRANCHgit branch &lt;branch-name>\n# CREATE AND MOVE TO NEW BRANCH# This one is based on the current `HEAD` (git log -1).git checkout -b &lt;new-branch># new branch based on another onegit checkout -b &lt;new-branch> &lt;existing-branch>\nTwo branches #\n# CHANGE TO ANOTHER BRANCHgit checkout &lt;branch-name># fatal: 'dev' could be both a local file and a tracking branch.git checkout &lt;branch_name> --\n# UPDATE ALL REMOTE BRANCHES TO LOCAL# (there may be deleted branches on remote)git remote update origin --prune\n\n# LIST ALL LOCAL BRANCHESgit branch\n# LIST ALL LOCAL + REMOTEgit branch -a\n\nComparing #\n\n# compare current branch with othergit diff &lt;branch>\n# COMPARE 2 BRANCHESgit diff &lt;source-branch> &lt;compared-branch>\n# a specific filegit diff mybranch master -- myfile\n# list all diff files: current vsgit diff --name-status master\n# 2 files vsgit diff mybranch master --name-status# can be \"--name-only\"\n# LOCAL &lt;-> REMOTE BRANCHESgit branch -vv\n\n# save to log filegit diff --output=log.txt branch_1 branch_2 --name-status\n# CORRESPONDING LOCAL BRANCH &lt;-> REMOTEgit fetchgit branch --set-upstream-to=origin/&lt;remote_branch> &lt;local_branch>\nDelete #\n\n# DEL A LOCAL BRANCHgit branch -d &lt;branch-name>git branch -D &lt;branch> # force to delete\n# DEL A REMOTE BRANCHgit push origin :&lt;branch-name>\n\nMerge #\n# MERGE &lt;branch> TO CURRENTgit merge &lt;branch>\n# MERGE &lt;sub-branch> TO master + REPLACE mastergit checkout &lt;sub-branch>git merge -s ours mastergit checkout mastergit merge &lt;sub-branch># master can be other\n# MERGE `/link/to/abc.xyz` FROM `&lt;branch-1>` TO `&lt;branch-2>` (can be `master`)git checkout branch-2git checkout branch-1 /link/to/abc.xyz\n# MERGE ONLY SOME FOLDERgit checkout &lt;branch>git checkout &lt;from-branch> folder1\\ folder2\\\n# MERGE commit from ONE BRANCH to CURRENTgit cherry-pick &lt;commit hash>\n# KEEP FILES/FOLDERS FROM MERGE# add line to .gitattributesecho 'file_name.txt merge=ours' >> .gitattributes\nConflict #\nIf there are changes from both local and remote, there will be conflicts! Something likes that,\n&lt;&lt;&lt;&lt;&lt;&lt; HEADchanges on local======changes from remote>>>>>> template/notetheme2\nIf you use Visual Studio Code, there is a small toolbar above each conflict and you can choose which one you prefer to keep!\nPrefer one of them?\n\n# keep remote changesgit pull -X theirs &lt;remote-repo>\n# keep local changesgit pull -X ours &lt;remote-repo>\n\nKeep both? Using Visual Studio Code or,\n# add below line to .gitattributes (on branch being merged)echo \"*.whatever merge=union\" .gitattributes# on windows, remove `\"\"`\nAlready in conflicted state?\n\ngit checkout --theirs path/to/file # remotegit checkout --ours path/to/file # local\n# Abort the conflicts# (go back to before merging)git merge --abort\n\nExclude from merging #\nExclude some files from merge (keep ours),\n# ONLY FOR FILES# add below line to .gitattributes (on branch being merged)echo \"file.ext merge=ours\" .gitattributes# on windows, remove `\"\"`\nExclude some folders (we cannot use git in this case):\n\n\nIf you delete these folders after merging, just commit and later merges will ignore them.\n\n\nIf you meet a conflict, add the folder's name in a file called reset_folders.sh,\n#!/bin/shecho 'Reset some only-this-branch folders after merging.'git reset folder_1, folder_2git checkout .git add .git commit -m \"update from merge (keep local in some folders)\"\nEach time,\ngit merge &lt;from-branch> &amp;&amp; sh reset_folders.sh\n\n\nRename #\n# CURRENT BRANCHgit branch -m &lt;newname>git branch -M &lt;newname> # if there are only capitalization changes\n# CURRENT IS ANOTHER BRANCHgit branch -m &lt;oldname> &lt;newname>\n# RENAME REMOTE BRANCH (delete old + push new)# (rename local branch first)git push origin :&lt;oldname> &lt;newname># reset the upstream branch for the new-name local branchgit checkout &lt;newname>git push origin -u &lt;newname>\nOthers #\nAdd a description (using Vim editor):\ngit branch --edit-description\nIn the case you wanna exit Vim, press ESC then type :q to quit or :wq to write and quit.\nRemove from git #\nRemove from git, not from system,\n\n# a filegit rm --cached &lt;file_name>\n# a foldergit rm -r --cached &lt;folder>\n\nDiscard the changes #\n# DISCARD CHANGES ON CURRENT DIRgit checkout -- . # for all changesgit checkout -- &lt;file-name> # for a specific file (go back the last commit of this file)\n# DISCARD ALL LOCAL CHANGESgit reset --hard\nIn the case you want to discard the changes but want to make a save before moving to another branch to test. You can use below line.\ngit stash\nIf you wanna get back to the place you saved (and remove it from the stashed list), just go back to the branch you make the save and use\ngit stash pop\nRestore #\n# RESTORE FROM LAST COMMITgit checkout -- &lt;file>\n# DISCARD ALL CHANGES ON LOCAL + GET FROM REMOTEgit fetch origingit reset --hard origin/master\n# DISCARD ALL CHANGES + get the last update from remotegit reset --hard @{u}\n# EREASE ALL COMMITS + BACK TO &lt;commit-id>git reset --hard &lt;commit_id># (force) to pushgit push -f origin master\nChange remote url #\n# check the current remote urlcat .git/config| grep \"url\"# change to the new onegit remote set-url origin new.git.url/here\nAlias #\n# use `git br` instead of `git branch`git config alias.br branch\nGitlab: Clone a private repo to local #\n\n(Windows) Generate a ssh key ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; in C:\\Users\\dinha\\.ssh under the name id_rsa (for private) and id_rsa.pub for public. It's important, the name!!!!\nOpen and copy key in C:\\Users\\dinha\\.ssh\\id_rsa.pub\nGo to Gitlab &gt; Settings &gt; SSH Keys &gt; paste a copied key and name it.\nClone again the repo and it shoule be working!\n\nErrors #\n# error: invalid object Error building treesgit hash-object -w &lt;error-file>\nYou can also go back to the previous commit (git reset --hard) and you LOSE all uncommit files.\n\nWARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!\nGo to ~/.ssh/ (Linux) or C:\\Users\\dinha\\.ssh (Windows), remove the host from known_hosts and re-connect again.\nGit submodules #\nGit submodules allow you to keep a git repository as a subdirectory of another git repository.\n# \"git clone\" &amp; \"git pull\" to automatically update submodules.git config --global submodule.recurse true# public repo: github.com/you/blog (clone)# private repo: github.com/you/postscd bloggit submodule add https://github.com/you/posts # blog/posts\n# update submodulesgit submodule update --remote# don't make change on the folder of submodules!!!!\n# clone a repo with submodulesgit clone &lt;repo> --recursive# orgit clone &lt;repo>git submodule initgit submodule update\nOthers #\n\nfast-forward means that the commits can be applied directly on top of the working tree without requiring a merge. When git pull and get this message, we can be sure that the new update are not confict with our current modifications.\nFind big files / commits: Using this scripts and this answer.\n\n"},"/jupyter-notebook/":{"id":"/jupyter-notebook/","title":"Jupyter Notebook","keywords":"pip conda hotkey magic function display side by side dataframes previous output hotkeys install packages multiline commands shortcuts pip conda figures markdown cell code cell check info system autoreload inline history description of a function IPython sys display_side_by_side version update upgrade jupyter notebook on remote server OSError: [Errno 99] Cannot assign requested address Running as root is not recommended localhost port ssh connection Cannot assign requested address list of variable environement toc extension table of content docker docker-compose SHA1 sha password hashed","tags":["posts","Skills"],"cat":"/img/cats/skills.svg","content":"Installation #\nJupyter notebook #\n\n# BY PIPpip install --upgrade pippip install --upgrade ipython jupyter\n# BY CONDAconda install ipython jupyter\n\nOr read more in this note.\nIf you meet error OSError: [Errno 99] Cannot assign requested address, try\njupyter notebook --ip=127.0.0.1 --port=8080# orjupyter notebook --ip=127.0.0.1 --port=8080 --allow-root\nSetting up a password #\n# create a juputer notebook config file# it can be used for other settings# https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#prerequisite-a-notebook-configuration-filejupyter notebook --generate-config# create a new password# note: sha1 cannot be reverted!!jupyter notebook password\nInside notebook:\nfrom notebook.auth import passwdpasswd()\nWith docker\n# create a sha1 password# download file create_sha1.py from https://github.com/dinhanhthi/scripts# run ./create_sha1.py# docker-compose.ymlenvironment: - PASSWD='sha1:d03968479249:319e92302e68d601392918f011d6c9334493023f'# DockerfileCMD /bin/bash -c 'jupyter lab --no-browser --allow-root --ip=0.0.0.0 --NotebookApp.password=\"$PASSWD\" \"$@\"'\nR with jupyter notebook #\nRead more here.\n# install jupytersudo apt-get install libzmq3-dev libcurl4-openssl-dev libssl-dev jupyter-core jupyter-client# install R on linuxsudo apt install r-base# R kernel for Jupyter NotebookR # enter R environnement# install R kernelinstall.packages(c('repr', 'IRdisplay', 'IRkernel'), type = 'source')# orinstall.packages(c('repr', 'IRkernel'), type = 'source')# make jupyter see r kernelIRkernel::installspec() # current userIRkernel::installspec(user = FALSE) # global\n# embedded R# use by cell magic %%Rpip install rpy2# in a notebook%load_ext rpy2.ipython# then use%%R# R's codes\nOther tips #\n\nRunning 2 tasks in the same cell TAKE LONGER TIME than running each on different cells.\nDownload a folder in jupyter notebook:\n\n\nInside notebook, use:\n%%bashtar -czf archive.tar.gz foldername\n\n\nOr using nbzip (only working on current server).\n\n\n\n\nCheck the info #\n\n# function's info?&lt;func-name>\n# function's shortcode??&lt;func-name>\n# get the list of current variableswhos\n\nCheck where command executed from (in your $path)?\n\n!type python\npython is /Users/thi/anaconda/envs/python3.6/bin/python\n\n\nMultiline commands #\n# Using '\\'df.columns = df.columns.str.replace('.', ' ')\\ .str.replace('\\s+', ' ')\\ .str.strip().str.upper()\nYou CANNOT put # comments at the end of each line break!\nHotkeys / Shortcuts #\nThere are 2 modes: command mode (pres ESC to activate) and edit mode (Enter to activate). Below are the most useful ones (for me).\nYou can edit / add more shortcuts in Help &gt; Edit Keyboard Shortcuts.\nClick to see the full listFor both modes,\n\n\nShift + Enter run the current cell, select below.\nCtrl + Enter run selected cells.\nAlt + Enter run the current cell, insert below.\nCtrl + S save and checkpoint.\n\nCommand modes,\n\n\nEnter take you into edit mode.\nH show all shortcuts.\nUp / Down select cell above / below.\nShift + Up / Down extend selected cells above / below.\nA / B insert cell above / below.\nX cut selected cells.\nC copy selected cells.\nV / Shift + V paste cells below / above.\nD, D (press the key twice) delete selected cells.\nZ undo cell deletion.\nS Save and Checkpoint.\nY change the cell type to Code.\nM change the cell type to Markdown.\n\nEdit mode,\n\n\nEsc take you into command mode.\nTab code completion or indent.\nCtrl + ] indent.\nCtrl + [ dedent.\nCtrl + A select all.\nCtrl + Z undo.\nCtrl + Shift + Z or Ctrl + Y redo.\n\n\nJupyter notebook on remote server #\nOpen jupyter notebook in local browser but the backend-server is on remote.\n\n\nIf jupyter server is already running on remote at http://192.168.0.155:9889,\nssh -N -L localhost:9888:192.168.0.155:9899 &lt;username-remote>@&lt;remote-host> -p &lt;port># if there is no port, remove `-p &lt;port>`\nOpen browser: http://localhost:9888 (type password if needed).\n\n\nIf jupyter server is not running on remote yet,\n# connect to remotessh &lt;username-remote>@&lt;remote-host> -p &lt;port># if there is no port, remove `-p &lt;port>`\nOn remote,\n# run juputer with custom portjupyter notebook --no-browser --port=9899# if there is error `OSError: [Errno 99] Cannot assign requested address`jupyter notebook --ip=0.0.0.0 --no-browser --port=9899# if there is error `Running as root is not recommended`jupyter notebook --ip=0.0.0.0 --no-browser --port=9899 --alow-root\nIt's running and there are somethings like that,\nhttp://127.0.0.1:9889/?token=717d9d276f0537a9...831793df6319ad389accd\nOpen another terminal window and type,\nssh -N -L localhost:9888:localhost:9889 &lt;username-remote>@&lt;remote-host> -p &lt;port># if there is no port, remove `-p &lt;port>`# there is nothing but it's running\nOpen browser: http://localhost:9888/?token=717d9d276f0537a9...831793df6319ad389accd.\n\n\nYou can choose any port number you wanna instead of 9888 and 9889 (they can be the same), note that, you need to use a port number GREATER THAN 8000!\nInstall new python package inside Jupyter Notebook #\nUsing condaref(https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/),\n# Install a conda package in the current Jupyter kernelimport sys!conda install --yes --prefix {sys.prefix} numpy# DON'T DO THIS!conda install --yes numpy\nUsing pip,\n# Install a pip package in the current Jupyter kernelimport sys!{sys.executable} -m pip install numpy# DON'T DO THIS!pip install numpy\nCheck version and update/upgrade,\n!pip show pandas\nDisplay dataframes side-by-side #\nfrom IPython.display import display_htmldef display_side_by_side(*args): html_str='' for df in args: html_str+=df.to_html() display_html(html_str.replace('table','table style=\"display:inline; margin-right: 5px;\"'),raw=True)\ndisplay_side_by_side(df1,df2,df1)\nGet previous outputs #\n_ # previous output__ # second-to-last output___ # third-to-last output\nDisplay 2 figures side-by-side markdown cell #\nPut below codes in the markdown cell of Jupyter Notebook.\n&lt;tr> &lt;td> &lt;img src=\"Nordic_trails.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> &lt;/td> &lt;td> &lt;img src=\"Nordic_trails.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> &lt;/td>&lt;/tr>\nMagic Functions #\n\nCheck the full list (in examples) here or their docs here.\nYou can define your custom magic functions here.\n\nAuto update the new updated modules (put at the beginning of the notebook)\n%load_ext autoreload%autoreload 2 # Reload all modules every time before executing%autoreload 0 # disable autoreloader\nCheck more settings of %autoreload here.\nShow the plots inside the notebook:\n%matplotlib inline\nGet the commands from 1 to 4:\n%history -n 1-4 # get commands 1 to 4\nExtensions #\nTable of contents #\n\nInstall npm and nodejs.\nInstall this extension.\nEnable in jupyter lab view.\nRefresh the page.\n\n# errors# UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 23: ordinal not in range(128)npm config set unicode false\nDebugger #\n\nInstall xeus-python, jupyterlab\n\npip install xeus-pythonpip install jupyterlab\n\nInstall this extension.\nRefresh the page, you have to choose kernel xpython (instead of Python 3) to use the debugger.\n\n"},"/python-with-sublime-text/":{"id":"/python-with-sublime-text/","title":"Sublime Text 3","keywords":"theme sublime text IDE tabnine build system anaconda python","tags":["posts","Skills"],"cat":"/img/cats/skills.svg","content":"This instruction taken from a video of Corey Schafer. You need to install Sublime Text 3 and its Package Control to do below stuffs.\nTheme #\nInstall theme Predawn and Material Theme:\n\nOpen Command Palette (Tool &gt; Command Palette or Ctrl + Shift + P). Type install to open Package Control: Install Package.\nSearch and install Predawn and Material Theme.\n\nPersonal settings #\nOpen Preferences &gt; Settings, replace the content in tab -User by,\nShow settings{\t\"bold_folder_labels\": true,\t\"caret_extra_width\": 1,\t\"caret_style\": \"phase\",\t\"close_windows_when_empty\": false,\t\"color_scheme\": \"Packages/Predawn/predawn.tmTheme\",\t\"copy_with_empty_selection\": false,\t\"detect_indentation\": false,\t\"drag_text\": false,\t\"draw_minimap_border\": true,\t\"enable_tab_scrolling\": false,\t\"ensure_newline_at_eof_on_save\": true,\t\"file_exclude_patterns\":\t[\t\t\"*.pyc\",\t\t\"*.pyo\",\t\t\"*.exe\",\t\t\"*.dll\",\t\t\"*.obj\",\t\t\"*.o\",\t\t\"*.a\",\t\t\"*.lib\",\t\t\"*.so\",\t\t\"*.dylib\",\t\t\"*.ncb\",\t\t\"*.sdf\",\t\t\"*.suo\",\t\t\"*.pdb\",\t\t\"*.idb\",\t\t\".DS_Store\",\t\t\"*.class\",\t\t\"*.psd\",\t\t\"*.sublime-workspace\"\t],\t\"folder_exclude_patterns\": [\".svn\", \".git\", \".hg\", \"CVS\",\t\t\"_site\", \"vendor\", \".jekyll-cache\", \"img\"\t],\t\"font_face\": \"Source Code Pro\",\t\"font_options\":\t[\t\t\"no_round\"\t],\t\"font_size\": 13,\t\"highlight_line\": true,\t\"highlight_modified_tabs\": true,\t\"ignored_packages\":\t[\t\t\"Vintage\"\t],\t\"line_padding_bottom\": 1,\t\"line_padding_top\": 1,\t\"match_brackets_content\": true,\t\"match_selection\": true,\t\"match_tags\": false,\t\"material_theme_accent_graphite\": true,\t\"material_theme_compact_sidebar\": true,\t\"open_files_in_new_window\": false,\t\"overlay_scroll_bars\": \"enabled\",\t\"preview_on_click\": false,\t\"scroll_past_end\": true,\t\"scroll_speed\": 5.0,\t\"shift_tab_unindent\": true,\t\"show_definitions\": false,\t\"show_encoding\": true,\t\"show_errors_inline\": false,\t\"show_full_path\": false,\t\"sidebar_default\": true,\t\"tab_size\": 2,\t\"theme\": \"Adaptive.sublime-theme\",\t\"translate_tabs_to_spaces\": true,\t\"trim_trailing_white_space_on_save\": true,\t\"use_simple_full_screen\": true,\t\"word_wrap\": true}\n\nUseful packages #\nInstall other useful packages (the same way as installing Predawn):\n\n\nBracketHighlighter: indicate the paired bracket.\nSidebarEnhancement: add more options to sidebar.\nTabNine: autocomplete extension using deep learning.\n\nPython #\nPackages #\n\n\nAnaconda: after installing this package, go go Preferences &gt; Package settings &gt; Anaconda &gt; Settings - Users &gt; paste following content,\n \n \n Show settings\n \n \n{\t\"auto_formatting\": true,\t\"autoformat_ignore\":\t[\t\t\"E309\",\t\t\"E501\"\t],\t\"pep8_ignore\":\t[\t\t\"E309\",\t\t\"E501\"\t],\t\"anaconda_linter_underlines\": false,\t\"anaconda_linter_mark_style\": \"none\",\t\"display_signatures\": false,\t\"disable_anaconda_completion\": true}\n \n \n\n\nCustom Build Systems #\nIf you wanna create different Build Systems w.r.t different versions of Python: Tools &gt; Build System &gt; New Build System... &gt; paste following codes (replace the directory to the directory of Python version that you want to use).\n{ \"cmd\": [\"/home/thi/anaconda3/bin/python\", \"-u\", \"$file\"], \"file_regex\": \"^[ ]*File \\\"(...*?)\\\", line ([0-9]*)\", \"quiet\": true}\nIn order to run codes, you need to choose the build system first, then use Ctrl + B.\nMarkdown #\n\n\nInstall package MarkdownEditting.\n\n\nChange hotkeys: Prefereces &gt; Package Settings &gt; Markdown Editing &gt; Key Bindings - User\n \n \n Show settings\n \n \n[\t{ \"keys\": [\"ctrl+b\"], \"command\": \"run_macro_file\", \"args\": {\"file\": \"Packages/MarkdownEditing/macros/Transform Word - Bold.sublime-macro\"}, \"context\":\t\t[\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": true, \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"ctrl+b\"], \"command\": \"insert_snippet\", \"args\": {\"contents\": \"${MD_BOLD_MARKER}$1${MD_BOLD_MARKER}\"}, \"context\":\t\t[\t\t\t{ \"key\": \"setting.auto_match_enabled\", \"operator\": \"equal\", \"operand\": true },\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": true, \"match_all\": true },\t\t\t{ \"key\": \"following_text\", \"operator\": \"regex_contains\", \"operand\": \"^(?:\\t| |\\\\)|]|\\\\}|$)\", \"match_all\": true },\t\t\t{ \"key\": \"preceding_text\", \"operator\": \"not_regex_contains\", \"operand\": \"['a-zA-Z0-9_]$\", \"match_all\": true },\t\t\t{ \"key\": \"eol_selector\", \"operator\": \"not_equal\", \"operand\": \"string.quoted.single\", \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"ctrl+b\"], \"command\": \"insert_snippet\", \"args\": {\"contents\": \"${MD_BOLD_MARKER}${SELECTION/(^[\\\\*_]*|[\\\\*_]*$)//g}${MD_BOLD_MARKER}\"}, \"context\":\t\t[\t\t\t{ \"key\": \"setting.auto_match_enabled\", \"operator\": \"equal\", \"operand\": true },\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": false, \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"ctrl+b\"], \"command\": \"run_macro_file\", \"args\": {\"file\": \"Packages/MarkdownEditing/macros/Transform Word - Unbold Unitalicize.sublime-macro\"}, \"context\":\t\t[\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": true, \"match_all\": true },\t\t\t{ \"key\": \"preceding_text\", \"operator\": \"regex_contains\", \"operand\": \"\\\\b__+\\\\S+__+$\", \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t// italics on Alt + I\t{ \"keys\": [\"alt+i\"], \"command\": \"run_macro_file\", \"args\": {\"file\": \"Packages/MarkdownEditing/macros/Transform Word - Italic.sublime-macro\"}, \"context\":\t\t[\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": true, \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"alt+i\"], \"command\": \"insert_snippet\", \"args\": {\"contents\": \"${MD_ITALIC_MARKER}$0${MD_ITALIC_MARKER}\"}, \"context\":\t\t[\t\t\t{ \"key\": \"setting.auto_match_enabled\", \"operator\": \"equal\", \"operand\": true },\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": true, \"match_all\": true },\t\t\t{ \"key\": \"following_text\", \"operator\": \"regex_contains\", \"operand\": \"^(?:\\t| |\\\\)|]|\\\\}|$)\", \"match_all\": true },\t\t\t{ \"key\": \"preceding_text\", \"operator\": \"not_regex_contains\", \"operand\": \"['a-zA-Z0-9_]$\", \"match_all\": true },\t\t\t{ \"key\": \"eol_selector\", \"operator\": \"not_equal\", \"operand\": \"string.quoted.single\", \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"alt+i\"], \"command\": \"insert_snippet\", \"args\": {\"contents\": \"${MD_ITALIC_MARKER}${SELECTION/(^[\\\\*_]*|[\\\\*_]*$)//g}${MD_ITALIC_MARKER}\"}, \"context\":\t\t[\t\t\t{ \"key\": \"setting.auto_match_enabled\", \"operator\": \"equal\", \"operand\": true },\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": false, \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"alt+i\"], \"command\": \"insert_snippet\", \"args\": {\"contents\": \"${SELECTION/(^[\\\\*_]|[\\\\*_]$)//g}\"}, \"context\":\t\t[\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": false, \"match_all\": true },\t\t\t{ \"key\": \"text\", \"operator\": \"regex_match\", \"operand\": \"^[*_].*[*_]$\", \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"alt+i\"], \"command\": \"run_macro_file\", \"args\": {\"file\": \"Packages/MarkdownEditing/macros/Transform Word - Unbold Unitalicize.sublime-macro\"}, \"context\":\t\t[\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": true, \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown markup.italic.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"alt+i\"], \"command\": \"run_macro_file\", \"args\": {\"file\": \"Packages/MarkdownEditing/macros/Transform Word - Unbold Unitalicize.sublime-macro\"}, \"context\":\t\t[\t\t\t{ \"key\": \"selection_empty\", \"operator\": \"equal\", \"operand\": true, \"match_all\": true },\t\t\t{ \"key\": \"preceding_text\", \"operator\": \"regex_contains\", \"operand\": \"\\\\b_(?!_)\\\\S+_$\", \"match_all\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t// run paste as link command on selected text\t{ \"keys\": [\"ctrl+k\"], \"command\": \"reference_new_inline_link\", \"context\":\t\t[\t\t\t{ \"key\": \"setting.mde.keymap_disable.reference_new_inline_link\", \"operator\": \"not_equal\", \"operand\": true },\t\t\t{ \"key\": \"selector\", \"operator\": \"equal\", \"operand\": \"text.html.markdown\", \"match_all\": true }\t\t]\t},\t{ \"keys\": [\"shift+alt+b\"], \"command\": \"toggle_side_bar\" },]\n \n \n\n\nMake main window be on left (not center): Prefereces &gt; Package Settings &gt; Markdown Editing &gt; Markdown GFM Settings - User\n{\t\"color_scheme\": \"Packages/Predawn/predawn.tmTheme\",\t\"draw_centered\": false,\t\"highlight_line\": true,}\n\n\n"},"/jekyll-tips/":{"id":"/jekyll-tips/","title":"Jekyll + Liquid","keywords":"lunrjs search js javascript content keywords jekyll markdown span markdown=\"1\" enlarge photo click to zoom in bigger photo bootstrap 4 run build jekyll site with draft posts --draft -I render the changes kramdown create plugin ruby hide show box nested block crossed using variables _plugins .rb badge liquid customizable liquid tags include proud of custom plugins custom domain rouge css syntax highlight pygment compress html jemoji emoji kramdown quick reference parse block html faster build jekyll-feed feed javascript benchmark liquid-c --profile profile jekyll-include-cache include cache jekyll clean cache clear list of posts alpha beta order ABC order sort posts category by name localhost list of tags list of categories github pages gems","tags":["posts","Web Dev","Jekyll","Static Site Generators"],"cat":"/img/cats/web-dev.svg","content":"This note is used for you who have already had the basic idea about jekyll and how to create a jekyll site. This note is only for quickly reference.\nUseful links #\n\n\nJemoji cheat sheet.\nLink to post / page.\nJekyll cheat sheet.\nRouge CSS file theme (Pygment)\nCompress HTML in Jekyll.\nKramdown quickref.\nOfficial dependencies / gems supported by Github Pages.\n\n\nUsing docker to run/deploy jekyll #\nRead this readme. An example is an old version of this site.\nInstall and run Jekyll on fresh machine #\nUbuntu #\n# install ruby-devsudo apt install ruby-dev# install bundlersudo gem install bundler# clone a jekyll theme# cd to that theme# install gems in the themebundle install --path vendor/bundle# servebundle exec jekyll serve# If error \"ExecJS and could not find a JavaScript runtime\"sudo apt-get install nodejs\nWindows #\nFollow this guide using WSL2 on Windows.\nMake jekyll build faster #\n\n# BENCHMARKING your sitebundle exec jekyll build --profile\n# clean cachebundle exec jekyll clean\n\n\nDisable jekyll-feed\nRun bundle exec jekyll serve -I (wuth -I) to generate the changed file only. If you create a new file, open a new terminal tab and run bundle exec jekyll build.\nUpgrade to Jekyll 4.0.\nAdd gem &quot;liquid-c&quot; to Gemfile and make bundle update\nUse jekyll-include-cache (both in Gemfile and _config.yml)\n\nRead more in this article.\nDisable jekyll-feed #\n\nComment line jekyll-feed in Gemfile\nComment line jekyll-feed in _config.yml\nRebuild.\n\nSitemap #\nIf in sitemap, there is error like &lt;loc&gt;/reading&lt;/loc&gt;, check your _config.yml + make sure there is an url inside url field.\nLoop through posts #\n{% for post in site.posts %} {{ post.title }}{% endfor %}\n\nIf you using baseurl,\n# in _config.ymlurl: \"\"baseurl: \"/tools\"\n&lt;ol>\t{% for post in site.posts %}\t&lt;li>\t\t&lt;a href=\"{{ site.baseurl }}{{ post.url }}\">{{ post.title }}&lt;/a>\t&lt;/li>\t{% endfor %}&lt;/ol>\n\nList all posts in each category,\n{% for category in site.data.categories %} {% if site.categories[category.name].size > 0 %} {% for post in site.categories[category.name] %} {{ post.title }} {% endfor %} {% endif %}{% endfor %}\nList all posts in ABC order[ref],\n{% assign sortedPosts = site.posts | sort: 'title' %}{% for post in sortedPosts %} {{ post.title }}{% endfor %}\nList of categories and tags in a single line with commas,\n{% for category in site.categories reversed %}{% capture category_name %}{{ category | first }}{% endcapture %}&lt;a href=\"{{site.url}}{{site.baseurl}}/#{{category_name | replace: \" \",\"_\"}}\">{{ category_name }}&lt;/a>{% if forloop.length > 1 and forloop.last != true %}, {% else %}.{% endif %}{% endfor %}\n{% for tag in site.tags %}{% capture test %}{{tag[0] | slice: 0}}{% endcapture %}{% capture testup %}{{tag[0] | slice: 0 | upcase}}{% endcapture %}&lt;a href=\"#{{tag[0] | slugify}}{% if test == testup %}_cap{% endif %}\">{{tag[0]}}&lt;/a>{% if forloop.length > 1 and forloop.last != true %}, {% else %}.{% endif %}{% endfor %}\nEdit tags for all posts #\nRead this source code.\nUsing markdown syntax inside html tags #\nYou can use directly by\n&lt;span markdown=\"span\">&lt;/span>&lt;div markdown=\"1\">&lt;/div>\nof only once,\n{::options parse_block_html=\"true\" /}&lt;!-- other html + markdown inside -->\nOr even shorter,\nTesting {::nomarkdown}**see**{:/} and test.\n\nCheck version #\n\nLocal gems: gem list jekyll.\nCurrent jekyll version of website: check Gemfile. Need to run bundle update if change any version in this file.\n\nLink to posts #\n[Name of Link]({% post_url 2010-07-21-name-of-post %})\n\nEdit this post on github (put below link in your post layout),\nhttps://github.com/dinhanhthi/dinhanhthi.com/edit/master/{{path.path}}\n\nCustom domain &amp; repository with Jekyll sites #\nThere are several choices for you to choose, it depends on your need.\nYou don't have a custom domain #\n\nSuppose your github account is &lt;username&gt;.\nCreate a repo &lt;username&gt;.github.io.\nPut your site in branch master (default).\nYour site is published at https://&lt;username&gt;.github.io\n\nIf you wanna store your site in a custom repo, e.g. mysite:\n\n\nCreate a branch gh-pages + set it as default + store your site here.\nRemove content at url: in _config.yml.\nYour site is live at https://&lt;username&gt;.github.io/mysite/\n\nYou have a custom domain #\n\nCreate file CNAME at root and put &lt;customdomain&gt;.com in it.\nCreate A or CNAME record in DNS provider. Check more.\nYou can also use netlify to set all things up automatically.\n\nUsing custom plugins? #\n\nBuild your site locally and get a folder _site.\nPut it to github and see the results.\n\nYou can also use netlify, it accepts custom plugin as well.\nUsing _data with include #\nYou can use,\n{% include proud-of.html data=site.data.proudof-notes %}\n\nwhere there is a data file located in _data/proudof-notes.yml.\nCreate a custom tags/blocks #\nRefs #\n\nOfficial Jekyll guid.\nHow to create customizable Liquid tags in Jekyll by Sverrir Sigmundarson.\nCreating an Accordion Plugin for Jekyll by Mike Lui.\n\nTag with single parameter #\n\n{% render_time page rendered at: %}\n\npage rendered at: Tue June 22 23:38:47 –0500 2010\n\nInside folder _plugins, create a file thi_single_tag.rb whose content is,\nmodule Jekyll class RenderTimeTag &lt; Liquid::Tag def initialize(tag_name, text, tokens) super @text = text end def render(context) \"#{@text} #{Time.now}\" end endendLiquid::Template.register_tag('render_time', Jekyll::RenderTimeTag)\nTag with two parameters #\n\n{% badge update | green %}\n\n&lt;span class=\"tbadge badge-green\">update&lt;/span>\n\nInside folder _plugins, create a file thi_badge.rb whose content is,\nclass Badge &lt; Liquid::Tag def initialize(tag_name, input, tokens) super @input = input end def render(context) # Split the input variable (omitting error checking) input_split = split_params(@input) text = input_split[0].strip color = input_split[1].strip # Write the output HTML string output = &lt;&lt;~EOS &lt;span class=\"tbadge badge-#{color}\">#{text}&lt;/span> EOS # Render it on the page by returning it return output; end def split_params(params) params.split(\"|\") endendLiquid::Template.register_tag('badge', Badge)\nBlock with single parameter #\nFor example, we wanna create a custom block alertbox using class from Bootstrap.\n\n{% alertbox warning %}\nContent\n{% endalertbox %}\n\n&lt;div class=\"alert alert-warning\" role=\"alert\" markdown=\"1\">Content&lt;/div>\n\nInside folder _plugins, create a file thi_alert.rb whose content is,\nmodule Jekyll class Alertbox &lt; Liquid::Block def initialize(tag_name, input, liquid_options) super @input = input.strip end def render(context) content = super case @input when \"warning\" box_type = 'warning' when \"success\" box_type = 'success' when \"primary\" box_type = 'primary' when \"secondary\" box_type = 'secondary' when \"danger\" box_type = 'danger' when \"info\" box_type = 'info' when \"light\" box_type = 'light' when \"dark\" box_type = 'dark' end output = &lt;&lt;~EOS &lt;div class=\"alert alert-#{box_type}\" markdown=\"1\"> #{content} &lt;/div> EOS end endendLiquid::Template.register_tag('alertbox', Jekyll::AlertBox)\nNested blocks with crossed-using variables #\nA more complicated example, suppose that you wanna create a hide/show box using Bootstrap's Collapse, you can use below shortcode. Its advantage is that you don't have to put manually the id for each box! Wonderful!\n\n{% hsbox %}\n\n{% hstitle %}\nBox's title\n{% endhstitle %}\n\n{% hscontent %}\nBox's content.\n{% endhscontent %}\n\n{% endhsbox %}\n\n&lt;div class=\"hide-show-box\">&lt;button type=\"button\" markdown=\"1\" class=\"btn collapsed box-button\" data-toggle=\"collapse\" data-target=\"#box1ct\">Box's title&lt;/button>&lt;div id=\"box1ct\" markdown=\"1\" class=\"collapse multi-collapse box-content\">Box's content.&lt;/div>&lt;/div>\n\nInside folder _plugins, create a file thi_hideshowbox.rb whose content is,\nmodule Jekyll class HideShowBox &lt; Liquid::Block def initialize(tag_name, contain, tokens) super end def generate_box_id(number) charset = Array('A'..'Z') + Array('a'..'z') Array.new(number) { charset.sample }.join end def render(context) context.stack do context[\"boxID\"] = generate_box_id(20) # create the box's ID @content = super end \"&lt;div class=\\\"hide-show-box\\\">#{@content}&lt;/div>\" end end class HSBtitle &lt; Liquid::Tag def initialize(tag_name, contain, tokens) super @title = contain end def render(context) boxID = context[\"boxID\"] # get the box's ID output = &lt;&lt;~EOS &lt;button type=\"button\" markdown=\"1\" class=\"btn collapsed box-button\" data-toggle=\"collapse\" data-target=\"##{boxID}\">#{@title}&lt;/button> EOS end end class HSBcontent &lt; Liquid::Block def initialize(tag_name, contain, tokens) super @showBox = contain.strip end def render(context) boxID = context[\"boxID\"] # get the box's ID if @showBox == 'show' classShow = 'show' else classShow = '' end output = &lt;&lt;~EOS &lt;div id=\"#{boxID}\" markdown=\"1\" class=\"collapse multi-collapse box-content #{classShow}\"> #{super} &lt;/div> EOS output end endendLiquid::Template.register_tag('hsbox', Jekyll::HideShowBox)Liquid::Template.register_tag('hstitle', Jekyll::HSBtitle)Liquid::Template.register_tag('hscontent', Jekyll::HSBcontent)\n💡 Actually, there is a simpler solution for this task. We can get\n\n{% hsbox **Box's title** | show %}\nBox's content.\n{% endhsbox %}\n\n&lt;div class=\"hide-show-box\">&lt;button type=\"button\" markdown=\"1\" class=\"btn collapsed box-button\" data-toggle=\"collapse\" data-target=\"#something\">&lt;strong>Box's title&lt;/strong>&lt;/button>&lt;div id=\"something\" markdown=\"1\" class=\"collapse multi-collapse box-content\">Box's content.&lt;/div>&lt;/div>\n\nby using\nmodule Jekyll class HideShowBox &lt; Liquid::Block def initialize(tag_name, contain, tokens) super @input = contain end def generate_box_id(number) charset = Array('A'..'Z') + Array('a'..'z') Array.new(number) { charset.sample }.join end def render(context) # Split the input variable (omitting error checking) input_split = split_params(@input) title = input_split[0] boxid = generate_box_id(20) if input_split[1] != nil if input_split[1].strip == 'show' showbox = \"show\" else showbox = \"\" end else showbox = \"\" end content = super output = &lt;&lt;~EOS &lt;div class=\"hide-show-box\"> &lt;button type=\"button\" markdown=\"1\" class=\"btn collapsed box-button\" data-toggle=\"collapse\" data-target=\"##{boxid}\"> #{title} &lt;/button> &lt;div id=\"#{boxid}\" markdown=\"1\" class=\"collapse multi-collapse box-content #{showbox}\"> #{content} &lt;/div> &lt;/div> EOS end def split_params(params) params.split(\"|\") end endendLiquid::Template.register_tag('hsbox', Jekyll::HideShowBox)\nProblem with kramdown #\nSomtimes, we cannot use markdown=&quot;1&quot; directly in ruby file. For example, below block of code produces a block of codes (&lt;pre&gt;) instead of a single text,\ndef initialize(tag_name, input, liquid_options) super @title = inputenddef render(context) content = super output = &lt;&lt;~EOS &lt;div class=\"def-box\" id=\"dn1\"> &lt;div class=\"box-title\" markdown=\"1\"> #{@title} &lt;/div> &lt;div class=\"box-content\" markdown=\"1\"> #{content} &lt;/div> &lt;/div> EOSend\nInstead, we change a little bit like this,\n&lt;div class=\"box-title\"> &lt;span markdown=\"span\">#{@title}&lt;/span>&lt;/div>\nRun with draft #\nInside the root folder, create a folder named _drafts. You can put your draft posts inside this folder and whenever you wanna show it in your site, use this command,\nbundle exec jekyll serve --draft\nIn the case you have already build your site (all new posts are rendered to _site), you only changes some small things in some post and you don't want jekyll to render again all things on your site (just look at your current post), use this,\nbundle exec jekyll serve -I\nServe in background #\n\n# startbundle exec jekyll serve 2>&amp;1 &amp;bundle exec jekyll serve -I 2>&amp;1 &amp;\n# stop# find jekyll server processps -ef | grep jekyll# substitute pid# with process idkill -9 pid#\n\nUsing markdown syntax inside a HTML tag/block #\nFor a block, we use markdown=&quot;1&quot;,\n&lt;div markdown=\"1\">paragraph&lt;/div>\nFor a tag, we use markdown=&quot;span&quot;,\n&lt;mark markdown=\"span\">text&lt;/span>\nAdd search with lunrjs #\nDownload lunr.min.js and search.js and put them in root/js/. The newest version of lunrjs given here but I'm not sur if it works with this technique or not.\nCreate a file search.html in the root folder with content:\n---layout: pagetitle: Search on this page---&lt;p class=\"p-intro\"> &lt;span id=\"search-process\">{{re_loading}}&lt;/span> {{re_result}} &lt;span id=\"search-query-container\" style=\"display: none;\">{{re_forkey}} \"&lt;strong id=\"search-query\">&lt;/strong>\"&lt;/span>&lt;/p>&lt;ul id=\"search-results\">&lt;/ul>&lt;script type=\"text/javascript\"> window.data = { {% for post in site.posts %} {% if post.title %} {% unless post.excluded_in_search %} {% if added %},{% endif %} {% assign added = false %} \"{{ post.url | slugify }}\": { \"id\": \"{{ post.url | slugify }}\", \"title\": \"{{ post.title | xml_escape }}\", \"categories\": \"{{ post.categories | join: \", \" | xml_escape }}\", \"tags\": \"{{ post.tags | join: \", \" | xml_escape }}\", \"url\": \" {{ post.url | xml_escape }}\", \"content\": {{ post.content | strip_html | replace_regex: \"[\\s/\\n]+\",\" \" | strip | jsonify }} } {% assign added = true %} {% endunless %} {% endif %} {% endfor %} };&lt;/script>&lt;script src=\"{{ site.baseurl }}/js/lunr.min.js\">&lt;/script>&lt;script src=\"{{ site.baseurl }}/js/search.js\">&lt;/script>\nNote that, you can change some personal settings in the files search.js and search.html if you like.\nRemark: if your site has so many posts, you can remove the last line (&quot;content&quot;....) to ignore the content from the search. You can even add &quot;keywords&quot; (resplace for &quot;content&quot;) and put that &quot;keywords&quot; in the frontmatter, change also the term &quot;content&quot; in search.js by &quot;keywords&quot;. That's what I did on this site.\n"},"/web-design-tips/":{"id":"/web-design-tips/","title":"Web Design extra","keywords":"autofocus separated columns page load google webfont sass Font ligatures terms two 2 columns list Font ligatures auto convert symbol focus on input field google webfont helper regex regular expression font download","tags":["posts","Web Dev"],"cat":"/img/cats/web-dev.svg","content":"👉 Web Dev tools.\nTerms #\n\nFont ligatures: When you type = + &gt;, it becomes ⇒.\n\nAuto focus on an input field when page loads #\nJust add autofocus into the &lt;input&gt; tag.\n&lt;input name=\"q\" class=\"search\" type=\"search\" placeholder=\"...\" autofocus>\nSeparate a list into 2 columns #\nAnd make it into 1 if the screen is small.\n\n&lt;div class=\"two-columns-list\"> &lt;ul> &lt;li>&lt;/li> &lt;/ul>&lt;/div>\n.two-columns-list { @media (min-width: $grid-md) { @include column-count(2); &amp; > li { padding-right: 10px; } }}\n\nUseful URLs #\n\nSia Karamalegos -- Making Google Fonts Faster.\nThe SASS way -- If-For-Each-While in SCSS.\n\n"},"/support-vector-machine/":{"id":"/support-vector-machine/","title":"Support Vector Machine (SVM)","keywords":"Maximum Margin Classifier hyperplane geometry margin hard margin soft margin quadratic programming dual form Lagrange multipliers kernal trick Mercer conditions linear kernel gaussian kernel RBF Radial Basic Function Exponential kernel Polynomial kernel Hybrid kernel Sigmoidal Andrew NG Face detection Detecting spam outliers detection Text and hypertext categorization Bioinformatics Regularization parameter parameter C gamma XOR problem Face Recognition Tiep Vu Simplilearn Jeremy Kun Jake VanderPlas Chris Albon","tags":["posts","Machine Learning","Classification"],"cat":"/img/cats/ml.svg","content":"What's the idea of SVM? #\nSVM (also called Maximum Margin Classifier) is an algorithm that takes the data as an input and outputs a line/hyperplane that separates those classes if possible.\nSuppose that we need to separate two classes of a dataset. The task is to find a line to separate them. However, there are many lines which can do that (countless number of lines). How can we choose the best one?\n\nAn idea of support vectors (samples on the margin) and SVM (find the optimal hyperplane).\nMore mathematical details on finding a hyperplaneWe need to find a hyperplane (H)(H)(H): wTx+b=0\\mathbf{w}^T\\mathbf{x} + b = 0wTx+b=0 where the weights w=(w1,…,wd)\\mathbf{w}=(w_1,\\ldots,w_d)w=(w1​,…,wd​) and a point x=(x1,…,xd)\\mathbf{x}=(x_1,\\ldots,x_d)x=(x1​,…,xd​). For example, in 2D (d=2d=2d=2), we need to find a hyperplane w1x1+w2x2+b=0w_1x_1 + w_2x_2 + b=0w1​x1​+w2​x2​+b=0. Note also that, the distance between a point x0\\mathbf{x}_0x0​ and (H)(H)(H) is given by,\nd(x0,H)=∣wTx0+b∣∥w∥2,(1)\\text{d}(\\mathbf{x}_0, H) = \\frac{\\vert\\mathbf{w}^T\\mathbf{x}_0 + b\\vert}{\\Vert\\mathbf{w}\\Vert_2}, \\quad (1)\nd(x0​,H)=∥w∥2​∣wTx0​+b∣​,(1)\nwhere ∥w∥2=∑i=1dwi2\\Vert\\mathbf{w}\\Vert_2 = \\sqrt{\\sum_{i=1}^d w_i^2}∥w∥2​=∑i=1d​wi2​​.\nIn order to understand the idea, we consider a 2D case with the classification of 2 classes (blue faces are numbered as &quot;+1+1+1&quot; and orange faces are numbered as &quot;−1-1−1&quot;).\n\nWe need to find an optimal hyperplane between 2 classes (find w1,w2w_1, w_2w1​,w2​ and bbb).\nRecall that a margin (geometric margin) is the minimum distance between a hyperplane and the closest point(s) to it. Thanks to (1)(1)(1), we can find the margin to a hyperplane by determining the closet distance from an arbitrary points (xi,yi)(\\mathbf{x}_i, y_i)(xi​,yi​) to that hyperplane via,\nmargin=min⁡iyi(wTxi+b)∣∣w∣∣2.(2)\\text{margin} = \\min_i \\frac{y_i(\\mathbf{w}^T\\mathbf{x}_i + b)}{||\\mathbf{w}||_2}. \\quad (2)\nmargin=imin​∣∣w∣∣2​yi​(wTxi​+b)​.(2)\nNote that, because yiy_iyi​ takes values −1-1−1 or +1+1+1 and it always has the same sign as wTxi+b\\mathbf{w}^T\\mathbf{x}_i + bwTxi​+b, yi(wTxi+b)y_i(\\mathbf{w}^T\\mathbf{x}_i + b)yi​(wTxi​+b) is always positive.\nThe SVM problem is to find (w,b\\mathbf{w}, bw,b) so that the hard-margin (2)(2)(2) has the maximum value, i.e.,\n(w,b)=arg⁡max⁡w,b(min⁡iyi(wTxi+b)∥w∥2)=arg⁡max⁡w,b(1∥w∥2min⁡iyi(wTxi+b))(3)\\begin{aligned}\n(\\mathbf{w}, b)\n&amp;= \\arg \\max_{\\mathbf{w}, b} \\left(\n \\min_i \\frac{y_i(\\mathbf{w}^T\\mathbf{x}_i + b)}{\\Vert\\mathbf{w}\\Vert_2}\n\\right)\\\\\n&amp;= \\arg \\max_{\\mathbf{w}, b}\\left(\n \\frac{1}{\\Vert\\mathbf{w}\\Vert_2} \\min_i y_i(\\mathbf{w}^T\\mathbf{x}_i + b)\n\\right)\n\\end{aligned} \\quad (3)\n(w,b)​=argw,bmax​(imin​∥w∥2​yi​(wTxi​+b)​)=argw,bmax​(∥w∥2​1​imin​yi​(wTxi​+b))​(3)\n(arg⁡\\argarg means you need to find w,b\\mathbf{w},bw,b so that the function reaches the max⁡\\maxmax.)\nThis is an optimal problem. Another remark is that we can multiply both sides of (H)(H)(H) by any real number k≠0k\\ne 0k=0, we obtain the same (H)(H)(H). With that reason, we can suppose that,\nyi(wTxi+b)=1,y_i(\\mathbf{w}^T\\mathbf{x}_i + b) = 1,\nyi​(wTxi​+b)=1,\nfor all points on the hyperplane, and the problem (3)(3)(3) becomes,\n(w,b)=arg⁡max⁡w,b1∥w∥2subject to  yi(wTxi+b)≥1,∀i=1,2,…,N.\\begin{aligned}\n &amp;(\\mathbf{w}, b) = \\arg\\max_{\\mathbf{w}, b} \\frac{1}{\\Vert\\mathbf{w}\\Vert_2} \\\\\n \\text{subject to} &amp;~~ y_i(\\mathbf{w}^T\\mathbf{x}_i + b) \\geq 1, \\forall i = 1, 2, \\dots, N.\n\\end{aligned}\nsubject to​(w,b)=argw,bmax​∥w∥2​1​  yi​(wTxi​+b)≥1,∀i=1,2,…,N.​\nThe second line due to the fact that the closet points have distance 111 to the hyperplane, the other points have distance greater than 111. We can write above problem as,\n(w,b)=arg⁡min⁡w,b12∥w∥22subject to  yi(wTxi+b)−1≥0,∀i=1,2,…,N.(4)\\begin{aligned}\n &amp;(\\mathbf{w}, b) = \\arg\\min_{\\mathbf{w}, b} \\frac{1}{2}\\Vert\\mathbf{w}\\Vert_2^2 \\\\\n \\text{subject to} &amp;~~ y_i(\\mathbf{w}^T\\mathbf{x}_i + b)-1 \\geq 0, \\forall i = 1, 2, \\dots, N.\n\\end{aligned} \\quad (4)\nsubject to​(w,b)=argw,bmin​21​∥w∥22​  yi​(wTxi​+b)−1≥0,∀i=1,2,…,N.​(4)\nThis is called &quot;primal formulation of linear SVMs&quot;. In mathematical optimization, one can prove that the problem (4)(4)(4) has an unique solution (We can get an unique hyperplane (H)(H)(H) which satisfies the classification problem). Such problems are generally called quadratic programming problems.\nProblem (4)(4)(4) can be solved &quot;more easily&quot; by considering its dual formulation. Apply the method of Lagrange multipliers, we define a Lagrangian,\nΛ(w,b,λ)=12∥w∥22−∑i=1Nλi(yi(wTxi+b)−1),\\Lambda(\\mathbf{w},b,\\lambda) = \\dfrac{1}{2}\\Vert \\mathbf{w}\\Vert_2^2 - \\sum_{i=1}^N \\lambda_i(y_i(\\mathbf{w}^T\\mathbf{x}_i+b)-1),\nΛ(w,b,λ)=21​∥w∥22​−i=1∑N​λi​(yi​(wTxi​+b)−1),\nwhere w,xi\\mathbf{w}, \\mathbf{x}_iw,xi​ are vectors with ddd elements and λ\\lambdaλ is a vector with NNN elements. We need to minimize this Lagrangian w.r.t. w,b\\mathbf{w}, bw,b and simultaneously require that the derivative w.r.t. λ\\lambdaλ vanishes, all subject to the constraints that λi≥0\\lambda_i \\ge 0λi​≥0. If we set the derivatives w.r.t. w,b\\mathbf{w}, bw,b, we obtain,\n∂Λ(w,b,λ)∂b=0⇒∑i=1Nλiyi=0,∂Λ(w,b,λ)∂w=0⇒w=∑i=1Nλiyixi.\\begin{aligned}\n\\dfrac{\\partial \\Lambda(\\mathbf{w},b,\\lambda)}{\\partial b} &amp;= 0 \\Rightarrow \\sum_{i=1}^N\\lambda_iy_i=0, \\\\\n\\dfrac{\\partial \\Lambda(\\mathbf{w},b,\\lambda)}{\\partial \\mathbf{w}} &amp;= 0 \\Rightarrow \\mathbf{w}=\\sum_{i=1}^N\\lambda_iy_i\\mathbf{x}_i.\n\\end{aligned}\n∂b∂Λ(w,b,λ)​∂w∂Λ(w,b,λ)​​=0⇒i=1∑N​λi​yi​=0,=0⇒w=i=1∑N​λi​yi​xi​.​\nWe substitute the above into the equation for Γ(w,b,λ)\\Gamma(\\mathbf{w},b,\\lambda)Γ(w,b,λ) and obtain &quot;dual formulation of linear SVMs&quot;,\nλ=arg⁡max⁡λ(∑i=1Nλi−12∑i=1N∑j=1NλiλjyiyjxiTxj)subject to  λi≥0,∑i=1Nλiyi=0, ∀i=1,…,N.(5)\\begin{aligned}\n &amp;\\lambda = \\arg\\max_{\\lambda} \\left( \\sum_{i=1}^N \\lambda_i -\\frac{1}{2}\\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i\\lambda_j y_i y_j \\mathbf{x}_i^T\\mathbf{x}_j \\right) \\\\\n \\text{subject to} &amp;~~ \\lambda_i \\ge 0, \\sum_{i=1}^N\\lambda_iy_i = 0, ~\\forall i=1,\\ldots,N.\n\\end{aligned} \\quad (5)\nsubject to​λ=argλmax​(i=1∑N​λi​−21​i=1∑N​j=1∑N​λi​λj​yi​yj​xiT​xj​)  λi​≥0,i=1∑N​λi​yi​=0, ∀i=1,…,N.​(5)\nin that, w\\mathbf{w}w is defined in terms of λi\\lambda_iλi​: w=∑1Nλiyixi\\mathbf{w} = \\sum_1^N\\lambda_iy_i\\mathbf{x}_iw=∑1N​λi​yi​xi​ and the solution becomes\nf(x)=sign(Σ1NλiyixiTxj+b).f(\\mathbf{x})=\\text{sign}(\\Sigma_1^N\\lambda_iy_i\\mathbf{x}_i^T\\mathbf{x}_j + b).\nf(x)=sign(Σ1N​λi​yi​xiT​xj​+b).\nThen given a new instance x\\mathbf{x}x, the classifier is,\nf(x)=sign(wTx+b).f(\\mathbf{x})=\\text{sign}(\\mathbf{w}^T\\mathbf{x} + b).\nf(x)=sign(wTx+b).\nThe benefits of using dual formulation are:[ref, slide 52]\n\nNo need to access original data, need to access only dot products xiTxj\\mathbf{x}_i^T\\mathbf{x}_jxiT​xj​.\nNumber of free parameters is bounded by the number of support vectors and not by the number of variables\n(beneficial for high-dimensional problems).\n\nRead more in this post (Vietnamese), this slide or this post.\n\nUsing SVM with kernel trick #\nMost of the time, we cannot separate classes in the current dataset easily (not linearly separable data). We need to use kernel trick first (transform from the current dimension to a higher dimension) and then we use SVM. These classes are not linearly separable.\n\nAn idea of kernel and SVM. Transform from 1D to 2D. Data is not linearly separable in the input space but it is linearly separable in the feature space obtained by a kernel.\n\nAn idea of kernel and SVM. Transform from 2D to 3D. Data is not linearly separable in the input space but it is linearly separable in the feature space obtained by a kernel.\nMore mathematical detailsOriginal data x\\mathbf{x}x (in input space),[ref, slide 59]\nf(x)=sign(wTx+b),w=∑i=1Nλiyixi\\begin{aligned}\nf(\\mathbf{x}) =\\text{sign}(\\mathbf{w}^T\\mathbf{x} + b), \\quad\n\\mathbf{w} =\\sum_{i=1}^N\\lambda_iy_i\\mathbf{x}_i\n\\end{aligned}\nf(x)=sign(wTx+b),w=i=1∑N​λi​yi​xi​​\nData in a higher dimensional feature space Φ(x)\\Phi(\\mathbf{x})Φ(x),\nf(x)=sign(wTΦ(x)+b),w=∑i=1NλiyiΦ(xi)\\begin{aligned}\nf(\\mathbf{x}) =\\text{sign}(\\mathbf{w}^T\\Phi(\\mathbf{x}) + b), \\quad\n\\mathbf{w} =\\sum_{i=1}^N\\lambda_iy_i\\Phi(\\mathbf{x}_i)\n\\end{aligned}\nf(x)=sign(wTΦ(x)+b),w=i=1∑N​λi​yi​Φ(xi​)​\nWe can rewrite f(x)f(\\mathbf{x})f(x) as,\nf(x)=sign(∑i=1NλiyiΦ(xi)TΦ(x)+b),f(\\mathbf{x}) =\\text{sign} \\left( \\sum_{i=1}^N\\lambda_iy_i\\Phi(\\mathbf{x}_i)^T\\Phi(\\mathbf{x}) + b \\right),\nf(x)=sign(i=1∑N​λi​yi​Φ(xi​)TΦ(x)+b),\nor,\nf(x)=sign(∑i=1NλiyiK(xi,x)+b),K(xi,x)=Φ(xi)TΦ(x).\\begin{aligned}\nf(\\mathbf{x}) &amp;=\\text{sign}(\\sum_{i=1}^N\\lambda_iy_iK(\\mathbf{x}_i,\\mathbf{x}) + b), \\\\\nK(\\mathbf{x}_i,\\mathbf{x}) &amp;= \\Phi(\\mathbf{x}_i)^T\\Phi(\\mathbf{x}).\n\\end{aligned}\nf(x)K(xi​,x)​=sign(i=1∑N​λi​yi​K(xi​,x)+b),=Φ(xi​)TΦ(x).​\nTherefore, we do not need to know Φ\\PhiΦ explicitly, we just need to define a kernel function K(⋅,⋅):Rd×Rd→RK(\\cdot,\\cdot): \\mathbb{R}^d\\times \\mathbb{R}^d \\to \\mathbb{R}K(⋅,⋅):Rd×Rd→R. However, not every function Rd×Rd→R\\mathbb{R}^d\\times \\mathbb{R}^d \\to \\mathbb{R}Rd×Rd→R can be a valid kernel. It has to satisfy so-called Mercer conditions. Otherwise, the underlying quadratic program may not be solvable.\n\nA kernel is a dot product in some feature space:\nK(xi,xj)=Φ(xi,xj).K(\\mathbf{x}_i, \\mathbf{x}_j) = \\Phi(\\mathbf{x}_i, \\mathbf{x}_j).\nK(xi​,xj​)=Φ(xi​,xj​).\nIt also measures the similarity between two points xi\\mathbf{x}_ixi​ and xj\\mathbf{x}_jxj​.\nWe have some popular kernels,\n\nLinear kernel: K(xi,xj)=xi⋅xjK(\\mathbf{x}_i, \\mathbf{x}_j) = \\mathbf{x}_i \\cdot \\mathbf{x}_jK(xi​,xj​)=xi​⋅xj​. We use kernel = 'linear' in sklearn.svm.SVM. Linear kernels are rarely used in practice.\nGaussian kernel (or Radial Basic Function -- RBF): K(xi,xj)=exp⁡(−γ∥xi−xj∥2)K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp(-\\gamma\\Vert \\mathbf{x}_i - \\mathbf{x}_j \\Vert^2)K(xi​,xj​)=exp(−γ∥xi​−xj​∥2). It's used the most. We use kernel = 'rbf' (default) with keyword gamma for γ\\gammaγ (must be greater than 000) in sklearn.svm.SVM.\nExponential kernel: K(xi,xj)=exp⁡(−γ∥xi−xj∥)K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp(-\\gamma\\Vert \\mathbf{x}_i - \\mathbf{x}_j \\Vert)K(xi​,xj​)=exp(−γ∥xi​−xj​∥).\nPolynomial kernel: K(xi,xj)=(r+γxi⋅xj)dK(\\mathbf{x}_i, \\mathbf{x}_j) = (r+\\gamma\\mathbf{x}_i \\cdot \\mathbf{x}_j)^dK(xi​,xj​)=(r+γxi​⋅xj​)d. We use kernel = 'poly' with keyword degree for ddd and coef0 for rrr in sklearn.svm.SVM. It's more popular than RBF in NLP. The most common degree is d=2d = 2d=2 (quadratic), since larger degrees tend to overfit on NLP problems.[ref]\nHybrid kernel: K(xi,xj)=(p+xi⋅xj)qexp⁡(−γ∥xi−xj∥2)K(\\mathbf{x}_i, \\mathbf{x}_j) = (p+\\mathbf{x}_i \\cdot \\mathbf{x}_j)^q\\exp(-\\gamma\\Vert \\mathbf{x}_i - \\mathbf{x}_j \\Vert^2)K(xi​,xj​)=(p+xi​⋅xj​)qexp(−γ∥xi​−xj​∥2).\nSigmoidal: K(xi,xj)=tanh⁡(γxi⋅xj+r)K(\\mathbf{x}_i, \\mathbf{x}_j) = \\tanh(\\gamma\\mathbf{x}_i \\cdot \\mathbf{x}_j+r)K(xi​,xj​)=tanh(γxi​⋅xj​+r). We use kernel = 'sigmoid' with keyword coef0 for rrr in sklearn.svm.SVM.\n\nWe can also define a custom kernel thanks to this help.\n\nChoose whatever kernel performs best on cross-validation data. Andrew NG said in his ML course.\n\nExamples of choosing a kernel\nUsing SVM with 3 different kernels in a XOR problem. In this case, Gaussian kernel is the choice.[ref]\n\nUsing SVM with 3 different kernels in the case of almost linearly separable data. In this case, Polynomial kernel is the choice.\n\nGood or Bad? #\nAdvantages:\n\n\nCompared to both logistic regression and NN, a SVM sometimes gives a cleaner way of learning non-linear functions.\nSVM is better than NN with 1 layer (Perceptron Learning Algorithm) thanks to the largest margin between 2 classes.\nAccurate in high-dimensional spaces + memory effecient.\nGood accuracy and perform faster prediction compared to Naïve Bayes algorithm.[ref]\n\nDisadvantages:\n\n\nProne to overfitting: if number of features are larger than number of samples.\nDon't provide probability estimation.\nNot efficient if your data is very big!\nIt works poorly with overlapping classes\nSensitive to the type of kernel used.\n\nSVM used for? #\nSome points:[re]\n\n\nClassification, regression and outliers detection.\nFace detection.\nText and hypertext categorization.\nDetecting spam.\nClassification of images.\nBioinformatics.\n\nUsing SVM with Scikit-learn #\nfrom sklearn.svm import SVCsvc = SVC(kernel='linear') # default = 'rbf' (Gaussian kernel)# other kernels: poly, sigmoid, precomputed or a callablesvc = svc.fit(X, y)svc.predict(X)# gives the support vectorssvc.support_vectors_\nThere are other parameters of sklearn.svm.SVM.\n\nIn the case of linear SVM, we can also use sklearn.svm.LinearSVC. It's similar to sklearn.svm.SVG with kernel='linear' but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.[ref]\n\nMeaning of some parameters #\nThe Regularization parameter (C, default C=1.0): if C is larger, hyperplane has smaller margin but do a better job of classification and otherwise. This is how you can control the trade-off between decision boundary and misclassification term.\n\n\nHigher values of C ⇒\\Rightarrow⇒ a higher possibility of overfitting, the softmargin SVM is equivalent to the hard-margin SVM.\nLower values of C ⇒\\Rightarrow⇒ a higher possibility of underfitting. We admit misclassifications in the training data\n\nWe use this in the case of not linearly separable data; It's also called soft-margin linear SVM.\n\nAn illustration of using C.\n\nAn illustration of using C. Bigger C, smaller margin.[ref]\nMore mathematical details on CCC and soft-margin problemsRecall that the hard-margin problem is,\n(w,b)=arg⁡min⁡w,b12∥w∥22subject to  yi(wTxi+b)−1≥0,∀i=1,2,…,N.(4 revisited)\\begin{aligned}\n &amp;(\\mathbf{w}, b) = \\arg \\min_{\\mathbf{w}, b} \\frac{1}{2}\\Vert\\mathbf{w}\\Vert_2^2 \\\\\n \\text{subject to} &amp;~~ y_i(\\mathbf{w}^T\\mathbf{x}_i + b) -1 \\geq 0, \\forall i = 1, 2, \\dots, N.\n\\end{aligned} \\quad (4~\\text{revisited})\nsubject to​(w,b)=argw,bmin​21​∥w∥22​  yi​(wTxi​+b)−1≥0,∀i=1,2,…,N.​(4 revisited)\nand its duality is,\nλ=arg⁡max⁡λ(∑i=1Nλi−12∑i=1N∑j=1NλiλjyiyjxiTxj)subject to  λi≥0,∑i=1Nλiyi=0, ∀i=1,…,N.(5 revisited)\\begin{aligned}\n &amp;\\lambda = \\arg\\max_{\\lambda} \\left( \\sum_{i=1}^N \\lambda_i -\\frac{1}{2}\\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i\\lambda_j y_i y_j \\mathbf{x}_i^T\\mathbf{x}_j \\right) \\\\\n \\text{subject to} &amp;~~ \\lambda_i \\ge 0, \\sum_{i=1}^N\\lambda_iy_i = 0, ~\\forall i=1,\\ldots,N.\n\\end{aligned} \\quad (5~\\text{revisited})\nsubject to​λ=argλmax​(i=1∑N​λi​−21​i=1∑N​j=1∑N​λi​λj​yi​yj​xiT​xj​)  λi​≥0,i=1∑N​λi​yi​=0, ∀i=1,…,N.​(5 revisited)\nInstead of considering a hard-margin (4)(4)(4), we consider following soft-margin problem (with the addition of slack variables)\n\n\nAn introduction to slack variables.[ref]\n(w,b,ξ)=arg⁡min⁡w,b,ξ(12∥w∥22+C∑i=1Nξi)subject to  yi(wTxi+b)≥1−ξi,∀i=1,…,N  ξi≤0, ∀i=1,2,…,N\\begin{aligned}\n &amp;(\\mathbf{w}, b, \\xi) = \\arg\\min_{\\mathbf{w}, b, \\xi} \\left( \\frac{1}{2}{\\Vert\\mathbf{w}\\Vert_2^2} + C \\sum_{i=1}^N \\xi_i \\right) \\\\\n \\text{subject to} &amp;~~ y_i(\\mathbf{w}^T\\mathbf{x}_i + b) \\geq 1 - \\xi_i, \\forall i = 1, \\dots, N \\\\\n &amp;~~ \\xi_i \\leq 0, ~\\forall i = 1, 2, \\dots, N\n\\end{aligned}\nsubject to​(w,b,ξ)=argw,b,ξmin​(21​∥w∥22​+Ci=1∑N​ξi​)  yi​(wTxi​+b)≥1−ξi​,∀i=1,…,N  ξi​≤0, ∀i=1,2,…,N​\n\nWith these new slack variables, we have to decide the trade-off between maximizing the margin (term 12∥w∥22\\frac{1}{2}\\Vert \\mathbf{w}\\Vert_2^221​∥w∥22​) and minimizing the mistakes (term CΣ1nξiC\\Sigma_1^n\\xi_iCΣ1n​ξi​).\nWhen CCC is big, the term 12∥w∥22\\frac{1}{2}\\Vert \\mathbf{w}\\Vert_2^221​∥w∥22​ is almost considered as 000 in the minimized problem and the problem focuses on minimizing the term CΣ1nξiC\\Sigma_1^n\\xi_iCΣ1n​ξi​ (avoiding misclassification). That's why the margin looks more narrow in the case of bigger CCC.\nA dual formulation of above soft-margin problem is,\nλ=arg⁡max⁡λ(∑i=1Nλi−12∑i=1N∑j=1NλiλjyiyjxiTxj)subject to  0≤λi≤C,∑i=1Nλiyi=0, ∀i=1,…,N.(6)\\begin{aligned}\n &amp;\\lambda = \\arg\\max_{\\lambda} \\left( \\sum_{i=1}^N \\lambda_i -\\frac{1}{2}\\sum_{i=1}^N \\sum_{j=1}^N \\lambda_i\\lambda_j y_i y_j \\mathbf{x}_i^T\\mathbf{x}_j \\right) \\\\\n \\text{subject to} &amp;~~ 0 \\le \\lambda_i \\le C, \\sum_{i=1}^N\\lambda_iy_i = 0,~\\forall i=1,\\ldots,N.\n\\end{aligned} \\quad (6)\nsubject to​λ=argλmax​(i=1∑N​λi​−21​i=1∑N​j=1∑N​λi​λj​yi​yj​xiT​xj​)  0≤λi​≤C,i=1∑N​λi​yi​=0, ∀i=1,…,N.​(6)\nNote that, (6)(6)(6) looks like (5)(5)(5) (duality of hard-margin problem) but condition 0≤λi≤C0 \\le \\lambda_i \\le C0≤λi​≤C.\n\nGamma (gamma, default gamma='auto' which uses 1/n_features): determine the number of points to construct the hyperplane.\n\nAn illustration of using gamma. In low-gamma case, we only consider points nearby the hyperplane, it may cause an overfitting.\n\nBigger gamma, more change to get overfitting (in a XOR problem).\nUnderstanding the idea of gamma in the Gaussian kernelWe have another form of Gaussian kernel which is,\nK(xi,xj)=exp(−∥xi−xj∥22σ2),K(\\mathbf{x}_i, \\mathbf{x}_j)\n= \\text{exp}\\left( - \\dfrac{\\Vert \\mathbf{x}_i - \\mathbf{x}_j \\Vert^2}{2\\sigma^2} \\right),\nK(xi​,xj​)=exp(−2σ2∥xi​−xj​∥2​),\nwhere σ\\sigmaσ is the standard deviation which shows the spread of the data.\nCompare to the one used in the scikit-learn, K(xi,xj)=exp⁡(−γ∥xi−xj∥2)K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp(-\\gamma\\Vert \\mathbf{x}_i - \\mathbf{x}_j \\Vert^2)K(xi​,xj​)=exp(−γ∥xi​−xj​∥2), we see that γ\\gammaγ is an inverse of σ\\sigmaσ. It implies,\n\nWhen σ\\sigmaσ is bigger (or γ\\gammaγ is smaller), the similarity between two points xi\\mathbf{x}_ixi​ and xj\\mathbf{x}_jxj​ are considered in a wide range (spreading widely).\nConversely, when σ\\sigmaσ is smaller (or γ\\gammaγ is bigger), only two points xi\\mathbf{x}_ixi​ and xj\\mathbf{x}_jxj​ which are really near to each other will be considered to be similar. That's why we see there are many &quot;groups&quot; in the figure corresponding to γ=100\\gamma=100γ=100. It leads to an overfitting problem.\n\n\nSVM in action #\n\n\nXOR problem to see the effect of gamma and C in the case of using RBF kernel: html file -- open in colab.\n\n\nFace Recognition[ref]: html file -- open in colab.\n \n What's interesting?\n \nSome points:[ref]\n\n\nWe will use a principal component analysis to extract 150 fundamental components to feed into our support vector machine classifier.\nGrid search cross-validation to explore combinations of parameters.\nFor a real-world facial recognition task, in which the photos do not come precropped into nice grids, the only difference in the facial classification scheme is the feature selection: you would need to use a more sophisticated algorithm to find the faces, and extract features that are independent of the pixellation. For this kind of application, one good option is to make use of OpenCV, which, among other things, includes pre-trained implementations of state-of-the-art feature extraction tools for images in general and faces in particular.\nI generally only turn to SVMs once other simpler, faster, and less tuning-intensive methods have been shown to be insufficient for my needs. Nevertheless, if you have the CPU cycles to commit to training and cross-validating an SVM on your data, the method can lead to excellent results.\n\n \n \n\n\nReferences #\n\nScikit-learn -- SVM official doc.\nSimplilearn -- How Support Vector Machine Works | SVM In Machine Learning.\nTiep Vu -- Bài 19: Support Vector Machine.\nJeremy Kun -- Formulating the Support Vector Machine Optimization Problem.\nTiep Vu -- Bài 20: Soft Margin Support Vector Machine.\nTiep Vu - Bài 21: Kernel Support Vector Machine.\nAlexander Statnikov, Douglas Hardin, Isabelle Guyon, Constantin F. Aliferis -- A Gentle Introduction to Support Vector Machines in Biomedicine.\nJake VanderPlas -- In-Depth: Support Vector Machines. -- Example: How to code and illustrate hyperplane and support vectors in Python?\nChris Albon -- Notes about Support Vector Machines.\nAndrew NG -- My raw note when I learned the course Machine Learning on Coursera.\n\n"},"/gambler-ruin-problem/":{"id":"/gambler-ruin-problem/","title":"Gamler Ruin Problem","keywords":"probabilities statistics random walk","tags":["posts","Prob & Stats"],"cat":"/img/cats/stats.svg","content":"Consider a gambler who starts with an initial fortune of iii$ and then on each successive gamble either wins 111$ or loses 111$ independent of the past with probabilities ppp and q=1−pq = 1-pq=1−p respectively. The gambler's objective is to reach a total fortune of NNN$, without first getting ruined (running out of money).\nLet PiP_iPi​ be the probability that the gambler wins when starting with iii$, we have\nP0=0PN=1Pi=pPi+1+qPi−1\\begin{aligned}\nP_0 &amp;= 0 \\\\\nP_N &amp;= 1 \\\\\nP_i &amp;= pP_{i+1} + qP_{i-1}\n\\end{aligned}\nP0​PN​Pi​​=0=1=pPi+1​+qPi−1​​\nFinally,\nPi={1−qp1−(qp)N,if p≠q;1Nif p=q=12.\\begin{aligned}\nP_i = \\begin{cases}\n\\dfrac{1-\\frac{q}{p}}{1-(\\frac{q}{p})^N}, &amp; \\text{if } p \\ne q; \\\\\n\\dfrac{1}{N} &amp;\\text{if }p=q=\\frac{1}{2}.\n\\end{cases}\n\\end{aligned}\nPi​=⎩⎪⎪⎪⎨⎪⎪⎪⎧​1−(pq​)N1−pq​​,N1​​if p=q;if p=q=21​.​​\nNote that, 1−Pi1-P_i1−Pi​ is the probability of ruin.\nAnother type of this question: Consider an ant walking along the positive integers. At position iii, the ant moves to i+1i+1i+1 with probabilities ppp and to i−1i-1i−1 with probabilities qqq. If the ant reach 000, it stops walking. Starting from i&gt;0i&gt;0i&gt;0, what is the probability that the ant reaches i=Ni=Ni=N before reaching 000?\nSometimes, we consider above problem as a random walk problem. This post is copied from this and we have a backup version here.\n"},"/dataset-collection/":{"id":"/dataset-collection/","title":"Datasets Collection","keywords":"dataset collection google dataset google AI kaggle dataset data hub stanford large network dataset FiveThirtyEight data.world quandl r/datasets scikit-learn dataset fruit images labeled faces Wild Home Iris flower digits dataset module generator fake data","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"Create artificial dataset #\n\nsklearn dataset module: from sklearn import datasets. This contains also some popular reference datasets.\n\nSource of datasets #\n\nGoogle Dataset Search.\nGoogle Trends Datastore\nGoogle AI Datasets — In order to contribute to the broader research community, Google periodically releases data of interest to researchers in a wide range of computer science disciplines.\nData Hub Datasets collection — high quality data and datasets organized by topic.\nKaggle Datasets.\nawesome-public-datasets — A topic-centric list of HQ open datasets.\nStanford Large Network Dataset Collection.\nFiveThirtyEight — hard data and statistical analysis to tell stories about politics, sports, societal matters and more.\ndata.world.\nBuzzFeedNews/everything — data from BuzzFeed.\ndata.gov — a large dataset aggregator and the home of the US Government’s open data.\nQuandl — your perfect choice for testing your machine learning algorithms and don’t waste your time on cleaning data.\nr/datasets.\nBuilt-in datasets in Scikit-Learn.\nNLP-progress.\nUCI\nThe Yahoo Webscope Program\nTensorFlow Datasets\n\nDatasets #\n\nWordNet -- A Lexical Database for English.\nImageNet -- ImageNet is an image database organized according to the WordNet hierarchy.\nFruit-Images-Dataset — A dataset of images containing fruits and vegetables.\nDataset samples from Machine Learning Mastery.\nUEA &amp; UCR Time Series Classification Repository\nSarcasm detection dataset.\nInsight - BBC News Datasets\nLarge Movie Review Dataset (IMDB)\nCOCO Dataset -- a large-scale object detection, segmentation, and captioning dataset.\n\nVietnamese #\n\nPhoBERT: Pre-trained language models for Vietnamese.\nIWSLT'15 English-Vietnamese data (small from Stanford).\nNLP-progress - Vietnamese\n\nSample datasets #\n\nLabeled Faces in the Wild Home (from sklearn.datasets import fetch_lfw_people).\nIris flower dataset (from sklearn.datasets import load_iris).\nThe digits dataset (sklearn.datasets.load_digits).\npydatafaker -- A python package to create fake data with relationships between tables.\n\nTools #\n\nTimeSynth -- A Multipurpose Library for Synthetic Time Series Generation in Python.\n\n"},"/pipeline/":{"id":"/pipeline/","title":"Pipeline","keywords":"sticky multiple processes into single process multiple tasks at once make_pipeline scaling svm pca sequential work algorithm training parameter best parameter tuning gridsearch cross validation scaling train test sets different folds folds scikit-learn naming name why what where when","tags":["posts","Machine Learning"],"cat":"/img/cats/ml.svg","content":"What's the idea of Pipeline? #\nStick multiple processes into a single (scikit-learn) estimation.\n\nWhy pipeline? #\n\nPipeline in Scikit-learn #\nfrom sklearn.pipeline import Pipelinefrom sklearn.pipeline import make_pipeline\nDifference between Pipeline and make_pipeline\n\nPipeline: naming.\nmake_pipeline: no need naming.\n\nmake_pipeline(StandardScaler(), GaussianNB(priors=None))Pipeline(steps=[('standardscaler', StandardScaler()), ('gaussiannb', GaussianNB())])\nExample #\n\nFace Recognition using SVM -- Open in HTML -- Open in Colab.\n\n"},"/principal-component-analysis/":{"id":"/principal-component-analysis/","title":"Principal Component Analysis (PCA)","keywords":"compress data dimensional reduction speed up algorithms or to visualize data feature selection Feature projection mean variance covariance eigenvalues covariance matrix eigenvectors explained_variance_ratio_ Whitening Image compression Luis Serrano Tiep Vu Jake VanderPlas UFLDL - Stanford Shankar Muthuswamy","tags":["posts","Machine Learning"],"cat":"/img/cats/ml.svg","content":"What? #\nSometimes we need to &quot;compress&quot; our data to speed up algorithms or to visualize data. One way is to use dimensionality reduction which is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. We can think of 2 approaches:\n\nFeature selection: find a subset of the input variables.\nFeature projection (also Feature extraction): transforms the data in the high-dimensional space to a space of fewer dimensions. PCA is one of the methods following this approach.\n\n\nFigure 1. An idea of using PCA from 2D to 1D.\n\nFigure 2. An idea of using PCA from 5D to 2D.\n\n❓ Questions: How can we choose the green arrows like in Figure 1 and 2 (their directions and their magnitudes)?\n\nFrom a data points, there are many ways of projections, for examples,\n\nFigure 3. We will project the points to the green line or the violet line? Which one is the best choice?\nIntuitively, the green line is better with more separated points. But how can we choose it &quot;mathematically&quot; (precisely)? We need to know about:\n\nMean: find the most balanced point in the data.\nVariance: measure the spread of data from the mean. However, variance is not enough. There are many different ways in that we get the same variance.\nCovariance: indicate the direction in that data are spreading.\n\nAn example of the same mean and variance but different covariance.\n\nFigure 4. Different data but the same mean and variance. That's why we need covariance!\nAlgorithm #\n\n\nSubtract the mean to move to the original axes.\n\n\nFrom the original data (a lot of features x1,x2,…,xNx_1, x_2, \\ldots, x_Nx1​,x2​,…,xN​), we construct a covariance matrix UUU.\n\n\nFind the eigenvalues λ1,λ2,…\\lambda_1, \\lambda_2,\\ldotsλ1​,λ2​,… and correspondent eigenvectors v1,v2,…v_1, v_2, \\ldotsv1​,v2​,… of that matrix (we call them eigenstuffs). Choose K&lt;NK &lt; NK&lt;N couples λ\\lambdaλ and vvv (the highest eigenvalues) and we get a reduced matrix UKU_KUK​.\n\n\nProjection original data points to the KKK-dimensional plane created based on these new eigenstuffs. This step creates new data points on a new dimensional space (KKK).\nZ=UKTXZ = U_K^TX\nZ=UKT​X\n\n\nNow, instead of solving the original problem (NNN features), we only need to solve a new problem with KKK features (K&lt;NK&lt;NK&lt;N).\n\n\n\nFigure 5. A big picture of the idea of PCA algorithm.[ref]\nCode #\nfrom sklearn.decomposition import PCAs = np.array([...])pca = PCA(n_components=150, whiten=True, random_state=42)# pca.fit(s)s1 = pca.fit_transform(s)print (pca.components_) # eigenvectorsprint (pca.explained_variance_) # eigenvalues\nSome notable components (see full):\n\npca.fit(X): only fit X (and then we can use pca for other operations).\npca.fit_transform(X): Fit the model with X and apply the dimensionality reduction on X (from (n_samples, n_features) to (n_samples, n_components)).\npca.inverse_transform(s1): transform s1 back to original data space (2D) - not back to s!!!\npca1.mean_: mean point of the data.\npca.components_: eigenvectors (n_components vectors).\npca.explained_variance_: eigenvalues. It's also the amount of retained variance which is corresponding to each components.\npca.explained_variance_ratio_: the percentage in that variance is retained if we consider on each component.\n\nSome notable parameters:\n\nn_components=0.80: means it will return the Eigenvectors that have the 80% of the variation in the dataset.\n\n\nWhen choosing the number of principal components (KKK), we choose KKK to be the smallest value so that for example, 99%99\\%99% of variance, is retained.[ref]\nIn Scikit-learn, we can use pca.explained_variance_ratio_.cumsum(). For example, n_components = 5 and we have,\n[0.32047581 0.59549787 0.80178824 0.932976 1.]\nthen we know that with K=4K=4K=4, we would retain 93.3%93.3\\%93.3% of the variance.\n\nWhitening #\nWhitening makes the features:\n\nless correlated with each other,\nall features have the same variance (or, unit component-wise variances).\n\n\nPCA / Whitening. Left: Original toy, 2-dimensional input data. Middle: After performing PCA. The data is centered at zero and then rotated into the eigenbasis of the data covariance matrix. This decorrelates the data (the covariance matrix becomes diagonal). Right: Each dimension is additionally scaled by the eigenvalues, transforming the data covariance matrix into the identity matrix. Geometrically, this corresponds to stretching and squeezing the data into an isotropic gaussian blob.\nIf this section doesn't satisfy you, read this and this (section PCA and Whitening).\nPCA in action #\n\n\nExample to understand the idea of PCA: html file -- open in colab.\n\nPlot points with 2 lines which are corresponding to 2 eigenvectors.\nPlot &amp; choose Principal Components.\nAn example of choosing n_components KKK.\nVisualization hand-written digits (the case of all digits and the case of only 2 digits -- 1 &amp; 8).\nUsing SVM to classifier data in the case of 1 &amp; 8 and visualize the decision boundaries.\n\n\n\nImage compression: html file -- open in colab.\n\nWhen input is an image, the values of adjacent pixels are highly correlated.\nImport images from scipy and Google Drive or Github (with git).\nCompress grayscale images and colored ones.\nPlot a grayscale version of a colorful images.\nSave output to file (Google Drive).\nFix warning Lossy conversion from float64 to uint8. Range [...,...]. Convert image to uint8 prior to saving to suppress this warning.\nFix warning Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nCalculate a size (in KB) of a image file.\n\n\n\nPCA without scikit-learn: html file -- open in colab.\n\n\nReferences #\n\nLuis Serrano -- [Video] Principal Component Analysis (PCA). It's very intuitive!\nStats.StackExchange -- Making sense of principal component analysis, eigenvectors &amp; eigenvalues.\nScikit-learn -- PCA official doc.\nTiep Vu -- Principal Component Analysis: Bài 27 and Bài 28.\nJake VanderPlas -- In Depth: Principal Component Analysis.\nTutorial 4 Yang -- Principal Components Analysis.\nAndrew NG. -- My raw note of the course &quot;Machine Learning&quot; on Coursera.\nShankar Muthuswamy -- Facial Image Compression and Reconstruction with PCA.\nUFLDL - Stanford -- PCA Whitening.\n\n"},"/gitbook/":{"id":"/gitbook/","title":"Gitbook","tags":["posts","Web Dev"],"cat":"/img/cats/web-dev.svg","content":"URLs #\n\nGitbook homepage.\nGitbook Docs.\nEmoji Copy (You cannot use :blush: in the markdown file, you need to copy icon itself).\n\nSetting up #\nFile book.json needs to be placed in the root of your gitbook repository on Github. Below are some settings that I have used.\n{\t\"plugins\": [\t\t\"mathjax\"\t],\t\"pluginsConfig\": {\t\t\"mathjax\":{\t\t\t\t\"forceSVG\": true\t\t}\t}}\nMath in Gitbook #\nYou have to use $$a+b$$ instead of $a+b$ for inline math. Others are the same as normal expressions in Markdown.\nBlocks #\nBoxes #\nInfo blocks,\n{% hint style=\"info\" %}Hint blocks.&lt;br />Line break.{% endhint %}\nDanger blocks,\n{% hint style=\"danger\" %}Content.{% endhint %}\nSuccess blocks,\n{% hint style=\"success\" %}Content.{% endhint %}\nWarning blocks,\n{% hint style=\"warning\" %}Content.{% endhint %}\nCode blocks #\n{% code-tabs %}{% code-tabs-item title=\"book.json\" %}```bashcd directory/```{% endcode-tabs-item %}{% endcode-tabs %}\nBox with tabs #\n{% tabs %}{% tab title=\"First Tab\" %}Content of tab 1.{% endtab %}{% tab title=\"Second Tab\" %}Content of tab 2.{% endtab %}{% endtabs %}\nTasks #\n* [x] Task 1* [ ] Task 2* [ ] Task 3\n"},"/python-matplotlib-tips/":{"id":"/python-matplotlib-tips/","title":"Matplotlib extra","keywords":"plot in python axes grayscale PIL Image cmap imshow savefig gcf imageio imwrite plt.plot line style marker scatter plot dot line connect point generate list of colors automatically based on a list of input legend from list of colors imshow plot true false grid squares figsize subplot multiple plots legend independent from the plot line2d","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Import library #\nimport matplotlib.pyplot as pltimport numpy as np\nGenerate colors based on list #\nWe wanna generate a list of colors automatically based on the elements in some list (the idea from popai),\ndef get_colors(list_vals, list_colors=[\"#fb4747\", \"#315ace\", \"#b5f6e5\", \"#FFB347\"]): dict_colors = polylinear_gradient(list_colors, n=len(list_vals)) dict_colors_ok = {} for i, val in enumerate(list_vals): dict_colors_ok[val] = dict_colors['hex'][i] return dict_colors_ok\nAxes #\nAxes' options,\n\n# Hide the axisplt.axis('off')# and 'on' to display it again\n# Set the limitplt.xlim(0, 3.5)plt.ylim(0, 3.5)\n# Axes' labelplt.xlabel('students', fontsize=14)plt.ylabel('mark')\n# axes' tick size &amp; rotationplt.xticks(fontsize=14, rotation=90)plt.yticks(fontsize=14, rotation=90)\n# range of ticksplt.xticks(np.arange(0., 1., step=0.01))plt.yticks(np.arange(0., 1., step=0.01))\n\nSet equal 2 axes[ref],\nmatplotlib.axes.Axes.set_aspect('equal')# get the current axes and apply the functionplt.gca().set_aspect()\nPlots #\nCheck the official doc for more information.\n# default for allmatplotlib.rcParams['figure.figsize'] = (20,5)\nplt.plot(X, y, 'ro') # red and 'o' points\n\n# set figure sizeplt.figure(figsize=(20, 5))plt.figure(figsize=(20, 5), dpi= 60)\n# rotate z labelplt.xticks(rotation=90, fontsize=10)\n# linestyle and markerplt.plot(marker='.', ls='') # scatter plotplt.plot(X, '.', markersize=15, linewidth=2)\n\nPlot directly with dataframe, #\n👉 Check more in official doc.\n\ndf.plot(figsize=(20, 5))df.plot(fontsize=12)\n# different typesdf.plot(style='.')df.plot(style=['r.', 'bx']) # 2 features\n# add x,y labelsdf.plot(kind='bar)plt.xlabel('features', fontsize=14)plt.ylabel('% of nans', fontsize=14)\n# rotate x ticksdf.plot(kind='bar', rot=90)\n\nLegend #\n# from the plotsplt.plot(x, np.sin(x), '-b', label='Sine')plt.plot(x, np.cos(x), '--r', label='Cosine')plt.legend(fontsize=13)\n# custom: independent from the plotsfrom matplotlib.lines import Line2Dplt.legend([Line2D([0], [0], color='b'), Line2D([0], [0], color='r')], ['blue', 'red'])\nLegend from list of colors #\nSuppose we have a list of group with different colors. We wanna make legends for them,\n# generate auto the colors based on list lst_clusters (see previous section)dict_colors = get_colors(lst_clusters)plt.legend( [Line2D([0], [0], color=dict_colors[key]) for key in dict_colors], dict_colors.keys(), loc='lower center', ncol=6, bbox_to_anchor=(.5, 1.), prop={'size': 15})\n\nimshow #\nPlot from a list of true/false (ref to an example of Bernoulli distribution)\nimage = # np.array(4, 4) of random True/Falseplt.imshow(image, cmap='gray') # plotplt.show()\nSubplot #\nFor example, we wanna create a 4x4 plots[ref],\nplt.figure(figsize=(12, 10), dpi= 60)for i in range(4): pos = i+1 plt.subplot(2,2,pos) plt.plot(X[i]) plt.title('title_'+str(pos), fontsize=18)\nUsing ax,\nsize = len(list_features)f, axs = plt.subplots(int((size+1)/2), 2, figsize=(15,15/5*int(size/2 + 1/2)))for ax, feat in zip(axs.ravel(), list_features): df_feat = df[feat] for idt, df_id in df_feat.groupby('batch_id'): ax.plot(x, y, color='royalblue', alpha=0.5) ax.set_title('plot_'+feat)plt.show()\nFill between range #\nplt.fill_between(df.index, df[\"yhat_lower\"], df[\"yhat_upper\"], color='#0072B2', alpha=0.2)\nPlot a photo (imshow) #\nWith grayscale and misc #\nfrom scipy import miscimg = misc.face(gray=True)plt.imshow(img, cmap='gray', vmin=0, vmax=255)plt.show()\nWith grayscale and custom file #\nimport numpy as npimport matplotlib.pyplot as pltfrom PIL import Imagefname = 'image.png'image = Image.open(fname).convert(\"L\")# If you have an L mode image, that means it is a single channel image - normally# interpreted as greyscale. The L means that is just stores the Luminance.# It is very compact, but only stores a greyscale, not colour.arr = np.asarray(image)plt.imshow(arr, cmap='gray', vmin=0, vmax=255)plt.show()print(arr.shape)\n# ERR: Clipping input data to the valid range for# imshow with RGB data ([0..1] for floats or [0..255] for integers)plt.imshow(img.astype('uint8'))\nSave figure to file #\nUsing plt.savefig() #\nTo be sure that plt.savefig()[ref] comes before plt.show(). In the case you wanna use any time you want, just call plt.gcf() to &quot;get current figure&quot; first. For example,[ref]\nfig1 = plt.gcf() # get the current figureplt.show() # show the plotfig1.savefig('test.png', dpi=100)\nRemark: There are the axes inside the exported photo (all are printed on notebook)!!\nUsing imageio #\nThey export only the photo.\nimport imageio# img = misc.face(gray=True)# or# img = np.asarray(Image.open('abc.jpg').convert(\"L\"))imageio.imwrite('filename.jpg', img) # save the file\n# ERR: Lossy conversion from float64 to uint8. Range […,…].# Convert image to uint8 prior to saving to suppress this warningimageio.imwrite('filename.jpg', img.astype(np.uint8))\n"},"/python-numpy-tips/":{"id":"/python-numpy-tips/","title":"Numpy extra","keywords":"linspace array arange range equal spaces range arange int integer numbers list step evenly spaced create creating initialize nans values empty array random number isinstance check type numpy array compare 2 two dict dictionaries remove delete an element from an array count nans non nans not null","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Import library #\nimport numpy as np\nChecking #\nIsinstance #\n# Check if an object is an instance numpy array?type(MyObect).__module__ == np.__name__\nComparing #\nCompare 2 dicts of multiple objects:\n# 2 dicts of multiple objectsdef _compare_two_dict(dct_1, dct_2): return np.array([(lambda key: (dct_1[key] == dct_2[key]).all() if type(dct_1[key]).__module__ == np.__name__ else dct_1[key] == dct2[key])(key) for key in dct_1]).all()\n# 2 numpy arrays containing `np.nan`def nan_equal(a,b): try: np.testing.assert_equal(a,b) except AssertionError: return False return True# if using in a pytest# instead of `assert np.testing`,# just usenp.testing.assert_equal(a,b)\nCount 0, NaNs #\n\n# count nansarr = [1,2,3,4, np.nan,np.nan, 0,0,0]np.isnan(arr).sum() # 2\n# count non-nansarr = [1,2,3,4, np.nan,np.nan, 0,0,0]np.count_nonzero(~np.isnan(arr)) # 7\n# count non-zerosarr = [1,2,3,4, np.nan,np.nan, 0,0,0]np.count_nonzero(arr) # 6\n\nCreating #\nRandom numbers #\n\n# random int between 0, 5np.random.randint(5)# random int between [1, 100]np.random.randint(1, 100 + 1)\n# random array of int between 1, 5np.random.randint(1,5,size=(2,3))# random array of int between 0, 3np.random.randint(3,size=(2,3))\n# random float number between [0, 1)np.random.random()\n# random float number between [a, b)(b - a)*np.random.random() + a\n# array of random between [0, 1)np.random.random_sample((5,)) # size: 5x1\n# array of random between (a, b)(b - a)*np.random.random_sample((5,1)) + a\n\nEqual size #\nCreate evenly spaced numbers over a specified interval[ref]\nx = np.linspace(0, 3.5, num=20) # default num = 50\nRange of int numbers\n\nnp.arange(0, 5)np.arange(0, 31, 5)\narray([0, 1, 2, 3, 4])\narray([ 0, 5, 10, 15, 20, 25, 30])\n\n\nIndexes and values in other arrays #\nCreate an array from nested arrays. Values in array_2 are indexes in array_1 and we create a new array take values in array_1 which is corresponding to its indexes showed in array_2.\n\narray_1 = np.array([ [0,0,0], [1,1,1], [2,2,2] ])array_2 = np.array([1,0,2,1,0,2,1]) # indexes in array_1array_3 = array_1[array_2]print(array_1)print(array_2)print(array_3)\n[[0 0 0]\n [1 1 1]\n [2 2 2]]\n\n[1 0 2 1 0]\n\n[[1 1 1]\n [0 0 0]\n [2 2 2]\n [1 1 1]\n [0 0 0]]\n\n\nArray of NaN values #\n\n# single arraynp.repeat(np.nan, 5)# multi dimensional arraysa = np.empty((2,3))a[:] = np.nan# other waynp.repeat([np.repeat(np.nan, 3)], 2, axis=0)\narray([nan, nan, nan, nan, nan])\n\narray([[nan, nan, nan],\n [nan, nan, nan]])\n\n\nRepeated values #\nnp.full((5,), 50) # 5x1 of 5\nDeleting #\n\n# DELETE BY POSITIONSarr = np.arange(6)np.delete(arr, [3,4])\narray([0, 1, 2, 3, 4, 5])\narray([0, 1, 2, 5])\n\n\n\n# DELETE BY VALUESa = np.array([1, 2, 3, 4, 5, 6])np.delete(a, np.where(a == 3))b = np.array([1, 2, 3, 'a'])np.delete(a, np.where(b == 'a'))# ORa[a!=3]b[b!='a']\narray([1, 2, 4, 5, 6])\n\narray(['1', '2', '3'], dtype='&lt;U21')\n\n\n\n# Remove 'NaT' from an arrayY = np.array([600000, 300000, 'NaT'], dtype='timedelta64[ns]')Y[~np.isnat(Y)]\narray([600000, 300000],\n dtype='timedelta64[ns]')\n\n\n"},"/small-projects-to-understand-concepts/":{"id":"/small-projects-to-understand-concepts/","title":"Small projects for understanding concepts","keywords":"Image compression K-Means PCA google drive github Lossy conversion Clipping input data to the valid range for imshow Face Recognition SVM XOR problem k means principal component analysis supoprt vector machine digit face Lossy conversion pipeline","tags":["posts","Project-based Learning","Collection"],"cat":"/img/cats/project.svg","content":"\nThis note will always be updated.\n\n🔅 Image compression using K-Means -- Open in HTML -- Open in Colab.\n\nLoad and write an image from/to Google Drive.\nChange the image's size from (height, weight, channels) to (height x weight, channels)\nReduce the image's quality using smaller number of clusters.\n\n🔅 Example to understand the idea of PCA -- Open in HTML -- Open in Colab.\n\nPlot points with 2 lines which are corresponding to 2 eigenvectors.\nPlot &amp; choose Principal Components.\nAn example of choosing n_components KKK.\nVisualization hand-written digits (the case of all digits and the case of only 2 digits -- 1 &amp; 8).\nUsing SVM to classifier data in the case of 1 &amp; 8 and visualize the decision boundaries.\n\n🔅 Image compression using PCA -- Open in HTML -- Open in Colab.\n\nWhen input is an image, the values of adjacent pixels are highly correlated.\nImport images from scipy and Google Drive or Github (with git).\nCompress grayscale images and colored ones.\nPlot a grayscale version of a colorful images.\nSave output to file (Google Drive).\nFix warning Lossy conversion from float64 to uint8. Range [...,...]. Convert image to uint8 prior to saving to suppress this warning.\nFix warning Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nCalculate a size (in KB) of a image file.\n\n🔅 PCA without scikit-learn -- Open in HTML -- Open in Colab.\n🔅 Face Recognition using SVM -- Open in HTML -- Open in Colab.\n\nUsing PCA to extract 150 fundamental components to feed into our SVG classifier.\nGrid search cross-validation to explore combinations of parameters (gamma and C).\nClassification report: precision, recall, f1-score, support.\nConfusion matrix.\nAn example of using pipeline.\n\n🔅 XOR problem using SVM to see the effect of gamma and C in the case of using RBF kernel -- Open in HTML -- Open in Colab.\n"},"/k-means-clustering/":{"id":"/k-means-clustering/","title":"K-Means Clustering","keywords":"k means k-means clustering method sensitive to outliers partitioning clustering cluster k-medoids k medoids PAM oartitioning around medoids handwritten digits data Luis Serrano Andrew NG elbow method number of clusters k-medoids k modes k-modes k-medians k median kmean kmeans distance between points","tags":["posts","Machine Learning","Clustering"],"cat":"/img/cats/ml.svg","content":"K-Means is the most popular clustering method any learner should know. In this note, we will understand the idea of KMeans and how to use it with Scikit-learn. Besides that, we also learn about its variants (K-medois, K-modes, K-medians).\nWhat's the idea of K-Means? #\n\nRandomly choose centroids (kkk).\nGo through each example and assign them to the nearest centroid (assign class of that centroid).\nMove each centroid (of each class) to the average of data points having the same class with the centroid.\nRepeat 2 and 3 until convergence.\n\n\nHow to choose number of clusters? #\nUsing &quot;Elbow&quot; method.\n\nDiscussion #\n\nA type of Partitioning clustering.\nNot good if there are outliers, noise.\nThe K-means method is sensitive to outliers ⇒ K-medoids clustering or PAM (Partitioning Around Medoids) is less sensitive to outliers[ref]\n\nUsing K-Means with Scikit-learn #\nfrom sklearn.cluster import KMeanskmeans = KMeans(n_clusters=10, random_state=0) # default k=8\n\nkmeans.fit(X)kmeans.predict(X)\n# orkmeans.fit_predict(X)\n\nSome notable parameters (see full):\n\n\nmax_iter: Maximum number of iterations of the k-means algorithm for a single run.\nkmeans.labels_: show labels of each point.\nkmeans.cluster_centers_ : cluster centroids.\n\nK-Means in action #\n\nK-Means clustering on the handwritten digits data.\nImage compression using K-Means -- Open in HTML -- Open in Colab.\n\nK-medois clustering #\nReferences #\n\nLuis Serrano -- [Video] Clustering: K-means and Hierarchical.\nAndrew NG. -- My raw note of the course &quot;Machine Learning&quot; on Coursera.\n\n"},"/js-101/":{"id":"/js-101/","title":"JavaScript 101","keywords":"practice directly on browser inspect ecmascript ES6 concise getters setters blocks variable scopes operators conditional statements if switch definition function strings special characters arrays objects destructuring assignment JSON javascript object notation iterate while for do while loops","tags":["posts","JavaScript"],"cat":"/img/cats/js.svg","content":"Quick references for fundamental things in JavaScript.\nMiscellaneous #\n\nUsing // for 1 line comment, /* */ for multi-line comment.\nEnd of each command by ;.\nVariables and function name are case sensitive.\nVariables / functions should be named in the form of nameOfVariable.\n\nNaming a constant: const FAV_PET = 'Cat';.\nUpperCamelCase should be used by convention for ES6 class names.\n\n\nUsing \\ for special characters, for example, \\&quot; for a &quot; inside a &quot;&quot;.\n'' can be used inside a &quot;&quot; and vice versa.\n\nPractice directly on the browser #\nOpen the browser (I use Chrome), press F12 to open the Inspect window, then choose tab Console. Now, you can practice on this console window, for example, try with 1+1 and press Enter.\nES6 #\n\n&quot;ES&quot; = &quot;ECMAScript&quot; ~ &quot;Javascript&quot;.\nMost of browsers use ES6 but not all.\nES6 = ES2015\nJS timeline.\nNew features: Arrow functions, Classes, Modules, Promises, Generators, let and const.\nRead more about ES6 on w3schools.\n\nConcise things #\n// Concise Object Literal Declarationsconst getMousePosition = (x, y) => ({ x, y });\n// Concise Declarative Functionsconst person = { name: \"Taylor\", sayHello() { return `Hello! My name is ${this.name}.`; }};\nGetters and setters #\nclass Book { constructor(author) { this._author = author; } // getter get writer() { return this._author; } // setter set writer(updatedAuthor) { this._author = updatedAuthor; }}const lol = new Book('anonymous');console.log(lol.writer); // anonymouslol.writer = 'wut';console.log(lol.writer); // wut\nExport/Import to share code blocks #\n// file ./math_funcs.jsconst add = (x, y) => {return x + y};const subtract = (x, y) => {return x - y};export { add, subtract }; // can be imported in other scripts// file ./math_default.js only has 1 exportexport default function(x, y) { // without name return x + y;}\n// main.jsimport {add, subtract } from './math_funcs.js';import * as myMathModule from \"./math_functions.js\"; // everythingimport anything from './math_default.js'; // from export default\nDeclare variables &amp; Scopes #\n\nvar varName; // global scopelet varName; // ES6, block scope (inside {} or function,...)const varName; // ES6, can't be changed\nfunction funcName(){ oopsGlobal = 5; // without `var`, it's a global variable}oppsGlobal; // returns 5\n\nDifference between var, let and const,\n\nvar a = 1;var a = 2; // ok, a=2 nowa = 5; // a=5 now\nlet c = 1;let c = 2; // errorc = 3; // c=3 now\nconst b = 1;const b = 2; // errorb = 2 // error\n\nconst s = [1, 2, 3];s = [1, 2, 4]; // errors[2] = 4; // OK\nOutput #\nmyName = \"Thi\"console.log(\"I'm \" + myName + \".\");console.log(`I'm ${myName}.`); // ES6\nBasic operators #\nCheck more operators &amp; more operators with Math.\n\ni = i + 1; // i++; // i += 1;i = i - 1; // i--; // i -= 1;i = i * 3; // i *= 3;i = i / 2; // i /= 2;11 % 3 // = 2, remainder\nMath.random(); // give a random number between 0 and 1Math.floor(); // round to its nearest whole numberparseInt(\"007a\"); // give number 7parseInt(\"11\", 2); // give number 3, \"2\" is radix\n\nConditional statements if / switch #\n\nComparison Operators: &lt;, ==, === (strict equality), &gt;, &gt;=, &lt;=, !=, !== (strict inequality).\n\nDifference between == and ===: 3=='3' (true), 3==='3' (false).\nDifference between != and !==: 3!='3' (false), 3!=='3' (true).\n\n\nLogical operators: &amp;&amp;, ||, !.\nShort-circuit evaluation: let a = b || 'Thi'; (if b isn't defined yet, a takes value 'Thi')\nTernary Operator: isNightTime ? console.log('Yes!') : console.log('No!');. We can use multiple nested ternary.\n\n\nif (true){ // commands}if (true){ // commands} else if (true){ // commands} else{ // commands}\nlet var = 'papaya';switch (var) { case 'val1': // commands break; case 'val2': // commands break; default: // commands break;}\n\nYou can remove break; to apply the same result for multiple cases.\nFunctions #\n\n// ES6 wayconst rectangleArea = (width=10, height=5) => { let area = width * height; return area;};\n// if there is no parameterconst &lt;func> = () => {};// if there is only one parameterconst &lt;func> = &lt;para> => {};// single line: no need \"{}\"const sumNumbers = number => number + number;\n\nOlder ways (ES5),\nfunction &lt;funcName>(&lt;para>){ // commands}\n\n\nRest parameter (ES6)\nconst last_element = (...args) => { return args[-1];}last_element(1,2,3); // 3\n\n\nSpread Operator (ES6)\nconst arr = [6, 89, 3, 45];const maximus = Math.max(...arr); // 89\n\n\nStrings #\nCheck more methods.\nvar a = 'Anh-Thi' + 'Dinh'; // plus the stringsa.length; // length of the stringa[0]; // first letter of the stringa[3]; // 4th lettera[a.length - 1]; // last lettera[0] = 'D'; // !!! CAN'T change an individual word\nSpecial characters: \\' (single quote), \\&quot; (double quote), \\\\(backslash), \\n (newline), \\r (carriage return), \\t (tab), \\b (word boundary), \\f (form feed).\nArrays #\nCheck more methods.\nvar arrName = ['a', 1, 'c'];var nestedArr = [[1, 2], [3, 4]];arrName[0] = 2; // 1st element is changed (different from string!)nestedArr[1]; // gives [3, 4]arrName.push(5); // add 5 at the END of an arrayarrName.unshift(6); // add 6 at the BEGINNING of an arraypopedElement = arrName.pop() // remove the LAST element of an arrayshiftedElement = arrName.shift() // remove the FIRST element of an array\nObjects #\n\nvar myObj = { top: \"hat\", \"bottom\": \"pants\"};// CHECK PROPERTIESmyObj.hasOwnProperty(\"top\"); // truemyObj.hasOwnProperty(\"middle\"); // false\n// Accessing Object PropertiesmyObj.top; // dotmyObj[\"bottom\"]; // bracketvar pos = \"top\";myObj[pos]; // via a variable\n\nmyObj.top = \"T-shirt\"; // Update object propertiesmyObj.middle = \"New shoe\"; // Add new propertiesdelete myObj.middle; // Delete a property\nWe can use object for lookups instead of using if..else or switch,\nvar alpha = {1:\"A\", 2:\"B\", 3:\"C\"};value = 2;alpha[value]; // instead of using if value==2 or switch value...\nWe can create a nested object inside an object.\nPrevent object mutation,\nlet obj = { name:\"FreeCodeCamp\", review:\"Awesome\"};Object.freeze(obj); // obj can't be changed\nDestructuring Assignment (ES6) #\nExtract values from object,\nconst user = {name: \"Thi\", age: 30};const {name, age} = user; // name=\"Thi\", age=30\nAssign variable from object,\nconst {name: uName, age: uAge} = user; // uName=\"Thi\", uAge=30\nAssign Variables from Nested Objects,\nconst user = { anhThi: { age: 30, email: 'dinhanhthi@gmail.com' }};const {anhThi: {age, email}} = user;const {anhThi: {age: userAge, email: userEmail}} = user;\nAssign Variables from Arrays,\n\nconst [a, b] = [1, 2, 3, 4, 5, 6];console.log(a, b); // 1, 2\nconst [a, b,,, c] = [1, 2, 3, 4, 5, 6];console.log(a, b, c); // 1, 2, 5\n\nAssignment with the Rest Parameter to Reassign Array Elements,\nconst [a, b, ...arr] = [1, 2, 3, 4, 5, 7];console.log(a, b); // 1, 2console.log(arr); // [3, 4, 5, 7]\nPass an Object as a Function's Parameters,\nconst profileUpdate = ({ name, age, nationality, location }) => { // do something with these fields}\nJSON #\nJavaScript Object Notation or JSON is a related data interchange format used to store data,\nvar ourMusic = [ { \"artist\": \"Daft Punk\", \"title\": \"Homework\", \"release_year\": 1997, \"formats\": [ \"CD\", \"Cassette\", \"LP\" ], \"gold\": true }, // first artist { ... } // second artist];\nTo access &quot;CD&quot;: ourMusic[0].formats[0].\nIterate with while / for / do..while loops #\nCheck more statements.\n\nwhile (&lt;conditions>){ // commands}\ndo{ // commands} while (&lt;conditions>);\nfor (var i=0; i&lt;5; i++){ // commands}\n// Iterate odd numbersfor (var i=0; i&lt;5; i+=2){ // commands}\n// Count backwardsfor (var i=10; i?5; i-=2){ // commands}\n\nReferences #\n\nfreeCodeCamp -- JavaScript Algorithms and Data Structures Certification (300 hours).\nw3schools -- JavaScript Tutorial.\nEvent bubbling and capture\n\n"},"/python-pandas/":{"id":"/python-pandas/","title":"Pandas extra","keywords":"pandaframe series df dataframe data overview data aggregation data combining data preprocessing cleaning row column select values export write csv files output input sep separate comma semicolon read csv read_csv from dictionary list numpy array np.array to_csv write to files multiindex indexing reverse values True False element wise invert integer rows and named columns index and column name selection convert true false to 1 0 add a row to current dataframe isin","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"In this note, a general dataframe is called df (type pandas.core.frame.DataFrame), a general series is call s (type pandas.core.series.Series).\nImport library #\nimport pandas as pdimport numpy as np # import numpy if necessary\nRead/Write .csv file #\n# READdf = pd.read_csv('filename.csv', sep=';') # default sep=','# if 1st col contains 0,1,2,...df = pd.read_csv('filename.csv', index_col=1)# with datetime infodf = pd.read_csv(PATH_DATA_FOLDER+\"raw_data.csv\", parse_dates=['timestamp'], infer_datetime_format=True, cache_dates=True)\n# WRITEdf.to_csv(path, index=False) # don't incldue index\nCreate a dataframe #\n# FROM A LISTpd.DataFrame(a_list, colummns=['col_name'])\n\n# FROM A DICTIONARYnames = ['John', 'Thi', 'Bi', 'Beo', 'Chang']ages = [10, 20, 21, 18, 11]marks = [8, 9, 10, 6, 8]city = ['Ben Tre', 'Paris', 'Ho Chi Minh Ville', 'New York', 'DC']my_dict = {'Name':names, 'Ages':ages, 'Marks':marks, 'Place': city}students = pd.DataFrame(my_dict)\n\n\n\n\nName\nAges\nMarks\nPlace\n\n\n\n\n0\nJohn\n10\n8\nBen Tre\n\n\n1\nThi\n20\n9\nParis\n\n\n2\nBi\n21\n10\nHo Chi Minh Ville\n\n\n3\nBeo\n18\n6\nNew York\n\n\n4\nChang\n11\n8\nDC\n\n\n\n\nAdding #\n\n# a columndf['new_col] = [new_values]\n# a rowdf.loc['new_index'] = [new_value]\n\n# add a new col based on another's valuesdf_im = df0.copy()[['col']]df_im['status'] = df0['col'].apply(lambda row: 1 if row>=80 else 0)\nShuffle rows #\n# shuffle all rows and reset the indexdf_new = df.sample(frac=1).reset_index(drop=True)\nSorting #\ndf.sort_values(by='col1', ascending=False)\nSelect rows/columns/item(s) #\n👉 Indexing and selecting data — pandas 1.1.2 documentation\nSelect Single value #\nSelect a single value (with condition): Get the mark of Thi (9).\n# interchange `.values[0]` and `.iloc[0]`df[df.Name=='Thi'].Marks.values[0]df.loc[df.Name=='Thi', 'Marks'].values[0]\n# with indexesdf.iloc[1,2] # row 2, column 3\n# column's name with row's indexdf[['Marks']].iloc[1].values[0] # column 'Marks', row 2\n# column's index with row's valuedf[df.Name=='Thi'].iloc[:,2].values[0] # column 3, row of 'Thi'\nSelect integer rows and named columns #\ndf.loc[1:5, 'col']\nSelect columns #\nSelect a column (returns a Series)\n\n# with column's namedf['Name']df.loc[:, 'Name']\n# with an indexdf.iloc[:,0]\n\nReturns a pd.DataFrame,\n\ndf[['Name']]df.loc[:, ['Name']]\n# with an indexdf.iloc[:,[0]]\n\nSelect multi-columns (type DataFrame): Get columns Name &amp; Place:\n\n# using columns's namesdf[['Name', 'Place']]df.loc[:, ['Name', 'Place']]\n# using indexesdf.iloc[:, [0,-1]]\n\nSelect rows #\nSelect a row (returns a Series)\n\n# with an indexdf.iloc[1]\n# with a conditiondf[df['Name']=='Thi'] # DataFramedf[df['Name']=='Thi'].iloc[0] # Series\ndf[df.Name=='Thi'] # DataFramedf[df.Name=='Thi'].iloc[0] # Seriesdf[df.Name=='Thi'].values[0] # ndarray\n\nSelect multi-rows (type DataFrame)\n\n# using indexesdf.iloc[:3]df.loc[:2]\n# with conditionsdf[df['A'].isin([3, 6])]\n\nMultiIndex #\n👉 MultiIndex / advanced indexing — pandas 1.1.2 documentation\nAll multiindex #\narrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo'], ['one', 'two', 'one', 'two', 'one', 'two']]index = pd.MultiIndex.from_arrays(arrays)df = pd.DataFrame(np.random.randn(3, 6), index=['A', 'B', 'C'], columns=index)\n\n \n \n \n bar\n baz\n foo\n \n \n \n one\n two\n one\n two\n one\n two\n \n \n \n \n A\n -0.752333\n 0.490581\n 0.774629\n 0.487185\n 1.767773\n 0.028956\n \n \n B\n -0.057864\n -0.221516\n -0.568726\n -0.563732\n 1.362453\n -0.563213\n \n \n C\n -0.338319\n -0.346590\n 0.012845\n 0.755455\n 1.260937\n -0.038209\n \n \n\nSelection,\n\ndf.loc['A', ('baz', 'two')]\n0.487185\n\n\n\ndf.loc[:,('baz', 'two')]\nA 0.487185\nB -0.563732\nC 0.755455\nName: (baz, two), dtype: float64\n\n\nWith a single name column #\nIf there are some column with single name,\narrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo'], [i for i in range(2)]*3]index = pd.MultiIndex.from_arrays(arrays)df1 = pd.DataFrame(np.random.randn(3, 6), index=['A', 'B', 'C'], columns=index)\nGood practice #\n# GOOD PRACTICEdf1['time'] = [1,2,3]df_rs2 = df1\n\n \n \n \n bar\n baz\n foo\n time\n \n \n \n 0\n 1\n 0\n 1\n 0\n 1\n \n \n \n \n \n A\n -1.386119\n -0.496755\n 1.482855\n 0.943795\n -1.173290\n -0.445365\n 1\n \n \n B\n -0.900710\n -1.571009\n 1.086964\n 1.546927\n -1.564426\n 0.622763\n 2\n \n \n C\n 0.712231\n 0.235247\n -0.807031\n 0.671802\n 0.597149\n 0.111332\n 3\n \n \n\nSelection,\n\n# FOR GOOD PRACTICEdf_rs2.loc['A', ('baz', 1)]df_rs2.loc['A', 'baz']\n0.9437950 1.4828551 0.943795\n\nBad practice #\n# BAD PRACTICEdf2 = pd.DataFrame([1,2,3], index=['A', 'B', 'C'], columns=['time'])df_rs1 = pd.concat([df1, df2], axis=1)\n\n \n \n \n (bar, 0)\n (bar, 1)\n (baz, 0)\n (baz, 1)\n (foo, 0)\n (foo, 1)\n time\n \n \n \n \n A\n -1.386119\n -0.496755\n 1.482855\n 0.943795\n -1.173290\n -0.445365\n 1\n \n \n B\n -0.900710\n -1.571009\n 1.086964\n 1.546927\n -1.564426\n 0.622763\n 2\n \n \n C\n 0.712231\n 0.235247\n -0.807031\n 0.671802\n 0.597149\n 0.111332\n 3\n \n \n\nSelection,\n\n# FOR BAD PRACTICEdf.loc['A', [('baz', 0)]]df_rs1.loc['A', [('baz', i) for i in [0,1]]]\n(baz, 0) 0.729023(baz, 0) 1.482855(baz, 1) 0.943795\n\nRename multiindex #\n# all columns' name at the level 1df.columns.set_levels(['b1','c1','f1'], level=1, inplace=True)\nDrop multiindex #\n\ndf.columns = df.columns.droplevel()\n a b c b c0 1 2 -> 0 1 21 3 4 1 3 4\n\nCompare 2 dataframes #\ndf1.equals(df2)\nTrue / False #\n\n# Invert True/False value in Seriess = pd.Series([True, True, False, True])~s\n# Convert True / False to 1 / 0df['col'] = df['col'].astype(int)# int or float\n\n"},"/data-aggregation/":{"id":"/data-aggregation/","title":"Data Aggregation","keywords":"dataframe groupby group agg apply pivot table melt tables lambda group different functions pivot_table","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"In this note, I use df for DataFrame, s for Series.\nLibraries #\nimport pandas as pd # import pandas packageimport numpy as np\nDataframe #\ndataquest_aio = 'https://raw.githubusercontent.com/dinhanhthi/dataquest-aio/master/step-2-data-analysis-and-visualization/'dataset_url = dataquest_aio + 'course-4-data-cleaning-and-analysis/data/World_Happiness_2015.csv'df = pd.read_csv(dataset_url) # read the data setdf.head()\n\n \n \n \n Country\n Region\n Happiness Rank\n Happiness Score\n Standard Error\n \n \n \n \n 0\n Switzerland\n Western Europe\n 1\n 7.587\n 0.03411\n \n \n 1\n Iceland\n Western Europe\n 2\n 7.561\n 0.04884\n \n \n 2\n Denmark\n Western Europe\n 3\n 7.527\n 0.03328\n \n \n 3\n Norway\n Western Europe\n 4\n 7.522\n 0.03880\n \n \n 4\n Canada\n North America\n 5\n 7.427\n 0.03553\n \n \n\nGroup dataset using groupby() #\nGroup df by column Region and then selct the column Western Europe,\ndf.groupby('Region').get_group('Western Europe') # returns a df\n\n \n \n \n Country\n Region\n Happiness Rank\n Happiness Score\n Standard Error\n \n \n \n \n 0\n Switzerland\n Western Europe\n 1\n 7.587\n 0.03411\n \n \n 1\n Iceland\n Western Europe\n 2\n 7.561\n 0.04884\n \n \n 2\n Denmark\n Western Europe\n 3\n 7.527\n 0.03328\n \n \n 3\n Norway\n Western Europe\n 4\n 7.522\n 0.03880\n \n \n 5\n Finland\n Western Europe\n 6\n 7.406\n 0.03140\n \n \n\nSelect just the Happiness Score column and then find the mean,\ndf.groupby('Region')['Happiness Score'].mean()# other methods: size, max, min, count\nRegion\nAustralia and New Zealand 7.285000\nCentral and Eastern Europe 5.332931\nEastern Asia 5.626167\nLatin America and Caribbean 6.144682\nMiddle East and Northern Africa 5.406900\nNorth America 7.273000\nSoutheastern Asia 5.317444\nSouthern Asia 4.580857\nSub-Saharan Africa 4.202800\nWestern Europe 6.689619\nName: Happiness Score, dtype: float64\n\nApply multiple/custom functions,\ndef max_min(group): return group.max() - group.min()df.groupby(['Country', 'Region']).agg([np.mean, np.max, max_min]).head()\n\n \n \n \n \n Happiness Rank\n Happiness Score\n \n \n \n \n mean\n amax\n max_min\n mean\n amax\n max_min\n \n \n Country\n Region\n \n \n \n \n \n \n \n \n \n \n Afghanistan\n Southern Asia\n 153\n 153\n 0\n 3.575\n 3.575\n 0.0\n \n \n Albania\n Central Europe\n 95\n 95\n 0\n 4.959\n 4.959\n 0.0\n \n \n Algeria\n Middle Africa\n 68\n 68\n 0\n 5.605\n 5.605\n 0.0\n \n \n\nIf you wanna apply different functions on different columns,\ndf.groupby(['Country', 'Region']).agg({ 'Happiness Rank': max_min, 'Happiness Score': ['min', 'max'], 'Standard Error': 'count'}).head(3)\n\n \n \n \n \n Happiness Rank\n Happiness Score\n \n \n \n \n max_min\n min\n max\n \n \n Country\n Region\n \n \n \n \n \n \n \n Afghanistan\n Southern Asia\n 0\n 3.575\n 3.575\n \n \n Albania\n Central Europe\n 0\n 4.959\n 4.959\n \n \n Algeria\n Middle Africa\n 0\n 5.605\n 5.605\n \n \n\nOr using apply and lambda function,\norders.groupby('shoes').price.apply(lambda x: np.min(x, 25)).reset_index()\nGroup using pivot_table() #\n\nAn example of pivotting by a single column[ref]\nGroup by Region (as an index) and choosing GDP and City columns,[ref]\ndf.pivot_table(values=['GDP', 'City'], index='Region') # returns df\n\n \n \n \n Happiness Rank\n Standard Error\n \n \n Region\n \n \n \n \n \n \n Australia and New Zealand\n 9.5\n 0.037270\n \n \n Central and Eastern Europe\n 79.0\n 0.045208\n \n \n Eastern Asia\n 64.5\n 0.037225\n \n \n\nApply some functions,\ndf.pivot_table(['GDP', 'City'], 'Region', aggfunc=[np.mean, np.max], margins=True)# margins shows the \"All\" row\n\n \n \n \n mean\n amax\n \n \n \n Happiness Rank\n Standard Error\n Happiness Rank\n Standard Error\n \n \n Region\n \n \n \n \n \n \n \n \n Australia and New Zealand\n 9.5\n 0.037270\n 10\n 0.04083\n \n \n Central and Eastern Europe\n 79.0\n 0.045208\n 134\n 0.06913\n \n \n Eastern Asia\n 64.5\n 0.037225\n 100\n 0.05051\n \n \n\nReorganizing df using pivot() #\n\nAn example of multi-column pivoting (ref)\nMake values in one columns be columns in a new &quot;pivot&quot; table,[ref]\ndf = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two', 'two'], 'bar': ['A', 'B', 'C', 'A', 'B', 'C'], 'baz': [1, 2, 3, 4, 5, 6], 'zoo': ['x', 'y', 'z', 'q', 'w', 't']})pivot_1 = df.pivot(index='foo', columns='bar', values='baz')pivot_2 = df.pivot(index='foo', columns='bar')['baz']pivot_3 = df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])display_side_by_side(df, pivot_1, pivot_2, pivot_3)\n\n \n \n \n foo\n bar\n baz\n zoo\n \n \n \n \n 0\n one\n A\n 1\n x\n \n \n 1\n one\n B\n 2\n y\n \n \n 2\n one\n C\n 3\n z\n \n \n 3\n two\n A\n 4\n q\n \n \n 4\n two\n B\n 5\n w\n \n \n 5\n two\n C\n 6\n t\n \n \n\n\n\n \n \n bar\n A\n B\n C\n \n \n foo\n \n \n \n \n \n \n \n one\n 1\n 2\n 3\n \n \n two\n 4\n 5\n 6\n \n \n\n\n \n \n bar\n A\n B\n C\n \n \n foo\n \n \n \n \n \n \n \n one\n 1\n 2\n 3\n \n \n two\n 4\n 5\n 6\n \n \n\n\n \n \n \n baz\n zoo\n \n \n bar\n A\n B\n C\n A\n B\n C\n \n \n foo\n \n \n \n \n \n \n \n \n \n \n one\n 1\n 2\n 3\n x\n y\n z\n \n \n two\n 4\n 5\n 6\n q\n w\n t\n \n \n\n\nFor one who wanna know display_side_by_side, check this note.\nChange shape of df with melt() #\nContrary to pivot, we now want to transform several columns into values of a single column,[ref]\ndf = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'}, 'B': {0: 1, 1: 3, 2: 5}, 'C': {0: 2, 1: 4, 2: 6}})df1 = pd.melt(df, id_vars=['A'], value_vars=['B'])df2 = pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])display_side_by_side(df, df1, df2)\n\n\n \n \n \n A\n B\n C\n \n \n \n \n 0\n a\n 1\n 2\n \n \n 1\n b\n 3\n 4\n \n \n 2\n c\n 5\n 6\n \n \n\n\n \n \n \n A\n variable\n value\n \n \n \n \n 0\n a\n B\n 1\n \n \n 1\n b\n B\n 3\n \n \n 2\n c\n B\n 5\n \n \n\n\n \n \n \n A\n variable\n value\n \n \n \n \n 0\n a\n B\n 1\n \n \n 1\n b\n B\n 3\n \n \n 2\n c\n B\n 5\n \n \n 3\n a\n C\n 2\n \n \n 4\n b\n C\n 4\n \n \n 5\n c\n C\n 6\n \n \n\n\nReferences #\n\nData Cleaning and Analysis on Dataquest.\nTransforming data with pandas on Dataquest.\npandas official -- Group By: split-apply-combine\n\n"},"/data-combining/":{"id":"/data-combining/","title":"Data Combining","keywords":"coupling dataframes inner outer left right merging pandas display side by side concatenate concat","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"Sometimes, we wanna couple multiple dataframes together. In this note, I use df as DataFrame, s as Series.\nLibraries #\nimport pandas as pdimport numpy as np\nCoupling dfs with merge() #\nThere are 4 types of merging, like in SQL.\n\nInner: only includes elements that appear in both dataframes with a common key.\nOuter: includes all data from both dataframes.\nLeft: includes all of the rows from the &quot;left&quot; dataframe along with any rows from the &quot;right&quot; dataframe with a common key; the result retains all columns from both of the original dataframes.\nRight: includes all of the rows from the &quot;right&quot; dataframe along with any rows from the &quot;left&quot; dataframe with a common key; the result retains all columns from both of the original dataframes.\n\n\nOn the same column name,\n# leftdf_left = pd.merge(left=df1, right=df2, how='left', on='Col_1', suffixes=('_df1', '_df2'))# rightdf_right = pd.merge(left=df1, right=df2, how='right', on='Col_1', suffixes=('_df1', '_df2'))display_side_by_side(df1, df2, df_left, df_right)\n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1\n \n \n 1\n E\n 3\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2\n \n \n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1\n \n \n 1\n B\n 2\n \n \n 2\n C\n -3\n \n \n 3\n F\n -4\n \n \n 4\n E\n NaN\n \n \n\n\n\n\n \n \n \n Col_1\n Col_2_df1\n Col_2_df2\n \n \n \n \n 0\n A\n 1\n 1\n \n \n 1\n E\n 3\n NaN\n \n \n 2\n C\n NaN\n -3\n \n \n 3\n D\n NaN\n NaN\n \n \n 4\n B\n 2\n 2\n \n \n\n\n \n \n \n Col_1\n Col_2_df1\n Col_2_df2\n \n \n \n \n 0\n A\n 1\n 1\n \n \n 1\n E\n 3\n NaN\n \n \n 2\n C\n NaN\n -3\n \n \n 3\n B\n 2\n 2\n \n \n 4\n F\n NaN\n -4\n \n \n\n\n# inner (defaut)df_inner = pd.merge(left=df1, right=df2, on='Col_1', suffixes=('_df1', '_df2'))# outerdf_outer = pd.merge(left=df1, right=df2, how='outer', on='Col_1', suffixes=('_df1', '_df2'))display_side_by_side(df1, df2, df_inner, df_outer)\n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1\n \n \n 1\n E\n 3\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2\n \n \n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1\n \n \n 1\n B\n 2\n \n \n 2\n C\n -3\n \n \n 3\n F\n -4\n \n \n 4\n E\n NaN\n \n \n\n\n\n\n \n \n \n Col_1\n Col_2_df1\n Col_2_df2\n \n \n \n \n 0\n A\n 1\n 1\n \n \n 1\n E\n 3\n NaN\n \n \n 2\n C\n NaN\n -3\n \n \n 3\n B\n 2\n 2\n \n \n\n\n \n \n \n Col_1\n Col_2_df1\n Col_2_df2\n \n \n \n \n 0\n A\n 1\n 1\n \n \n 1\n E\n 3\n NaN\n \n \n 2\n C\n NaN\n -3\n \n \n 3\n D\n NaN\n NaN\n \n \n 4\n B\n 2\n 2\n \n \n 5\n F\n NaN\n -4\n \n \n\n\nOn the different column names,\n# leftdf_left = pd.merge(left=df1, right=df2, how='left', left_on='Col_1', right_on='Col_X', suffixes=('_df1', '_df2'))display_side_by_side(df1, df2, df_left)\n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1\n \n \n 1\n E\n 3\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2\n \n \n\n\n \n \n \n Col_X\n Col_2\n \n \n \n \n 0\n A\n 1\n \n \n 1\n B\n 2\n \n \n 2\n C\n -3\n \n \n 3\n F\n -4\n \n \n 4\n E\n NaN\n \n \n\n\n\n\n \n \n \n Col_1\n Col_2_df1\n Col_X\n Col_2_df2\n \n \n \n \n 0\n A\n 1\n A\n 1\n \n \n 1\n E\n 3\n E\n NaN\n \n \n 2\n C\n NaN\n C\n -3\n \n \n 3\n D\n NaN\n NaN\n NaN\n \n \n 4\n B\n 2\n B\n 2\n \n \n\n\nThe result keeps both Col_1 and Col_X while in the case of the same column name, there is only 1 column. Other words, in this case, we only want to keep Col_1 and don't need Col_X. How to do that?\ndf_left = df1.set_index('Col_1').join(df2.set_index('Col_X'), how=\"left\", lsuffix=\"_df1\", rsuffix=\"_df2\").reset_index()display_side_by_side(df1, df2, df_left)\n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n E\n 3.0\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2.0\n \n \n\n\n \n \n \n Col_X\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n B\n 2.0\n \n \n 2\n C\n -3.0\n \n \n 3\n F\n -4.0\n \n \n 4\n E\n NaN\n \n \n\n\n\n \n \n \n Col_1\n Col_2_df1\n Col_2_df2\n \n \n \n \n 0\n A\n 1.0\n 1.0\n \n \n 1\n E\n 3.0\n NaN\n \n \n 2\n C\n NaN\n -3.0\n \n \n 3\n D\n NaN\n NaN\n \n \n 4\n B\n 2.0\n 2.0\n \n \n\nConcatenate dfs with concat() #\n# axis=0 (default)df_concat_0 = pd.concat([df1, df2]) # the same columnsdf_concat_1 = pd.concat([df1, df2], axis=1) # the same rowsdf_concat_0_idx = pd.concat([df1, df2], ignore_index=True)# ignore_index=True prevent duplicating indexesdisplay_side_by_side(df1, df2)display_side_by_side(df_concat_0, df_concat_1, df_concat_0_idx)\n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n E\n 3.0\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2.0\n \n \n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n B\n 2.0\n \n \n 2\n C\n -3.0\n \n \n 3\n F\n -4.0\n \n \n 4\n E\n NaN\n \n \n\n\n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n E\n 3.0\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2.0\n \n \n 0\n A\n 1.0\n \n \n 1\n B\n 2.0\n \n \n 2\n C\n -3.0\n \n \n 3\n F\n -4.0\n \n \n 4\n E\n NaN\n \n \n\n\n \n \n \n Col_1\n Col_2\n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n A\n 1.0\n \n \n 1\n E\n 3.0\n B\n 2.0\n \n \n 2\n C\n NaN\n C\n -3.0\n \n \n 3\n D\n NaN\n F\n -4.0\n \n \n 4\n B\n 2.0\n E\n NaN\n \n \n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n E\n 3.0\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2.0\n \n \n 5\n A\n 1.0\n \n \n 6\n B\n 2.0\n \n \n 7\n C\n -3.0\n \n \n 8\n F\n -4.0\n \n \n 9\n E\n NaN\n \n \n\n\nCombine 2 dataframes with missing values #\nWe consider a situation in that we need to combine 2 dfs containing missing values in each. The missing values will be filled by taking from the others. For example, the value of C in the left df can be fulfilled by the value of C in the right df.\ndf_comb = df1.copy() # we don't want to change df1df_new = df_comb.fillna(df2)display_side_by_side(df1, df2, df_comb, df_new)\n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n E\n 3.0\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2.0\n \n \n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n B\n 2.0\n \n \n 2\n C\n -3.0\n \n \n 3\n F\n -4.0\n \n \n 4\n E\n NaN\n \n \n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n E\n 3.0\n \n \n 2\n C\n NaN\n \n \n 3\n D\n NaN\n \n \n 4\n B\n 2.0\n \n \n\n\n \n \n \n Col_1\n Col_2\n \n \n \n \n 0\n A\n 1.0\n \n \n 1\n E\n 3.0\n \n \n 2\n C\n -3.0\n \n \n 3\n D\n -4.0\n \n \n 4\n B\n 2.0\n \n \n\n\n"},"/data-preprocessing-cleaning/":{"id":"/data-preprocessing-cleaning/","title":"Data Processing & Cleaning","keywords":"pandas numpy remove columns drop choose some column except rename column make index reset_index drop NaNs missing values null fill nans fillnan text data dropna preprocessing warning A value is trying to be set on a copy of a slice from a DataFrame Couple different columns duplicate things need to be checked steps rename index column drop NaNs multi index filled with mean of each row","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"In this note, I use df as DataFrame, s as Series.\nLibraries #\nimport pandas as pd # import pandas packageimport numpy as np\nThings need to be checked #\n\n\ncsv file:\n\nValues are separated by , of ;?\nEncoding.\nTimestamp type.\n\n\nIndexes are sorted?\nIndexes are continuous with step 1 (especially after using .dropna() or .drop_duplicates)?\nAre there NaN values? Drop them?\nAre there duplicates? Drop them?\nHow many unique values?\nFor 0/1 features, they have only 2 unique values (0 and 1)?\nKDE plot to check the values distribution.\nThe number of columns?\nUnique labels?\nTime series:\n\nTime range.\nTime step.\nTimestamp's type.\nTimezone.\nTimestamps are monotonic?\n\n\n\n\nDeal with columns #\nRemove or Keep some #\n# REMOVING COLUMNSdf.drop('New', axis=1, inplace=True) # drop column 'New'df.drop(['col1', 'col2'], axis=1, inplace=True)\n\n# ONLY KEEP SOMEkept_cols = ['col1', 'col2', ...]df = df[kept_cols]\n# ALL EXCEPT SOMEdf[df.columns.difference(['b'])]\n\nRename columns #\n# IMPLICITLYdf.columns = ['Surname', 'Years', 'Grade', 'Location']\n# EXPLICITLYdf.rename(columns={'Name': 'Surname', 'Ages': 'Years'}, inplace=True)\n# A SPECIFIC COLUMNdata.rename(columns={'gdp':'log(gdp)'}, inplace=True)\n# RENAME INDEX COLUMNdf.index.name = 'new_name'\nMake index #\n\n# COLUMN HAS UNIQUE VALUES?df['col'].is_unique # True if yes\n# INDEX -> NORMAL COLUMNdf.reset_index(inplace=True)\n# NORMAL COLUMN -> INDEXdf.set_index('column')df.set_index(['col1', 'col2'])\n\nDrop duplicates #\n👉 Overview duplicates.\n# check duplicatesdf['Student'].duplicated().any()\n# remove duplicates in some columnsdf.drop_duplicates(['col1', 'col2'])# use \"ignore_index=True\" if you wanna reset indexes to 0,1,...,n-1\nCouple different columns #\ndf = df0[['Date', 'Heure', 'tH (°C)']].copy()df['timestamp'] = df['Date'] + ' ' + df['Heure']# if you use without `.copy()`# WARNING: A value is trying to be set on a copy of a slice from a DataFrame.\nDeal with missing values NaN #\n👉 Overview missing values.\nDrop NaN values #\nFull reference of dropna is here.\n\n# Drop any rows which have any nansdf.dropna()\n# Drop if all values in that col are NAdf.dropna(how='all', axis=1)\n# Drop columns that have any nansdf.dropna(axis=1)\n# Only drop columns having min 90% non-NaNsdf.dropna(thresh=int(df.shape[0]*.9), axis=1)\n# Only keep rows having >=2 non-NA valuesdf.dropna(thresh=2)\n# Only consider some colsdf.dropna(subset=['col1', 'col2'])\n\n# multi-indexdf.dropna(subset=[(1,'a'), (1,'b'), (2,'a'), (2,'b')])# consider all cols '1' and '2'df.dropna(subset=df.loc[[], [1,2]].columns)\nFill NaN with others #\nCheck other methods of fillna here.\n\n# Fill NaN with ' 'df['col'] = df['col'].fillna(' ')\n# Fill NaN with 99df['col'] = df['col'].fillna(99)\n# mean / median of each columndf.fillna(df.mean())\n# Fill NaN with the mean of the columndf['col'] = df['col'].fillna(df['col'].mean())\n# Fill NA with mean of rowm = df.mean(axis=1)for col in df.columns: df.loc[:, col] = df.loc[:, col].fillna(m)\n\nDo with conditions #\nnp.where(if_this_condition_is_true, do_this, else_this)df['new_column'] = np.where(df[i] > 10, 'foo', 'bar) # example\nWork with text data #\nThere are a lot of methods we can work with text data (pd.Series.str). We can use it coupling with regular expression.\n"},"/dataframe-overview/":{"id":"/dataframe-overview/","title":"Data Overview","keywords":"dataframe dataset import csv pandas numpy describe shape dtype list of columns counting missing values NaNs null heatmap seaborn check duplicate show all deal handle processing KDE Kernel Density Estimation values distribution bar plot visuzlize visualization null values percentage features","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"In this note, I use df as DataFrame, s as Series.\nLibraries #\nimport pandas as pd # import pandas packageimport numpy as np\nImport and have a look #\ndf = pd.read_csv('filename.csv', na_values=['none']) # \"none\" is missing datadf.head() # read first 5 rowsdf.tail() # last 5 rowsdf.head(10) # first 10 rows\nGet general infos #\ndf.info() # show dtype of dataframedf.describe() # numerical featuresdf.describe(include=['O']) # categorical featuresdf.describe(include='all') # all typesdf.shape # dataframe's shapedf.dtypes # type of each columndf.get_dtype_counts() # count the number of data types\nCheck distribution of values using KDE (Kernel Density Estimation),\nplt.figure(figsize=(20, 5))df['value'].plot.kde()\nGet columns' info #\n\n# LIST OF COLUMNSdf.columnslen(df.columns) # #cols?\n# UNIQUE VALUES IN COLdf['col'].unique()df['col'].unique().size #unique valsdf['col'].nunique() # number of unique vals\n\nCounting #\n# Counting #elements of each class in dfdf.Classes.value_counts() # give number of each 0 and 1\n# count #elements each unique values in a col/seriesdf[col].value_counts()\nMissing values #\n👉 Handle missing values.\n\n# total number of nans in dfdf.isnull().sum().sum()\n# #nans in each col (including zeros)df.isnull().sum()\n# #not-nans in each coldf.count()# each rowdf.count(axis=1)\n# columns having the nulls (any nan)null_columns = df.columns[df.isna().any()].tolist()# how many?df[null_columns].isnull().sum()\n# number of rows having ALL nansdf.isna().all(axis=1).sum()\n# number of columns having ALL nansdf.isna().all(axis=0).sum()\n# find index of rows having ALL nansdf.index[df.isna().all(axis=1)].to_list()\n\n# number of nans in dfdf.isnull().sum().sort_values(ascending=False)# find % of null values(df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)\n# Visualize the locations of missing values,import seaborn as snsdf = df.set_index('YEAR') # y-axis is YEARsns.heatmap(df.isnull(), cbar=False) # x-axis is columns' name\n# Plot the percentage of nans w.r.t. each column (feature)df_tmp = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False).to_frame(name='percentage')df_tmp.reset_index().plot(kind='bar', x='index', y='percentage', figsize=(20,5))plt.xlabel('features', fontsize=14)plt.ylabel('% of nans', fontsize=14)\nDuplicates #\n👉 Handle duplicates.\n# Check if there are duplicated values?df['col'].duplicated().any() # returns True/False\n# How many duplicates? (only count the first occurs)df['col'].duplicated().sum()\n# How many (including the repeated occurs)df['col'].duplicated(keep=False).sum()\n# List all duplicated values (LONG EXECUTING!!!)pd.concat( g for _, g in df.groupby('col') if len(g)>1 )\n"},"/titanic-disaster/":{"id":"/titanic-disaster/","title":"Titanic Disaster on Kaggle","keywords":"survive passenger drop features convert to dummy variables impute missing data gridsearchcv Continuous to categorical random forest create an output file Manav Sehgal Dataquest Abhinav Sagar","tags":["posts","Project-based Learning"],"cat":"/img/cats/project.svg","content":"Introduction #\nIn this challenge, we are going to answer the question: &quot;What sorts of people were more likely to survive?&quot; using passenger data. Datasets to be used: train.csv (for training and predicting), test.csv (for submitting).\nhtml file -- open in colab\n\nFirst 10 rows of the dataset.\n\n\n\nVariable\nDefinition\nKey\n\n\n\n\nsurvival\nSurvival\n0 = No, 1 = Yes\n\n\npclass\nTicket class\n1 = 1st, 2 = 2nd, 3 = 3rd\n\n\nsex\nSex\n\n\n\nAge\nAge in years\n\n\n\nsibsp\n# of siblings / spouses aboard the Titanic\n\n\n\nparch\n# of parents / children aboard the Titanic\n\n\n\nticket\nTicket number\n\n\n\nfare\nPassenger fare\n\n\n\ncabin\nCabin number\n\n\n\nembarked\nPort of Embarkation\nC = Cherbourg, Q = Queenstown, S = Southampton\n\n\n\nTL;DR; #\n\nTake an overview about dataset.\n\n.describe for numerical / categorical features.\nFind percentage of missing data on each feature.\nSurvival based on some categorical features.\nVisualize survival based on Age.\nCheck if the result depends on the titles indicated in the Name?\n\n\nPreprocessing data:\n\nDrop unnecessary features (columns) (Name, Ticket, Cabin) using df.drop().\nConvert categorical variables to dummy ones using pd.get_dummies().\nImpute missing continuous values using sklearn.impute.SimpleImputer.\nTake an idea to change Age to a categorical feature and then also convert to dummy.\n\n\nUsing GridSearchCV to find the optimal hyper parameters and apply some algorithms, e.g. Random Forest.\nExport the result to an output file.\n\nPreliminaries #\nimport numpy as npimport matplotlib.pyplot as plt # plotimport pandas as pd # working with datasetfrom sklearn import preprocessingfrom sklearn.impute import SimpleImputer # impute missing datafrom sklearn.model_selection import GridSearchCV, cross_val_score\nOverview datasets #\nRead data\ntrain = pd.read_csv(\"train.csv\")test = pd.read_csv(\"test.csv\")\nTake a look\ntrain.head(10)train.info()train.info()train.describe() # for numerical featurestrain.describe(include=['O']) # for categorical features\nFind the percentage of missing data on each feature,\ntotal = train.isnull().sum().sort_values(ascending=False)percent = (round(train.isnull().sum()/train.isnull().count()*100, 1)).sort_values(ascending=False)pd.concat([total, percent], axis=1, keys=['Total', '% of missing'])\nSurvival based on some categorical features,\ntrain.pivot_table(index=\"Sex\", values=\"Survived\")train.pivot_table(index=\"Pclass\", values=\"Survived\")train.pivot_table(index=\"SibSp\", values=\"Survived\")train.pivot_table(index=\"Parch\", values=\"Survived\")\nVisualize survival based on Age (numerical),\ntrain[train[\"Survived\"]==1]['Age'].plot.hist(alpha=0.5, color='blue', bins=50) # survivedtrain[train[\"Survived\"]==0]['Age'].plot.hist(alpha=0.5, color='blue', bins=50) # died\nList of titles (Mr., Mrs., Dr.,...) from Name,\ntrain.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\nPreprocessing data #\nIn this task, you have to do the same techniques for both train and test sets!\nDrop unnecessary features #\nDrop some unnecessary features (columns),\ntrain.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)test.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\nConvert to dummy #\nConvert categorical features to dummy variables,\ndef create_dummies(df, column_name): # Convert the column_name training feature into dummies using one-hot # and leave one first category to prevent perfect collinearity dummies = pd.get_dummies(df[column_name], prefix=column_name, drop_first=True) df = pd.concat([df, dummies], axis=1) return df\n# Sextrain = create_dummies(train, 'Sex')test = create_dummies(test, 'Sex')\n# Embarkedtrain = create_dummies(train, 'Embarked')test = create_dummies(test, 'Embarked')\n# Social Classtrain = create_dummies(train, 'Pclass')test = create_dummies(test, 'Pclass')\nImpute Missing Values #\nFor continuous variables, we wanna fill missing data with the mean value.\ndef impute_data(df_train, df_test, column_name): imputer = SimpleImputer(missing_values=np.nan, strategy='mean', verbose=0) # Fit the imputer object on the training data imputer.fit(df_train[column_name].values.reshape(-1, 1)) # transform single column to 1 # Apply the imputer object to the df_train and df_test df_train[column_name] = imputer.transform(df_train[column_name].values.reshape(-1, 1)) df_test[column_name] = imputer.transform(df_test[column_name].values.reshape(-1, 1)) return df_train, df_test\n# Agetrain, test = impute_data(train, test, 'Age')# Faretrain, test = impute_data(train, test, 'Fare')\nContinuous to categorical #\nIn the case, for example, you wanna convert Age feature which is initially a numerical feature to a categorical feature (many ranges of ages, for example).\ndef process_age(df, cut_points, label_names): df[\"Age\"] = df[\"Age\"].fillna(-0.5) df[\"Age_categories\"] = pd.cut(df[\"Age\"], cut_points, labels=label_names) return dfcut_points = [-1, 0, 5, 12, 18, 35, 60, 100]label_names = [\"Missing\", 'Infant', \"Child\", 'Teenager', \"Young_Adult\", 'Adult', 'Senior']train = process_age(main, cut_points, label_names)test = process_age(test, cut_points, label_names)\nConvert to a dummy variable,\nmain = create_dummies(main, 'Age_categories')test = create_dummies(test, 'Age_categories')\nTraining with Random Forest #\nWe will use Grid Search to test with different parameters and then choose the best ones.\n# Create a dictionary containing all the candidate values of the parametersparameter_grid = dict(n_estimators=list(range(1, 5001, 1000)), criterion=['gini','entropy'], max_features=list(range(1, len(features), 2)), max_depth= [None] + list(range(5, 25, 1)))# Creata a random forest objectrandom_forest = RandomForestClassifier(random_state=0, n_jobs=-1)# Create a gridsearch object with 5-fold cross validation, and uses all cores (n_jobs=-1)clf = GridSearchCV(estimator=random_forest, param_grid=parameter_grid, cv=5, verbose=1, n_jobs=-1)\nSplit into X_train, y_train:\nX_train = train[train.columns.difference(['Survived'])]y_train = train['Survived']\n# Nest the gridsearchCV in a 3-fold CV for model evaluationcv_scores = cross_val_score(clf, X_train, y_train)# Print resultsprint('Accuracy scores:', cv_scores)print('Mean of score:', np.mean(cv_scores))print('Variance of scores:', np.var(cv_scores))\nRetrain The Random Forest With The Optimum Parameters\n# Retrain the model on the whole datasetclf.fit(X_train, y_train)# Predict who survived in the test datasetpredictions = clf.predict(test)\nCreate an output file #\nfinal_ids = test[\"PassengerId\"]submission_df = {\"PassengerId\": final_ids, \"Survived\": predictions}submission = pd.DataFrame(submission_df)submission.to_csv('titanic_submission.csv', index=False)\nAnother way, check the last section of this post.\nOther approaches #\n\nBased on the number of family/sibling members: combination of SibSp and Parch.\nGo alone?\nConsider the title from Name.\nUse Decision Tree with K-fold.\n\nReferences #\n\nChris Albon -- Titanic Competition With Random Forest.\nManav Sehgal -- Titanic Data Science Solutions.\nDataquest -- Kaggle fundamental -- on my Github.\nAbhinav Sagar -- How I scored in the top 1% of Kaggle’s Titanic Machine Learning Challenge.\n\n"},"/grid-search/":{"id":"/grid-search/","title":"Grid Search","keywords":"hyper parameter tuning Random Forest in solving the Titanic problem","tags":["posts","Machine Learning"],"cat":"/img/cats/ml.svg","content":"A process of performing hyper parameter tuning to determine optimal values for a given model.\nBelow are an example of using Grid Search with Random Forest in solving the Titanic problem.\nfrom sklearn.model_selection import GridSearchCV, cross_val_scorefrom sklearn.ensemble import RandomForestClassifier as RF\n# Create a DICTIONARY containing all the candidate values of the parametersparameter_grid = dict(n_estimators=list(range(1, 5001, 1000)), criterion=['gini','entropy'], max_features=list(range(1, len(features), 2)), max_depth= [None] + list(range(5, 25, 1)))# Creata a random forest objectrandom_forest = RF(random_state=0, n_jobs=-1)# Create a gridsearch object with 5-fold cross validation,# and uses all cores (n_jobs=-1)gsc = GridSearchCV(estimator=random_forest, param_grid=parameter_grid, cv=5, verbose=1, n_jobs=-1)\n\nestimator: model we are using (RF).\nparam_grid: a dictionary of required parameters and their range of values specified in estimator.\n\nFit and get the best parameters,\ngrid_result = gsc.fit(X, y)best_params = grid_result.best_params_\nIn the case you wanna use these best_params,\nbest_clf = RF(n_estimators = best_params[\"n_estimators\"], criterion = best_params[\"criterion\"], max_features = best_params[\"max_features\"], max_depth = best_params[\"max_depth\"] )\nOr you can just use directly the result to predict,\ngsc.fit(X, y)gsc.predict(X_test)\nTake the cross validation (take a long time to run!!!),\ncv_scores = cross_val_score(gsc, X, y)print('Accuracy scores:', cv_scores)print('Mean of score:', np.mean(cv_scores))print('Variance of scores:', np.var(cv_scores))\nReference #\n\nChris Albon -- Titanic Competition With Random Forest.\nScikit-learn -- Parameter estimation using grid search with cross-validation.\n\n"},"/regular-expression/":{"id":"/regular-expression/","title":"Regular Expression in Python","keywords":"special characters","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"We can select string with some patterns.\nImport library #\nimport re\nSpecial characters #\n\n. matches any character except a newline\n^a all strings starting with 'a'\na$ all strings ending with 'a'\nab+ matches 'ab', 'abb' but not 'a', 'ac'.\n[bcr]at any characters within [] can be filled the space\nUsing \\ to escape special characters\n\n\\s : whitespace characters. \\S: any except whitespace.\n\\b : empty strings (only at the beginning or end of a word). \\B:\n\n\ncat|dog would match 'catfish' and 'hotdog' for begin and end characters\n[amk] will match 'a', 'm', or `'k``\n[0-9] will match any character that falls between 0 and 9\n[a-z] : lowercase\n[0-9]{4}: repeat the pattern [0-9] four times by writing\na{m,n} matches from m to n repetitions of 'a'.\n\na{m,} matches from m to infinity repetitions of 'a'.\n\n\n\nReferences #\n\nPython docs -- Regular Expression.\n\n"},"/gatsby-js/":{"id":"/gatsby-js/","title":"Gatsby 101","keywords":"create a website static web react js","tags":["posts","Web Dev","GatsbyJS","Static Site Generators"],"cat":"/img/cats/web-dev.svg","content":"Jekyll is great but for a note-taking site like this site, it's slow. I decide to learn about Gatsby to make my note site more faster!\nMisc #\n👉 If you wanna install some additional plugins/components, remember to add --save at the end of the installation line. This step is to add to package.json.\n# for examplenpm i gatsby-plugin-react-head react-head --save\nWhen you install something new, don't forget to cd to the current working directory, e.g. /gatsby-site.\n👉 React / Gatsby use JSX syntax. It's an XML/HTML-like syntax used by React that extends ECMAScript so that XML/HTML-like text can co-exist with JavaScript/React code.\n👉 Read this to understand the differences between Class Component and Functional Component (a.k.a. stateless). Below are 2 examples which give the same result.\n\n// Class Componentclass MyComponentClass extends React.Component { render() { return &lt;div>{this.props.name}&lt;/div>; }}\n// Functional Componentconst MyStatelessComponent = props => &lt;div>{props.name}&lt;/div>;// without JSXconst MyStatelessComponent = props => React.createElement('div', null, props.name);\n\n\nFunctional Component (stateless component): just a plain javascript function which takes props as an argument and returns a react element. You can't reach this.state inside it.\nComponent class: has a state, lifecycle hooks and it is a javascript class.\n\nThe rule would be: if your component needs some data which cannot be passed as a prop use class component to get that data. If you need to keep UI state in your component(expandable blocks) so it’s a good place to keep that info in a components state.\nInstallation on localhost #\nInstall npm and NodeJS (with npm). Check the current version: npm -v (for npm) and node -v (for nodejs). After that, you can install Gatsby,\n# installnpm install --global gatsby-cli# check versiongatsby -v# updatenpm i -g gatsby-cli\nIf error EACCES occurs (fix on Linux)\n\nCreate a new folder by: mkdir ~/.npm-global\n\n\nOpen ~/.profile\n\n\nAdd following lines to this file\nnpm config set prefix '~/.npm-global'export PATH=~/.npm-global/bin:$PATH\n\n\nSave the file and then run (if you don't restart the computer, do the same below work for new tab of terminal): source ~/.profile.\n\n\n\nInstall new site with\ngatsby new gatsby-site # create a new site with name 'gatsby-site'cd gatsby-sitegatsby develop # run the site at http://localhost:8000\nYou can view GraphiQL, an in-browser IDE, to explore your site's data and schema,\nhttp://localhost:8000/___graphql\nHow to use ___graphql?Suppose that in ListAccount.js,\nexport default props => ( &lt;StaticQuery query={graphql` query AccountItemsQuery { allAccountItemsJson{ edges{ node{ name icon{ childImageSharp { fixed(width: 150, height: 150) { ...GatsbyImageSharpFixed_tracedSVG } } } url opacity title } } } } `} render={data => &lt;ListSocial accounts={data} {...props} />} />)\nIn http://localhost:8000/___graphql,\nquery AccountItemsQuery { allAccountItemsJson { edges { node { name icon { childImageSharp { fixed(width: 150, height: 150) { tracedSVG } } } url opacity title } } }}\nand then click on Run icon to see the result!\n\nErrors? #\n👉 Requires...\n# bootstrap@4.4.1 requires a peer of jquery@1.9.1npm i jquery@1.9.1 --save# tsutils@3.17.1 requires a peer of typescript@>=2.8.0npm i typescript --save\n👉 Cannot read property...\n# TypeError: Cannot read property 'fileName' of undefined\nAbove error comes from inserting images using query. To overcome this, we have to use StaticQuery which is introduced in Gatsby v2 (I don't know why it works!?) 👉 The reason is that the (old) page query can only be added to page components (in my try, I add in Header.js component). StaticQuery can be used as a replacement of page query, it can be added to any component.[ref]\n👉 Fail to build on Netlify Build script returned non-zero exit code: 127,\n\nDelete package-lock.json, don't include it and node_modules on git.\nRemove either package.json or yarn.lock on Github (remove yarn).\n&quot;version&quot;: &quot;0.1&quot;, is wrong, changing to &quot;1.0.1&quot; is OK.\nTry to debug with netlify on localhost.\n\nAfter installing, cd to gatsby-site and then run netlify dev.\nRead more and more.\n\n\n\n👉 Fail to build on Netlify Can't resolve '../components/Header' in '/opt/build/repo/src/components' for examples. 👉 The problem comes from the original name of file Header.js is header.js. I renamed it to Header.js but it's still actually header.js (check the Github Desktop to see). You can change is to HeaderNew.js to fix the problem!\n👉 If you wanna use adjacent react components, you have to put them inside &lt;&gt;..&lt;/&gt; (React fragment) like below example,\nreturn ( &lt;> &lt;Navigation>&lt;/Navigation> &lt;Header type={headerType} /> &lt;span>Thi&lt;/span> &lt;/> )\nThis allows you to return multiple child components without appending additional nodes to the DOM.\n👉 Warning: Each child in a list should have a unique &quot;key&quot; prop. You have to make sure that each child of a list in react component has a unique key. For example\n\n// error{links.map(link => ( &lt;> &lt;span key={link.name}> Thi &lt;/span> &lt;Link key={link.name}> {link.name} &lt;/Link> &lt;/>))}\n// but this{links.map(link => ( &lt;span key={link.name}> &lt;span> Thi &lt;/span> &lt;Link> {link.name} &lt;/Link> &lt;/>))}\n\nComponents from Gatsby #\n👉 Link (replaces &lt;a&gt; tag for internal links). For external links, use &lt;a&gt;&lt;/a&gt; as usual.\nimport { Link } from 'gatsby'&lt;Link to=\"/\">Text&lt;Link/> // only used for internal links\nYou cannot use target='_blank' with &lt;Link&gt; because whenever you use internal links, they are always in the same window!\n👉 Use className instead of class=. E.g. className = &quot;abc&quot; or className = &quot;abc xyz&quot;.\n👉 Inline CSS, &lt;div style={{ color: &quot;#ffff&quot;, paddingTop: &quot;10px&quot; }}&gt;&lt;/div&gt;.\n👉 Date in Gatsby: {new Date().getFullYear()} or using moment.js.\nGatsby structure #\n\nRecipes -- a cookbook on how to build things, Gatsby style.\nGatsby Project Structure -- a tour of all the common folders and files.\nBuilding with Components.\nLayout Components\n\nUnderstand props #\nWhen React sees an element representing a user-defined component, it passes JSX attributes to this component as a single object. We call this object &quot;props&quot; (properties).[ref]\nComponents #\nA page is basically,\n\nimport React from \"react\"function AboutPage(props) { return ( &lt;div className=\"about-container\"> &lt;p>About me.&lt;/p> &lt;/div> )}export default AboutPage\nimport React from \"react\"export default (props) => { return ( // ... )}// orconst AboutPage = (props) => ( // ...)export default AboutPage\n\nApply Bootstrap #\nLearn from Starter theme #\n💡 You can install a Gatsby Bootstrap Starter,\ngatsby new gatstrap https://github.com/jaxx2104/gatsby-starter-bootstrap\nUsing plugins #\n❓ What if you wanna start from the beginning? 👉 Install react-bootstrap and bootstrap,\nnpm install react-bootstrap bootstrap --save# --save to save to package.json\nImport below line in /gatsby-browser.js,\nimport 'bootstrap/dist/css/bootstrap.min.css';\nUsing CDN from Bootstrap #\n❓ If you wanna use CDN? 👉 Put below line in &lt;head&gt; by using React Helmet,\n&lt;Helmet> &lt;link rel=\"stylesheet\" href=\".../bootstrap.min.css\" integrity=\"...\" crossOrigin=\"anonymous\" /> &lt;script src=\".../jquery-3.4.1.slim.min.js\" integrity=\"...\" crossOrigin=\"anonymous\">&lt;/script> &lt;script src=\".../popper.min.js\" integrity=\"...\" crossOrigin=\"anonymous\">&lt;/script> &lt;script src=\".../bootstrap.min.js\" integrity=\"...\" crossOrigin=\"anonymous\">&lt;/script>&lt;/Helmet>\nYou can put above codes directly in your layout.js or index.js. All the &lt;link&gt; and &lt;script&gt; tags will be included in the &lt;head&gt;. For example in the file src/pages/index.js,\n// src/pages/index.jsimport Layout from \"../layouts/layout\"import Helmet from \"react-helmet\"const IndexPage = () => ( &lt;Layout> &lt;Helmet> // the codes &lt;/Helmet> &lt;h1>Hi people&lt;/h1> &lt;p>Welcome to your new Gatsby site.&lt;/p> // other codes... &lt;/Layout>)export default IndexPage\n❓ If you wanna put bootstrap.js in the footer? 👉 You can read this tutorial to add &lt;script&gt; / &lt;link&gt; tags in &lt;head&gt;, start or end of &lt;body&gt; tag. For example, in order to put above scripts/links before &lt;/body&gt;, paste below code in /gatsby-ssr.js,\n// file /gatsby-ssr.jsconst React = require(\"react\")exports.onRenderBody = ({ setHeadComponents, setPostBodyComponents,}) => { setHeadComponents([ &lt;link key='bootstrap-css' rel=\"stylesheet\" href=\".../bootstrap.min.css\" integrity=\"...\" crossOrigin=\"anonymous\" />, ]) setPostBodyComponents([ &lt;script key=\"jquery-3-4-1\" type=\"text/javascript\" src=\".../jquery-3.4.1.slim.min.js\" integrity=\"...\" crossOrigin=\"anonymous\" />, &lt;script key=\"proper-1-16\" type=\"text/javascript\" src=\".../popper.min.js\" integrity=\"...\" crossOrigin=\"anonymous\" />, &lt;script key=\"bootstrap-js\" type=\"text/javascript\" src=\".../bootstrap.min.js\" integrity=\"...\" crossOrigin=\"anonymous\" />, ])}\nRemember to restart gatsby (Ctrl + C to stop and run gatsby develop to start again).\nUsing sass #\n\n// in /scr/pages/index.jsimport Layout from \"../layouts/layout\"\n// in /scr/layouts/layout.jsimport \"../styles/main.scss\"\n// in /scr/styles/main.scss@import \"layout\";\n// in /scr/styles/_layout.scss// scss codes\n\nDifferences between layouts and templates #\nThere are 2 separated folders /src/layouts and /src/templates.\n\n\nlayouts: components are for everything shared across pages e.g. headers, footers, sidebars, etc.\ntemplates: components are for page types e.g. blog posts, documentation pages, etc.\n\nDesign base layout #\nWhat I need in the base layout:\n\n\nA fixed navigation bar on top.\nA fixed footer on bottom.\nA flexible header.\nA body wraper.\n\nDesign post / page templates #\nTheir differences are just the width of the container.\nDifferent &lt;Header&gt; for different page types #\n// in src/components/Header.jsimport React, { Component } from 'react'export default class Header extends Component { render() { const headerType = this.props.type switch (headerType) { case 'index': return ( &lt;> &lt;header className=\"idx-header header\"> ... &lt;/header> &lt;/> ) default: return ( &lt;> &lt;header className=\"header\"> ... &lt;/header> &lt;/> ) } }}\n\n// in src/layouts/base.jsimport Header from \"../components/Header\"const Layout = ({ children, headerType='page' }) => { return ( &lt;> &lt;Header type='index' /> {children} &lt;/> )}export default Layout\n// in src/pages/index.jsimport Layout from \"../layouts/base\"const IndexPage = () => ( &lt;Layout headerType='index'> ... &lt;/Layout>)export default IndexPage\n\nAdd Navigation bar #\nUsing react-bootstrap, create a file src/components/Navigation.js whose content is,\nimport React from 'react'import {Navbar, Nav, NavDropdown, Form, FormControl, Button} from 'react-bootstrap'export default (props) => ( // the codes from https://react-bootstrap.netlify.com/components/navbar/#navbars)\nThen, in /src/Header.js,\nimport Navigation from '../components/Navigation'const Header = () => ( &lt;header ..> &lt;Navigation>&lt;/Navigation> // other codes &lt;/header>)\nIf you get stuck, check this video.\nUsing Font Awesome #\nInstall (the free things) (if you have a pro license, read this) or this,\nnpm i --save @fortawesome/fontawesome-svg-core @fortawesome/react-fontawesome @fortawesome/free-regular-svg-icons @fortawesome/free-solid-svg-icons @fortawesome/free-brands-svg-icons\nTo import everything in one place instead of importing each icon into each separate file, we'll create a Font Awesome library. Creat src/components/fontawesome.js\n// import the libraryimport { library } from '@fortawesome/fontawesome-svg-core';// import your iconsimport { faHome, faFire, faEdit, } from '@fortawesome/free-solid-svg-icons';library.add( faHome, faFire, faEdit,);\nNote that, an icon fas fa-money-bill will have name faMoneyBill from free-solid-svg-icons. In the case you wanna import an entire package,\nimport { library } from '@fortawesome/fontawesome-svg-core';import { fab } from '@fortawesome/free-brands-svg-icons';library.add(fab);\nIn src/pages/index.js (for example),\nimport '../components/fontawesome'import { FontAwesomeIcon } from '@fortawesome/react-fontawesome'&lt;FontAwesomeIcon icon={'home'} /> // for 'faHome' or 'fas fa-home'&lt;FontAwesomeIcon icon={['fab', 'github']} /> // for 'faGithub' or `fab fa-github`\n💡 Yes! fortawesome is correct!!!\n💡 If you have a problem in that the icon is firstly flashing big and then smaller, you need to set the configuration autoAddCss to false,[ref]\nimport { config } from '@fortawesome/fontawesome-svg-core'import \"@fortawesome/fontawesome-svg-core/styles.css\"config.autoAddCss = false\nGoogle Fonts #\nUsing typeface.js (search font in npmjs),\n\n# installnpm install --save typeface-open-sans\n# in gatsby-browser.jsrequire('typeface-open-sans');\n\nRebuild to see the result!\nBelow is the old method (it didn't work well, it doesn't contain font-weight 600 for Open Sans without reason).\nnpm install --save gatsby-plugin-prefetch-google-fonts\n// in /gatsby-config.jsmodule.exports = { plugins: [ { resolve: `gatsby-plugin-prefetch-google-fonts`, options: { fonts: [ { family: `Roboto Mono`, variants: [`400`, `700`] }, { family: `Roboto`, subsets: [`latin`] }, ], }, } ]}\nInsert images / photos #\nRead this note.\nAdding markdown posts #\nPosts (.md files) are stored in /content/posts/. Install gatsby-transformer-remark,\nnpm install --save gatsby-transformer-remark\nAnd add the following to gatsby-config.js (),\nplugins: [ { resolve: `gatsby-source-filesystem`, options: { name: `posts`, path: `${__dirname}/content/posts`, }, }, `gatsby-transformer-remark`, // there may be already others like this { resolve: `gatsby-source-filesystem`, options: { name: `images`, path: `${__dirname}/src/images`, }, },]\nCreate a file called post-1.md in content/posts/,\n---\npath: &quot;/first-post&quot;\ndate: &quot;2019-05-04&quot;\ntitle: &quot;My first blog post&quot;\n---\n\n...read this and this example for more...\nDisplay site / post info on browser tab #\nimport Layout from \"../layouts/base\"import Helmet from 'react-helmet'const IndexPage = () => ( &lt;Layout> &lt;Helmet title={`Thi | I failed my way to success`} /> &lt;/Layout>)\nCreate page template and markdown file #\nRead this note.\nRender html tag in a string #\nInstead of &lt;p dangerouslySetInnerHTML={{ headerIntro }} /&gt;, you can use &lt;p dangerouslySetInnerHTML={{__html: headerIntro }} /&gt;. If there is a html tag in headerIntro, e.g. &quot;&lt;i&gt;Hello&lt;/i&gt;&quot; will be rendered as Hello.\nJSX in Markdown #\n\nDownload and use MDX plugin.\nWe have to put all mdx files in /src/pages. The mdx files will be renders automatically! That's why we need to indicate defaultLayouts in /gatsby-config.js[ref]. I have tried to render mdx in /content/pages/ but it didn't work!\nFor an example of using graphql in mdx file, check /src/pages/about.mdx.\nFor a specific page, one can use props.pageContext.frontmatter.title to take the title of that page.\nFor writing pages, read this.\n\nCreate page template and markdown file #\nSuppose that you wanna create a page /about taking content from file /content/pages/about.md and it applies template /src/templates/page.js. All you need to do is following this post.\n\nFirst, add to /gatsby-config.\nCreate /src/templates/page.js,\nCreate markdown file /content/pages/about.md.\nModify /gatsby-node.js to tell gatsby to create a page /about from about.md using template page.js.\n\nReferences #\n\nOfficial documentation.\n\nExamples.\nGatsby Docs -- Tutorials (step-by-step).\n\n\nReact Bootstrap -- get the components.\nReact Main Concepts -- understand some main concepts in React.\nJSX in depth -- understand the syntax of JSX.\nw3schools -- React Tutorial.\nThe Fullstack Tutorial for GraphQL\n\n"},"/gatsby-images/":{"id":"/gatsby-images/","title":"Gatsby Images","keywords":"create a website static web react js inserting images","tags":["posts","Web Dev","GatsbyJS","Static Site Generators"],"cat":"/img/cats/web-dev.svg","content":"Because the post Gatsby 101 is too long, I write a separate post just for images in Gatsby.\nRule of thumb #\n\nStatic images (icon, logo, favicon): just import and use img.\nsvg cannot be used with childImageSharp, just use &lt;img&gt; with its publicURL.\npng, jpg can be used with &lt;Img&gt; and childImageSharp.\nData can be used: json or yaml, cannot use js for images.\nList of images are get up to edges. After edges, there are a loop of nodes.\nquery components must placed in &lt;StaticQuery /&gt;.\nDifferent screen solution: use fixed.\nDifferent screen size: use fluid.\nUse http://localhost:8000/___graphql to check the query.\nUse {condition &amp;&amp; condition &amp;&amp; output} instead of using if..else...\nThe relative path of images is compared with the path of data file where the urls are indicated.\n\nType of images to be processed #\nRead this post from CSS-Tricks to know which images should be processed, which ones should not.\n\n\nNo processing required: &quot;static images&quot;, icons and logos, favicons 👉 We can import and use &lt;img&gt; to directly import them.\nProcess required: PNG, JPG files, gallery, ...\n\nSingle photo #\nInstall stuffs following this doc,\nnpm install --save gatsby-image gatsby-plugin-sharp gatsby-transformer-sharp\nInsert directly, #\nimport avatar from \"src/images/site/avatar.jpg\"function Header() { return &lt;img src={logo} alt=\"Logo\" />}export default Header\nUsing data/query #\nSo that we can have the lazing loading / resizing / blur-up (traced placeholder) effects.\nnpm install --save gatsby-image gatsby-transformer-sharp gatsby-plugin-sharp\nBelow technique is just for single photos.\n// gatsby-config.jsmodule.exports = { plugins: [ ... 'gatsby-plugin-sharp', 'gatsby-transformer-sharp', { resolve: 'gatsby-source-filesystem', options: { name: 'images', path: path.join(__dirname, `src`, `images`), }, }, ],}\n// src/components/Header.jsimport { StaticQuery, graphql } from 'gatsby';import Img from 'gatsby-image';const Header = ({ data }) => ( &lt;header> &lt;Img fluid={data.myAvatar.childImageSharp.fluid} /> &lt;/header>)// src/images/avatar.pngexport default props => ( &lt;StaticQuery query={graphql` query { myAvatar: file(relativePath: { eq: \"avatar.png\" }) { childImageSharp { fluid(maxWidth: 150) { ...GatsbyImageSharpFluid } } } } `} render={data => &lt;Header data={data} {...props} />} />)\n👉 Most of tutorials like this or this don't talk about StaticQuery (Gatsby v2). I followed them but it didn't work, we have to use StaticQuery to make things work! 👉 The reason is that the (old) page query can only be added to page components (in my try, I add in Header.js component). StaticQuery can be used as a replacement of page query, it can be added to any component.[ref]\n👉 There are 2 types:\n\n\nfixed: has a set width and height and is for supporting different screen resolutions. It accepts width and height.\nfluid: has a max-width and sometimes a max-height, and will create multiple images for supporting different screen sizes. It accepts maxWidth and maxHeight.\n\nYou need to use them with fragments like GatsbyImageSharpFixed_tracedSVG or GatsbyImageSharpFluid (more).\nUsing absolute path #\nIf you want to query to an image in /src/images/example.png, you can use,\nexport const query = graphql` query { file(absolutePath: { regex: \"/\\\\/src\\\\/images\\\\/example\\\\.png/\" }) { childImageSharp { fixed(width: 800) { ...GatsbyImageSharpFixed } } } }`\nSVG files #\ngatsby-plugin-sharp / gatsby-image doesn't handle SVGs or GIFs. If you want to use your svg you, e.g. could import / use it like import yourSVG from './logo_large.svg'.[ref]\nChange favicon #\nPut favicon.png in src/images and then change gatsby-config.js\n{ resolve: `gatsby-plugin-manifest`, options: { // other stuffs icon: `src/images/favicon.png`, },},\nYou need to restart gastby to see the result!\nMultiple images from data file/folder #\nImages' URLs stored in a JSON file #\nSuppose that we store some images in /src/images/ and we indicate them in a json file like this,\n// File /data/AccountItem.json[ { \"name\": \"Github\", \"icon\": \"./github.svg\", }, { \"name\": \"LinkedIn\", \"icon\": \"./linkedin.svg\", }, { \"name\": \"Math2IT\", \"icon\": \"./math2it.png\", }]\nImages (github.svg, linkedin.svg, math2it.png) are stored in the same folder of your json file, that why we put ./ before them!\n❓ There are both png and svg files in the list. We cannot use childImageSharp for svg files. How can we &quot;loop&quot; through each item and consider differently svg and png files?\n💡 Read this tutorial to read data from a json file.\n\n\nHaving a json file, in this example, it's /data/AccountItem.json (you can name it whatwever you want but its name is really important for using later!!!)\n\n\nInstall\nnpm install gatsby-transformer-json gatsby-source-filesystem --save\n\n\nInside /gatsby-config.js, add following (direction in path is the direction to the folder containing your json file),\n`gatsby-transformer-json`,{ resolve: 'gatsby-source-filesystem', options: { name: 'data', path: `${__dirname}/data/`, },}\n\n\nSuppose that we wanna load images in a component /src/components/ListAccount.js. Put in it,[ref]\nimport { StaticQuery, graphql } from 'gatsby';import Img from 'gatsby-image'const ListAccount = ( {accounts} ) => ( &lt;div> {accounts.map(account => ( &lt;div className=\"item\"> &lt;div className=\"img\"> {!account.node.icon.childImageSharp &amp;&amp; (account.node.icon.extension === 'svg') &amp;&amp; &lt;img src={account.node.icon.publicURL} /> } {account.node.icon.extension !== 'svg' &amp;&amp; &lt;Img fixed={account.node.icon.childImageSharp.fixed} /> } &lt;/div> &lt;/div> ))} &lt;/div>)//export default props => ( &lt;StaticQuery query={graphql` query AccountItemsQuery { allAccountItemsJson{ edges{ node{ name icon{ childImageSharp { fixed(width: 150, height: 150) { ...GatsbyImageSharpFixed_tracedSVG } } extension publicURL } } } } } `} render={data => &lt;ListAccount accounts={data.allAccountItemsJson.edges} {...props} />} />)\n\n\nExplaination:\n\n\nWe have to put extension and publicURL inside icon because there are svg files!\nFor more intuition, look at http://localhost:8000/___graphql.\nIn edges, there are many nodes, each of them is relating to the item inside AccountItem.json. That's why the input data for &lt;ListAccount /&gt; must be data.allAccountItemsJson.edges.\nFor each account in accounts, we have to pass account.node before each attribute name, icon.\n{condition &amp;&amp; condition &amp;&amp; output} is a trick for not using if...else.\n\n👉 In the case you store images in a different folder, let's say /src/images/accounts/, you have to indicate it in /data/AccountItems.json:\n[ { \"icon\": \"../src/images/accounts/github.svg\", }]\nUsing YAML data file #\nSuppose our yaml file,\n// File /data/AccountItem.yaml- name: Github icon: ./github.svg- name: LinkedIn icon: ./linkedin.svg- name: Math2IT icon: ./math2it.png\nThe same technique as in the case of json file. In this case, we need to install gatsby-transformer-yaml,\nnpm install --save gatsby-transformer-yaml\nIn your gatsby-config.js,\n`gatsby-transformer-yaml`,{ resolve: `gatsby-source-filesystem`, options: { name: 'data', path: `${__dirname}/data/`, },},\nquery as an input #\nIn the previous step, query is considered inside the component file. What if you wanna query data and then pass it in a JSX components? (check index.js for an example)\nThere is a data file /data/MostProudOfItems.yaml.\n// in /src/pages/index.jsimport ShortcutListing from \"../components/ShortcutListing\"const indexPage = (props) => ( &lt;ShortcutListing shortcuts={props.data.allMostProudOfItemsYaml.edges} nShortcutsPerRow='3' />)export default IndexPageexport const pageQuery = graphql` query IndexQuery { allMostProudOfItemsYaml{ edges { node { title img { childImageSharp { fixed(width: 100, height: 100) { ...GatsbyImageSharpFixed_tracedSVG } } extension publicURL } url } } }, anotherYaml{ .... } }`\n// in /src/components/ShortcutListingconst ListShortcut = ({shortcuts, nShortcutsPerRow}) => ( // ...)export default ListShortcut\nGet all images from a specific folder #\n👉 This is also a way you use the name indicate in gatsby-config.js.\nSuppose that you wanna show all images in /sketches/.[ref]\n\n// In /gatsby-config.js{ resolve: \"gatsby-source-filesystem\", options: { path: `${__dirname}/sketches/`, name: \"sketchFolder\", },},\nexport const pageQuery = graphql` query IndexQuery { allFile(filter: { extension: {regex: \"/(jpg)|(jpeg)|(png)/\"}, sourceInstanceName: {eq: \"sketchFolder\"}}) { edges { node { childImageSharp { fluid { originalName } } absolutePath } } } }`\n\n💢 Above method is only works with /sketches (folder locates at the root of site). It doesn't work with /src/images/sketches, for example. I don't know why!\n👉 If you want to get all images from a folder (without using sourceInstanceName) you can use relativeDirectory in the query. Suppose that we have 2 folders with the same name sketches, one is in /content/sketches, one is in /src/images/sketches. The following code will load all images in these two folders!\n\n// In /gatsby-config.js{ resolve: \"gatsby-source-filesystem\", options: { path: `${__dirname}/content/`, name: \"content\", },},{ resolve: \"gatsby-source-filesystem\", options: { path: `${__dirname}/src/images`, name: \"images\", },},\nexport const pageQuery = graphql` query IndexQuery { allFile(filter: { extension: {regex: \"/(jpg)|(jpeg)|(png)/\"}, relativeDirectory: {eq: \"sketches\"}}) { edges { node { childImageSharp { fluid { originalName } } absolutePath } } } }`\n\n💢 Make sure the name of your folder is unique if you don't want to load images from a wrong location.\nReferences #\n\nA comprehensive guide to images in Gatsby by James Allardice.\nImage Processing with gatsby-transformer-sharp.\nBuilding A Custom, Accessible Image Lightbox In GatsbyJS\n\n"},"/pytorch/":{"id":"/pytorch/","title":"PyTorch extra","keywords":"pytorch device gpu cuda nvidia graphical device torch deep learning neural network","tags":["posts","Deep Learning"],"cat":"/img/cats/dl.svg","content":"This note is for things with PyTorch. Personal notes only.\nInstallation #\n\nVerify that your computer has a graphic card (NVIDIA): lspci -nn | grep '\\[03'\nCheck the CUDA version on Ubuntu: nvidia-smi. If have problems, check this note.\nInstall the lates version: here.\n\nErrors #\nProblem with CUDA version #\nFor example, need to install corresponding versions: torch==1.2.0 &lt;- torchvision==0.4.0 &lt;- Pillow&lt;7.0.0\npip3 install -U torch==1.2.0pip3 install -U torchvision==0.4.0pip3 install -U \"pillow&lt;7\"\nAnother option (worked on XPS 15 7950): torch==1.5.1, torchvision==0.6.1, pillow==7.2.0 (with nvcc --version is 11.1).\nNVIDIA too old #\nProblem The NVIDIA driver on your system is too old (found version 10010).\nFrom this website, problem is solved by\n\nSwitching from nvidia-driver-435 to nvidia-driver-440.\nRestart the computer.\n\nIt works on Dell XPS 7950 whose GPU is NVIDIA GTX 1650.\nOthers #\n🔅 RuntimeError: cuda runtime error (804) : forward compatibility was attempted on non supported HW at /pytorch/aten/src/THC/THCGeneral.cpp:47 (after update system including nvdia-cli, maybe): check this note.\nImport #\nimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optim\nDevice's info #\nprint('cuda is available? ', torch.cuda.is_available())print('device_count: ', torch.cuda.device_count())print('current device: ', torch.cuda.current_device())print('device name: ', torch.cuda.get_device_name(0))\n# Determine supported devicedef get_device(): if torch.cuda.is_available(): device = torch.device('cuda:0') # or something else else: device = torch.device('cpu') # don't have GPU return device\nConvert DataFrame / Series to Tensor #\ndef df_to_tensor(df): device = get_device() # see other section return torch.from_numpy(df.values).float().to(device)\n"},"/simple-autoencoder-ae/":{"id":"/simple-autoencoder-ae/","title":"Simple AutoEncoder (AE)","keywords":"autoencoder simple AE pytorch torch basic idea neural network NN layers activations encode encoder decode decoder relu linear sigmoid sequential anomaly detection wave data dataswati test interview","tags":["posts","Deep Learning"],"cat":"/img/cats/dl.svg","content":"Basic idea of AE #\n\nIdea: using AE in Anomaly Detection #\n\nUsing Keras #\nimport tensorflow as tftf.keras.backend.set_floatx('float64')from tensorflow.keras.layers import Dense, Inputfrom tensorflow.keras.models import Modelfrom sklearn.model_selection import train_test_split\nFrom this notebook,\nencoding_dim = 30input_dim = arr_signal_nor.shape[1] # 200 features# this is our input placeholderinput_arr = Input(shape=(input_dim,))encoded = Dense(encoding_dim, activation='relu')(input_arr)decoded = Dense(input_dim, activation='sigmoid')(encoded)# this model maps an input to its reconstructionautoencoder = Model(inputs=input_arr, outputs=decoded)# autoencoder.summary()autoencoder.compile(optimizer='adam', loss='mse')nb_epoch = 100batch_size = 50size_test = 0.1arr_train, arr_test = train_test_split(arr_signal_nor, test_size=size_test)autoencoder.fit(arr_train, arr_train, epochs=nb_epoch, batch_size=batch_size, shuffle=True, validation_data=(arr_test, arr_test), verbose=0 )\nUsing PyTorch #\nimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optim\n\nclass Autoencoder(nn.Module): def __init__(self, input_size=100, encoded_size=10): super(Autoencoder, self).__init__() s0 = input_size s1 = int((input_size + encoded_size)/2) s2 = encoded_size self.e1 = nn.Linear(s0, s1) self.e2 = nn.Linear(s1, s2) self.d2 = nn.Linear(s2, s1) self.d1 = nn.Linear(s1, s0) def encode(self, x): x = F.relu(self.e1(x)) x = F.relu(self.e2(x)) return x def decode(self, x): x = F.relu(self.d2(x)) x = torch.sigmoid(self.d1(x)) return x def forward(self, x): x = self.encode(x) x = self.decode(x) return x\n# USING SEQUENTIALclass Autoencoder(nn.Module): def __init__(self): super(Autoencoder, self).__init__()\t\t\t\ts0 = input_size s1 = int((input_size + encoded_size)/2) s2 = encoded_size self.encoder = nn.Sequential( nn.Linear(s0, s1), nn.ReLU(True), nn.Linear(s1, s2), nn.ReLU(True) ) self.decoder = nn.Sequential( nn.Linear(s2, s1), nn.ReLU(True), nn.Linear(s1, s0), torch.sigmoid(True), ) def forward(self, x): x = self.encoder(x) x = self.decoder(x) return x\n\n"},"/date-time-tips/":{"id":"/date-time-tips/","title":"Date / Time extra","keywords":"resample rule time step timedelta delta constructor format representation days hours minute second milisecond microsecond nanosecond offset string frequency resampling how DateOffsets frequencies strings offset aliases freq compare arithmetic timedelta different well sorted correctly pandas time series user guide convert timedelta timedelta64 numpy. np. TimedeltaIndex diff() difference datetimeindex Timedelta UNIX timestamp UTC +0 to_offset cannot use single T without number check info timestamp of a dataframe set index ISO 8601 format isoformat duration datetime","tags":["posts","Time Series"],"cat":"/img/cats/ts.svg","content":"ISO 8601 format #\nFor duration:\n\n\nP (duration, always at the beginning of the duration), Y (year), M (month), W (week), D (day), T (time designator, always precedes the time components), H (hour), M (minute), S (second).\nExample: P3Y6M4DT12H30M5S -- a duration of three years, six months, four days, twelve hours, thirty minutes, and five seconds.\n\nConverter,\nfrom datetime import datetime, timedeltafrom isodate import duration_isoformat # used only for datetime.timedeltadef get_isoformat(time): \"\"\" Convert pd.Timedelta, pd.Timestamp, datetimme.datetime, datetime.time, datetime.date, datetime.timedelta to isoformat \"\"\" if not isinstance(time, timedelta): return time.isoformat() else: return duration_isoformat(time)\nTimedelta #\nTo Timedelta, #\n# numpy.timedelta64(208206000000000,'ns') → Timedelta('2 days 09:50:06')pd.Timedelta(time, unit='ns')\n# DateOffsets ('14T') → Timedelta('0 days 00:14:00')pd.to_timedelta('14T')\n# Can't use 'T' as '1T'?from pandas.tseries.frequencies import to_offsetpd.to_timedelta(to_offset('T'))\nFrom Timedelta, #\n# Timedelta('0 days 00:01:20') -> 80 (s)# (SINGLE VALUE)td.total_seconds() # float\n# Timedelta('0 days 00:01:20') -> 80 (s) (FLOAT)# (ONLY WORK with a series, not a single value)series.astype('timedelta64[s]') # or 'ms'\n# '1 minutes' -> '1T'def timedelta_to_string(timedelta): units = ['D', 'H', 'T', 'S', 'L', 'U', 'N'] time_format = '' for i, c in enumerate(timedelta.components): if c != 0: time_format += str(c) + units[i] return time_format\n\n## EXAMPLEimport pandas as pdtest = pd.Timedelta('1 minutes')timedelta_to_string(test)\nTimedelta('0 days 00:01:00')\n'1T'\n\n\nTimedeltaIndex differences #\nThere is no .diff method with TimedeltaIndex, you can use,\nnp.subtract(df[1:], df[:-1])# convert to hournp.subtract(df[1:], df[:-1]) / pd.Timedelta('1 hour')\nCompare/Make arithmetic different frequency strings #\nWe wanna compare 150S (150 seconds) with 1T (1 minutes).\n\nimport pandas as pdpd.to_timedelta('150S') > pd.to_timedelta('1T')pd.to_timedelta('120S') == pd.to_timedelta('1T')pd.to_timedelta('120S') == pd.to_timedelta('2T')\nTrue\nFalse\nTrue\n\n\nTimestamps #\nfrom datetime import datetime\n# to same timezone (UTC, +0)df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, infer_datetime_format=True, cache=True)\n# UTC+0 to UNIX timestamp (POSIX timestamp)df['timestamp'] = df['timestamp'].apply(lambda x: int(datetime.timestamp(x)*1000)) # miliseconds# unix timestamp to Timestampsdatetime.fromtimestamp(unix_ts//1000)\n# UNIX float (ms) -> datetime64df['timestamp'] = df['timestamp'].astype('datetime64[ms]')# change `ms` with others, e.g. `ns` for nanosecond\n# remove timezonedf['time'].dt.tz_localize(None)\nGet info timestamps #\ndef set_index(data, col_time): \"\"\" Make a copy of a time-series dataframe `df` and set the column-time be the index of the dataframe. In the case index has no name, we set it as `'index'`. \"\"\" df0 = data.copy() if col_time != 'index': # col_time is not the index df0 = df0.set_index(col_time) else: if df0.index.name is None: df0.index.name = 'index' return df0\ndef get_info_timestamps(df, col_date='index'): # make sure timestamps are on index df = set_index(df, col_date) index_name = df.index.name df = df.reset_index() print('Time range: ', df[index_name].max() - df[index_name].min()) print('Number of different time steps: ', df[index_name].diff().value_counts().count()) print('Max time step: ', df[index_name].diff().max()) print('Min time step: ', df[index_name].diff().min()) print('The most popular time step: ', df[index_name].diff().value_counts().index[0]) print('timestamps are monotonic increasing? ', df[index_name].is_monotonic) print('Are there duplicate timestamps? ', df[index_name].duplicated().any()) print('How many unique duplicates? ', df[index_name].duplicated().sum(), ' (in total ',df.shape[0], ')') print('How many repeated duplicates? ', df[index_name].duplicated(keep=False).sum(), ' (in total ',df.shape[0], ')')\nCheck timestamps are well sorted? #\n\n# CHECKdf.date.is_monotonic # monotonic increasing?df.date.is_monotonic_decreasing # decreasing?# if using groupbydef check_monotonic(group): return group.is_monotonicdf.groupby('label').agg({'timestamp': [check_monotonic] })\n# ARRANGE THEMdf.sort_values(by='date', inplace=True)\n\nDetect time series frequency #\nFind the different time steps in a datetime columns,\n\n# count the number of elements for each time stepsdf.date.diff().value_counts()# count number of different time stepsdf.date.diff().value_counts().count()# take the index of the largestdf.date.diff().value_counts().index[0]# take the index of the smallestdf.date.diff().value_counts().index[-1]\n00:01:00 11\n00:03:00 2\n00:02:00 1\n00:04:00 1\nName: date, dtype: int64\n\n4\n\nTimedelta('0 days 00:01:00')\n\nTimedelta('0 days 00:04:00')\n\n\nOne can couple with function timedelta_to_string in the previous section to find out the most-appeared time steps to feed into df.resample()'s rule.\nList of resampling rules #\nOfficial ref here — search &quot;DateOffsets&quot; to jump to the table.\nB business day frequency\nC custom business day frequency (experimental)`\nD calendar day frequency\nW weekly frequency\nM month end frequency\nSM semi-month end frequency (15th and end of month)\nBM business month end frequency\nCBM custom business month end frequency\nMS month start frequency\nSMS semi-month start frequency (1st and 15th)\nBMS business month start frequency\nCBMS custom business month start frequency\nQ quarter end frequency\nBQ business quarter endfrequency\nQS quarter start frequency\nBQS business quarter start frequency\nA year end frequency\nBA, BY business year end frequency\nAS, YS year start frequency\nBAS, BYS business year start frequency\nBH business hour frequency\nH hourly frequency\nT, min minutely frequency\nS secondly frequency\nL, ms milliseconds\nU, us microseconds\nN nanoseconds\n\nReferences #\n\nTime Series User Guide on pandas.\n\n"},"/dbscan-hdbscan-clustering/":{"id":"/dbscan-hdbscan-clustering/","title":"DBSCAN / HDBSCAN Clustering","keywords":"cluster clustering dbscan hdbscan density based spatial clustering of application with noise high varying shapes sort data points neighborhood min point core points border noise phase discover number of clusters automatically ignoire outliers detect outliers Scikit-learn density based clustering DTW (Dynamic Time Warping)","tags":["posts","Machine Learning","Clustering"],"cat":"/img/cats/ml.svg","content":"What? #\nThe key idea is that for each point of a cluster, the neighborhood of a given radius has to contain at least a minimum number of points.\nDBSCAN #\n\n&quot;DBSCAN&quot; = Density-based-spatial clustering of application with noise.\nSeparate clusters of high density from ones of low density.\nCan sort data into clusters of varying shapes.\nInput: set of points &amp; neighborhood N &amp; minpts (density)\nOutput: clusters with density (+ noises)\nEach point is either:\n\ncore point: has at least minpts points in its neighborhood.\nborder point: not a core but has at least 1 core point in its neighborhoods.\nnoise point: not a core or border point.\n\n\nPhase:\n\nChoose a point → it's a core point?\n\nIf yes → expand → check core / check border\nIf no → form a cluster\n\n\nRepeat to form other clusters\nEliminate noise points.\n\n\nPros:\n\nDiscover any number of clusters (different from K-Means which need an input of number of clusters).\nCluster of varying sizes and shapes.\nDetect and ignore outliers.\n\n\nCons:\n\nSensitive → choice of neighborhood parameters (eg. If minpts is too small → wrong noises)\nProduce noise: unclear → how to calculate metric indexes when there is noise.\n\n\n\nHDBSCAN #\nHigh DBSCAN.\nWhen? #\n\nWe are not sure the number of clusters (like in KMeans)\nThere are outliers or noises in data.\nArbitrary cluster's shape.\n\nIn Code #\nDBSCAN with Scikit-learn #\nfrom sklearn.cluster import DBSCANclr = DBSCAN(eps=3, min_samples=2)\n::: code-2-equal\nclr.fit(X)clr.predict(X)\n# orclr.fit_predict(X)\n:::\nParameters (others):\n\n\nmin_samples: min number of samples to be called &quot;dense&quot;\neps: max distance between 2 samples to be in the same cluster. Its unit/value based on the unit of data.\nHigher min_samples + lower eps indicates higher density necessary to form a cluster.\n\nAttributes:\n\nclr.labels_: clusters' labels.\n\nHDBSCAN #\nFor a ref of paramaters, check the API.\nfrom hdbscan import HDBSCANclr = HDBSCAN(eps=3, min_cluster_size=3, metric='euclidean')\nParameters:\n\n\n\nmin_cluster_size: [ref] the smallest size grouping that you wish to consider a cluster.\n\n\nmin_samples: [ref] The number of samples in a neighbourhood for a point to be considered a core point. The larger value →\\to→ the more points will be declared as noise &amp; clusters will be restricted to progressively more dense areas.\n\n\nWorking with DTW (Dynamic Time Warping) (more): metric='precomputed' [ref]\nfrom dtaidistance import dtwmatrix = dtw.distance_matrix_fast(series) # something likes thatmodel = HDBSCAN(metric='precomputed')clusters = model.fit_predict(matrix)\n\n\nExamples to understand min_cluster_size and min_samples\nmin_cluster_size=12 &amp; min_samples=2 gives less noises than min_cluster_size=12 &amp; min_samples=3: It's because we need at least min_samples points to determine a core points. That's why the bigger min_samples, the harder to form a cluster, or the more chances we have more noises.\nmin_cluster_size=7 &amp; min_sampls=3 gives less noises than min_cluster_size=12 &amp; min_samples=3: It's because we need at least min_cluster_size points to determine a cluster. That's why the bigger min_cluster_size, the harder the form a cluster, or the more chances we have more noise.\n\n\nAttributes:\n\n\nLabel -1 means that this sample is not assigned to any cluster, or noise!\nclt.labels_: labels of clusters (including -1)\nclt.probabilities_: scores (between 0 and 1). 0 means sample is not in cluster at all (noise), 1 means the heart of cluster.\n\nHDBSCAN and scikit-learn #\nNote that, HDBSCAN is built based on scikit-learn but it doesn't have an .predict() method as other clustering methods does on scikit-learn. Below code gives you a new version of HDBSCAN (WrapperHDBSCAN) which has an additional .predict() method.\nfrom hdbscan import HDBSCANclass WrapperHDBSCAN(HDBSCAN): def predict(self, X): self.fit(X) return self.labels_\nReference #\n\nOfficial doc -- How HDBSCAN works?\n\n"},"/python-loop/":{"id":"/python-loop/","title":"Python Loop","keywords":"python for while loop iteration skip ignore some iteration loop","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"for #\n\nfor i in range(3): print(i)\n1\n2\n3\n\n\n\nfor i in range(3): print(i)else: print('no left')\n0\n1\n2\nno left\n\n\nSkip some step #\n\n# don't contain 5 (way 1)for i in [x for x in range(10) if x != 5]: print i\n# don't contain 5 (way 2)for i in list(range(5)) + list(range(6, 10)): print i\n# next (skip 5)xr = iter(range(10))for i in xr: print(i) if i == 4: next(xr)\n# continue (skip 5)for i in range(10): if i == 5: continue print(i)\n\nwhile #\n\ni = 1while i &lt; 4: print(i) i += 1\n1\n2\n3\n\n\nYou can also use next and continue like in the case of for but with caution!\nbreak #\n\nfor i in range(6): print(i) if i==2: break\n0\n1\n2\n\n\n\ni = 1while i &lt; 6: print(i) if i==3: break i += 1\n1\n2\n3\n\n\n"},"/good-applications/":{"id":"/good-applications/","title":"Useful tools for working & studying","keywords":"useful applications softwares tools download terminal cmd commander cmder unikey vietnamese input keyboard screen to gif screen recorder lock hunter delete apps soft goldendict dictionary lingoes deepl translate qtranslate hotkeys google translate deep learning machine learning collection reminder stretch RSI download manager IDM XDM Repetitive Strain Injury iterm2 guake terminal cmder drop-down commander cmd quick open terminal commanline workrave time out screentogif lock hunter everything spotlight goldendict deepl lingoes Qtranslate tabcloud avim flash video downloader hush mate pdf printer internet tools image photo compression jpeg png remove background transparent photo luna lunapic resize images iloveimg side by side images learning movie relax","tags":["posts","Others","Collection","Windows","Linux"],"cat":"/img/cats/others.svg","content":"👉 Useful tools for Data Science, Machine Learning.\n👉 Web Dev tools.\n\nThis note will always be updated.\n\nOnline tools #\nImages #\n\nCompress images: PNG, JPG.\nRemove background / Transparent photos: online png tools, lunapic.\niloveimg: resize, crop, compress, rotate.\nSide by side images: this tool.\nChange color:\n\nof a single color: onlinepngtools\nall colors to a single different one: manytools\n\n\nFree photos:\n\nIcon / Logo: vectorlogo (only marques), flaticon (a lot, be able to custom color)\nStocks: unsplash &amp; pexels &amp; pixabay (taken by photographers), freepik (with vector sources).\n\n\nGet link Google Photos\nAdd border to png -&gt; onlinephototools\nConvert to SVG\n\nOffice #\n\nPDF tools:\n\nConvert PDF to Word (conserve format): freepdfconverter.\nPDF Editor online free: pdfescape\n\nEdit text: sejda\nChange metadata: bluepdf\nView pdf's metadata: pdfyeah\n\n\n\n\nEtherpad -- a highly customizable Open Source online editor providing collaborative editing in really real-time.\nText recognition (OCR): newocr\nLaTeX tools\n\nOverleaf -- online LaTeX editor.\nIguanaTex -- A Free LaTeX Add-In for PowerPoint on Windows\n\n\nObsidian -- Obsidian is a powerful knowledge base that works on top of\na local folder of plain text Markdown files.\n\nMulti-platforms #\n\nGitKraken -- git client for ubuntu (better than Github Desktop when importing local)\nGoldenDict -- dictionaries + its dictionaries.\nGoogle Play Music Desktop Player (support Youtube Music with custom controllers, online only).\nJitsi Meet -- More secure, more flexible, and completely free video conferencing.\nMailspring -- Email client.\nTypora -- WYSWYG markdown editor.\nVirtualBox -- virtual machine.\nXDM -- download manager.\nDownload Youtube playlist\nShareDrop -- P2P file transfer.\n\nWindows #\n\nBig Stretch Reminder -- free simple reminder tool that prompts a user to take regular breaks and helps prevent the symptoms of Repetitive Strain Injury (RSI).\ncmder (Console Emulator) -- (update 11/20: should use Windows Terminal with dropdown support) drop-down terminal for windows. My setting file.\nDeepL -- Quickly translate app (by using Ctrl + C + C).\nEverything -- an alternative to Spotlight in Mac. You can search any thing (app, docs, files,...) in your computer with hotkeys.\nFastStone Capture -- screen recorder.\nLingoes -- dictionary (used alongside with GoldenDict) -- its dictionaries.\nLockHunter -- find what application/process is preventing us from deleting some folder/file.\nScreenToGif -- screen recorder and auto convert to gif file.\nUnikey -- Vietnamese input method on Windows.\n\nLinux #\n\nCheese (Appstore) -- webcam for linux.\nFoliate (Appstore) -- Book reader.\ngThumb (Appstore) -- photo viewer + quick editing tools.\nGuake Terminal -- drop-down terminal (more settings)\nKazam (Appstore) -- Screen Recorder.\nLotion -- Unofficial Notion client for linux (online only)\nLutris -- playing games on linux.\nNotejot (Appstore) -- sticky note.\nOpenComic -- read offline comic with many supported files (zip, folder containing images,...)\nRhythmbox (Appstore) -- Music player on Linux (custom hotkeys).\nWorkrave -- a program that assists in the recovery and prevention of Repetitive Strain Injury (RSI).\nexfalso (Appstore) -- edit mp3 tag on linux.\n\nMacOS #\n\niTerm2 -- drop-down terminal.\nTime Out -- a program that assists in the recovery and prevention of Repetitive Strain Injury (RSI).\n\nEducation #\n\nForeign language learning:\n\nDeepL -- &quot;better than google translate&quot; app for Windows. You can use Ctrl + C + C to quickly translate a word or phrase.\nGoldenDict -- global dictionary (multi-platform). Its dictionaries.\nLingoes -- Global dictionary for Windows. Its dictionaries.\nQTranslate -- quickly translate any word / phrase and also their pronunciation by using hotkeys (for example, you can use Ctrl + E to hear the pronunciation and Ctrl + Q to see the translation). The data is obtained from various sources including deepl and google translate.\nLyricsTraining -- a new way to learn English and other languages through music and the lyrics of your favourite songs.\nPhimLearning -- watch movie and learning foreign language with bilanguage-subtitles.\nGrammar &amp; Spell check online: Scriben, Grammarly, 1checker.\n\n\nRaindrop -- bookmark to read later the articles (like Pocket)\narXiv Vanity -- renders academic papers from arXiv as responsive web pages so you don’t have to squint at a PDF.\nb-ok -- download books (may be illigal).\n\nMath tools #\n\nMatcha -- draw / write LaTeX / Tikz online, very beautiful.\nWolframAlpha -- powerfully computational intelligence.\nGeogebra Graphhing Calculator -- draw graph online with Geogebra.\nDesmos -- advanced Graphing calculator.\nSketchometry\nDiagram\n\nChrome extension #\n\nAVIM -- Vietnamese input method\nFlash Video Downloader -- get any video download link.\nHush -- private bookmarking\nMate -- Quick translater.\nPrint Friendly &amp; PDF -- print any web page into pdf.\nTabCloud -- save current tab list\n\nOthers #\n\ntalentoday -- Empowering Growth for Individuals and Teams\n\n"},"/algorithm-1/":{"id":"/algorithm-1/","title":"Algorithm 1","keywords":"chunker slide slicing rolling batches windows list sequence split imshow plot true false grid squares bernoulli distribution algorithm python","tags":["posts","Algorithms"],"cat":"/img/cats/algo.svg","content":"This note contains questions/puzzle and algorithms to answer these problems. Most of the codes in this type of note are in Python.\nMake chunkers / windows #\nSplit a sequence into windows with size and slide.\ndef chunker(seq, size, slide=None, exact_size=False): if slide is None: slide = size if exact_size: return [seq[pos:pos + size] for pos in range(0, len(seq), slide) if len(seq[pos:pos + size]) == size] else: return [seq[pos:pos + size] for pos in range(0, len(seq), slide)]\n\nseq = [i for i in range(10)]chunker(seq, 3)chunker(seq, 3, exact_size=True)chunker(seq, 3, slide=2)\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n[[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n[[0, 1, 2], [2, 3, 4], [4, 5, 6], [6, 7, 8], [8, 9]]\n\n\nMake all arrays equal in size, filled with np.nan,\ndef chunker2(seq, size, slide=None): if slide is None: slide = size return [np.append( seq[pos:pos + size], np.repeat(np.nan, size-len(seq[pos:pos + size])) ) for pos in range(0, len(seq), slide)]\n\nseq = [i for i in range(10)]chunker2(seq, size=4, slide=2)\n[array([0., 1., 2., 3.]),\n array([2., 3., 4., 5.]),\n array([4., 5., 6., 7.]),\n array([6., 7., 8., 9.]),\n array([ 8., 9., nan, nan])]\n\n\nPlot a grid of squares #\nPlot a square of NxN small other squares. Each one has a probability Pxi/N of being coloured, where i is the line where it stands.\n\nN = 100P = 0.5im_size = 5image = np.repeat(np.array(range(1,N+1)).reshape(N, 1), N, axis=1)# LESS understandable but executing FASTERimage = (P/N * image) &lt;= np.random.rand(N,N)# MORE understandable but executing SLOWERdef bernoulli(num, P, N): return 1-np.random.binomial(1, P*num/N)vfunc = np.vectorize(bernoulli)image = vfunc(image, P, N)plt.figure(figsize=(im_size, im_size))plt.imshow(image, cmap='gray')plt.show()\n\n"},"/docker/":{"id":"/docker/","title":"Docker 101","keywords":"pybash tania rascia CI CD continuous integration deployment pipeline docker idea how to use airflow kubernetes k8s k apache container images dangling images vscode vsc visual studio code ssh container env environnement file variable","tags":["posts","MLOps"],"cat":"/img/cats/mlops.svg","content":"👉 Note: Docker + GPUs\n👉 Note: Wordpress Docker\n👉 Note: Airflow + Kubernetes 101\n👉 Note: Tensorflow extra\nWhat and Why? #\nIntuitive images\nSouce rollout.io.\n\nContainer vs Virtual Machine, souce docker.com.\n\nRAM usage: Docker vs Virtual Machine, souce eureka.com.\n\nAbbreviate #\n\n\nps = process status : check running containers (with -a for all)\n-i = interactive : used in docker exec or docker run\n-t = terminal : used in docker exec or docker run\n-m = memory\n-v or --volume : corresponding folders in/out containers.\n--rm : create temprarily a container (removed after exit)\n\n\nInstallation #\nFor all platforms, check this.\nLinux #\n\n\n\nFor Linux, check this!\nShow codes# uninstall old versionssudo apt-get remove docker docker-engine docker.io containerd runcsudo apt-get updatesudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# make sure: 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88sudo apt-key fingerprint 0EBFCD88sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\"# install docker enginesudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io# check if everything is oksudo docker run hello-world# incase docker-compose isn't installedsudo apt install docker-compose\nIf you use Ubuntu 20.04+, replace $(lsb_release -cs) with eoan because docker currently (17 May 20) doesn't support 20.04 yet!\n\n\nIf wanna run docker without root, check this.\nsudo groupadd docker # create a docker groupsudo usermod -aG docker &lt;user> # add &lt;user> to groupnewgrp docker # activate the changes\n\n\nConfigure docker start on boot (Ubuntu 15.04 or later)\nsudo systemctl enable docker\n\n\nMacOS #\nCheck this.\nWindows #\nIf meet the error Failed to construct a huffman tree using the length array. The stream might be corrupted.\n\n\n\nYou must have Windows 10: Pro, Enterprise, or Education (Build 15063 or later). Check other requirements.\n# POWERSHELL# check window versionGet-WmiObject -Class Win32_OperatingSystem | % Caption# check window build numberGet-WmiObject -Class Win32_OperatingSystem | % Buildnumber\n\n\nActive Hyper-V and Containers (you can do it manually in Turn Windows features on or off)\n# Open PowerShell with Administrator and run followingEnable-WindowsOptionalFeature -Online -FeatureName containers –AllEnable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V –All# restart\n\n\nDownload and install.\n\n\nCheck docker version.\n\n\nTry docker run hello-world.\n\n\nWith GPUs support? #\nCheck this note.\nUninstall #\nLinux #\n# from docker officialsudo apt-get remove docker docker-engine docker.io containerd runc\n# identify what installed package you havedpkg -l | grep -i docker# uninstallsudo apt-get purge -y docker-engine docker docker.io docker-ce docker-ce-clisudo apt-get autoremove -y --purge docker-engine docker docker.io docker-ce\n# remove images containerssudo rm -rf /var/lib/docker /etc/dockersudo rm /etc/apparmor.d/dockersudo groupdel dockersudo rm -rf /var/run/docker.sock\nLogin &amp; Download images #\ndocker login# using username (not email) and password\n\n\nDownload at Docker Hub.\nDownload images are store at C:\\ProgramData\\DockerDesktop\\vm-data (Windows) by default.\n\nCheck info #\n# docker's versiondocker --version\nImages #\n\n# list images on the hostdocker images\n# check image's infodocker inspec &lt;image_id>\n\nContainers #\n\n# list running containersdocker psdocker ps -a # all (including stopped)\n# only the idsdocker ps -qdocker ps -a -q\n# container's sizedocker ps -sdocker ps -a -s\n# container's names onlydocker ps --format '{{.Names}}'docker ps -a --format '{{.Names}}'\n# Check the last command in containerdocker ps --format '{{.Command}}' --no-trunc\n# check log# useful if we wanna see the last running tasks'sdocker container logs &lt;container_name>\n# get ip addressdocker inspect &lt;container_name> | grep IPAddress\n\nOthers #\n\n# RAM &amp; CPU usagesdocker statsdocker stats &lt;container_name>\n\nAttach / Start / Stop #\nWe can use sometimes interchangeable between &lt;container_id&gt; and &lt;container_name&gt;.\n\n# get info (container's id, image's id first)docker ps -a\n# start a stopped containerdocker start &lt;container_id>\n# stop a containerdocker stop &lt;container_id>\n# going to running container envdocker exec -it &lt;container_name> bash\n# stop all running containersdocker stop $(docker ps -a -q)\n\nDelete #\nRead more here.\nEverything #\n\n# any resourcesdocker system prune\n# with all unused imagesdocker system prune -a\n\nImages #\n\n# list all imagesdocker images -a\n# remove a specific imagedocker image rm &lt;IMAGE_ID>\n\nDangling images are layers that have no relationship to any tagged images.\n\n# list dangling imagesdocker images -f dangling=true\n# remove dangling imagesdocker images purge\n\nContainers #\n\n# remove a specific containersdocker rm -f &lt;container-id>\n# remove all containersdocker rm -f $(docker ps -a -q)\n\nBuild an image #\nCreate #\n\n# build image with Dockerfiledocker build -t &lt;img_name> .# custom Dockerfile.abcdocker build -t &lt;img_name> . -f Dockerfile.abc\n# with docker-composedocker-compose up# with custom filedocker-compose -f docker-compose.amin.yml up -d\n# if success# service name \"docker_thi\"docker run -it &lt;service_name> bash\n# from current containerdocker ps -a # check all containersdocker commit &lt;container_id> &lt;new_image_name>\n\nDockerfile #\nFROM nvidia/cuda:10.2-base# encodingENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8# fix (tzdatachoose)ARG DEBIAN_FRONTEND=noninteractiveRUN apt-get -y update &amp;&amp; \\ apt-get -y upgrade &amp;&amp; \\ apt-get install -y openssh-server &amp;&amp; \\ apt-get install -y python3-pip python3-dev locales git r-base# ssh serverRUN mkdir /var/run/sshdRUN echo 'root:qwerty' | chpasswdRUN sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config# SSH login fix. Otherwise user is kicked off after loginRUN sed 's@session\\s*required\\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd# need?ENV NOTVISIBLE \"in users profile\"RUN echo \"export VISIBLE=now\" >> /etc/profile# create aliasRUN echo 'alias python=\"python3\"' >> ~/.bashrcRUN echo 'alias pip=\"pip3\"' >> ~/.bashrc# create shortcutsRUN ln -s /abc/xyz /xyz/xyz# install python's requirementsCOPY requirements_dc.txt requirements.txtRUN python3 -m pip install --upgrade pip &amp;&amp; \\ python3 -m pip install -r requirements.txtCOPY . .# export port sshEXPOSE 22COPY script.sh starting_script.sh# runCMD [\"sh\",\"-c\",\"cd /data_controller/utils/ &amp;&amp; sh generate_grpc_code_from_protos.sh &amp;&amp; cd /srv/ &amp;&amp; sh starting_script.sh\"]\nConnect to container via sshFROM ubuntu:20.04RUN apt-get update &amp;&amp; apt-get install -y openssh-serverRUN mkdir /var/run/sshdRUN echo 'root:THEPASSWORDYOUCREATED' | chpasswdRUN sed -i 's/#*PermitRootLogin prohibit-password/PermitRootLogin yes/g' /etc/ssh/sshd_config# SSH login fix. Otherwise user is kicked off after loginRUN sed -i 's@session\\s*required\\s*pam_loginuid.so@session optional pam_loginuid.so@g' /etc/pam.d/sshdENV NOTVISIBLE \"in users profile\"RUN echo \"export VISIBLE=now\" >> /etc/profileEXPOSE 22CMD [\"/usr/sbin/sshd\", \"-D\"]\nFor more about ssh connection, check official doc.\nIf .env doesn't work? =&gt; This is expected. SSH wipes out the environment as part of the login process. [ref]\n# For example, all environement variables are stored in a# /home/thi/.env# add them to container's envcat /home/thi/.env >> /etc/environment# exit current ssh session# connect again# checkenv\nMore references: here and here.\n\nMeaning of terms\n\nFROM: the base image you use, can be obtained from Docker Hub. For example, FROM ubuntu:18.04 (18.04 is a tag, latest is default)\n\n\nWORKDIR app/: Use app/ as the working directory.\n\n\nRUN: install your application and packages requited, e.g. RUN apt-get -y update.\n\nRUN &lt;command&gt; (shell form)\n\nRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)\n\n\n\n\n\nCMD: sets default command and/or parameters, which can be overwritten if docker container runs with command lines. If there are many CMDs, the last will be used.\n# in DockerfileCMD echo \"Hello world\"# run onlydocker run -it &lt;image># output: \"Hello world\"# run with a command linedocker run -it &lt;image> /bin/bash# output (CMD ignored, bash run instead): root@7de4bed89922:/#\n\nCMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, preferred)\nCMD [&quot;param1&quot;,&quot;param2&quot;] (sets additional default parameters for ENTRYPOINT in exec form)\nCMD command param1 param2 (shell form)\nMultiple commands: CMD [&quot;sh&quot;,&quot;-c&quot;,&quot;mkdir abc &amp;&amp; cd abc &amp;&amp; touch new.file&quot;]\n\n\n\nENTRYPOINT: configures a container that will run as an executable. Look like CMD but ENTRYPOINT command and parameters are not ignored when Docker container runs with command line parameters.\n \n \n \tMore detail\n \n \n# DockerfileENTRYPOINT [\"/bin/echo\", \"Hello\"]CMD [\"world\"]# rundocker run -it &lt;image># produces 'Hello world'# but rundocker run -it &lt;image> John# produces 'Hello John'\n \n \n\nENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form, preferred)\nENTRYPOINT command param1 param2 (shell form)\n\n\n\nEXPOSE 5000: Listen on the specified port\n\n\nCOPY . app/: Copy the files from the current directory to app/\n\n\n\nExample of run mutiple commandsIf we run multiple interative commands (wait for action), for example, a jupyter notebook with a ssh server, we cannot put them directly in CMD command.\nSolution: using a file .sh and put &amp; at the end of the 1st command like:\n$(which sshd) -Ddp 22 &amp;jupyter lab --no-browser --allow-root --ip=0.0.0.0 --NotebookApp.token='' --NotebookApp.password=''\n\nCreate a container #\nCLI #\n# container test from an imagedocker create --name container_test -t -i &lt;image_id> bashdocker start container_testdocker exec -it container_test bash\ndocker run --name &lt;container_name> -dp 3000:3000 -v todo-db:/etc/todos &lt;docker_img>\n# run a command in a running docker without entering to that container# e.g. running \"/usr/sbin/sshd -Ddp 22\"docker exec -it -d docker_thi_dc /usr/sbin/sshd -Ddp 22# \"-d\" = Detached mode\n# want docker auto removes a container after exitdocker run --rm ...\ndocker-compose.yml #\nUse to create various services with the same image.\ndocker-compose up -d # up and detachdocker-compose -f file_name.yml up -d # custom docker-compose.yml file name# if you run 2 container in the same folder namedocker-compose -p \"project_1\" up -ddocker-compose -p \"project_2\" up -d\n# docker-compose.yml#------------------------------# run by `docker-compose up`version: '3'services: dataswati: container_name: docker_thi image: docker_thi_img:latest ports: - \"8888:8888\" volumes: - \"/local-folder/:/docker-folder/\"\tworking_dir: /srv\nMeaning of terms\n\ndepends_on:[ref] Express dependency between services (with orders).\nIn docker-compose.yml: db and redis start before web.\nversion: \"3.8\"services:web:\tbuild: .\tdepends_on:\t\t- db\t\t- redisredis:\timage: redisdb:\timage: postgres\n\n\ncommand:[ref] Override the default command.\n\n\nstdin_open: true and tty: true: keep container alive!\n\n\nvolumes (outside containers): volumes controlled by docker. They're located on different places,\n# check info of a volumedocker volume inspect &lt;volume_name>\n\n\nrestart: always (auto start container after logging in), no (default), on-failure.\n\n\nbuild: &lt;dir_to_Dockerfile_file&gt;: build an image before using docker-compose.\n\n\nruntime: nvidia: if docker-compose --version higher than 2.3 and there is NVIDIA GPU on your computer (check more detail in this note).\n\n\n\n🔅 If there is no already built image, you can use a Dockerfile in the same place as docker-compose.yml. In docker-compose.yml, use\nservices:\tdataswati:\t\tbuild: .\nThen run docker-compose up --build.\n🔅 Update to the newer version of docker-compose?\nErrors #\nDocker can't connect to docker daemon`.\n# check if daemon is running?ps aux | grep docker# runsudo /etc/init.d/docker start\n\nsudo systemctl restart docker meets Job for docker.service failed because the control process exited with error code.\n\nTry to remove failed daemon.json file in /etc/docker/ (if the problem comes from here)\nTry running either sudo /etc/init.d/docker start or sudo service docker restart (twice if needed).\n\n\nperl: warning: Please check that your locale settings: when using below in the Dockerfile,\nENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8# Replace them byRUN echo \"LC_ALL=en_US.UTF-8\" >> /etc/environmentRUN echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.genRUN echo \"LANG=en_US.UTF-8\" > /etc/locale.confRUN locale-gen en_US.UTF-8\nReference #\n\nPlay with Docker -- right on the web.\nYury Pitsishin -- Docker RUN vs CMD vs ENTRYPOINT.\n\n"},"/screen/":{"id":"/screen/","title":"Screen","keywords":"screen session attach reattach detach continue working shutdown computer cheatsheet quick reference cheat sheet remote host interrupt suddenly stop GNU screen terminal multiplexer virtual terminal","tags":["posts","Skills","Linux"],"cat":"/img/cats/skills.svg","content":"Keep the running tasks on the remote host continue after turning off the local caller.\nInstall #\nsudo apt install screen # ubuntu\nBasic command lines #\n\n# check screen versionscreen -v\n# start new session (with name)screen -S &lt;name>\n# list running sessionsscreen -ls\n# attach to a running session (without name)screen -x\n# attach to a running session (with name)screen -rx &lt;name># -x for an interactive (scrolling)\n# detach a running sessionscreen -d &lt;name> # or Ctrl + A, D\n# kill a sessionscreen -X -S &lt;name> quit\n\nDelete sessions #\n\nReattach first: screen -r &lt;name&gt;\nCtrl + A, K then Y\n\n# kill ALL auto-created sesssionsscreen -ls | grep pts | cut -d. -f1 | awk '{print $1}' | xargs kill# kill all detached sessionsscreen -ls | grep Detached | cut -d. -f1 | awk '{print $1}' | xargs kill\nCreate a screen + list of command lines #\nscreen -S 'dat' -dm bash -c 'cd /jekyll-site; bundle exec jekyll serve -I; exec sh'\nHotkeys #\n\nDetach: Ctrl + A, D\nReattach: Ctrl + A, R\nKill current session: Ctrl + A, K then Y\n\nErrors #\n# Cannot make directory '/run/screen': Permission deniedmkdir ~/.screen &amp;&amp; chmod 700 ~/.screenexport SCREENDIR=$HOME/.screen# also add this line to ~/.zshrc or ~/.bashrc\nReference #\n\nScreen Quick Reference\n\n"},"/fast-fourier-transform-fft/":{"id":"/fast-fourier-transform-fft/","title":"Fast Fourier Transform (fft)","keywords":"fft DFT discrete fourier transform phase frequency amplitude 3 properties of a wave fundamental","tags":["posts","Time Series"],"cat":"/img/cats/ts.svg","content":"Discrete Fourirer Transform (DFT) #\nFFT #\nFrom wiki : &quot;A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT). Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa.&quot;\nPhase - Frequency - Amplitude #\n\n3 fundamental properties of a wave. Two waves have the same amplitude and frequency but different phase\nFrequency (Hertz) -- number of circles in 1 second!\nReferences #\n\nMathBitsNotebook -- Trigonometric Graphs Vocabulary\nMath is fun -- Amplitude, Period, Phase Shift and Frequency\nBetterExplained -- An Interactive Guide To The Fourier Transform\nOSCON 2014 (video) -- Intuitive Understanding of the Fourier Transform and FFTs\n\n"},"/tsfresh/":{"id":"/tsfresh/","title":"tsfresh","keywords":"tsfresh feature extraction feature selection video install how it works how to use reference Nils Braun","tags":["posts","Time Series"],"cat":"/img/cats/ts.svg","content":"Install #\npip install tsfresh\nHow tsfresh works? #\n\n\nHow to use? #\nReference #\n\nOfficial docs.\nNils Braun - Time series feature extraction with tsfresh (video)\n\n"},"/time-series-tips/":{"id":"/time-series-tips/","title":"Time Series extra","keywords":"find the common time invervals timestamps burst detection bursting burst firing term terminology gaps biggest gaps spaces algorithm starting and ending of each window average moyenne size max min problems with time series time series regression time series classification anomaly detection input read csv read_csv","tags":["posts","Time Series"],"cat":"/img/cats/ts.svg","content":"Terminologies &amp; fields of research #\n\nBurst detection: An unexpectedly large number of events occurring within some certain temporal or spatial region is called\na burst, suggesting unusual behaviors or activities.\nTime Series Regression: [ref] Time series regression is a statistical method for predicting a future response based on the response history (known as autoregressive dynamics) and the transfer of dynamics from relevant predictors. Time series regression can help you understand and predict the behavior of dynamic systems from experimental or observational data. Time series regression is commonly used for modeling and forecasting of economic, financial, and biological systems.\nTime Series Classification: [ref] Time series classification deals with classifying the data points over the time based on its' behavior. There can be data sets which behave in an abnormal manner when comparing with other data sets. Identifying unusual and anomalous time series is becoming increasingly common for organizations\n\n[ref] Time series classification data differs from a regular classification problem since the attributes have an ordered sequence.\n\n\nAnomaly Detection:\n\nA part in the same time series.\nFinding one or more time series which are different from others.\nSome abnormal points in the same time series.\nApplied for both univariate and multivariate time series.\n\n\n\nRead_CSV #\nMore here.\ndf_13 = pd.read_csv(path_file, index_col='timestamp', parse_dates=True, # index contains dates infer_datetime_format=True, # auto regconize format cache_dates=True) # faster\nFind the windows of time series #\nSuppose we have data like in below, we wanna find the common length interval of all groups.\n\n# find the biggest gapdf['date'].diff().max()# 4 biggest gapsdf['date'].diff().sort_values().iloc[-5:]# starting of each window (the gap used to separate windows is '1D')w_starts = df.reset_index()[~(df['date'].diff() &lt; pd.to_timedelta('1D'))].index# ending of each windoww_ends = (w_starts[1:] - 1).append(pd.Index([df.shape[0]-1]))# count the number of windowslen(w_starts)# the biggest/average window size (in points)(w_ends - w_starts).max()(w_ends - w_starts).values.mean()# the biggest window size (in time range)pd.Timedelta((df.iloc[w_ends]['date'] - df.iloc[w_starts]['date']).max(), unit='ns')\nIf you wanna add a window column to the original dataframe,\ndf_tmp = df.copy()w_idx = 0for i in range(w_starts.shape[0]): df_tmp.loc[w_starts[i]:(w_ends[i]+1), 'window'] = w_idx w_idx += 1df_tmp.window = df_tmp.window.astype(int) # convert dtype to int64\nThere are other cases need to be considered,\n\nThe gaps are not regular\n\nIf we choose the gaps (to determine the windows) too small, there are some windows have only 1 point like in this case.\nFind the gap's threshold automatically,\nfrom sklearn.cluster import MeanShiftdef find_gap_auto(df): X = df['date'].diff().unique() X = X[~np.isnat(X)] # remove 'NaT' X.sort() X = X.reshape(-1,1) clustering = MeanShift().fit(X) labels = clustering.labels_ cluster_min = labels[0] gap = pd.to_timedelta((X[labels!=cluster_min].min() + X[labels==cluster_min].max())/2) return gap\n"},"/linux-tips/":{"id":"/linux-tips/","title":"Linux notes","keywords":"find with command line in linux ubuntu elementary os distro distribution move files to trash wrong owner gnome screen shot windows shrink partition resize disk drive turn off animation minimize gnome tweak tool vietnam vietnamese input method vn ime F2 kill process .bin .run install bookmark evince pdf reader PPA does not have Release file ip address ipconfig nautilus window explorer file manager shortcut hotkey thumbnail shorten directory terminal open as admin remove delete files folders folder size mount iso virtual disk extract iso file sync files mega megatools vim quit vim download upload $PATH path copy files from ubuntu to iOS check current path rename files folders surface book linux-surface errors problem bluetooth failed to load module user group ownership add user permission matlab graphic ui drive connector install silently remove matlab uninstall matlab download from google drive ssh control access another computer remote control server machine download playlist youtube youtube-dl mp3 tag mogrify wget ppa remove dconf guake free vpn vpnbook openvpn","tags":["posts","Skills","Linux"],"cat":"/img/cats/skills.svg","content":"Quick tips / references for using Linux / Ubuntu.\n👉 Fresh installation Ubuntu note.\n👉 Bash\nGeneral #\n🔅 Run MacOS apps on Linux, use Darling.\n🔅 Run Android apps on Linux, use Anbox.\n🔅 Find in linux with command lines ⇾ link\n🔅 Cannot move files to the trash/wrong owner ⇾ link\n🔅 Gnome screenshot ⇾ link\n🔅 Windows shrink drive in windows ⇾ link (partition, resize disk drive, hard disk)\n🔅 Type Vietnamese in SublimeText, install vn ime (exactly like that). Press F2 for using.\n🔅 Look and kill an app process:\nps ax | grep teamviewer # check the idkill -9 &lt;pid> # kill some process\n🔅 Install file .bin, .run\nchmod +x file-name.run./file-name.run\n🔅 Make a script executable: chmod a+x script_file\n🔅 Unzip a file,\nsudo apt-get install unzipunzip &lt;file>unzip &lt;file> -d &lt;destination>\n🔅 Terminal multi windows:\nsudo apt-get install terminator\n🔅 Add bookmark for evince (default pdf reader)\n\nF9: hide/show sidebar\nMenu on the top right &gt; Add bookmarks\nClick on bookmark and rename it\nCtrl + Shift + S to save (instead of Ctrl + S)\n\n🔅 Remove PPA from ubuntu by terminal. For example, The repository 'http://ppa.launchpad.net/b-eltzner/qpdfview/ubuntu artful Release' does not have a Release file. Remove the file b-eltzner-qpdfview-ubuntu from directory /etc/apt/sources.list.d\nsudo rm /etc/apt/sources.list.d/&lt;file>\nOr using below command lines\n# installsudo add-apt-repository ppa:name# removesudo add-apt-repository --remove ppa:name\n🔅 Get ip address: ifconfig\nSettings #\n🔅 Make Monday as the start of the week:\nsudo -H gedit /usr/share/i18n/locales/en_GB# change to 1first_weekday 1# save and restart the system\n🔅 Add / Remove / Manage app icon in launcher:\nsudo apt-get install alacarte\n🔅 Change ubuntu logo in settings: replace\n/usr/share/icons/hicolor/256x256/apps/ubuntu-logo-icon.png\n🔅 Turn off animation open and minimize windows on ubuntu 17.10 and later (gnome desktop): Gnome Tweak Tools &gt; Apperance &gt; Animations OFF\n🔅 Choose between &quot;lightdm&quot; and &quot;gdm3&quot; (ref):\nsudo apt install lightdmdpkg-reconfigure lightdm# current configlightdm --show-config\n🔅 Save / Load dconf[ref]: ~/.config/dconf/user\n# save guake configs to a filedconf dump / > dconf-settings.ini# loaddconf load / &lt; dconf-settings.ini# orcat dconf-settings.ini | dconf load /\n🔅 Save / load custom keyboard shortcuts (ref)\n# keybindingsdconf dump /org/gnome/desktop/wm/keybindings/ > keybindings.dconf# media keysdconf dump /org/gnome/settings-daemon/plugins/media-keys/ > media-keys.dconf# loaddconf load /org/gnome/desktop/wm/keybindings/ &lt; keybindings.dconfdconf load /org/gnome/settings-daemon/plugins/media-keys/ &lt; keybindings.dconf\nApplications #\n🔅 Completely remove LibreOffice,\n# zsh uses \\*sudo apt-get remove --purge libreoffice*sudo apt-get cleansudo apt-get autoremove\n🔅 Remove snap store\nsudo apt autoremove --purge snapd\n🔅 Uninstall snap applications\nsudo snap remove &lt;app_name>\n🔅 Convert office's files to pdf\n# install firstsudo apt install libreoffice# pptx -> pdfsoffice --headless --convert-to pdf prezentacja.pptx\n🔅 Modify / Add icon in launcher: alacarte&quot; (Main Menu, can be found in App Store).\nNautilus / Files management #\n🔅 Force Unity Dash to index all files on Home\nsudo updatedb\n🔅 Sync one folder to another (more info)\n# A -> B/Arsync -avu --delete \"/home/user/A\" \"/home/user/B\"# A/* -> B/Arsync -avu --delete \"/home/user/A/\" \"/home/user/B/A\"# A, C -> B/A, B/Crsync -avu --delete \"/home/user/A\" \"/home/user/C\" \"/home/user/B\"\n\n-a Do the sync preserving all filesystem attributes\n-v run verbosely\n-u only copy files with a newer modification time (or size difference if the times are equal)\n--delete delete the files in target folder that do not exist in the source\n\n# excludersync -a --exclude 'dir1' src_directory/ dst_directory/rsync -a --exclude={'file1.txt','dir1/*','dir2'} src_directory/ dst_directory/\n🔅 Make a shortcut link to a folder/file in linux terminal ⇾ link\n🔅 Shortcut to a folder in linux ⇾ link\n🔅 Thumbnail nautilus: go to setting, set and apply this line\nsudo chown -R yourusername:yourusername ~/.cache/thumbnails\n🔅 Shorten directory in terminal\n\n\nTemporarily, just enter PS1='\\u:\\W\\$ ' en press enter.\n\n\nPermanently, open sudo gedit ~/.bashrc and find\nif [ \"$color_prompt\" = yes ]; thenPS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ 'elsePS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ 'fi\n\n\nRemove @\\h and replace \\w by \\W so that it becomes,\nif [ \"$color_prompt\" = yes ]; thenPS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u\\[\\033[00m\\]:\\[\\033[01;34m\\]\\W\\[\\033[00m\\]\\$ 'elsePS1='${debian_chroot:+($debian_chroot)}\\u:\\W\\$ 'fi\n\n\nSave, exit, close terminal and start another to see the result.\n\n\n🔅 Right click nautilus &quot;Open as Administrator&quot;:\nsudo apt-get install nautilus-adminnautilus -q # restart nautilus\n🔅 Mount iso file on linux\n# create a foldermkdir /mnt/&lt;folder>sudo mount -o loop &lt;image>.iso /mnt/&lt;folder># unmountsudo umount /mnt/&lt;folder> # umount, not \"unmount\"!!!\nIf you mount another iso file to the same , it will replace the current one.\n🔅 Extract a iso file: first, mount it like in previous tut to a folder named iso then copy all the contents in iso to some folder you want.\n# copy all files in /iso/ to &lt;directory>/cp -r /mnt/iso/* &lt;directory>/\n🔅 Sync files with mega right on terminal\n\n\nInstall megatools:\nsudo apt-get install megatools\n\n\nUsing megatools, cf the main website.\n\n\nCreate a condig file which stores your login information (be careful, everyone can see your pass)\nsudo apt-get install vim # in case that you don't have vim on your systemvim .megarc # create a file named .megarc\n\n\nvim opens and type\n[Login]Username = your@emailPassword = yourpassword\nIf you have back slash in your password, you must escape it with another backslash\n\n\nQuit vim and save the file by pressing ESC and then :wq!\n\n\nUpload a file: megaput --path /Root/&lt;folder&gt; file\n\n\nSee the list of file on remote: megals\n\n\nUpload a folder: megacopy --local &lt;folder&gt; --remote &lt;folder&gt;\n\n\nDownload from link: megadl &lt;mega-link&gt;\n\n\nDownload a single file: megaget &lt;file&gt;\nmegaget /Root/Apps/matlab17b/R2017b_glnxa64_dvd2.iso\n\n\nDownload from uploaded directory:\nmegacopy --local &lt;folder> --remote &lt;folder-to-download> --download\n\n\n🔅 Save a directory a $PATH of local profile.\nsudo gedit ~/.profile# copy and paste following line (should change the path)export PATH=/home/thi/anaconda3/bin:$PATH# save and close .profile and then apply following line to get instant updatesource ~/.profile\n🔅 Copy files from ubuntu to iPhone iOS iPad\n\nDon't need to install any files if one needs to copy photos/videos from iphone to ubuntu, one can use gThumb to do this or just use file manager to copy.\nIf one wants to copy files to iphone. Follow this one\n\n🔅 Check the current path: pwd\nConnect to iOS / iPhone / iPad #\n# Installsudo apt install libimobiledevice6 ifuse libimobiledevice-utils ideviceinstaller# Connect iDevice to computer with usbidevicepair pair # Trust on iDevice and then rerun thissudo mkdir /media/$USER/ipadsudo chown -R $USER /media/$USER/ipadifuse /media/$USER/ipad# Check File Manager and see ipad!\nSurface #\n🔅 Tweaks for ubuntu on surface book ⇾ link\n🔅 App linux-surface.\nUser / Group / Ownership #\n🔅 How to add existing user to an existing group[ref]\nsudo usermod -a -G groupName userName\n🔅 Change ownership of a folder and its children\n# folder and its childrenchown -R thi:root folder# a filechown &lt;user>:&lt;group> file\n🔅 Check the permission of curent directory:\nls -lls -l &lt;file>\nCheck this photo\n\nMatlab #\n🔅 Scale matlab: need to install matleb version &gt;= R2017b\ns = settings;s.matlab.desktop.DisplayScaleFactors.matlab.desktop.DisplayScaleFactor.PersonalValue = 2\n🔅 Launching matlab without graphic ui[ref]\nmatlab -nodesktop\n🔅 Cannot open matlab without sudo: change the owner permission of folder /home/thi/.matlab to thi*\nAnother solution: suppose that matlab is installed on a user's directory and you have already add this to the $PATH. IT's only work if you use matlab (not sudo matlab). Then do\nsudo env \"PATH=$PATH\"\nfrom this, you can sudo matlab\n🔅 Matlab drive connector: after installing, run\n~/bin/MATLABConnector toggle\n🔅 How to install matlab silently (only with command lines) on linux? (if below doesn't work, you can check here, my method is different from this one)\n\n\nSuppose that you have 2 dvd iso files which contains the installation of matlab (dvd1.iso and dvd2.iso)\n\n\nFor the activation, you have libmwservices.so and license_standalone.lic\n\n\nFirst, you need to extract 2 dvd iso files to a common folder named install_matlab in /home/thi/\n\n\nCreate a new folder to install matlab called matlabR in /home/thi/\n\n\nExtract all files in 2 iso files to folder install_matlab like the other tut (search for &quot;mount&quot;).\n\n\nRun below command line\nsudo /home/thi/matlab_install/install -agreeToLicense yes -mode silent -destinationFolder /home/thi/matlabR -fileInstallationKey xxxxx-xxxxx-xxxxx -outputFile /home/matlab_install.log\n\n\nAfter the installation, copy file license_standalone.lic to /home/thi/matlabR/licenses/\n\n\nCopy file libmwservices.so to /home/thi/matlabR/bin/glnxa64/\n\n\nTry running matlab: /home/thi/matlabR/bin/matlab\n\n\nIf you have an error like,\n\t# ERR: libXt.so.6: cannot open shared object file: No such file or directorysudo apt-get install libxt6\n\n\nMake linux recognize your matlab command matlab like in the instruction 40.\n\n\n🔅 Make linux recognize matlab command\n\n\nSuppose that you have installed matlab on /home/thi/matlabR\n\n\nYou need to add above directory to the $PATH so that the system can recognize your matlab command\nexport PATH=$PATH:/home/thi/matlabR/bin\n\n\nYou can use echo $PATH to check if the path is located in it or not.\n\n\n🔅 Remove matlab on linux: simply\nrm -rf &lt;matlab-folder>\nNetwork #\n🔅 Don't show &quot;Turn on wifi hotspot...&quot; for clicking =&gt; try: click on &quot;Network&quot; and then &quot;Wifi&quot; in Settings.\n🔅 Share terminal for other (via SSH): using Teleconsole,\n# installcurl https://www.teleconsole.com/get.sh | sh# share current terminalteleconsole# choose to connect via web browser# or via terminalteleconsole join &lt;id># stop broadcastingexit# port forwarding# suppose that a port is open at 3000 on your machine and you# wanna share it with your friendteleconsole -f localhost:3000\n🔅 Download a direct link by terminal\nwget &lt;direct-link> -O &lt;name-of-file>.&lt;file-extension>\n🔅 Download from google drive by terminal\n\nDownload as usual without terminal by a web browser\nOpen Downloads windows of the browser and then copy the download link.\nStop the download process\nUse the command link in 33 where &lt;direct-link&gt; is the link copied above.\n\n🔅 Use ssh to get access to another computer in the same network (LAN)\n\nFollow (a little bit) here.\nOn the remote machine\n\nupdate and upgrade install\ninstall openssh-server\nopen /etc/ssh/sshd_config and uncomment on Port 22 and lines starting with Hostkey...\nstart the network: sudo service ssh start\nstop the network: sudo service ssh stop\ncheck if the network is running or not? sudo service ssh status\nCheck the current ip: ifconfig: look on the inet\n\n\nOn the local machine\n8. Install the same tool and use ssh username@remote-host\n\n🔅 Connect ssh to a virtual machine (the same network)\n\n\nInstall openssh for both client and server machine\nsudo apt-get install openssh-clientsudo apt-get install openssh-server\n\n\nOn server machine, check ssh is running or not\nps -A | grep sshd# return [number] ? 00:00:00 sshd then it works\n\n\n🔅 Download playlist audio youtube, using youtube-dl\nsudo apt-get install curl -y (cài curl nếu chưa cài)sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dlsudo chmod a+rx /usr/local/bin/youtube-dl# update 11/11/20: not working with playlist but single song!youtube-dl --extract-audio --audio-format mp3 -o \"%(title)s.%(ext)s\" &lt;link-playlist>\nFree VPN #\nUsing vpnbook and its tutorial. Note that, at the last step, we need to run with sudo! Note: very low speed!\nMedia / Photo / Music #\n🔅 Add shortcut keys for Rhythmbox Music Player -&gt; read this.\n\nEnable plugin &quot;MPRIS D-Bus interface&quot;.\nAdd custom shortcuts keyboards as\n\nPlay/Pause: rhythmbox-client --play-pause\nNext: rhythmbox-client --next\nPrevious: rhythmbox-client --previous\n\n\n\n🔅 Convert .ts videos to .mp4\nsudo apt install ffmpegffmpeg -i input.ts -c:v libx264 -c:a aac output.mp4\n🔅 Mp3 tag editor:\nsudo apt install exfalso # Ex Falso\n🔅 Spotify controller shortcut keyboards on Ubuntu (ref): using below commands for controlling playbacks in spotify, put them in a shortcut keys on ubuntu:\n# play/puasedbus-send --print-reply --dest=org.mpris.MediaPlayer2.spotify /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.PlayPause# next trackdbus-send --print-reply --dest=org.mpris.MediaPlayer2.spotify /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.Next# previous trackdbus-send --print-reply --dest=org.mpris.MediaPlayer2.spotify /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.Previous\n🔅 Resize multiple photos (keep the ratio/scale) (more options):\n🔅 Youtube Music Controller for Linux:\n\nDownload and install this app.\nChange to Youtube Music interface.\nRemove all shortcut keyboards that look like the ones you wanna set in the app in Ubuntu system (Keyboard shortcuts).\nOn taskbar, right click on the You Tube Music app &gt; Desktop settings &gt; Hotkeys &gt; Set your keyboards (eg. Ctrl+Shift+&gt; for next track, Ctrl+Shift+&lt; for previous track, Ctrl+Shift+Space for play/pause track).\n\n\n# installsudo apt-get install imagemagick\n# resize but keep the ratio (save to jpg)mogrify -resize 50% -format jpg *\n# resize keep the extensionmogrify -resize 50% *\n# with a specific size (save to jpg)mogrify -resize 800x600 -format jpg *\n# just the width (save to jpg)mogrify -resize 800x -format jpg *\n# only resize images bigger than 1000px widthmogrify -resize 1000x\\> *\n\nGame #\n🔅 Game platforms: Steam, Lutris.\n🔅 Xbox Controller on Ubuntu:\n\n# for bluetooth recognizesudo apt-get install xboxdrv# start the servicesudo systemctl start xboxdrv.service# if: Failed to start xboxdrv.service: Unit xboxdrv.service not found# installsudo apt-add-repository -y ppa:rael-gc/ubuntu-xboxdrvsudo apt-get updatesudo apt-get install ubuntu-xboxdrv\n# for GUI testing appsudo apt-get install jstest-gtk\n\nIf you cannot connect controller to bluetooth,[ref]\nsudo apt install sysfsutils# edit as root/etc/sysfs.conf# add below line to the end of above file/module/bluetooth/parameters/disable_ertm=1# save changes and restart\nLutris tips #\n🔅 Install GOG's games: Open Lutris &gt; Search Lutris.net &gt; Install with option &quot;GOG&quot;. Installed from GOG Galaxy may be not working but with this method is working!\n🔅 Add icon in the Lutris windows:\n\n\nCLick on &quot;+&quot; (Add Game)\n\n\nTab Game info: &quot;Name&quot; the game + choose &quot;Runner&quot;.\n\n\nTab Game options: &quot;Excutable&quot; choose\n# an example~/Games/epic-games-store/drive_c/Program Files/Epic Games/ShadowTactics/Shadow Tactics.exe\n\n\n🔅 Add icon on Ubuntu/POP!_OS launcher: on Lutris interface, right click on a game &gt; &quot;Create application menu shortcut&quot;, it will appear on the launcher after that. You can use &quot;alacarte&quot; (Main Menu, can be found in App Store).\nSystem #\n🔅 System monitor in terminal: vtop\nsudo apt install nodejssudo apt install npmsudo npm install -g vtop\nErrors #\n🔅 Problem save file as root user and cannot open later ⇾ link\n🔅 Prevent bluetooth devices disconnected after sleep ⇾ link\n🔅 Failed to load module 'canberra-gtk-module\nsudo apt install libcanberra-gtk-module libcanberra-gtk3-module\n🔅 nvidia docker signatures invalid. The following signatures were invalid: EXPKEYSIG\ncurl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -\n🔅 bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\necho \"LC_ALL=en_US.UTF-8\" >> /etc/environmentecho \"en_US.UTF-8 UTF-8\" >> /etc/locale.genecho \"LANG=en_US.UTF-8\" > /etc/locale.conflocale-gen en_US.UTF-8\n🔅 dpkg: error processing package install-info\nsudo mv /var/lib/dpkg/info/install-info.postinst /var/lib/dpkg/info/install-info.postinst.bad\n🔅 APT had planned for dpkg to do more than it reported back\ndpkg --configure -aapt-get install -f\nGPU-NVDIA problems #\n🔅 Problems with pytorch versions: check this.\n🔅 RuntimeError: cuda runtime error (804) : forward compatibility was attempted on non supported HW at /pytorch/aten/src/THC/THCGeneral.cpp:47 (after update system including nvdia-cli, maybe) =&gt; The same problem with below, need to restart the computer.\n🔅 nvidia-smi: Failed to initialize NVML: Driver/library version mismatch.\n\nThis thread: just restart the computer.\n\n"},"/visual-studio-code/":{"id":"/visual-studio-code/","title":"VSCode","keywords":"visual studio code vsc regex regular expression ssh remote server character combining font ligatures couple characters symbols letters new characters installation install extension plugin add extra path to auto complete reStructuredText rst markdown extension pythonremote regular expression regex vscode live server scss css compiler","tags":["posts","Skills"],"cat":"/img/cats/skills.svg","content":"Install #\nDownload and install here.\nExtensions #\n# list the installed extensions# unixcode --list-extensions | xargs -L 1 echo code --install-extension# windowscode --list-extensions | % { \"code --install-extension $_\" }# To re-install on a new machine# just copy-paste the results and run on terminal\nMy favorite extensioscode --install-extension bierner.markdown-emojicode --install-extension bierner.markdown-preview-github-stylescode --install-extension CoenraadS.bracket-pair-colorizercode --install-extension eamodio.gitlenscode --install-extension formulahendry.auto-close-tagcode --install-extension himanoa.Python-autopep8code --install-extension James-Yu.latex-workshopcode --install-extension lextudio.restructuredtextcode --install-extension mdickin.markdown-shortcutscode --install-extension mhutchie.git-graphcode --install-extension mrmlnc.vscode-apachecode --install-extension ms-azuretools.vscode-dockercode --install-extension ms-mssql.mssqlcode --install-extension ms-python.pythoncode --install-extension ms-vscode-remote.remote-containerscode --install-extension ms-vscode-remote.remote-sshcode --install-extension ms-vscode-remote.remote-ssh-editcode --install-extension ms-vscode-remote.remote-wslcode --install-extension ms-vscode-remote.vscode-remote-extensionpackcode --install-extension Perkovec.emojicode --install-extension ritwickdey.live-sasscode --install-extension ritwickdey.LiveServercode --install-extension ronnidc.nunjuckscode --install-extension SolarLiner.linux-themescode --install-extension streetsidesoftware.code-spell-checkercode --install-extension yzhang.markdown-all-in-onecode --install-extension zxh404.vscode-proto3\n\nreStructuredText #\npreview engine sphinx is not installed =&gt; in Ubuntu 20.04+\nsudo apt install python-is-python3# prevent Python 2 from being installed as a dependency of somethingsudo apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\nAdd extra path to auto complete #\nOpen settings.json and add,\n{\t\"python.autoComplete.extraPaths\": [\t\t\"C:\\\\Users\\\\dinha\\\\Documents\\\\GitHub\\\\dataswati\\\\python-dataswati\"\t],}\nFix Pylint unable to import #\nOpen settings.json and add,\n\"python.linting.pylintArgs\": [\t\"--init-hook\",\t\"import sys; sys.path.append('C:\\\\Users\\\\dinha\\\\Documents\\\\GitHub\\\\dataswati\\\\python-dataswati')\"]\nAppearances #\nChange font for internal terminal #\nMake a good corresponding to zsh.\n# Open settings JSON\"terminal.integrated.cursorStyle\": \"line\",\"terminal.integrated.fontFamily\": \"Source Code Pro Medium\",\"terminal.integrated.fontSize\": 15\nEnable font ligatures #\n👉 Reference.\nFor example, you type = + &gt;, it becomes ⇒.\n\n\nDownload Fira Code Font.\n\n\nExtract and then install the font after that.\n{\"editor.fontFamily\": \"'Fira Code', 'Consolas', 'Courier New', monospace\",\"editor.fontLigatures\": true}\n\n\nReload VSC.\n\n\n💡 If you only wanna apply this setting for some file format, you can click on the language at the bottom right of VSC, then click Configure 'Markdown' language based setting.\nRegular Expression #\nOfficial doc of using regex in vscode.\n\n# Replacehttp://bit.ly/abc# with[http://bit.ly/abc](http://bit.ly/abc)# find box(http://bit.ly.*)# replace box[$1]($1)\n# Replace**Course 1**# withCourse 1# Find box\\*\\*Course (.*)\\*\\*# replace boxCourse $1\n# Replace::: col-2-equalcontent\n\nwith #\n\ncontent\n\nIn find box -&gt; the key: [\\s\\S\\r]*? #\n::: col-2-equal([\\s\\S\\r]*?):::\nIn replace box #\n\\n$1\n```\n:::\nExlude files/folders in file search Visual Studio Code (VSC) #\nGo to Preferences &gt; Settings &gt; search exclude and modify inside section Search: Exclude. More patterns can be found here.\nBelow is an example list,\n**/node_modules\n**/bower_components\n**/*.code-search\n**/_site\n**/.jekyll-cache\n**/.sass-cache\n**/*.ico\n**/*.png\n**/*.ipynb\n**/*.jpg\n**/*.jpeg\n**/*.svg\n\nConnect ssh folders in VSC #\nRead this tutorial.\n\nInstall extension Remote - SSH\nView &gt; Command Palette... &gt; type &quot;SSH&quot; and choose &quot;Remote-SSH: Connect to Host...&quot; &gt; choose &quot;+ Add New SSH Host...&quot;\nType ssh user@host &gt; Enter &gt; choose a file to be updated, e.g. ~/.ssh/config.\nClick Connect if there is any popup in VSC.\nChoose platform on the server, usually Linux.\n\nError? #\n# Could not establish connection to \"undefined\". Could not resolve hostname.# ref: https://github.com/microsoft/vscode-remote-release/issues/1047# Open config ssh file# Ctrl+Shift+P then \"Remote-SSH: Open Configuration File\"# In stead ofHost XXX.XXX.XXX.XXXUser bobPort 22IdentityFile ~/.ssh/id# use thisHost server_name # Do not put ip hereHostName XXX.XXX.XXX.XXX # But put it hereUser bobPort 22IdentityFile ~/.ssh/id# Then Ctrl+Shift+P > \"Remote-SSH: Connect to host\"# Pick \"server_name\"\nSettings #\n👉 Check this file.\nUse settings for a custom file extension,\n# the list of extension name will be showed when typing\"[markdown]\": { \"editor.tabSize\": 4,},\"[restructuredtext]\": { \"editor.wordWrap\": \"on\",}\nPylint #\n# _Unable to import_ some user-defined package# 1. Make sure the right env running in vscode# For example, popai (conda)# 2. Make a symblic linkln -s /home/thi/git/dataswati/python-dataswati/popai /home/thi/miniconda3/envs/popai/lib/python3.8/popai\n# unresolved import# Ctrl + Shift + P# Preferences: Open Workspace Settings (JSON)\"settings\": { \"python.pythonPath\": \"/usr/bin/python3\", \"python.autoComplete.extraPaths\": [ \"/usr/lib/python3/dist-packages\", \"/app/src/python/\" # or other paths you want! ]}\nHot keys #\nOne can change the default keyboard shortcut by going to: File &gt; Preferences &gt; Keyboard Shortcuts.\n\n\nQuick search file: Ctrl + P.\nGet back to previous views: Ctrl + Alt + - (Linux), Alt + &lt; (Windows), Ctrl + - (MacOS).\nGet forward: Ctrl + Shift + - (Linux), Alt + &gt; (Windows), Ctrl + Shift + - (MacOS).\nOpen Command Palette: Ctrl + Shift + P.\nForat on save: Ctrl + Shift + I.\nGo to line: Ctrl + Shift + P then Go to line.\n\n"},"/pytest/":{"id":"/pytest/","title":"Pytest","keywords":"test result verify check algorithms error ImportError: No module named atomicwrites fixture not found","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Install #\npip install pytest\nRules #\n\nName all testing files with[ref] test_*.py or *_test.py.\nName all &quot;be tested&quot; functions with def test_*.\n\nExecuting #\n\n-rf: list files having bugs.\nMost useful command lines.\n\n\npytest test_sample.pypytest -q test_sample.py # quiet mode\n# ignore all files in folder statisticspytest -k \"not statistics\"\n\nSimple #\n# test_sample.pydef func(x): return x + 1def test_answer(): assert func(3) == 5\n# then runpytest test_sample.py\nWith parameters #\n\n# test_sample.py@pytest.mark.parametrize( \"input, param_1, param_2, result\", [ (df_1, 'date', np.mean, df_result_1), (df_2, 'date', np.mean, df_result_2), ])def test_run(input, param_1, param_2, result): spts = SPTS(param_1=param_1, param_2=param_2) df_tmp = spts.run(df) assert isinstance(df_tmp, pd.DataFrame) assert df_tmp.equals(result)\n# To get all combinations@pytest.mark.parametrize(\"x\", [0, 1])@pytest.mark.parametrize(\"y\", [2, 3])def test_foo(x, y): pass# Then the arguments set to `x=0/y=2`,# `x=1/y=2`, `x=0/y=3`, and `x=1/y=3`.\n\nNote that, @pytest.mark.parametrize must be placed right before the function who uses it. Otherwise, there is an error fixture not found.\n\n# ERROR@pytest.mark.parametrize(\"x\", [0, 1])def test_foo(x): passdef test_bar(x): pass\n# FIX@pytest.mark.parametrize(\"x\", [0, 1])def test_foo(x): pass@pytest.fixturedef test_bar(x): pass\n\nCustom marker #\nRun tests who have a specific marker.[ref]\n\n@pytest.mark.marker_1def test_func1(): pass@pytest.mark.marker_2def test_func2(): pass@pytest.mark.marker_1def test_func3(): pass\n# with tag 'marker_1'pytest -v -m marker_1# except tag 'marker_1'pytest -v -m 'not marker_1'\n\nErrors #\n# ImportError: No module named atomicwritespython -m pytestpython3 -m pytest\nIgnore warning #\n👉 Main reference.\n# eg: RuntimeWarning: numpy.ufunc size changed,@pytest.mark.filterwarnings('ignore::RuntimeWarning')@pytest.mark.level_1def test_load(df_test, report):\nReferences #\n\npytest official docs.\n\n"},"/wordpress-installation/":{"id":"/wordpress-installation/","title":"Wordpress Installation","keywords":"LAMP create website wordpress wp apache2 mysql php phpmyadmin run locally database MAMP WAMP WampServer www clone a website to localhost locally theme template desgin PHP visual studio code vsc PHP IntelliSense database ftp app winscp filezilla transmit localhost","tags":["posts","Web Dev","Wordpress"],"cat":"/img/cats/web-dev.svg","content":"I create Math2ITwp theme for math2it.com from scratch. This note contains the basic things to create a theme like that.\nInstall Apache + MySQL + PHP. #\nLinux #\nBelow are the short steps from this post.\nInstall Apache2 + MySQL# upate systemsudo apt update# install apache2sudo apt install apache2# Adjust the Firewall to Allow Web Trafficsudo ufw app listsudo ufw app info \"Apache Full\" # it should show that it enables traffic to ports 80 and 443sudo ufw allow in \"Apache Full\"# try browsing http://localhost\n# install mysqlsudo apt install mysql-server# setup mysql (choose Y for all, set passwords if neccessary)sudo mysql_secure_installationsudo mysqlSELECT user,authentication_string,plugin,host FROM mysql.user;# change 'YourPassword' with your own password!!!ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'YourPassword';FLUSH PRIVILEGES;# verify that 'root' has 'mysql_native_password' in filed 'plugin'SELECT user,authentication_string,plugin,host FROM mysql.user;exit\nAfter set a new password to root user of mysql, instead of using sudo mysql, you have to use following command to access mysql with the root\nmysql -u root -p # and then type the new password (YourPassword above)!\n\nInstall PHP# install phpsudo apt install php libapache2-mod-php php-mysql# tell web server to prefer .php filesudo gedit /etc/apache2/mods-enabled/dir.conf# find IfModule mod_dir.c and move index.php to the first# restart apache webserversudo systemctl restart apache2# check status on apache2sudo systemctl status apache2 # press Q to exit# install some additional modulesapt search php- | less # press Q to quit\nTesting a php file in /var/www/html/\nsudo gedit /var/www/html/info.php\nand paste\n&lt;?phpphpinfo();?>\nGoto localhost/phpmyadmin to test.\n\nInstall phpMyAdmin# install phpmyadminsudo apt updatesudo apt install phpmyadmin php-mbstring php-gettext# choose apache2 as default if you are asked for this# enable the mbstring PHP extensionsudo phpenmod mbstring# restart Apache for your changes to be recognizedsudo systemctl restart apache2\nIf you meet error ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO), follow this help on stackoverflow.\nIf you have error Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock', check this.\nAll above errors: Try to remove and reinstall again mysql and\nsudo apt-get remove --purge mysql*sudo apt-get autoremovesudo apt-get autocleansudo apt-get install mysql-server mysql-client\n\nWorking in MySQLLogin to mysql\nmysql -u root -p\nSee the list of current user in mysql\n# in the mysql environmentSELECT user,authentication_string,plugin,host FROM mysql.user;\nCreate a new user and give it a strong password\nCREATE USER 'thi'@'localhost' IDENTIFIED BY 'YourPassword';\nGrant your new user appropriate privileges\nGRANT ALL PRIVILEGES ON *.* TO 'thi'@'localhost' WITH GRANT OPTION;\nAfter installing phpmyadmin, there has to be an user phpmyadmin in the list of user of mysql, if not, you need to create a such user and give it grant control like above.\nGo to http://localhost/phpmyadmin. Login with your user and password you created above (thi for example).\n\nChange apache2 root document\nThe Apache server is installed on /var/www/html.\nSimply download this tool and follow the instructions. You can also check the author's answer on SE.\n\n\nWindows #\n\nDownload and install WampServer.\nBy default, after installing, your site will be at C:\\wamp64\\www.\nRun WarmServer, an green icon on the right of taskbar will appear.\n\nMacOS #\n\nInstall MAMP.\nFollow this post.\n\nPHP executable (optional) #\nJust for running PHP + PHP IntelliSense on Visual Studio Code.\n\n\nDownload PHP (Windows, portable).\n\n\nPut below lines in VSC setting file (change the path to yours).\n{\"php.validate.executablePath\": \"C:\\\\wamp64\\\\bin\\\\php\\\\php7.0.4\\\\php.exe\",\"php.executablePath\": \"C:\\\\wamp64\\\\bin\\\\php\\\\php7.0.4\\\\php.exe\"}\n\n\nCreate local database + Wordpress #\nCreate a database #\nOnly for Linux# Sign in to MySQLmysql -u root -p# Check the list of usersSELECT user,authentication_string,plugin,host FROM mysql.user;# Create a new user `thi` and assign to this user a password, e.g. `thipassword`CREATE USER 'thi'@'localhost' IDENTIFIED BY 'thipassword';# Set the orivileges to this userGRANT ALL PRIVILEGES ON *.* TO 'thi'@'localhost' WITH GRANT OPTION;\n\n\nOpen http://localhost/phpmyadmin/,\nCreate a new database testing_db (remember to choose utf8_general_ci before pressing Create)\nCreate a new user thi with ALL PRIVILEGES (click on Check all).\n\nInstall Wordpress #\n\nDownload Wordpress.\nCreate a folder thi in C:\\wamp64\\www (Windows), /var/www/html (Linux).\nExtract the content (wp-admin, wp-content,...) of the zip file downloaded in step 1 to /thi/.\nGo to http://localhost/thi and follow the instructions.\nType the username and password you created (thi and thipassword).\nPress Install and wait.\nLogin with username and password.\nAll the configuration is at http://localhost/texmath/wp-admin/.\n\nClone a website to localhost #\n\nInstall Apache + MySQL + PHP.\nCreate database + install Wordpress.\nAt least, you have a workable site at http://localhost/thi/.\nDownload and install an FTP app like WinSCP (Windows) or FileZilla or Transmit.\nDownload the current theme on the remote to local. The theme is located at /wp-content/themes/.\nClone database from remote site to local by using plugin All-in-One WP Migration. More detailed guid: English, Vietnamese. If your site's too big, exlude the media files and copy them later. They're all in wp-content/uploads.\nNote that, you have to use username and password given in the downloaded database instead of the one you created on localhost.\nEnable the downloaded theme in /wp-admin.\n\n"},"/bash-command-line/":{"id":"/bash-command-line/","title":"Bash","keywords":"cmder cmd terminal powershell macos mac linux ubuntu windows vim editor download wget check ip permission administrator block compress file zip rar unzip RAM CPU printenv environmental variables alias quick command quick shortcut multiple commands and script bash print print tree folder files structure windows terminal sh file","tags":["posts","Skills","Linux"],"cat":"/img/cats/skills.svg","content":"Bash commands are mainly supported in MacOS, Linux but also support in Windows. You can use integrated tools for using bash on these platforms.\n👉 Note about terminals.\n👉 Note about Screen.\nTools #\n\nApps: cmder (Windows), iTerm2 (MacOS), Guake Terminal (Linux).\nOnline: repl.it\n\nHotkeys #\n\nCtrl + C : interrupt current tasks.\nCtrl + L : clear the screen.\nTab : autocomplete the commands / directories / file names / ....\nCtrl + Shift + V : paste from clipboard.\nFor a long list: Enter to continue to read, q to quit.\n\nMultiple commands #\n# run at oncecommand_1 &amp;&amp; command_2\n.sh file #\n\n# using script: file.sh#!/bin/shecho 'some info'command_1command_2# and then sh file.sh\n# with arguments$file1 = $1wc $file1 # word count# multiple input argsfor FILE1 in \"$@\"; do\twc $FILE1done\n\nNAME=\"defaut\" # default value! DON'T HAVE SPACE!!!# with flagswhile getopts n:f: option; do\tcase \"${option}\"\t\tin\t\t\tn) NAME=${OPTARG};;\t\t\tf) FILE=${OPTARG};;\tesacdoneecho $NAMEwc $FILE# how to use?sh test.sh -n \"ThiD\" -f test.md\nSearch / grep / sed #\n\n# all files / folders containing 'abc'ls | grep -i abc\n# find command lines containing 'abc'dpkg -l | grep -i abc\n# search and extract a part of resultpip show numpy# Location: /usr/lib/python3/dist-packagespip show numpy | sed -n 's/Location: //p'# /usr/lib/python3/dist-packages\n\nCheck info #\nSystem #\n\n# DISK SPACEdf -h\n# like monitortop\n# MEM USAGEfree -m\n# ALL ENVprintenv# add newexport ABC=/xyz/thi/\n# NVIDIAnvidia-smilspci -nn | grep '\\[03' # another way\n# list of deviceslsusb\n\n# CPUcat /proc/cpuinfo | grep 'model name' | uniq # modelcat /proc/cpuinfo | grep 'vendor' | uniq # vendorcat /proc/cpuinfo | grep processor | wc -l # number of processes\nFolders / Files #\n\n# CHANGE ACTIVE DIRcd &lt;dir>cd # to the startup dircd / # to rootcd .. # to father dircd - # back to previous dir\n# CREATE NEW FOLDERmkdir &lt;dir>\n# LISTlsls -a # including hiddenls | grep 'ubuntu' # files containing 'ubuntu' in name\n# CURRENT PATHpwd\n# FOLDER/FILE SIZEdu -hs &lt;directory / file># `h` : human readable (6.7G)# `s` : display size# all folders/files of current folderdu -hs * | sort -rh# only foldersdu -sh ./*/# only first 5 retrievesdu -h /home/thi/ | sort -rh | head -5\n# REMOVINGrm &lt;file>rm -f &lt;file> # force to removerm -rf &lt;dir> # remove folderrmdir &lt;empty-dir> # remove empty\n# COMPRESSzip file.zip file/folderunzip file.zip # decompress\n# PRINT TREE folder structuretreetree -d # only folderstree -d -I 'abc' # except folder \"abc\"tree -I 'abc|xyz' # except folder \"abc\" and \"xyz\"tree -I 'test_*|__pycache__|__init__.py' # use wildcattree -L 2 # level 2tree -P 'test_' # list only files starting with \"test_\"\n\nPermission #\n\n# list of groupsgroups\n# which groups a user belongs togroup &lt;user_name>id -nG # or\n# check info of a current userid &lt;user_name>\n# list all members of a groupgrep &lt;group_name> /etc/group\n# CHECK PERMISSIONls -lls -l &lt;file>\n# ADD existing USER to existing GROUPsudo usermod -a -G groupName userName\n# CHANGE PERMISSIONchown &lt;user>:&lt;group> filechown -R thi:root folder # folder &amp; children\n\nNetwork #\n\n# CHECK IPifconfigipconfig # windows\n# DOWNLOAD A FILEwget https://website.com/filename.ext\n# open portssudo apt install nmapnmap localhost\n# very simple serverpython3 -m http.server # localhost:8000python3 -m http.server 1337 # localhost:1337\n# current running serverssudo apt install net-toolsnetstat -lepunt# kill a process, e.g. 29231/sshkill &lt;pid> # eg. kill 29231\n# mb data usedsudo apt install vnstatvnstat -d\n\n# INTERNET SPEED (need python)curl -s https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py | python -\nText file #\n\n# QUICK LOOK CONTENTmore file.txtcat file.txt\n# JUST CREATEtouch file.txt\n# CREATE + MODIFYnano file.txt # Ctrl+X to quitvim file.txt # ESC, :q to quit\n# SEARCH STRINGgrep \"string\" file.txt\n# ADD A LINE TO A FILE WITHOUT OPENNING ITecho \"hello 'thi' world\" >> my_file.txt\n\nImages #\n# open an imageeog image_file.jpg\nSymbolic link (shortcut) #\nln -s original_folder sym_folder# removerm sym_folder\nAlias #\nCreate your own &quot;alias&quot; command for short,\n\n# CREATEalias yourAlias='cd /usr/'alias yourAlias=cd /usr/ # windows\n# CALLyourAlias\n# LIST OF ALIASESaliasalias abc # \"abs\" stands for what?\n# remove an aliasunalias abc\n\n# group of commandsmy_alias() { screen -S dat -dm bash -c \"cd /dinhanhthi.com; iserve; exec sh\"}\n# list of commandsmy_alias(){ cd /home/user/git/abc/ git add . git commit -m \"abc\" git push}\n\n\nLinux / MacOS: Add your alias to .bash_aliases (in home dir, printenv HOME) if you wanna store your alias permanently.\nWindows: Using cmder (its setting file), add more aliases to &lt;cmder-install&gt;/config/user_aliases.cmd. You can also add (automatically) on the cmder UI, it adds them for you to the .cmd file.\n\nCreate / Copy / Cut / Paste #\n\n# Create a new foldermkdir &lt;folder>mkdir -p &lt;folder> # already exist accepted\n# MOVEmv &lt;old-dir> &lt;new-dir>move &lt;old-dir> &lt;new-dir> # windows\n# RENAME a file/foldermv olname.txt newname.txt\n# COPYcp file filecp -r file&amp;dir file&amp;dir\n\nDisplay #\n\n# only display 3 last directory namesPROMPT_DIRTRIM=3\n# display only user:current_folder#PS1='\\u:\\W\\$ '\n\nReferences #\n\nHow to Pass Arguments to a Bash Script\n\n"},"/wordpress-101/":{"id":"/wordpress-101/","title":"Wordpress 101","keywords":"localhost template theme theme directory url website name description template author info post info","tags":["posts","Web Dev","Wordpress"],"cat":"/img/cats/web-dev.svg","content":"In this note, wp theme's components are supposed to be placed in folder wp-thi.\nTools #\n\nFTP: WinSCP (Windows) or FileZilla or Transmit (MacOS).\n\nGeneral #\n\nTheme is placed at ./wp-content/themes/\nWP needs at least 2 files to exist: style.css and index.php.\nAdmin page wpsite.com/wp-admin.\n\nWP theme components #\nTheme's\necho get_bloginfo('template_directory'); // theme directory\nWebsite's\nget_bloginfo( 'wpurl' ) // urlget_bloginfo( 'name' ) // nameget_bloginfo( 'description' ) // description\nPost's\nthe_content() // contentthe_title() // titlethe_date() // datethe_author() // author\nAuthor's\nthe_author_meta( 'description' ); // description\nKaTeX for Wordpress #\nI don't like 2 available plugins (WP-KaTeX and KaTeX). The former doesn't support dollar symbols ($) to display equations, the latter doesn't support inline math.\nWe will use directly KaTeX.\n\n\nPut below code inside &lt;head&gt;&lt;/head&gt;,\n&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css\" integrity=\"sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq\" crossorigin=\"anonymous\">&lt;script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js\" integrity=\"sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz\" crossorigin=\"anonymous\">&lt;/script>&lt;script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js\" integrity=\"sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI\" crossorigin=\"anonymous\" onload=\"renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true},{left: '$', right: '$', display: false}]});\">&lt;/script>\n\n\nIn Wordpress, for display mode, switch to html block. For inline mode, use $$ as usual.\n\n\n"},"/python-exception/":{"id":"/python-exception/","title":"Python Exception","keywords":"error except try","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Try..Except #\ntry: # codesexcept: # codes run if there is an exception\n\ntry: # codesexcept: # codes run if there is an exceptionelse: # no exception?\ntry: # try codesexcept FileNotFoundError as fnf_error: print(fnf_error)except AssertionError as error: print(error)\n\nOther Errors, check this list.\nApply #\nCheck str of float #\nelement = 'mean'try: print(float(element))except ValueError: if element == 'mean': print('hello mean')\n"},"/mean-shift/":{"id":"/mean-shift/","title":"Mean Shift clustering","keywords":"distance between points Mode-seeking algorithm Non-Parametric Density Estimation PDF Search Results Web results Probability density function Kernel Density Estimation","tags":["posts","Machine Learning","Clustering"],"cat":"/img/cats/ml.svg","content":"What? #\n\n\nMean-Shift assigns the data points to the clusters iteratively by shifting points towards the mode (mode is the highest density of data points in the region, in the context of the Meanshift)\n\n\nNon-Parametric Density Estimation.\n\n\nThe data points are sampled from an underlying PDF (Probability density function)[ref].\n\nData point density implies PDF.\n\n\nMean-shift built based on the idea of Kernel Density Estimation.\n\n\nMean shift exploits this KDE idea by imagining what the points would do if they all climbed up hill to the nearest peak on the KDE surface. It does so by iteratively shifting each point uphill until it reaches a peak[ref].\n \n\nPoints climb to the nearest hill.\n\nPoints climb to the nearest hill.\n \n\n\nWhen? #\n\nImage processing and computer vision.\nImage Segmentation Application[ref].\n\nPros &amp; Cons #\n\nPros: Non-Parametric Density Estimation.\nCons: It's computationally expensive O(n²) [ref].\n\nCode? #\nfrom sklearn.cluster import MeanShiftclustering = MeanShift(bandwidth=2).fit(X)\n\nclustering.fit(X)clustering.predict(X)\n# orclustering.fit_predict(X)\n\nComponents:\n\nclustering.labels_: clusters' labels.\n\nUsage example #\n\nUsed to determined windows of time in time series data.\n\nReferences #\n\nSaravanan Thirumuruganathan -- Introduction To Mean Shift Algorithm.\nGeeksforgeeks -- Mean-Shift clustering.\nR.Collins -- Mean-Shift tracking.\nMatt Nedrich -- Mean Shift Clustering.\n\n"},"/python-dictionary/":{"id":"/python-dictionary/","title":"Python Dictionary","keywords":"dict dictionary access elements sorted by keys","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Checking #\n# check if emptybool(my_dict) # False if empty\nCreating #\n\n# empty dictmy_dict = {}\n# integer keysmy_dict = {1: \"a\", 2: 3}\n\n# contains complicated typesmy_dict = {1: [\"1\", \"2\"], \"2\": {1: 1, 2: 2}, 3: (1, 2)}\nUpdating #\nd = {1: \"one\", 2: \"three\"}d1 = {2: \"two\"}# update value of key \"2\"d.update(d1)# add new key \"3\"d2 = {3: \"three\"}d.update(d2)\nAccess elements #\n\nmy_dict = {1: \"a\", 2: \"b\"}my_dict[1]my_dict.keys()my_dict.values()my_dict.items()\n'a'\ndict_keys([1, 2])\ndict_values(['a', 'b'])\ndict_items([(1, 'a'), (2, 'b')])\n\n\n\nfor key, val in my_dict.items(): print(key, val)\n1 a\n2 b\n\n\nIf the key doesn't exist, use the default!\n\ndct = {1: 'a', 2: 'b'}dct.get(1)dct.get(3, 'c')\n'a'\n'c'\n\n\nSorted keys #\nfor key in sorted(my_dict.keys()): pass\n"},"/python-json/":{"id":"/python-json/","title":"Python JSON","keywords":"json JavaScript Object Notation Serialization Deserialization","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"JSON (JavaScript Object Notation) is a format that encodes objects in a string.\nTerms #\n\nSerialization : convert an object → string.\nDeserialization : convert string → object.\n\n\n# object{foo: [1, 4, 7, 10], bar: \"baz\"}\n# string'{\"foo\":[1,4,7,10],\"bar\":\"baz\"}'\n\nJSON with python[ref] #\nBasics #\nimport json\n\n# DECODINGjson.load()\n# ENCODINGjson.dumps()json.dump()\n\nDict to JSON #\ndef dict_to_json(dictionary): \"\"\" Transform dictionary that contain numpy instances into a JSON serializable dictionary. Parameters ---------- dictionary: dict The dictionary to tranform. Returns ------- dict The JSON serializable dictionary. \"\"\" dict_json = {} for key in dictionary: if isinstance(dictionary[key], dict): dict_json[key] = dict_to_json(dictionary[key]) elif isinstance(dictionary[key], str): dict_json[key] = dictionary[key] elif hasattr(dictionary[key], \"__len__\"): dict_json[key] = [to_json(v) for v in dictionary[key]] elif isinstance(dictionary[key], (np.integer, int, np.int64)): dict_json[key] = int(dictionary[key]) elif isinstance(dictionary[key], (np.floating, float)): dict_json[key] = float(dictionary[key]) elif isinstance(dictionary[key], (pd.Timedelta, pd.Timestamp, dt.timedelta, dt.datetime, dt.date, dt.time)): dict_json[key] = str(dictionary[key]) elif isinstance(dictionary[key], np.bool_): # numpy boolean dict_json[key] = bool(dictionary[key]) elif dictionary[key] is None: dict_json[key] = None elif dictionary[key] == True: dict_json[key] = bool(True) elif dictionary[key] == False: dict_json[key] = bool(False) else: log.debug('type pb: %s', type(dictionary[key])) dict_json[key] = 'not JSON serializable' return dict_json\n"},"/deeplearning-ai-course-1/":{"id":"/deeplearning-ai-course-1/","title":"DL 1 - NN and DL","keywords":"logistic regression sigmoid derivative function python tips softmax activation function forward propagation and backward propagation simple neural network model predict an image of cat tanh relu leaky relu gradient descent L layer L-layer initialize parameters and hyperparameters shallow nn recognize a cat reshape neural networks supervised learning geoffrey hinton binary classification logistic gradient descent derivatives computation graph vetorization jupyter notebook Pieter Abbeel NN representation backprop intuition matrix dimension deep l-layer building blocks hyperparameters andrew ng","tags":["posts","MOOC","deeplearning.ai","Deep Learning"],"cat":"/img/cats/mooc.svg","content":"This is my note for the course (Neural Networks and Deep Learning). The codes in this note are rewritten to be more clear and concise.\n👉 Course 1 -- Neural Networks and Deep Learning.\n👉 Course 2 -- Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.\n👉 Course 3 -- Structuring Machine Learning Projects.\n👉 Course 4 -- Convolutional Neural Networks.\n👉 Course 5 -- Sequence Models.\nIf you want to break into cutting-edge AI, this course will help you do so.\nActivation functions #\n👉 Check Comparison of activation functions on wikipedia.\nWhy non-linear activation functions in NN Model? #\nSuppose g(z)=zg(z)=zg(z)=z (linear)\na[1]=g(z[1]=z[1])=w[1]x+b[1](linear)a[1]=g(z[2]=z[2])=w[2]a[1]+b[2]=(w[2]w[1])x+(w[2]b[1]+b[2])(linear again).\\begin{aligned}\na^{[1]} &amp;= g(z^{[1]} = z^{[1]}) = w^{[1]}x + b^{[1]} \\quad \\text{(linear)} \\\\\na^{[1]} &amp;= g(z^{[2]} = z^{[2]}) = w^{[2]}a^{[1]} + b^{[2]} \\\\\n &amp;= (w^{[2]}w^{[1]})x + (w^{[2]}b^{[1]} + b^{[2]}) \\quad \\text{(linear again)}.\n\\end{aligned}\na[1]a[1]​=g(z[1]=z[1])=w[1]x+b[1](linear)=g(z[2]=z[2])=w[2]a[1]+b[2]=(w[2]w[1])x+(w[2]b[1]+b[2])(linear again).​\nYou might not have any hidden layer! Your model is just Logistic Regression, no hidden unit! Just use non-linear activations for hidden layers!\nSigmoid function #\n\nUsually used in the output layer in the binary classification.\nDon't use sigmoid in the hidden layers!\n\n\nσ(z)=11+e−zσ(z)→z→∞1σ(z)→z→−∞0σ′(x)=σ(x)(1−σ(x))\\begin{aligned}\n\\sigma(z) &amp;= \\dfrac{1}{1+e^{-z}} \\\\\n\\sigma(z) &amp;\\xrightarrow{z\\to \\infty} 1 \\\\\n\\sigma(z) &amp;\\xrightarrow{z\\to -\\infty} 0 \\\\\n\\sigma&#x27;(x) &amp;= \\sigma(x) (1 - \\sigma(x))\n\\end{aligned}\nσ(z)σ(z)σ(z)σ′(x)​=1+e−z1​z→∞​1z→−∞​0=σ(x)(1−σ(x))​\n\nSignmoid function graph on Wikipedia.\n\n\nimport numpy as npimport numpy as npdef sigmoid(z): return 1 / (1+np.exp(-z))\ndef sigmoid_derivative(z): return sigmoid(z)*(1-sigmoid(z))\n\nSoftmax function #\n\nThe output of the softmax function can be used to represent a categorical distribution – that is, a probability distribution over K different possible outcomes.\n\nUdacity Deep Learning Slide on Softmax\n\n\nσ(z)i=ezi∑j=1Kezj for i=1,…,K and z∈RK\\sigma (\\mathbf {z} )_{i}={\\frac {e^{z_{i}}}{\\sum _{j=1}^{K}e^{z_{j}}}}{\\text{ for }}i=1,\\dotsc ,K{\\text{ and }}\\mathbf {z}\\in \\mathbb {R} ^{K}\nσ(z)i​=∑j=1K​ezj​ezi​​ for i=1,…,K and z∈RK\ndef softmax(x): z_exp = np.exp(z) z_sum = np.sum(z_exp, axis=1, keepdims=True) return z_exp / z_sum\n\ntanh function (Hyperbolic tangent) #\n\ntanh is better than sigmoid because mean →\\to→ 0 and it centers the data better for the next layer.\nDon't use sigmoid on hidden units except for the output layer because in the case 0≤y^≤10 \\le \\hat{y} \\le 10≤y^​≤1, sigmoid is better than tanh.\n\n\n\nσ(z)=ez−e−zez+e−z\\sigma(z) = \\dfrac{e^{z} - e^{-z}}{e^{z} + e^{-z}}\nσ(z)=ez+e−zez−e−z​\ndef tanh(z): return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n\n\nGraph of tanh from analyticsindiamag.\n\nReLU #\n\nReLU (Rectified Linear Unit).\nIts derivative is much different from 0 than sigmoid/tanh →\\to→ learn faster!\nIf you aren't sure which one to use in the activation, use ReLU!\nWeakness: derivative ~ 0 in the negative side, we use Leaky ReLU instead! However, Leaky ReLU aren't used much in practice!\n\n\n\nσ(z)=max(0,z)\\sigma(z) = max(0,z)\nσ(z)=max(0,z)\ndef relu(z): return np.maximum(0, z)\n\n\nReLU (left) and Leaky ReLU (right)\n\nLogistic Regression #\n\nUsually used for binary classification (there are only 2 only 2 outputs). In the case of multiclass classification, we can use one vs all (couple multiple logistic regression steps).\n\nGradient Descent #\nGradient Descent is an algorithm to minimizing the cose function JJJ. It contains 2 steps: Forward Propagation (From XXX to compute the cost JJJ) and Backward Propagation (compute derivaties and optimize the parameters w,bw, bw,b).\nInitialize w,bw, bw,b and then repeat until convergence (mmm: number of training examples, α\\alphaα: learning rate, JJJ: cost function, AAA: activation function):\n\n\nA=σ(wTX+b)A = \\sigma(w^TX + b)A=σ(wTX+b)\nJ(w,b)=−1m(Ylog⁡AT+(1−Y)log⁡(1−AT))J(w,b) = -\\frac{1}{m} \\left( Y \\log A^T + (1-Y)\\log(1-A^T) \\right)J(w,b)=−m1​(YlogAT+(1−Y)log(1−AT))\n∂wJ=1mX(A−Y)T\\partial_{w}J = \\frac{1}{m}X(A-Y)^T∂w​J=m1​X(A−Y)T\n∂bJ=1mΣ(A−Y)\\partial_{b}J = \\frac{1}{m} \\Sigma (A-Y)∂b​J=m1​Σ(A−Y)\nw:=w−α∂wJw := w - \\alpha \\partial_{w}Jw:=w−α∂w​J\nb:=b−α∂bJb := b - \\alpha \\partial_{b}Jb:=b−α∂b​J\n\nThe dimension of variables: X∈Rnx×m,Y∈R1×m,b∈R1×m,w∈Rnx×1,A∈R1×m,J∈RX\\in \\mathbb{R}^{n_x \\times m}, Y\\in \\mathbb{R}^{1\\times m}, b\\in \\mathbb{R}^{1\\times m}, w\\in \\mathbb{R}^{n_x \\times 1}, A\\in \\mathbb{R}^{1\\times m}, J\\in \\mathbb{R}X∈Rnx​×m,Y∈R1×m,b∈R1×m,w∈Rnx​×1,A∈R1×m,J∈R, ∂wJ∈R\\partial_wJ \\in \\mathbb{R}∂w​J∈R, ∂bJ∈R\\partial_bJ \\in \\mathbb{R}∂b​J∈R.\nCode #\ndef logistic_regression_model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5): m = X_train.shape[1] # number of training examples # INITIALIZE w, b w = np.zeros((X_train.shape[0], 1)) b = 0 # GRADIENT DESCENT for i in range(num_iterations): # FORWARD PROPAGATION (from x to cost) A = sigmoid(np.dot(w.T, X_train) + b) cost = -1/m * (np.dot(Y, np.log(A.T)) + p.dot((1-Y), np.log(1-A.T))) # BACKWARD PROPAGATION (find grad) dw = 1/m * np.dot(X_train, (A-Y).T) db = 1/m * np.sum(A-Y) cost = np.squeeze(cost) # OPTIMIZE w = w - learning_rate*dw b = b - learning_rate*db # PREDICT (with optimized w, b) Y_pred = np.zeros((1,m)) w = w.reshape(X.shape[0], 1) A = sigmoid(np.dot(w.T,X_test) + b) Y_pred_test = A > 0.5\nNeural Network overview #\nNotations #\n\n\nX(i)X^{(i)}X(i) : iiith training example.\nmmm : number of examples.\nLLL : number of layers.\nn[0]=nXn^{[0]} = n_Xn[0]=nX​ : number of features (# nodes in the input).\nn[L]n^{[L]}n[L] : number of nodes in the output layer.\nn[l]n^{[l]}n[l] : number of nodes in the hidden layers.\nw[l]w^{[l]}w[l] : weights for z[l]z^{[l]}z[l].\na[0]=Xa^{[0]} = Xa[0]=X : activation in the input layer.\nai[2]a^{[2]}_iai[2]​ : activation in layer 222, node iii.\na[2](i)a^{[2](i)}a[2](i) : activation in layer 222, example iii.\na[L]=y^a^{[L]} = \\hat{y}a[L]=y^​.\n\n\nDimensions #\n\n\nA[0]=X∈Rn[0]×mA^{[0]} = X \\in \\mathbb{R}^{n^{[0]} \\times m}A[0]=X∈Rn[0]×m\nZ[l],A[l]∈Rn[l]×mZ^{[l]}, A^{[l]} \\in \\mathbb{R}^{n^{[l]}\\times m}Z[l],A[l]∈Rn[l]×m.\ndZ[l],dA[l]∈Rn[l]×mdZ^{[l]}, dA^{[l]} \\in \\mathbb{R}^{n^{[l]}\\times m}dZ[l],dA[l]∈Rn[l]×m.\ndW[l],W[l]∈Rn[l]×[l−1]dW^{[l]}, W^{[l]} \\in \\mathbb{R}^{n^{[l]} \\times ^{[l-1]}}dW[l],W[l]∈Rn[l]×[l−1].\ndb[l],b[l]∈Rn[l]×1db^{[l]}, b^{[l]} \\in \\mathbb{R}^{n^{[l]} \\times 1}db[l],b[l]∈Rn[l]×1.\n\n\nL-layer deep neural network #\n\n\nL-layer deep neural network. Image from the course.\n\n\nInitialize parameters / Define hyperparameters\nLoop for num_iterations:\n\nForward propagation\nCompute cost function\nBackward propagation\nUpdate parameters (using parameters, and grads from backprop)\n\n\nUse trained parameters to predict labels.\n\n\n\nInitialize parameters #\n\nIn the Logistic Regression, we use 000 for w,bw, bw,b (it's OK because LR doesn't have hidden layers) but we can't in the NN model!\nIf we use 000, we'll meet the completely symmetric problem. No matter how long you train your NN, hidden units compute exactly the same function ⇒\\Rightarrow⇒ No point to having more than 1 hidden unit!\nWe add a little bit in WWW and keep 000 in bbb.\n\nForward &amp; Backward Propagation #\n\nBlocks of forward and backward propagation deep NN. Unknown source.\n\nBlocks of forward and backward propagation deep NN. Image from the course.\nForward Propagation: Loop through number of layers:\n\n\nA[0]=XA^{[0]} = XA[0]=X\nZ[l]=W[l]A[l−1]+b[l]Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}Z[l]=W[l]A[l−1]+b[l] (linear)\nA[l]=σ[l](Z[l])A^{[l]} = \\sigma^{[l]}(Z^{[l]})A[l]=σ[l](Z[l]) (for l=1…L−1l=1 \\ldots L-1l=1…L−1, non-linear activations)\nA[L]=σ[L](Z[L])A^{[L]} = \\sigma^{[L]}(Z^{[L]})A[L]=σ[L](Z[L]) (sigmoid function)\n\nCost function: J(w,b)=−1m(Ylog⁡AT+(1−Y)log⁡(1−AT))J(w,b) = -\\frac{1}{m} \\left( Y \\log A^T + (1-Y)\\log(1-A^T) \\right)J(w,b)=−m1​(YlogAT+(1−Y)log(1−AT))\nBackward Propagation: Loop through number of layers\n\n\ndA[L]=−yA[L]+1−y1−A[L]dA^{[L]} = -\\frac{y}{A^{[L]}} + \\frac{1-y}{1-A^{[L]}}dA[L]=−A[L]y​+1−A[L]1−y​.\nfor l=L…1l=L \\ldots 1l=L…1, non-linear activations:\n\ndZ[l]=dA[l](σ[l])′(Z[l])dZ^{[l]} = dA^{[l]} (\\sigma^{[l]})&#x27;(Z^{[l]})dZ[l]=dA[l](σ[l])′(Z[l]).\ndW[l]=dJ∂W[l]=1mdZ[l](A[l−1])TdW^{[l]} = \\frac{dJ}{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} (A^{[l-1])^T}dW[l]=∂W[l]dJ​=m1​dZ[l](A[l−1])T.\ndb[l]=dJ∂b[l]=1mσ1mdZ[l](i)db^{[l]} = \\frac{dJ}{\\partial b^{[l]}} = \\frac{1}{m}\\sigma_1^m dZ^{[l](i)}db[l]=∂b[l]dJ​=m1​σ1m​dZ[l](i).\ndA[l−1]=(W[l])TdZ[l]dA^{[l-1]} = (W^{[l])^T}dZ^{[l]}dA[l−1]=(W[l])TdZ[l].\n\n\n\nUpdate parameters: loop through number of layers (for l=1…Ll=1\\ldots Ll=1…L)\n\n\nW[l]=W[l]−αdW[l]W^{[l]} = W^{[l]} - \\alpha dW^{[l]}W[l]=W[l]−αdW[l].\nb[l]=b[l]−αdb[l]b^{[l]} = b^{[l]} - \\alpha db^{[l]}b[l]=b[l]−αdb[l].\n\nCode #\ndef L_Layer_NN(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False): costs = [] m = X_train.shape[1] # number of training examples L = len(layer_dims) # number of layers # INITIALIZE W, b params = {'W':[], 'b':[]} for l in range(L): params['W'][l] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01 params['b'][l] = np.zeros((layer_dims[l], 1)) # GRADIENT DESCENT for i in range(0, num_iterations): # FORWARD PROPAGATION (Linear -> ReLU x (L-1) -> Linear -> Sigmoid (L)) A = X caches = {'A':[], 'W':[], 'b':[], 'Z':[]} for l in range(L): caches['A_prev'].append(A) # INITIALIZE W, b W = params['W'][l] b = params['b'][l] caches['W'].append(W) caches['b'].append(b) # RELU X (L-1) Z = np.dot(W, A) + b if l != L: # hidden layers A = relu(Z) else: # output layer A = sigmoid(Z) caches['Z'].append(Z) # COST cost = -1/m * np.dot(np.log(A), Y.T) - 1/m * np.dot(np.log(1-A), 1-Y.T) #FORWARD PROPAGATION (Linear -> ReLU x (L-1) -> Linear -> Sigmoid (L)) dA = - (np.divide(Y, A) - np.divide(1 - Y, 1 - A)) grads = {'dW':[], 'db':[]} for l in reversed(range(L)): cache_Z = caches['Z'][l] if l != L-1: # hidden layers dZ = np.array(dA, copy=True) dZ[Z &lt;= 0] = 0 else: # output layer dZ = dA * sigmoid(cache_Z)*(1-sigmoid(cache_Z)) cache_A_prev = caches['A_prev'][l] dW = 1/m * np.dot(dZ, cache_A_prev.T) db = 1/m * np.sum(dZ, axis=1, keepdims=True) dA = np.dot(W.T, dZ) grads['dW'].append(dW) grads['db'].append(db) # UPDATE PARAMETERS for l in range(L): params['W'][l+1] = params['W'][l] - grads['dW'][l] params['b'][l+1] = params['b'][l] - grads['db'][l] if print_cost and i % 100 == 0: print (\"Cost after iteration %i: %f\" %(i, cost)) if print_cost and i % 100 == 0: costs.append(cost) return parameter\nParameters vs Hyperparameters #\n\nParameters: W,bW, bW,b.\nHyperparameters:\n\nLearning rate (α\\alphaα).\nNumber of iterations (in gradient descent algorithm) (numiterationsnum_iterationsnumi​terations).\nNumber of layers (LLL).\nNumber of nodes in each layer (n[i]n^{[i]}n[i]).\nChoice of activation functions (their form, not their values).\n\n\n\nComments #\n\nAlways use vectorized if possible! Especially for number of examples!\nWe can't use vectorized for number of layers, we need for.\nSometimes, functions computed with Deep NN (more layers, fewer nodes in each layer) is better than Shallow (fewer layers, more nodes). E.g. function XOR.\nDeeper layer in the network, more complex features to be determined!\nApplied deep learning is a very empirical process! Best values depend much on data, algorithms, hyperparameters, CPU, GPU,...\nLearning algorithm works sometimes from data, not from your thousands line of codes (surprise!!!)\n\nApplication: recognize a cat #\nThis section contains an idea, not a complete task!\n\n\nImage to vector conversion. Image from the course.\n\nL-layer deep neural network. Image from the course.\n\nPython tips #\n○ Reshape quickly from (10,9,9,3) to (9*9*3,10):\nX = np.random.rand(10, 9, 9, 3)X = X.reshape(10,-1).T\n○ Don't use loop, use vectorization!\n👉 Course 2 -- Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.\n"},"/python-os-sys/":{"id":"/python-os-sys/","title":"Python sys & os","keywords":"list all files in a directory add path","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Library #\nimport os, sys\nAppend path to the environnement #\nsys.path.append('../') # the path of current file's father\nGet files' info #\n\n# LIST OF ALL FILESfile_path = '.' # current diros.listdir(file_path)\n# The last modificationos.path.getmtime(&lt;full-path-to-file-name>)\n"},"/airflow-k8s-101/":{"id":"/airflow-k8s-101/","title":"Airflow + Kubernetes 101","keywords":"airflow kubernetes k8s docker apache","tags":["posts","MLOps"],"cat":"/img/cats/mlops.svg","content":"👉 Note: Docker 101\n👉 Note: Wordpress Docker\n👉 Note: Docker &amp; GPUs\n👉 Note: Tensorflow extra\nInstallation #\n\nsudo snap install microk8s --classic\n# make an aliasalias k='microk8s.kubectl'\n# add to sudo groupsudo usermod -a -G microk8s thisudo chown -f -R thi ~/.kube# log out and log in again\n\n\nWe use k which stands for kubectl or microk8s.kubectl in this notebook!\nk8s #\nPods #\nPod: (full): a group of one or more containers (such as Docker containers), with shared storage/network, and a specification for how to run the containers.\n\n# list of podsmicrok8s.kubectl get pods\n# enter a podmicrok8s.kubectl exec -it &lt;pod_id> bash\n\nNamespaces #\n\nDetail is here.\nMultiple virtual clusters (namespaces) backed by the same physical cluster.\nMotivation for using namespaces: here =&gt; one word: isolation!\nAvoid creating namespace with prefix kube-.\n\n\n# list of current namespacesk get namespace\n# createk create namespace &lt;name_space># follows DBS label: https://bit.ly/2Cxge0K\n# deletek delete namespaces &lt;name_space># This deletes everything under the namespace!\n\nAirflow #\nQuickstart #\nCheck here.\nKubernetesPodOperator #\n\ntask_id=&quot;abc_xyz&quot; (required): the name of task given in the airflow ui.\nimage=&quot;localhost:32000/airflow-abc:debug&quot; (required): docker image to use.\nnamespace=&quot;default&quot; (required, ref):\nin_cluster=True:\ntrigger_rule=&quot;all_success&quot;: ref\nimage_pull_policy=&quot;Always&quot;: if you changes something on the docker image.\n\nIf using a dictionary and feed to env_vars (error &quot;TypeError: string indices must be integers&quot;),\n\nex_var = {'a': 1, 'b': 2}with DAG( # ...) as dag: abc = KubernetesPodOperator( # ... env_vars = { \"EX_VAR\": str(ex_var) } # ... )\n# used in another fileimport osimport astex_var = ast.literal_eval(os.environ[\"EX_VAR\"])\n\nReferences:\n\nAPI document: ref.\nKubernetesPodOperator Configuration -- Google Cloud.\n\nBranching #\nAirflow Errors #\n🔅 ERROR - Exception when attempting to create Namespaced Pod.\n\nNote that if you don't use in_cluster=True, then you won't run into this problem.[ref]\nThere may be something wrong with variables or their type of values. Check again carefully!\n\nReferences #\n\nAirflow official document.\nkubernetes blog -- Airflow on Kubernetes\n\n\n"},"/python-tuple/":{"id":"/python-tuple/","title":"Python Tuple","keywords":"","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Check #\n# a tuple has None / empty valuenot all(mytuple) # None ~ 0 ~ O.0# only consider Noneany(map(lambda x: x is None, mytuple)\n"},"/KS-test/":{"id":"/KS-test/","title":"Kolmogorov–Smirnov Test","keywords":"KS test p-value D statistic Probability Density Function Cumulative distribution function ks-test Kolmogorov Smirnov distribution of 2 two samples the same null hypothesis H0 earth mover's distance","tags":["posts","Prob & Stats"],"cat":"/img/cats/stats.svg","content":"What &amp; Why? #\nTo check the similar distribution of 2 samples drawn from population. If these samples are normal, we can use T-test, but if they are not normal, we need to use KS-test. KS-test is a non-parametric test.\nNull hypothesis (H0H_0H0​): &quot;Two samples drawn from population with the same distribution.&quot;\n👉 Read more about p-value. We use this value to evaluate the true/false of above null hypothesis.\nThe difference (in use) of T-test (need an assumption of nomality) and KS-test (don't need),\n\n\nTwo samples have the same mean &amp; standard deviation ⇒ p-value is high ⇒ cannot reject H0H_0H0​ (not true)\nKS-test can detect the variance ⇒ p-value is low ⇒ we can reject H0H_0H0​ ⇒ 2 samples are not the same distribution!!! (yep!)\n\nHow? #\nIf the KS statistic is small or the p-value is high, then we cannot reject the hypothesis that the distributions of the two samples are the same.\nCode? #\nfrom scipy import stats\n\n# one-sample KS teststats.kstest(x, 'norm')\n# two-sample KS teststats.ks_2samp(x, y)\n\nReferences #\n\nMatthew E. Clapham -- 10: Kolmogorov-Smirnov test (video)\nAn example of why we need to use EMD instead of Kolmogorov–Smirnov distance (video).\n\n"},"/p-value/":{"id":"/p-value/","title":"p-value","keywords":"p values null hypothesis reject alternate hypothesis nullify Chi-Square Test statistical significance multiple testing multiple comparison problem correction multiple testing multiple tests multipletests","tags":["posts","Prob & Stats"],"cat":"/img/cats/stats.svg","content":"Null hypothesis #\n\nNull hypothesis ⇒ questions scientist want to nullify.\n\nExample: H0H_0H0​ = &quot;The world is flat.&quot;\n\n\nAlternate hypothesis: &quot;The world is round.&quot;\nIn order to change an opinion, we first prove it wrong!\n\np-value #\n\nSmall p-value ⇒ reject null hypothesis!\nMostly, we need p&lt;0.05p&lt;0.05p&lt;0.05 (statistical significance) to reject a null hypothesis.\n\nSmaller 0.050.050.05, we are more sure!\n\n\nExample: &quot;Gender IS NOT linked to pet preference (cat/dog).&quot; With p=0.043&lt;0.05p=0.043&lt;0.05p=0.043&lt;0.05, we reject that hypothesis and conclude &quot;Gender IS linked to pet preference.&quot;[ref]\n\nUnderstand p-value? #\n\nIf p=0.75p=0.75p=0.75, it means that there are 75%75\\%75% the null hypothesis is true! We cannot reject it!\n\nCalculate p-value #\nIn order to calculate p-value, we use Chi-Square Test (X2X^2X2 test).\n\nThis test only works for categorical data (men, women), not numerical data (height, weight).\nThe number of entries must be large enough.\n\nMultiple tests + p-value correction #\n\nThe goal of multiple comparisons corrections is to reduce the number of false positives, because false positives can be embarrassing, confusing, and cause you and other people to waste your time.\nThe conclusion from p-value depends much on signigicance α\\alphaα (usually α=0.05\\alpha=0.05α=0.05). What if we wanna test multiple tests simultaneously? The same α\\alphaα for all cases?\nDealing with multiple testing ⇒\\Rightarrow⇒ adjusting α\\alphaα.\n\nReferences #\n\nMath is fun -- Chi-Square Test.\nWhy, When and How to Adjust Your P Values?\nLecture 10: Multiple Testing\nStatistics for Bioinformatics\nMultiple comparisons\n\n"},"/fresh-install-windows/":{"id":"/fresh-install-windows/","title":"Fresh Windows 10 Installation","keywords":"windows 10 reinstall install reset application softs need to do k380 keyboard logitech","tags":["posts","Others","Fresh Installation","Windows"],"cat":"/img/cats/others.svg","content":"This is my personal list of to-do things after reinstall Windows.\n👉 Ubuntu / Pop!_OS fresh start\n👉 Mac fresh start\n\nUpdate and install drivers.\nGoogle Chrome browsers and sign in to sync. Install also these extensions: mate translate, google dictionary, TabCloud, raindrop, last pass, AVIM, adblock, GNOME Shell integration.\nDeepL: best translator for Windows using AI.\nQTTranslate: quick and easy translate words and hear the pronunciation.\nUnikey: Vietnamese Input Method.\nLog in to online accounts (Google, Stack Overflow, Github, Dropbox,...)\ncmder: drop-down terminal &amp; install personal setting file (can be found in /config/) 👉 Check this note to set up WSL2 and Bash.\nIObit Uninstaller.\nWinRAR.\nNotion.\nGit &amp; Gitkraken/Github Desktop.\nClone repositories from Github.\nVisual Studio Code and extensions (Bracket Pair Colorizer, Docker, Markdown All in One, Markdown Shortcuts, Python, Remote Development, Auto Close Tag)\nMicrosoft Office.\nGoldenDict + dictionaries &amp; Lingoes + dictionaries.\nUninstall OneDrive.\nMicrosoft Teams + Slack + Trello.\nLockHunter: delete being used files/folders.\nQTTabBar: Tabs for Windows Explorer. After installing and opening, choose View &gt; Options &gt; tick on QTTabBar only then right click on toolbar and choose Lock the toolbar.\nMailSpring: email client.\nMail and Calendar but don't enable sync for Mail, use MailSpring instead.\nTeXLive + Texmaker.\nGoogle Backup and Sync.\nAnaconda (python and it dependencies)\nDocker Desktop.\nInternet Download Manager / Extreme Download Manager.\nMatlab.\nAffinity Designer.\nK-Lite Codec Pack: video media player.\nFoxit Reader: PDF reader.\nCustom/Disable fn function on keyboard K380 -&gt; download Logitech Options -&gt; install &amp; signin with dinhanhthimail@gmail.com -&gt; check on &quot;Use F1-F12 as standard function keys&quot;.\n\n"},"/fresh-installation-ubuntu/":{"id":"/fresh-installation-ubuntu/","title":"Fresh Ubuntu / Pop!_OS Installation","keywords":"to do list after installing ubuntu debian elementary os linux airpod bluetooth capture screen screen recorder guake xps k380 keyboard logitech pop os popos","tags":["posts","Others","Fresh Installation","Linux"],"cat":"/img/cats/others.svg","content":"The basic steps I often do every time I install a new Ubuntu system. The order of things is important.\n👉 Linux note.\n👉 Windows fresh start\n👉 Mac fresh start\n👉 Bash\n\nMost of commands are for both Ubuntu and Pop!_OS, there are some which are only for Pop!_OS.\n\n\nFor Pop!_OS: You don't need to do everything in below steps.\n\n\n\n\nDownload Ubuntu ISO. If you like a MacOS-like version, you can choose Elementary OS.\n\n\n[Pop!_OS] Download Pop!_OS (with NVIDIA)\n\n\nUsing Rufus (on Windows) or Etcher (on any system) or popsicle (usb flasher, on pop!_os) to create a bootable USB drives.\n\n\nUpdate &amp; Upgrade\nsudo apt update &amp; sudo apt upgrade\n\n\nDownload and install Google Chrome.\n\nSign in to Google Account + sync all extensions + settings.\nDisable Tab hover information: Go to chrome://flags/ and search &quot;tab hover&quot; then choose &quot;Disable&quot;.\nInstall also these extensions:\n\nmate translate, google dictionary, TabCloud, raindrop, last pass, AVIM, adblock, GNOME Shell integration.\nGoogle Aut alternative on Chrome: use this.\n\n\n\n\n\nInstall Guake Terminal (drop-down terminal supporting tabs). We install it first because we working mainly on terminal.\nsudo apt-get install guake# then add it to startup applications## load preferencesguake --restore-preferences ~/Downloads/guake_prefs\n\n\nInstall git\nsudo add-apt-repository ppa:git-core/ppasudo apt updatesudo apt install git\n\n\n[Pop!_OS] Dual boot with Windows and others Linux distro: different from Ubuntu (using groub), Pop!_OS uses systemd-boot -&gt; follow this guide.\n# 1. Open Disks# Click on \"play\" icon on the partition having \"Partition type\" is \"EFI system\"## 2. Run to check the mount point of these partitionslsblk -o NAME,FSTYPE,FSSIZE,MOUNTPOINT# output (s/t like that)# nvme0n1# ├─nvme0n1p1 vfat 176M /media/thi/ESP # &lt;- this is windows mounting point# ├─...# └─nvme0n1p9 vfat 511M /boot/efi## 3. copy to pop!_ossudo cp -r /media/thi/ESP/EFI/Microsoft /boot/efi/EFI## 4. Add timeout (wait for choosing)sudo nano /boot/efi/loader/loader.conf# add below otherstimeout 15\n\n\nMake emojis showing up\nsudo apt install fonts-noto-color-emoji\nAfter that (make browser regonize more icons), create a new file\n~/.config/fontconfig/conf.d/01-emoji.conf\nwith this content.\n\n\nClone firstly repos: scripts, dinhanhthi.com.\n\n\nChange user avatar and desktop background.\n\n\n[Ubuntu only] Auto install drivers\nsudo ubuntu-drivers autoinstall\nIn case you wanna switch between Intel (more power efficient) and NVDIA driver (more powerful)\nsudo prime-select intelsudo prime-select nvidia\n\n\n[Ubuntu only] Check the NVDIA driver and install the newest version: check in Additional Drivers. In case you wanna remove it and reinstall it later, use\nsudo apt purge nvidia-*\n\n\nInstall GNOME Tweaks from App Store.\n\n\nInstall Dash to panel extension and use this config for pop and this for ubuntu.\n\n\n[Ubuntu only] Install GNOME Shell extensions\nsudo apt install gnome-shell-extensions\nInstall also chrome extension. Go to the corresponding extension link and turn it on and install it. List of useful extensions: Start Overlay in Application View, ESC to close overview from applications list, Caffein, Alt-Tab Switcher Popup Delay Removal, Sound Input &amp; Output Device Chooser, gtile, icon-hider (on gnome taskbar), Emoji selector.\n\n\nInstall video codecs,\nsudo apt install ubuntu-restricted-extras\n\n\nLog in to online accounts: Google, Ubuntu One, StackOverflow, Notion, Trello, Facebook,...\n\n\nDownload and install an email client, I use Mailspring. Log in to email accounts and let Mailspring downloads the necessary things.\n\n\nInstall GoldenDict (app store) and dictionaries.\n\n\nPython is installed on Ubuntu system with 2 versions. By default, python prefers version 2, if you wanna use python 3, you can use python3 or add an alias\nalias python='python3' # and call python 2 as `python2`\nInstall pip\npip sudo apt install python3-pipalias pip=pip3\n\n\nVisual Studio Code and its basic extensions: Bracket Pair Colorizer, Docker, Linux Themes for VS Code, Markdown All in One, Markdown Shortcuts, Remote Development, Python, Auto Close Tags\nAlso add below settings to setting json file (Ctrl + Shift + P and search &quot;Preferences: Open Settings (JSON)&quot;, it's in ~/.config/Code/User)\n\n\nInstall Git Client as Gitkraken. Log in with Github account and clone all working repositories.\n\n\nTurn off Gnome Shell Activities Animations (click on window taskbar to toggle max/min),\ngsettings set org.gnome.desktop.interface enable-animations true # enablegsettings set org.gnome.desktop.interface enable-animations false # disable\n\n\nIBUS Bamboo, Vietnamese Input Method. Need to restart Ibus and choose Bamboo in the keyboard layout. You can use also Shift + ~ for changing the options (remove the underline, for example). Use Super + Space to change between input methods.\n\n\nGoogle Drive client for Ubuntu: OverGrive (5$ for each account). An alternative to Vgrive.\n# startup commandline for overgrivepython3 /opt/thefanclub/overgrive/overgrive\n\n\nLaTeX\nsudo apt-get install texlive-full # 5GBsudo apt-get install texmaker\n\n\nIf you install Matlab, you can install matlab-support to add matlab icon to applications. Note that, if matlab exe file is at /usr/local/MATLAB/R2017b/bin/matlab, we add the location of folder as /usr/local/MATLAB/R2017b/.\n\n\nUse super + E to open File Manager: change in Keyboard shortcut.\n\n\nDefault text editor gedit, you can use this command in terminal.\n\n\nGnome Calendar in app store.\n\n\nScreen Recorder, use Kazam (app store). If cannot recognize mic and speaker, read this solution. An alternative is SimpleScreenRecorder.\n\n\nVLC (app store). If there is a problem of displaying video (there is only sound without video), check this.\n\n\nRead SD card\nsudo apt-get install exfat-utils exfat-fuse\n\n\nIf you wanna make nautilus default again:\nxdg-mime default nautilus.desktop inode/directory application/x-gnome-saved-searchgsettings set org.gnome.desktop.background show-desktop-icons true\n\n\nIf you wanna make some web app a desktop app, use nativefier.\n\n\nBluetooth problem on Dell XPS 15 only: cannot turn on bluetooth ⇒ Try turn off and turn on again the bluetooth in BIOS setting.\n\n\nUseful shortcuts:\n\nCapture fullscreen: Ctrl+Alt+Print (photos will be saved in Pictures)\nShow desktop: set in Keyboards settings, try to find &quot;Hide all normal windows&quot;.\n\n\n\n[Only Ubuntu] Connect Airpod to Ubuntu 20.04:\n# check bluetooth service is runninghciconfig -a## open a filesudo nano /etc/bluetooth/main.conf## addControllerMode = bredr## restart bluetooth servicesudo /etc/init.d/bluetooth restart## disconnect other headphone device# press and hold backward button in the airpod case (flash light)# connect to airpod as other device via bluetooth\n\n\nLocation of .desktop files,\n~/.local/share/applications//usr/share/applications//var/lib/snapd/desktop/applications/# orlocate *.desktop # bashlocate \\*.desktop # zsh\n\n\n[Optional]Xbox controller bluetooth connection: check this.\n\n\nRemove icon from dash application\nsudo add-apt-repository ppa:caldas-lopes/ppasudo apt-get updatesudo apt-get install ezame\n\n\nRestore dconf setting:\ndconf load / &lt; dconf-settings.ini# orcat dconf-settings.ini | dconf load /\n\n\nRestore custom keyboard shortcuts,\n# loaddconf load /org/gnome/desktop/wm/keybindings/ &lt; keybindings.dconfdconf load /org/gnome/settings-daemon/plugins/media-keys/ &lt; keybindings.dconf\n\n\n[Optional] Disable touchpad automatically when plugging mouse:\nsudo add-apt-repository ppa:atareao/atareaosudo apt updatesudo apt install touchpad-indicator# then open > click on icon > preferences# > action tab > \"Disable touchpad when mouse plugged\"\n\n\nOther applicatons:\n\nSkype\nExtreme Download Manager (uninstall by running as root /opt/xdman/uninstall.sh)\nAO (MS to do for Ubuntu): snap install ao\nShotwell or gThumb (image viewer + quick editor, install on Store)\nKolourPaint (photo editor supports cut and move a selection like Paint on Windows, install from AppStore)\nCheese (camera app)\nDrawing\nStacer (optimizer system like Advanced System Care)\nYoutube Music\nAuthenticator\nalacarte (Main Menu, can be found in App Store): change/add icon in launcher.\n\n\n\nSwap function keyboards on Logitech K380, using this tool (try all keyboard hidraws if you are not sure!).\n\n\nForce Unity Dash to index all files on Home: sudo updatedb (install by sudo apt-get install mlocate)\n\n\n[Only Ubuntu] There are 2 ubuntu softwares in dash? (ref this question). &quot;Ubuntu software&quot; is pre-installed snap store (run by snap-store), the other is gnome-software.\n\n\nBackup before installing a new system.\n\nsettings in ~/.config/ or ~/.&lt;software-name&gt;\nall apps in ~/apps/ with their desktop files in ~/.local/share/applications/\n\n\n\nPop!_OS Tips:\n\nSuper + Y: toggle tiling mode.\nAdd a windows/applition exepton of tiling mode (it won't be counted)\nMake clocks + dates 2 lines -&gt; tutorial.\n\n\nInstall clock override extension.\nUsing %H:%M%n%d/%m/%Y in text to display instead of the clock (with the spaces so that they are center aligned).\n\n\n\n"},"/ssh/":{"id":"/ssh/","title":"SSH","keywords":"ssh command line remove server rsa public key private key","tags":["posts","Skills"],"cat":"/img/cats/skills.svg","content":"How it works? #\n\nLocal creates public_key (id_rsa.pub) &amp; private_key (id_rsa).\nOnly private_key can understand public_key.\nRemote sends messages encrypted based on public_key.\nLocal has to use private_key to understand (decrypt) remote's messages.\n\nGenerate a public key #\n\n\nWindows: Using below command, if it asks for a location, indicate C:\\Users\\dinha\\.ssh\\\n\n\nLinux: /home/thi/.ssh/\nssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"# without emailssh-keygen -t rsa -f ~/.ssh/id_rsa.home\n\n\nMultiple ssh keys #\n\n\nCreate key with different names, e.g. id_rsa.home, id_rsa.work.\n\n\nAdd to ~/.ssh/config,\nHost homeHostname home.example.comIdentityFile ~/.ssh/id_rsa.homeUser &lt;your home acct>#Host workHostname work.example.comIdentityFile ~/.ssh/id_rsa.workUser &lt;your work acct>\n\n\nAdd to ssh-agent (don't need to retype password again)\neval \"$(ssh-agent -s)\"ssh-add ~/.ssh/id_rsa.homessh-add ~/.ssh/id_rsa.work\n\n\nDon't forget to clone you repo with git instead of https.\n\n\nAdd public key to remote #\nSuppose that we wanna connect to a remote host username@remote.com from a local machine.\n\nOn local machine, copy public key at C:/Users/dinha/.ssh (Windows) and ~/.ssh (Linux) (something like id_rsa.pub) (copy its content).\nOn remote server (Linux), go to ~/.ssh, open file authorized_keys by vim authorized_keys\n\nBe carefull, you can modify the current keys!\nGo to the end of this file (by W)\nPress I to enter to the editing mode, press Enter for a new line.\nUsing mouse to copy/paste the key in the 1st step (on your local machine).\nNote that, each key stays in a separated line.\nESC and then type :wq to quick and save.\nTry to connect again!\n\n\n\nConnecting #\nssh remote_username@remote_hostssh remote_username@remote_host -p remote_port\n\n# CHECK VERSIONssh -V\n# DISCONNECTexit\n# COPY FILE: LOCAL -> REMOTEscp local_file user@remote-host:/var/tmp/# multiple files, using wildcat \"\\*\"\n# REMOTE -> LOCALscp user@remote:/usr/local/bin/add.sh .# multiple files, using wildcat \"\\*\"\n# pass inside the commandsudo apt-get install sshpasssshpass -p your_password ssh user@hostname\n\n# copy with sudo on remote# 1. copy to a place you have permissionsscp * thi@remote:/home/thi/tmp/# 2. move to the place you wantssh thi@remote sudo mv /home/thi/tmp/\\* /place/we/want\nCommand line parameters #\n# FOR EXAMPLEssh -C # use data compression\nUsage: Access jupyter notebooks from remote server on local machine.\nBelow are some popular commands[ref]:\n\n# check the full listman ssh\n# exit background runningsudo apt install net-toolsnetstat -lepunt# kill a process, e.g. 29231/sshkill &lt;pid> # eg. kill 29231\n\n\n\n-C: use data compression.\n-f: Requests ssh to go to background just before command execution\n-L: local port forwarding[ref].\n-N: Do not execute a remote command. This is useful for just forwarding ports\n-p &lt;port&gt;: port to connect.\n-q: quiet mode.\n-v: verbose mode.\n-X: running GUI remote app locally.\n\n\nErrors #\n# REMOTE HOST IDENTIFICATION HAS CHANGED# Offending ECDSA key in /home/thi/.ssh/known_hosts:21# SOLUTION:# Open /home/thi/.ssh/known_host and delete line 21\n"},"/wordpress-docker/":{"id":"/wordpress-docker/","title":"Wordpress Docker","keywords":"docker wordpress install a-z a to z automatically docker image docker container wamp lamp mamp all in one wordpress migration cli wp-cli backup migration locally docker","tags":["posts","Web Dev","Wordpress"],"cat":"/img/cats/web-dev.svg","content":"👉 Note: Docker 101\n👉 Note: Docker + GPUs\n👉 Note: Airflow + Kubernetes 101\n👉 Note: Tensorflow extra\nIn this note, I wanna an automatical setting up of basic things.\n👉 Install Docker by following this note.\nWP basic without backup #\nMake a folder name mysite containing,\nmysite|-- docker-compose.yml # main file|-- backup # contains backup files using AIO WP Migration plugins|-- plugins # contains plugins|-- themes # contains templates|-- wordpress # main site's sources\nIn the docker-compose.yml,\nversion: '3.1'services: wordpress: image: wordpress restart: always ports: - 8080:80 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: exampleuser WORDPRESS_DB_PASSWORD: examplepass WORDPRESS_DB_NAME: exampledb volumes: - './html/:/var/www/html/' - './plugins/:/var/www/html/wp-content/plugins/' - './themes/&lt;theme>/:/var/www/html/wp-content/themes/&lt;theme>' db: image: mysql:5.7 restart: always environment: MYSQL_DATABASE: exampledb MYSQL_USER: exampleuser MYSQL_PASSWORD: examplepass MYSQL_RANDOM_ROOT_PASSWORD: '1'\nStart the container,\ncd mysitedocker-compose up -d# check running containersdocker ps -a\nBrowse http://localhost:8080 to install wordpress by gui.\nDebug #\nIn the case you wanna see the list of users or access to the mysql environement,\n# connect to MySQL running containerdocker exec -it &lt;container_db> bash# connect to mysql databasemysql -u wordpress -p# list all usersSELECT host, user FROM mysql.user;\nInstall WP-CLI #\n# Download wp-clicurl -O https://raw.githubusercontent.com/wp-cli/builds/gh-pages/phar/wp-cli.phar# Make it executablechmod +x wp-cli.phar# Move it into /usr/local/bin/wpsudo mv wp-cli.phar /usr/local/bin/wp# Check whether the installation workedwp --info\nFor example, activate all-in-one-wp-migration (already copied / placed in folder plugins)\nwp plugin activate all-in-one-wp-migration --allow-root\nErrors &amp; warnings #\napache2: Could not reliably determine the server's fully qualified domain name\n# enter to wordpress container's bashdocker exec -it &lt;container> bash# addecho 'ServerName localhost' >> /etc/apache2/apache2.conf# restart apache/containerservice apache2 restart\n\nCould not create directory on mounted volume\n\n# enter to wordpress container's bashdocker exec -it &lt;container> bash# thenchown -R www-data:www-data /var/www\n\nYour file exceeds the maximum upload size for this site: 2 MB\n# .htaccessphp_value upload_max_filesize 400Mphp_value post_max_size 400M# php_value memory_limit 256M# php_value max_execution_time 300# php_value max_input_time 300\nReferences #\n\nNiku Hietanen -- wpcli-ai1wm.\nAll-in-One WP Migration WP CLI Integration.\nDocker Hub -- wordpress-with-wp-cli.\nDocker - Quickstart: Compose and WordPress.\nHow to get WordPress running with Docker.\n\n"},"/deeplearning-ai-course-2/":{"id":"/deeplearning-ai-course-2/","title":"DL 2 - Improving DNN: Hyperparameter tuning, Regularization and Optimization","keywords":"He initialization Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization specialization Initialization step zero initialization Random initialization break symmetry He initialization Xavier initialization Regularization L2 regularization Dropout activation Gradient checking Optimization Momentum RMSprop Adam Mini-batch gradient descent slow the training oscillated Shuffle Partition Batch Gradient Descent Stochastic Gradient Descent Exponentially weighted averages Bias correction Adaptive Moment Estimation Hyperparameter choicesLearning rate decay Problem of local optima Problem of plateau Tuning process Hyperparameter tuning Coarse to fine Panda Caviar Babysitting one model Training many models in parallel Batch Normalization Covariate shift problem test time Deep Learning Frameworks Tensorflow train test validation dev set bias variance basic recipe for ML regulaization overfitting Vanishing / Exploding gradients Weight Initialization for Deep Networks Numerical approximation of gradients Gradient checking Yoshua Bengio Yuanqing Lin Fitting Batch Norm into a neural network Batch Norm andrew ng deep learning neural networks","tags":["posts","MOOC","deeplearning.ai","Deep Learning"],"cat":"/img/cats/mooc.svg","content":"This is my note for the course (Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization). The codes in this note are rewritten to be more clear and concise.\n👉 Course 1 -- Neural Networks and Deep Learning.\n👉 Course 2 -- Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.\n👉 Course 3 -- Structuring Machine Learning Projects.\n👉 Course 4 -- Convolutional Neural Networks.\n👉 Course 5 -- Sequence Models.\nThis course will teach you the &quot;magic&quot; of getting deep learning to work well. Rather than the deep learning process being a black box, you will understand what drives performance, and be able to more systematically get good results. You will also learn TensorFlow.\nInitialization step #\nlayers_dims contains the size of each layer from 000 to LLL.\nzero initialization #\nparameters['W'+str(l)] = np.zeros((layers_dims[l], layers_dims[l-1]))parameters['b'+str(l)] = np.zeros((layers_dims[l], 1))\n\nThe performance is really bad, and the cost does not really decrease.\ninitializing all the weights to zero ⇒ failing to break symmetry ⇒ every neuron in each layer will learn the same thing ⇒ n[l]=1n^{[l]}=1n[l]=1 for every layer ⇒ no more powerful than a linear classifier such as logistic regression.\n\nRandom initialization #\nTo break symmetry, lets intialize the weights randomly.\nparameters['W'+str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * 10 # &lt;- LARGE (just an example of SHOULDN'T)parameters['b'+str(l)] = np.zeros((layers_dims[l], 1))\n\nHigh initial weights ⇒ The cost starts very high (near 0 or 1 or infinity).\nPoor initialization ⇒ vanishing/exploding gradients ⇒ slows down the optimization algorithm.\nIf you train this network longer ⇒ better results, BUT initializing with overly large random numbers ⇒ slows down the optimization.\n\nHe initialization #\nMultiply randomly initial WWW with 2n[l−1]\\sqrt{\\frac{2}{n^{[l-1]}}}n[l−1]2​​. It's similar to Xavier initialization in which multipler factor is 1n[l−1]\\sqrt{\\frac{1}{n^{[l-1]}}}n[l−1]1​​\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2./layers_dims[l-1])parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\nRegularization step #\nTo reduce the overfitting problem.\nL2 regularization #\nL2_regularization_cost = 0for l in range(1, L+1): L2_regularization_cost += 1/m * lambd/2 * (np.sum(np.square(W[l]))\n\n\nThe standard way. Modify cost function from,\nJ=−1m∑i=1m(y(i)log⁡(a[L](i))+(1−y(i))log⁡(1−a[L](i)))J = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)}\nJ=−m1​i=1∑m​(y(i)log(a[L](i))+(1−y(i))log(1−a[L](i)))\nto\nJregularized=−1m∑i=1m(y(i)log⁡(a[L](i))+(1−y(i))log⁡(1−a[L](i)))⏟cross-entropy cost+1mλ2∑l∑k∑jWk,j[l]2⏟L2 regularization costJ_{regularized} = \\small \\underbrace{-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} }_\\text{cross-entropy cost} + \\underbrace{\\frac{1}{m} \\frac{\\lambda}{2} \\sum\\limits_l\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2} }_\\text{L2 regularization cost}\nJregularized​=cross-entropy cost−m1​i=1∑m​(y(i)log(a[L](i))+(1−y(i))log(1−a[L](i)))​​+L2 regularization costm1​2λ​l∑​k∑​j∑​Wk,j[l]2​​​\n\n\nThe value of λ\\lambdaλ is a hyperparameter that you can tune using a dev set.\n\n\nL2 regularization makes your decision boundary smoother. If λ\\lambdaλ is too large, it is also possible to &quot;oversmooth&quot;, resulting in a model with high bias.\n\n\nDropout #\n# [Forward] An example at layer 3D3 = np.random.rand(A3.shape(0), A3.shape(1)) &lt; keep_dropA3 *= D3A3 /= keep_drop# [Backprop]dA3 *= D3dA3 /= keep_drop\n\nDropout is a widely used regularization technique that is specific to deep learning.\nRandomly shuts down some neurons in each iteration.\nWhen you shut some neurons down, you actually modify your model. The idea behind drop-out is that at each iteration, you train a different model that uses only a subset of your neurons.\nWith dropout, your neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time.\nDon't apply dropout to the input layer or output layer.\nUse dropout during training, not during test time.\nApply dropout both during forward and backward propagation.\n\nGradient checking #\n\n\nTo answer &quot;Give me a proof that your backpropagation is actually working!&quot;\n\n\nWe are confident on computing JJJ but ∂J∂θ\\frac{\\partial J}{\\partial\\theta}∂θ∂J​.\n\n\nUse JJJ to compute an approximation of ∂J∂θ\\frac{\\partial J}{\\partial\\theta}∂θ∂J​ and compare with ∂J∂θ\\frac{\\partial J}{\\partial\\theta}∂θ∂J​.\n∂J∂θ=lim⁡ε→0J(θ+ε)−J(θ−ε)2ε\\frac{\\partial J}{\\partial \\theta} = \\lim_{\\varepsilon \\to 0} \\frac{J(\\theta + \\varepsilon) - J(\\theta - \\varepsilon)}{2 \\varepsilon}\n∂θ∂J​=ε→0lim​2εJ(θ+ε)−J(θ−ε)​\n\n\nOptimization algorithms #\nIntuition:\n\nGradient Descent: go down the hill.\nMomentum / RMSprop / Adam: which direction?\n\nMini-batch gradient descent #\n\nProblem: NN works great on big data but many data leads to slow the training ⇒ We need to optimize!\nSolution: Divide into smaller &quot;mini-batches&quot; (for example, from 5M to 5K of 1K each).\n\nX(nX,m=5M)=[X(1),…,X(1K)⏟X(nX,1K){1},X(1K+1),…,X(2K)⏟X(nX,1K){2},…,X(m−1K+1),…,X(m)⏟X(nX,1K){5K}],Y(1,m=5M)=[y(1),…,y(1K)⏟Y(1,1K){1},y(1K+1),…,y(2K)⏟Y(1,1K){2},…,y(m−1K+1),…,y(m)⏟Y(1,1K){5K}]\\begin{aligned}\nX_{(n_X, m=5M)} &amp;= [\\underbrace{X^{(1)},\\ldots,X^{(1K)}}_{X^{\\{1\\}}_{(n_X,1K)}}, \\underbrace{X^{(1K+1)},\\ldots,X^{(2K)}}_{X^{\\{2\\}}_{(n_X,1K)}}, \\ldots, \\underbrace{X^{(m-1K+1)},\\ldots,X^{(m)}}_{X^{\\{5K\\}}_{(n_X,1K)}}], \\\\\nY_{(1, m=5M)} &amp;= [\\underbrace{y^{(1)},\\ldots,y^{(1K)}}_{Y^{\\{1\\}}_{(1,1K)}}, \\underbrace{y^{(1K+1)},\\ldots,y^{(2K)}}_{Y^{\\{2\\}}_{(1,1K)}}, \\ldots, \\underbrace{y^{(m-1K+1)},\\ldots,y^{(m)}}_{Y^{\\{5K\\}}_{(1,1K)}}]\n\\end{aligned}\nX(nX​,m=5M)​Y(1,m=5M)​​=[X(nX​,1K){1}​X(1),…,X(1K)​​,X(nX​,1K){2}​X(1K+1),…,X(2K)​​,…,X(nX​,1K){5K}​X(m−1K+1),…,X(m)​​],=[Y(1,1K){1}​y(1),…,y(1K)​​,Y(1,1K){2}​y(1K+1),…,y(2K)​​,…,Y(1,1K){5K}​y(m−1K+1),…,y(m)​​]​\n\nDifferent between mini-batch and normal batch on the cost function. It's oscillated for mini-batch because the cost may be large for this mini-batch but small for the others. Image from the course.\nNotations #\n\nX(i)X^{(i)}X(i): iiith training example.\nz[l]z^{[l]}z[l]: zzz value in lllth layer.\nX{t},Y{t}X^{\\{t\\}}, Y^{\\{t\\}}X{t},Y{t}: index of different mini-batches.\n\nAlgorithm #\nX = data_inputY = labelsparameters = initialize_parameters(layers_dims)for i in range(0, num_iterations): # loop through epoches: to get the convergence for t in range(0, num_batches): # loop through the batches # Forward propagation a, caches = forward_propagation(X[:,t], parameters) # Compute cost cost += compute_cost(a, Y[:,t]) # Backward propagation grads = backward_propagation(a, caches, parameters) # Update parameters. parameters = update_parameters(parameters, grads)\nHow to build mini-batches? #\nWe need 2 steps:\n\n\nShuffle: shuffle columns (training examples) correspondingly between XXX and YYY. The shuffling step ensures that examples will be split randomly into different mini-batches.\nPartition: choose a batch size and take mini-batches. Note that, the last batch may be smaller than the others.\n\nType of mini-batch #\nThere are 3 types based on the size of batches:\n\n\nBatch Gradient Descent (nt=mn_t = mnt​=m) : entire training examples, i.e. (X{1},Y{1})=(X,Y)(X^{\\{1\\}}, Y^{\\{1\\}}) = (X,Y)(X{1},Y{1})=(X,Y).\nStochastic Gradient Descent (nt=1n_t = 1nt​=1) : every training example is it own a mini-batch (mmm mini batches).\n1&lt;nt&lt;m1&lt;n_t&lt;m1&lt;nt​&lt;m.\n\n\nDifferent between 3 types of mini-batch. Image from the course.\nGuideline:\n\n\nIf small training set (m≤2000m \\le 2000m≤2000): using batch gradient descent.\nTypical mini-batch sizes: 64,128,256,512,…64, 128, 256, 512, \\ldots64,128,256,512,…\nMake sure mibi-batch size in CPU/GPU memory!\n\nExponentially weighted averages #\n\n\nIt's faster than Gradient Descent!\n\n\nExample (temperature in London):\n\n\nθt\\theta_tθt​: the temperature on day ttt.\n\n\nvtv_tvt​: the average temp of each day. It's called exponential average over 11−β\\frac{1}{1-\\beta}1−β1​ days temperature.\nvt=βvt−1+(1−β)θtv_t = \\beta v_{t-1} + (1-\\beta)\\theta_t\nvt​=βvt−1​+(1−β)θt​\n\n\nE.g. β=0.9⇒vt≃10\\beta=0.9 \\Rightarrow v_t \\simeq 10β=0.9⇒vt​≃10 days temperature; β=0.98⇒vt≃50\\beta=0.98 \\Rightarrow v_t \\simeq 50β=0.98⇒vt​≃50 days temperature.\n\n\n\n\nβ\\betaβ larger ⇒ smoother average line because we consider more days. However, curve is now shifted further to the right.\n\nExponentially weighted average curves: red line (β=0.9\\beta=0.9β=0.9), green line (β=0.98\\beta=0.98β=0.98). Image from the course.\n\n\nWhen β\\betaβ is so large ⇒ vtv_tvt​ adapts slowly to the changes of temperature (more latency).\n\n\nWhy we call &quot;exponentially&quot;?\nv100=0.9×v99+0.1×θ100=0.1×θ100+0.1×0.99×θ99+0.1×0.992×θ99+…\\begin{aligned}v_{100} &amp;= 0.9\\times v_{99} + 0.1\\times \\theta_{100}\\\\&amp;= 0.1\\times \\theta_{100} + 0.1\\times 0.99\\times\\theta_{99} + 0.1\\times 0.99^2 \\times\\theta_{99} + \\ldots\\end{aligned}\nv100​​=0.9×v99​+0.1×θ100​=0.1×θ100​+0.1×0.99×θ99​+0.1×0.992×θ99​+…​\n\n\nBias correction #\n\n\nProblem: the value of vtv_tvt​ at the beginning of exp ave curves may be lower than what we expect. For example, with v0=0v_0=0v0​=0, we have v1=0.02θ1v_1 = 0.02\\theta_1v1​=0.02θ1​ instead of v1=v0+0.02θ1v_1 = v_0 + 0.02\\theta_1v1​=v0​+0.02θ1​.\n\n\nSolution: Instead of using vtv_tvt​, we take\nvt1−βt\\dfrac{v_t}{1-\\beta_t}\n1−βt​vt​​\n\n\nWhen ttt is large ⇒ βt≃0⇒vt1−βt≃vt\\beta^t \\simeq 0 \\Rightarrow \\dfrac{v_t}{1-\\beta_t} \\simeq v_tβt≃0⇒1−βt​vt​​≃vt​\n\nBias correction for the green line, it's effective at the beginning of the line, with bigger ttt, green and violet are overlapped. Image from the course.\n\n\nIn practice, we don't really see people bothering with bias correction!\n\n\nGradient Descent with Momentum #\n\n\nIt's faster than Gradient Descent!\n\n\nWhy: when we use mini-batch, there are oscillation, momentum helps use reduce this.\n\n\nOne sentence: compute the exponential weighted average of your gradient ⇒ use that gradient to update your weights instead.\n\n\nIdea: Momentum takes into account the past gradients to smooth out the update. We will store the 'direction' of the previous gradients in the variable vvv . Formally, this will be the exponentially weighted average of the gradient on previous steps.\n\n\nIntuition: You can also think of vvv as the &quot;velocity&quot; of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill.\n\ndW,dbdW, dbdW,db like &quot;acceleration&quot;.\nVdW,VdbVdW, VdbVdW,Vdb like &quot;velocity&quot;.\nβ\\betaβ likes &quot;friction&quot;.\n\n\nWe want slower learning in vertial direction and faster in horizontal direction. Image from the course.\n\n\nAlgorithm: on iteration ttt:\n\nCompute dW,dbdW, dbdW,db on current mini-batch.\nVdW=βVdW+(1−β)dWVdW = \\beta VdW + (1-\\beta)dWVdW=βVdW+(1−β)dW.\nVdb=βVdb+(1−β)dbVdb = \\beta Vdb + (1-\\beta)dbVdb=βVdb+(1−β)db.\nW:=W−αVdWW:=W-\\alpha VdWW:=W−αVdW.\nb:=b−αVdbb:=b-\\alpha Vdbb:=b−αVdb.\n\n\n\nImplementation:\n\nTry to tune between [0.8;0.999][0.8; 0.999][0.8;0.999], commonly use β=0.9\\beta=0.9β=0.9.\nDon't bother bias correction, NO NEED.\nDon't need (1−β)(1-\\beta)(1−β) in the formulas but Andrew prefer to keep it!\nBigger β\\betaβ, smaller in vertical direction.\n\n\n\nRMSprop #\n\nIt's &quot;Root Mean Square propagation&quot;.\nAlgorithm: on iteration ttt,\n\nCompute dW,dbdW, dbdW,db on current element-wise mini-batch.\nSdW=βSdW+(1−β)dW2SdW = \\beta SdW + (1-\\beta)dW^2SdW=βSdW+(1−β)dW2.\nSdb=βSdb+(1−β)db2Sdb = \\beta Sdb + (1-\\beta)db^2Sdb=βSdb+(1−β)db2.\nW:=W−αdWSdW+ϵW:=W -\\alpha \\frac{dW}{\\sqrt{SdW}+\\epsilon}W:=W−αSdW​+ϵdW​.\nb:=b−αdbSdW+ϵb:=b-\\alpha \\frac{db}{\\sqrt{SdW} + \\epsilon}b:=b−αSdW​+ϵdb​.\n\n\nWe choose ϵ=10−8\\epsilon=10^{-8}ϵ=10−8 if SdW\\sqrt{SdW}SdW​ is too small, otherwise ϵ=0\\epsilon=0ϵ=0.\nIn practice: dW,dbdW, dbdW,db are very high dimensional vectors.\n\nAdam Optimization #\n\nIt's &quot;Adaptive Moment Estimation&quot;.\nOne of the most effective optimization algorithm for training NN. It's commonly used and proven to be very effective for many different NN of a very wide variety of architectures.\nAdam = Momentum + RMSprop.\nImplementation: on iteration ttt,\n\nCompute dW,dbdW, dbdW,db using current mini-batch.\n(Monentum) VdW=β1VdW+(1−β1)dWVdW = \\beta_1 VdW + (1-\\beta_1)dWVdW=β1​VdW+(1−β1​)dW; Vdb=β1Vdb+(1−β1)dbVdb = \\beta_1 Vdb+(1-\\beta_1)dbVdb=β1​Vdb+(1−β1​)db.\n(RMSprop) SdW=β2SdW+(1−β2)dW2SdW = \\beta_2 SdW + (1-\\beta_2)dW^2SdW=β2​SdW+(1−β2​)dW2; Sdb=β2Sdb+(1−β2)db2Sdb = \\beta_2Sdb +(1-\\beta_2)db^2Sdb=β2​Sdb+(1−β2​)db2.\nVdWcorrected=VdW1−β1tV_{dW}^{\\text{corrected}} = \\dfrac{VdW}{1-\\beta_1^t}VdWcorrected​=1−β1t​VdW​; Vdbcorrected=Vdb1−β1tV_{db}^{\\text{corrected}} = \\dfrac{Vdb}{1-\\beta_1^t}Vdbcorrected​=1−β1t​Vdb​.\nSdWcorrected=SdW1−β2tS_{dW}^{\\text{corrected}} = \\dfrac{SdW}{1-\\beta_2^t}SdWcorrected​=1−β2t​SdW​; Sdbcorrected=Sdb1−β2tS_{db}^{\\text{corrected}} = \\dfrac{Sdb}{1-\\beta_2^t}Sdbcorrected​=1−β2t​Sdb​.\nW:=W−αVdWcorrectedSdWcorrected+ϵW:=W-\\alpha \\dfrac{V_{dW}^{\\text{corrected}}}{\\sqrt{S_{dW}^{\\text{corrected}}} + \\epsilon}W:=W−αSdWcorrected​​+ϵVdWcorrected​​; b:=b−αVdbcorrectedSdbcorrected+ϵb:=b-\\alpha \\dfrac{V_{db}^{\\text{corrected}}}{\\sqrt{S_{db}^{\\text{corrected}}} + \\epsilon}b:=b−αSdbcorrected​​+ϵVdbcorrected​​.\n\n\nInitialization of the velocity is zero, i.e. VdW=SdW=Vdb=Sdb=0VdW=SdW=Vdb=Sdb=0VdW=SdW=Vdb=Sdb=0.\nIf β=0\\beta=0β=0, it's standard gradient descent without momentum.\nHyperparameter choices:\n\nα\\alphaα = needs to be tuned, very important!\nβ1=0.9\\beta_1 = 0.9β1​=0.9 (dWdWdW), first moment.\nβ2=0.999\\beta_2 = 0.999β2​=0.999 (dW2dW^2dW2), second mement.\nϵ=10−8\\epsilon = 10^{-8}ϵ=10−8.\n\n\n\nLearning rate decay #\n\n\nIdea: slowly reduce learning rate over time, it's learning rate decay.\n\n\nWhy? Below figure showes that, we need slower rate α\\alphaα (smaller step) at the area near the center.\n\nExample of learning rate decay. Image from the course.\n\n\nRecall that, 1 epoch = 1 pass through data.\n\n\nLearning rate decay can be chosen 1 of below,\n\n\nα=11+decay_rate×epoch_num×α0,α=0.95epoch_num×α0−exponentially_decay,α=kepoch_number×α,α=kt×α0.\\begin{aligned}\n\\alpha &amp;= \\dfrac{1}{1 + \\text{decay\\_rate} \\times \\text{epoch\\_num}} \\times \\alpha_0, \\\\\n\\alpha &amp;= 0.95^{\\text{epoch\\_num}} \\times \\alpha_0 - \\text{exponentially\\_decay}, \\\\\n\\alpha &amp;= \\dfrac{k}{\\sqrt{\\text{epoch\\_number}}} \\times \\alpha, \\\\\n\\alpha &amp;= \\dfrac{k}{\\sqrt{t}} \\times \\alpha_0.\n\\end{aligned}\nαααα​=1+decay_rate×epoch_num1​×α0​,=0.95epoch_num×α0​−exponentially_decay,=epoch_number​k​×α,=t​k​×α0​.​\nProblem of local optima #\n\nLocal optima problem: local &amp; right optima (left) and saddle point (right). Image from the course.\n\nIn high dimension, you likely see saddle points than local optimum.\nProblem of plateau: a region where derivative is close to zero for a long time.\n\nUnlikely get stuck in a bad local optimal.\nPlateau can make learning slow: use Momentum, RMSprop, Adam.\n\n\n\nBatch GD makes learning too long? #\n\nTry better random initialization for weights.\nTry mini-batch GD.\nTry using Adam\nTry tuning learning rate α\\alphaα.\n\nHyperparameter tuning #\nTuning process #\n\n\nThere are many hyperparameters but some are more important than others!\n\n\nLearning rate α\\alphaα (most important), #hiddien units, β\\betaβ, mini-batch size (2nd important), #layers, learning decay,...\n\n\nDon't use grid, use random!\n\nTuning process. Don't use grid (left), use random (right). Image from the course.\n\n\nCoarse to fine: find an area containing effective values ⇒ zoom in and take more points in that area,\n\nCoarse to fine: first try on a big square, then focus on the smaller one (blue). Image from the course.\n\n\nChoose randomly but NOT mean uniform scale! We can choose uniformly on #hidden units, #layers, but not for the others (e.g. α\\alphaα).\n\n\nFor α\\alphaα, for example, we need to divide into equal &quot;large&quot; spaces and then use uniform.\n\nAppropriate scale for hyperparameters. Image from the course.\n\n\nHyperparameters for exponentially weighted averages:\n\n\nWe cannot try with values between [0.9,0.999][0.9, 0.999][0.9,0.999] because,\n\nβ:0.9000→0.9005\\beta: 0.9000 \\to 0.9005β:0.9000→0.9005 : no much changes,\nβ:0.999→0.995\\beta: 0.999 \\to 0.995β:0.999→0.995 : huge impact!\n\n\n\nConsider 1−β∈[10−1,10−3]1-\\beta \\in [10^{-1}, 10^{-3}]1−β∈[10−1,10−3] instead!\nr∈[−3,−1]1−β=10r⇔β=1−10r\\begin{aligned}r &amp;\\in [-3, -1] \\\\1-\\beta = 10^r &amp;\\Leftrightarrow \\beta = 1-10^r\\end{aligned}\nr1−β=10r​∈[−3,−1]⇔β=1−10r​\n\n\n\n\nIn practice: Panda vs Caviar #\n\nHow to organize your hyperparameter search?\nAdvice: Re-testing/Re-evaluating your hyperparameters at least once every several months.\n2 ways:\n\nBabysitting one model (Panda): when we have huge data but weak CPU/GPU ⇒\\Rightarrow⇒ try very small number of models at a time. Check the performance step by step (cost function reduces...)\n\nIn some domains like advertising, computer vision apps,...\nWe call &quot;panda&quot; because panda has very few number of babies at a time (and in their life) ⇒\\Rightarrow⇒ try to keep them alike once at a time.\n\n\nTraining many models in parallel (Caviar): when we don't work on huge data + strong CPU/GPU. ⇒\\Rightarrow⇒ Try many models in parallel and choose the best performance!\n\nWe call &quot;Caviar&quot; because of intuition.\n\n\n\n\n\nBatch Normalization #\n\nMake NN much more robust to the choice of hyperparameters. ⇐\\Leftarrow⇐ doesn't work for all NN but if it does, make training faster!\nOne of the most important ideas in the rise of Deep Learning.\nLike we wanna normalize input to speed up learning, in this case, we wanna normalize ZZZ (in the hidden layers)\n\nGiven some initial values in NN Z[l](1),…,Z[l](m)Z^{[l](1)},\\ldots, Z^{[l](m)}Z[l](1),…,Z[l](m),\n\n\nμ=1m∑iZ[l](i)\\mu = \\dfrac{1}{m} \\sum_i Z^{[l](i)}μ=m1​∑i​Z[l](i)\nσ2=1m∑i(Z[l](i)−μ)2\\sigma^2 = \\dfrac{1}{m}\\sum_i (Z^{[l](i)} - \\mu)^2σ2=m1​∑i​(Z[l](i)−μ)2\nZnorm[l](i)=Z[l](i)−μσ2+ϵZ^{[l](i)}_{\\text{norm}} = \\dfrac{Z^{[l](i)} - \\mu}{\\sqrt{\\sigma^2} + \\epsilon}Znorm[l](i)​=σ2​+ϵZ[l](i)−μ​ to get mean μ=0\\mu=0μ=0 and STD σ=1\\sigma=1σ=1.\nZ~[l](i)=γZnorm[l](i)+β\\tilde{Z}^{[l](i)} = \\gamma Z^{[l](i)}_{\\text{norm}} + \\betaZ~[l](i)=γZnorm[l](i)​+β to have different other normal distribution.\n\nNow, γ,β\\gamma, \\betaγ,β are learnable parameters of the model.\n\n\nIf we choose different β,γ\\beta, \\gammaβ,γ ⇒\\Rightarrow⇒ hidden units have other means &amp; variances.\nInstead of using Z[l](1),…,Z[l](m)Z^{[l](1)}, \\ldots, Z^{[l](m)}Z[l](1),…,Z[l](m), we use Z~[l](i)\\tilde{Z}^{[l](i)}Z~[l](i).\nDifference between normalizing input XXX and normalizing in hidden units:\n\nXXX: after normalizing, μ=0,σ=1\\mu=0, \\sigma=1μ=0,σ=1.\nZZZ: after normalizing, various μ,σ\\mu, \\sigmaμ,σ.\n\n\n\nX→W[1],b[1]Z[1]→Batch Normβ[1],γ[1]Z~[1]→a[1]=g[1](Z~[1])→W[2],b[2]Z[2]→Batch Normβ[2],γ[2]Z~[2]→a[2]→…X \\xrightarrow[]{W^{[1]}, b^{[1]}} Z^{[1]} \\xrightarrow[\\text{Batch Norm}]{\\beta^{[1]}, \\gamma^{[1]}} \\tilde{Z}^{[1]} \\to a^{[1]} = g^{[1]}(\\tilde{Z}^{[1]}) \\xrightarrow[]{W^{[2]}, b^{[2]}} Z^{[2]} \\xrightarrow[\\text{Batch Norm}]{\\beta^{[2]}, \\gamma^{[2]}} \\tilde{Z}^{[2]} \\to a^{[2]} \\to \\ldots\nXW[1],b[1]​Z[1]β[1],γ[1]Batch Norm​Z~[1]→a[1]=g[1](Z~[1])W[2],b[2]​Z[2]β[2],γ[2]Batch Norm​Z~[2]→a[2]→…\n\n\nNote that, β\\betaβ in this case is different from β\\betaβ in Adam optimization!\n\n\nWe can use gradient descent to update β\\betaβ and even use Adam/RMSprop/Momentum to update params γ,β\\gamma, \\betaγ,β, not just for Gradient Descent.\n\n\nIn practice, we won't have to implement Batch Norm step by step by ourself, programming framework (like Tensorflow) will do!\n\n\nIn practice, Batch Norm is usually applied with mini-batch of your training set.\n\n\nParameters: W[l],β[l],γ[l]W^{[l]}, \\beta^{[l]}, \\gamma^{[l]}W[l],β[l],γ[l]. We don't need to consider b[l]b^{[l]}b[l] becase it will be subtracted out in the process of normalization!\n\n\nFitting Batch Norm into a NN: for ttt goes through the number of mini-batches,\n\nCompute forward prop on X{t}X^{\\{t\\}}X{t}.\nIn each hidden layer, use Batch Norm to reparameter Z[l]Z^{[l]}Z[l] to Z~[l]\\tilde{Z}^{[l]}Z~[l].\nUse backprop to compute dW[l],dβ[l],dγ[l]dW^{[l]}, d\\beta^{[l]}, d\\gamma^{[l]}dW[l],dβ[l],dγ[l].\nUpdate params (we can use Momentum / RMSprop / Adam):\n\nW[l]:=W[l]−αdW[l],β[l]:=β[l]−αdβ[l],γ[l]:=γ[l]−αdγ[l].\\begin{aligned}W^{[l]} &amp;:= W^{[l]} - \\alpha dW^{[l]}, \\\\\\beta^{[l]} &amp;:= \\beta^{[l]} - \\alpha d\\beta^{[l]}, \\\\\\gamma^{[l]} &amp;:= \\gamma^{[l]} - \\alpha d\\gamma^{[l]}.\\end{aligned}\nW[l]β[l]γ[l]​:=W[l]−αdW[l],:=β[l]−αdβ[l],:=γ[l]−αdγ[l].​\n\n\nSometimes, BN has a 2nd effect as a regularization technique but it's unintended! We don't use it for the purpose of regularization, use L1, L2 or dropout instead.\n\n\n(Recall) Regularization: techniques that lower the complexity of a NN during training, thus prevent the overfitting.\nWhy BN works? #\n\nMake weights in later / deeper layers be more robust to changing to the weights in the earlier layers.\nCovariate shift problem: suppose we have X→YX \\to YX→Y. If XXX's distribution changes, it changes the result in YYY much. We have to re-train our model.\n\nExample: &quot;cat vs non-cat&quot; problem. If we apply params from the model of &quot;black cat vs non-cat&quot; to the problem of &quot;colored-cat vs non-cat&quot;, it won't work because distribution in &quot;black cat&quot; is different from &quot;colored cat&quot;.\n\n\n\n\nCovariate problem. Image from the course.\n\nWhy BN works?. Image from the course.\nIn the perspective of layer 3, it depends only on layer 2 ⇒\\Rightarrow⇒ If layers before layer 2 changes ⇒\\Rightarrow⇒ distribution of layer 2 changes ⇒\\Rightarrow⇒ covariate shift problem for layer 3 ⇒\\Rightarrow⇒ Batch Norm makes sure that mean and variance in layer 2 is always robust before going to layer 3!\nBatch Norm in test time #\n\nBN processes our data one min-batch at a time. However, in test time, you need to process the examples at a time. ⇒\\Rightarrow⇒ Need to adapt your network to do that.\nIdea: calculate μ,σ2\\mu, \\sigma^2μ,σ2 using exponentially weighted average (across mini-batches). Other words,\n\nIn the training time, we calculate (and store) also the μ{t}[l],σ{t}[l]\\mu^{\\{t\\}[l]}, \\sigma^{\\{t\\}[l]}μ{t}[l],σ{t}[l] in each mini-batch.\nFind μ,σ2\\mu, \\sigma^2μ,σ2 (exponentially weighted average) of all mini-batches.\nUse this μ,σ2\\mu, \\sigma^2μ,σ2 to find ZnormZ_{\\text{norm}}Znorm​ and Z~\\tilde{Z}Z~ (at each example iii).\n\n\nDon't worry, it's easy to use with Deep Learning Frameworks.\n\nTensorflow introduction #\nWriting and running programs in TensorFlow has the following steps:\n\n\nCreate Tensors (variables) that are not yet executed/evaluated.\nWrite operations between those Tensors.\nInitialize your Tensors.\nCreate a Session.\nRun the Session. This will run the operations you'd written above.\n\n# create placeholdersx = tf.placeholder(tf.int64, name = 'x')X = tf.placeholder(tf.float32, [n_x, None], name=\"X\")# initializeW1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\nThere are two typical ways to create and use sessions in tensorflow:\n\nMethod 1:\n\nsess = tf.Session()# Run the variables initialization (if needed), run the operationsresult = sess.run(..., feed_dict = {...})sess.close() # Close the session\n\nMethod 2:\n\nwith tf.Session() as sess: # run the variables initialization (if needed), run the operations result = sess.run(..., feed_dict = {...}) # This takes care of closing the session for you :)\nWhat you should remember:\n\n\nTensorflow is a programming framework used in deep learning\nThe two main object classes in tensorflow are Tensors and Operators.\nWhen you code in tensorflow you have to take the following steps:\n\nCreate a graph containing Tensors (Variables, Placeholders ...) and Operations (tf.matmul, tf.add, ...)\nCreate a session\nInitialize the session\nRun the session to execute the graph\n\n\nYou can execute the graph multiple times as you've seen in model()\nThe backpropagation and optimization is automatically done when running the session on the &quot;optimizer&quot; object.\n\n👉 Check more details about the codes in the notebook.\n👉 Course 3 -- Structuring Machine Learning Projects.\n"},"/sphinx-restructuredtext/":{"id":"/sphinx-restructuredtext/","title":"Sphinx & reStructuredText & docstring","keywords":"documentation sphinx napoleon google style numpy style ReadTheDocs rst reStructuredText autodoc class theme docstrings docstring __doc__ help sphinx numpydoc formats","tags":["posts","Python"],"cat":"/img/cats/python.svg","content":"Install #\n# install python firstpip install sphinxpip install sphinx-autobuildpip install sphinx_rtd_themepip install sphinxcontrib-napoleon # theme\nFolder structure #\n|-- project |-- custom_lib # python package |-- custom_lib-doc |-- source |-- conf.py\n# conf.pyimport os, sysimport sphinx_rtd_themeimport sphinxcontribpath_custom_lib = os.path.abspath('../../')sys.path.append(path_custom_lib)project = 'My notes'copyright = '2020, Math2IT'author = 'Anh-Thi DINH'release = '0.2'extensions = [ 'sphinxcontrib.napoleon', 'sphinx_rtd_theme', 'sphinx.ext.mathjax']napoleon_include_init_with_doc = Truenapoleon_google_docstring = Truenapoleon_use_param = Truenapoleon_use_ivar = Truehtml_theme = 'sphinx_rtd_theme'html_theme_options = { 'display_version': True, 'prev_next_buttons_location': 'both', 'style_external_links': True, 'style_nav_header_background': '#F5A603', 'sticky_navigation': True, 'navigation_depth': 4,}\nBuild #\n# folder structure|-- project |-- custom_lib |-- custom_lib-doc |-- source |-- conf.py\n\n# buildsphinx-build source build\n# auto build + watch the changesphinx-autobuild source _local -p 8555# http://127.0.0.1:8555/\n\nFormat #\nHeadings #\nH1 heading==========H2 heading----------H3 heading..........H4 heading~~~~~~~~~~\nLink #\nCross url (in the same document)[ref]\n\n# place to ref:ref:`custum text&lt;CSVLoader>`.# Display \"CSV\":ref:`CSVLoader`\n# somewhere.. _CSVLoader:CSV===\n\n# if heading inside the same file as the callerCall to `Name of heading`_Name of heading===============\nExternal urls:\n\nExternal hyperlinks, like Python_... _Python: http://www.python.org/# or inline`Python &lt;http://www.python.org/>`_.\nExternal hyperlinks, like `About Python`_... _About Python: http://www.python.org/\n\nTo a class, method,... in the python library (this question -&gt; ref),\n:py:meth:`mymodule.MyClass.mymethod`# or even shorter (if python is default):meth:`mymodule.MyClass.mymethod`# custom text:py:meth:`custom text&lt;mymodule.MyClass.mymethod>`\n\n:class:: for classes.\n\nAlert boxes #\n\n# note.. note:: First paragraph. Second paragraph.\n# warning.. warning:: Content of the warning.\n\nInsert images #\n\n# block.. image:: images/ball1.gif\n# inlineThe |biohazard| symbol... |biohazard| image:: biohazard.png\n\nInsrt code #\n\n# without syntax highlight:: def abc(): pass\n# with syntax highlight.. code-block:: python def abc(): pass\n\nAutodoc from python library #\n👉 Main ref.\n\n# folder structure|-- project |-- custom_lib |-- custom_lib-doc |-- source |-- conf.py\n# conf.pyimport osimport syspath_custom_lib = os.path.abspath('../../')sys.path.append(path_custom_lib)\n# all classes in classes.py.. automodule:: custom_lib.folder.classes :members:# in case `fit`, `predict` didn't show.. automodule:: custom_lib.folder.classes :members: :undoc-members:\n# a specific class in classes.py.. autoclass:: custom_lib.folder.classes.ClassA :members:\n\nProblem of &quot;Attributes&quot; #\n\nWhen we use &quot;Attributes&quot; in docstring, the sphinx (sphinx_rtd_theme template) will render it as &quot;Variables&quot; if we indicate napoleon_use_ivar = True in the config. (check this issue)\nList of supported section headers in docstring.\nRead this blog as an option. It works for Google Docstring, not numpy docstring yet!\n\nProblem with decorator #\nSphinx doesn't render docstring for classes coming with decorator, i.e. @something (before def). We can't use only :members:.\n\nfrom functools import wrapsdef my_decorator(f): @wraps(f) def wrapper(*args, **kwds): \"\"\"Doc from wrapper\"\"\" print('Calling decorated function') return f(*args, **kwds) return wrapper\n@my_decoratordef example(): \"\"\"Docstring\"\"\" print('Called example function')\n\n\nexample.__doc__ # with @wraps(f)example.__doc__ # without @wraps(f)\n'Docstring''Doc from wrapper'\n\nDocstring #\nWhat? #\nIf you wanna make a docstring (showing the information of a function when using help(&lt;func&gt;) or func.__doc__).\n\ndef reverse(text): \"\"\"Reverse a text. Input the text. Return text reversed. \"\"\" return text[::-1]help(reverse)\nHelp on function reverse in module __main__:\n\nreverse(text)\n Reverse a text.\n Input the text.\n Return text reversed.\n\n\n\nreverse.__doc__print(reverse.__doc__)\n'Reverse a text.\\n Input the text.\\n Return text reversed.\\n '\n\nReverse a text.\n Input the text.\n Return text reversed.\n\n\nNumpy Style #\n👉 Official docs.\n👉 Example of numpy docstring with sphinx.\nAn overview example,\n\ndef ex_class(var1, var2): \"\"\" Quick description. Longer description with `keywords`. Parameters ---------- var1 : int Desc for var1. var2 : {0 or 'index', 1 or 'columns'}, default 0 Long desc for var2. It may take a long line and we can break this like that. Returns ------- Resampler object See Also -------- groupby : Group by mapping, function, label, or list of labels. Series.resample : Resample a Series. Notes ----- See the `user guide &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`_ for more. Examples -------- Start by creating a series with 9 one minute timestamps. >>> index = 1 +1 2 Description for this example. \"\"\" # some commands return return_values\nQuick description.\nLonger description with `keywords`.\n\nParameters\n----------\nvar1 : int\n Desc for var1.\nvar2 : {0 or 'index', 1 or 'columns'}, default 0\n Long desc for var2. It may take a long line and we can break\n this like that.\n\nReturns\n-------\nResampler object\n\nSee Also\n--------\ngroupby : Group by mapping, function, label, or list of labels.\nSeries.resample : Resample a Series.\n\nNotes\n-----\nSee the `user guide\n&lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling&gt;`_\nfor more.\n\nExamples\n--------\nStart by creating a series with 9 one minute timestamps.\n&gt;&gt;&gt; index = 1 +1\n2\nDescription for this example.\n\n\nMath equations,\n\n# inline equation\"\"\".. math:: \\\\drac{1}{2}\"\"\"\n# break very long equation\"\"\".. math:: x_{\\\\text{min}} + \\\\dfrac{1} {2} # for a very long equation\"\"\"\n# aligned\"\"\".. math:: x+y &amp;= z 1+2 &amp;= 3\"\"\"\n# cases\"\"\".. math:: f(x) = \\smash{ \\\\begin{cases} 0, &amp;\\\\text{ if } x &lt; 40, \\\\\\\\ 1, &amp; \\\\text{ if } 40 \\leq x &lt;60, \\\\\\\\ \\\\end{cases} }\"\"\"\n\n# Methof, url.\"\"\"Instantiate the class.Parameters----------lst_comparison_type: str, default \"wasserstein\" Type of comparison. The supported types are in `dict_tests` which contains: - \"pearsonr\": `Pearson correlation coefficient &lt;https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html>`_. - \"wasserstein\": Wasserstein distance (earth mover's distance). It measures the distance between 2 distributions. Check :meth:`popai.distribution_wasserstein_score`.\"\"\"\n# long line url\"\"\"- \"pearsonr\": `Pearson correlation coefficient &lt;https://docs.scipy.org/doc/scipy/reference/\\generated/scipy.stats.pearsonr.html>`_.\"\"\"\n\n# single returns\"\"\"Returns-------tuple (float, dict) Description.\"\"\"\n# return a tuple\"\"\"Returns-------reject : ndarray, boolean Description.pvals_corrected : ndarray p-Description.\"\"\"\n# break lines in itemize\"\"\"Returns-------info: dict Description. - Item 1. - Item 2 very long lines can be broken here.\"\"\"\n\nGoogle Style Python Docstring #\n👉 Example Google Style Python Docstrings — napoleon 0.7 documentation\n👉 styleguide | Style guides for Google-originated open-source projects\n# function\"\"\"Args: param1 (int): The first parameter. param2 (str): The second parameter.Returns: bool: The return value. True for success, False otherwise.\"\"\"\nErrors #\nProblems with VSCode which cannot run the preview:\n\nSelect and activate an environment, Ctrl + Shift + P then choose Python: Select Interpreter then choose the right version of python you wanna run the docs on.\nMake sure the conda is already in $PATH + update the bashrc or zshrc (try conda --version).\nMake sure the right environement is activate in VSCode + all necessary libs are already istalled!\n\nReferences #\n\nRest and Sphinx Memo.\ndocutils -- Quick ref to rst format.\nThomas Cokelaer -- Sphinx and RST syntax guide\nSam Nicholls -- An idiot’s guide to Python documentation with Sphinx and ReadTheDocs\nsphinx-doc -- Include documentation from docstrings\nSphinx configuration.\n\n"},"/terminal/":{"id":"/terminal/","title":"Terminals","keywords":"bash terminal cmd cmder command line commandline powershell window terminal zsh guake terminal linux ubuntu mac os osx","tags":["posts","Skills","Linux"],"cat":"/img/cats/skills.svg","content":"A collection of console terminals in serveral operation systems. For bash command lines, check this note.\n👉 Bash Command Lines.\nWindows #\nI use Windows Terminal: my setting file, read this tut for more.\n# where windows terminal setting file locates?C/Users/dinha/AppData/Local/Packages/Microsoft.WindowsTerminal_8wekyb3d8bbwe/LocalState/settings.json\nDracular theme? Follow this tut.\nDrop-down (quake style) whenever Ctrl + ~? Using this app + this setting file. Don't forget to put it in a fixed location and make it starting with your windows\nOld optionscmder (drop-down): my setting files.\n\nLinux #\nGuake terminal #\n\n\nDownload guake terminal\n\n\nInstall Zsh, follow this note.\n\n\nSave/Restore settings:\n# save settingsguake --save-preferences ~/Downloads/guake_prefs# load settingsguake --restore-preferences ~/Downloads/guake_prefs\n\n\nMacOS #\nUsing iTerms2. Download its settings. Below is the guide of making iTerms2 working like Guake.\n\n\nPreferences &gt; Tab Keys &gt; Hotkey &gt; tick on Show/ hide all windows with a system-wide hotkey &gt; choose key combination (Cmd + ~).\nPreferences &gt; Profiles &gt; Default &gt; tab Windows &gt; set Style to Full-Width Top of Screen and Screen to Screen with Cursor.\nPreferences &gt; Appearance &gt; check Exclude from Dock and ⌘-Tab Switcher\nRun on startup: System Preferences &gt; Users and Groups &gt; Login Items &gt; [+] &gt; choose iTerm.\n\nZsh #\n# CLI tools for Xcodexcode-select -rxcode-select —-install# install hombrew/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\nZsh (Linux) #\n👉 Check WSL2 + Windows + Windows Terminal\nInstall Zsh + oh-my-zsh #\n\n# check is installedzsh --version\n# install (linux)sudo apt install zsh# install (macos - integrated)\n# make zsh default bashchsh -s $(which zsh) # log out &amp; log in\n# checkecho $SHELL # /bin/zsh or similar\n\n# install oh-my-zshsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\nPlugins #\n# PLUGINS# zsh-autosuggestionsgit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions# zsh-syntax-highlightinggit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\nAfter installing plugins, put them in ~/.zshrc,\nplugins=(git docker docker-compose zsh-syntax-highlighting dnf npm)# for me# plugins=(git docker docker-compose npm ruby python emoji)\nspaceship-prompt theme #\nThis is my choice. Source code.\n# need to install oh-my-zsh firstgit clone https://github.com/denysdovhan/spaceship-prompt.git \"$ZSH_CUSTOM/themes/spaceship-prompt\"ln -s \"$ZSH_CUSTOM/themes/spaceship-prompt/spaceship.zsh-theme\" \"$ZSH_CUSTOM/themes/spaceship.zsh-theme\"\nSet ZSH_THEME=&quot;spaceship&quot; in your .zshrc.\npowerlevel10k (I don't use it)# theme powerlevel10kgit clone https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/themes/powerlevel10k# after installingp10k configure\n\nFonts #\nInstall font Source Code Pro:\nShow the code\n\nFollow instruction here. If some folders don't exist, create them!\nwget https://github.com/powerline/powerline/raw/develop/font/PowerlineSymbols.otfwget https://github.com/powerline/powerline/raw/develop/font/10-powerline-symbols.confmv PowerlineSymbols.otf ~/.local/share/fonts/fc-cache -vf ~/.local/share/fonts/mv 10-powerline-symbols.conf ~/.config/fontconfig/conf.d/\n\n\nDownload Source Code Pro and move all downloaded otf fonts to\nmv SourceCode-* ~/.local/share/fonts/\n\n\n\nPowerline font,\nsudo apt-get install fonts-powerline\n\nIn terminal, choose the corresponding installed fonts.\nAdd alias to ~/.zshrc (search &quot;alias&quot; to find the place to put).\n"},"/deeplearning-ai-course-3/":{"id":"/deeplearning-ai-course-3/","title":"DL 3 - Structuring ML Projects","keywords":"machine learning strategy ML orthogonalization single number evaluation metric Satisficing and Optimizing metric train test dev set human level performance avoidable bias surpassing improve your model performance Andrej Karpathy carrying out error analysis cleaning up incorrectly labeled data build your first system quickly then iterate training and testng on different distributions bias variance with mismatched data distribution addressing data mismatch transfer learning multi task learning end to end deep learning Ruslan Salakhutdinov andrew ng the quick brown fox jumps over the lazy dog A-Z shortest sentence speech recognition","tags":["posts","MOOC","deeplearning.ai","Deep Learning"],"cat":"/img/cats/mooc.svg","content":"This is my note for the course (Structuring Machine Learning Projects). The codes in this note are rewritten to be more clear and concise.\n👉 Course 1 -- Neural Networks and Deep Learning.\n👉 Course 2 -- Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.\n👉 Course 3 -- Structuring Machine Learning Projects.\n👉 Course 4 -- Convolutional Neural Networks.\n👉 Course 5 -- Sequence Models.\n⭐ Case study (should read): Bird recognition in the city of Peacetopia.\n⭐ Case study (should read): Autonomous driving (I copied it from this).\nThis course will give you some strategies to help analyze your problem to go in a direction that will help you get better results.\nIntroduction to ML Strategy #\nWhy ML strategy? #\n\n\n&quot;ML strategy&quot; = How to structure your ML project?\n\n\nIdeas to improve your ML systems:\n\n\nCollect more data.\nCollect more diverse training set.\nTrain algorithm longer with gradient descent.\nTry different optimization algorithm (e.g. Adam).\nTry bigger network.\nTry smaller network.\nTry dropout.\nAdd L2 regularization.\nChange network architecture (activation functions, # of hidden units, etc.)\n\n\n\n\nHowever, don't spend too much time to do one of above things, we need to go right direction!\n\n\nOrthogonalization #\n\nIn orthogonalization, you have some controls, but each control does a specific task and doesn't affect other controls.\nChain of assumptions in ML:\n\nYou'll have to fit training set well on cost function (near human level performance if possible).\n\n\nIf it's not achieved you could try bigger network, another optimization algorithm (like Adam)...\n\n\nFit dev set well on cost function.\n\n\nIf its not achieved you could try regularization, bigger training set...\n\n\nFit test set well on cost function.\n\n\nIf its not achieved you could try bigger dev. set...\n\n\nPerforms well in real world.\n\n\nIf its not achieved you could try change dev. set, change cost function...\n\n\n\nSetting up your goal #\nSingle number evaluation metric #\n\nAdvice : It's better and faster to set a single number evaluation metric for your project before you start it.\nExample: instead of using both precision and recall, just use f1. Check this note.\nDev set + single row number evaluation metric ⇒\\Rightarrow⇒ enough to make a choice!\n\nSatisfying and Optimizing metric #\n\nIt's difficult to set all parameters to a single row number evaluation metric ⇒\\Rightarrow⇒ set up (many) satisfying + (one) optimizing matrix.\n\nSatisfying (use threshold): satisfying this is enough.\nOptimizing: more important, it's accuracy!\n\n\nExample: call &quot;Hi Siri&quot;,\n\nAccuracy: is it awoken? ⇐\\Leftarrow⇐ optimizing\nFalse positive: it's awoken but we don't call it! ⇐\\Leftarrow⇐ set the satisfying as less then 1 false positive per day!\n\n\n\nTrain/dev/test distributions #\n\nThe way we set the distribution of train / dev / test sets can impact much on the running time.\nDev set = developement set / hold out cross validation set.\nAdvice: Make dev set and test set come from the same distribution!\n\nSize of the dev and test sets #\n\nOld (less data, &lt;100000): 70% train - 30% test or something like that.\nNow (big data): 98% - 1% - 1%.\nTest set: set your test set to be big enough to give high confiance in the overall performance of your system.\n\nWhen to change dev/test sets and metrics #\n\nSometimes, we put our target a wrong place ⇒\\Rightarrow⇒ should change metric!\nExample: cat classification,\n\n\nAlgo A: 3% error but contains porn ⇐\\Leftarrow⇐ train / test error like this!\nErr (old metric)=1mdev∑i=1mdevL{ypred(i)≠y(i)}\\text{Err (old metric)} = \\dfrac{1}{m_{\\text{dev}}} \\sum_{i=1}^{m_{\\text{dev}}} \\mathcal{L} \\{ y^{(i)}_{\\text{pred}} \\ne y^{(i)} \\}\nErr (old metric)=mdev​1​i=1∑mdev​​L{ypred(i)​=y(i)}\n\n\nAlgo B: 5% error but no porn ⇐\\Leftarrow⇐ human like this!\nErr (adapted metric)=1ΣiW(i)∑i=1mdevW(i)L{ypred(i)≠y(i)}W(i)={1 if X(i) contains non-porn,10 if X(i) contains porn.\\begin{aligned}\\text{Err (adapted metric)} &amp;= \\dfrac{1}{\\Sigma_i W^{(i)}} \\sum_{i=1}^{m_{\\text{dev}}} W^{(i)} \\mathcal{L} \\{ y^{(i)}_{\\text{pred}} \\ne y^{(i)} \\} \\\\\nW^{(i)} &amp;= \\begin{cases}1 \\text{ if } X^{(i)} \\text{ contains non-porn}, \\\\10 \\text{ if } X^{(i)} \\text{ contains porn}.\\end{cases}\\end{aligned}Err (adapted metric)W(i)​=Σi​W(i)1​i=1∑mdev​​W(i)L{ypred(i)​=y(i)}={1 if X(i) contains non-porn,10 if X(i) contains porn.​​\n\n\n\nThis is actually an example of an orthogonalization where you should take a machine learning problem and break it into distinct steps:\n\nFigure out how to define a metric that captures what you want to do (place the target).\nWorry about how to actually do well on this metric (how to aim/shoot accurately at the target).\n\n\nConclusion: if doing well on your metric + dev/test set doesn't correspond to doing well in your application, change your metric and/or dev/test set.\n\nComparing to human-level performance #\nWhy human-level performance? #\n\nReasons:\n\nML algos are now work better &amp; easier (than the past) ⇒\\Rightarrow⇒ only them is not enough ⇒\\Rightarrow⇒ need human-level performance (HLP).\nWorkflow of building ML system ⇒\\Rightarrow⇒ wanna more efficient? ⇒\\Rightarrow⇒ try to do something that human can also do.\n\n\nBayes error = best possible error (theory).\nAfter surpassing HLP, it's slow down, why?\n\nHLP is very closed to Bayes optimal error. Ex: we can recognize things in blur.\nWhenever under HLP, there are certain tools to use to improve the performance but there is no tool to do after surpassing HLP.\n\n\nSo long as ML is worse than HLP, you can:\n\nGet labeled data from human.\nGain insight from manual error analysis: why did a person get this right?\nBetter analysis of bias / variance.\n\n\n\nAvoidable bias #\n\n\nSometimes we don't want algo works TOO WELL on the training set ⇒\\Rightarrow⇒ use HLP.\n\n\nExample: cat recognition gives 2 different results (but the same gap between train &amp; test)\n\nBig gap between train and human. ⇒\\Rightarrow⇒ focus on reducing bias (bigger NN, run training longer,...) ⇐\\Leftarrow⇐ Underfitting!\n\n\n\n\nHumans\n1%\n1%\n\n\n\n\nTraining error\n8%\n8%\n\n\nDev Error\n10%\n10%\n\n\n\n\nSmall gap between train and human. ⇒\\Rightarrow⇒ focus on reducing variance ⇐\\Leftarrow⇐ Overfitting!\n\n\n\n\nHumans\n1%\n7.5%\n\n\n\n\nTraining error\n8%\n8%\n\n\nDev Error\n10%\n10%\n\n\n\n\n\nBased on the human error ⇒\\Rightarrow⇒ decide whether high/low error ⇒\\Rightarrow⇒ bias / variance reduction!\n\n\nGap between human &amp; training ⇒\\Rightarrow⇒ Avoidable bias.\n\n\nGap between training &amp; test ⇒\\Rightarrow⇒ Variance!\n\n\nUnderstanding human-level performance #\n\nUse the nearest value to Bayes error as a human level error! (the smallest)\nThe way we choose HL error sometimes can impact the way we improve our algo (bias or variance reduction)\nUse human level error as a proxy of Bayes error!\n\nSurpassing human-level performance #\n\nWhen training error less than human error, it's difficile to decide what's avoidable bias!\nIn some problems, deep learning has surpassed human-level performance. Example: Online advertising, Product recommendation, Loan approval. ⇐\\Leftarrow⇐ Structured data.\nIn natural perception tasks (speech recognition, NLP,...): ML surpasses human!\nIn short:\n\nMachine &gt; human ⇐\\Leftarrow⇐ structured data.\nMachine &gt; One person ⇐\\Leftarrow⇐ some natural perception tasks.\nMachine &gt; human ⇐\\Leftarrow⇐ natural perception tasks.\n\n\n\nImproving your model performance #\n\nThe two fundamental asssumptions of supervised learning:\n\nYou can fit the training set pretty well. This is roughly saying that you can achieve low avoidable bias.\nThe training set performance generalizes pretty well to the dev/test set. This is roughly saying that variance is not too bad.\n\n\nTo improve your deep learning supervised system follow these guidelines:\n\nLook at the difference between human level error and the training error - avoidable bias.\nLook at the difference between the dev/test set and training set error - Variance.\nIf avoidable bias is large you have these options:\n\nTrain bigger model.\nTrain longer/better optimization algorithm (like Momentum, RMSprop, Adam).\nFind better NN architecture/hyperparameters search.\n\n\nIf variance is large you have these options:\n\nGet more training data.\nRegularization (L2, Dropout, data augmentation).\nFind better NN architecture/hyperparameters search.\n\n\n\n\n\nError Analysis #\nCarrying out error analysis #\n\n\nError Analysis = manually examining mistakes that your algorithm is making can give you insight what to do next.\n\n\nExample: in cat recognition, there are some factors affecting ⇒\\Rightarrow⇒ Consider a table ERROR ANALYSIS ⇒\\Rightarrow⇒ Evaluate multiple ideas in parallel,\n\n\n\nImage\nDog\nGreat Cats\nblurry\nInstagram filters\nComments\n\n\n\n\n1\n✓\n\n\n✓\nPitbull\n\n\n2\n✓\n\n✓\n✓\n\n\n\n3\n\n\n\n\nRainy day at zoo\n\n\n4\n\n✓\n\n\n\n\n\n....\n\n\n\n\n\n\n\n% totals\n8%\n43%\n61%\n12%\n\n\n\n\nWe focus on Great Cats and blurry (have much influence).\n\n\nTo carry out error analysis ⇒\\Rightarrow⇒ you should find a set of mislabeled examples in dev set ⇒\\Rightarrow⇒ look at mislabeled: False Positive or False Negative (number of errors) ⇒\\Rightarrow⇒ decide if to create a new category?\n\n\nCleaning up incorrectly labaled data #\n\nIn training: DL algo is robust to random errors ⇒\\Rightarrow⇒ we can ignore them!\n\nHowever, DL algo is LESS robust to systematic errors.\n\n\nSolutions: Using table Error Analysis to decide what types of error to focus in the next step (base of their fraction of errors in the total of errors).\n(Recall) The purpose of dev set is to help you select between 2 classifier A and B.\nIf you decide to fix labels:\n\nApply the same process to dev and test sets and make sure they come from the same distribution!\nExamine also on examples got right (not only on the ones got wrong) ⇒\\Rightarrow⇒ otherwise, we have overfitting problem!\nTrain vs dev/test may have different distribution ⇒\\Rightarrow⇒ No need to be corrected mislabeled on training set!\n\n\n\nWhen starting a new project? #\nAdvice: Build your first system quickly and then iterate!!\n\n\nQuickly set up dev/test sets + metric.\nBuild initial system quickly.\nCheck bias analysis and Error analysis ⇒\\Rightarrow⇒ Priopritize the next step!\n\nMismatched training and dev/test set #\nTraining &amp; testing on different distribution #\n\nExample: training (photos from internet, 200K), dev &amp; test (photos from phone, 4K).\nShouldn't: Shufflt all 204K and split into train/dev/test!\nShould:\n\nTrain - 200K (web) + 2K (mobile).\nDev = Test = 0.5K (mobile).\n\n\n\nBias and Variance with mismatched data dist #\n\n\nSometimes, dev err &gt; training err ⇒\\Rightarrow⇒ (possibly) the data in dev is more difficult to predict than the data in training.\n\n\nWhen comming from training err to dev err:\n\nThe algo saw data in training set but not in dev set.\nThe distribution of data in dev set is different!\n\n\n\nIDEA: create a new &quot;train-dev&quot; set which has the same distribution as training data but not used for training.\n\n\nKeys to be considered: Human error, Train error, Train-dev error, Dev error, Test error:\n\nAvoidable bias = train - human.\nVariance problem = train-dev - train\nData mismatch = dev - train-dev\nOverfitting to dev set = test - dev\n\n\n\nIf there is a huge gap between dev &amp; test err ⇒\\Rightarrow⇒ overtune to the dev set ⇒\\Rightarrow⇒ may need to find a bigger dev set!\n\n\nExample 1: A high variance problem! (train/train-dev →\\to→ big, train-dev/dev →\\to→ small)\n\nHuman error: 0%\nTrain error: 1%\nTrain-dev error: 9%\nDev error: 10%\n\n\n\nExample 2: data mismatch problem (train/train-dev →\\to→ small, train-dev/dev →\\to→ big)\n\nHuman error: 0%\nTrain error: 1%\nTrain-dev error: 1.5%\nDev error: 10%\n\n\n\nExample 3: avoidable bias problem (because training err is much worse than human level, others are small)\n\nHuman error: 0%\nTrain error: 10%\nTrain-dev error: 11%\nDev error: 12%\n\n\n\nExample 4: Avoidable bias problem and mismatch problem. (human/train →\\to→ big, train-dev/dev →\\to→ big)\n\nHuman error: 0%\nTrain error: 1%\nTrain-dev error: 1.5%\nDev error: 10%\n\n\n\nRemark: most of the time, the errs are decreasing from human to test. However if (sometimes) dev &gt; train-dev, we rewrite all above errors in to a new table like this,\n\nError table. Image from the course.\nWe find by hand 2 6% errors to consider the quality of dev/test err. In the figure, your figure is infact GOOD!\n\n\nAddressing data mismatch #\n\nAddressing data mismatch (don't garantee it will work but you can try):\n\nCarry out manually error analysis ⇒\\Rightarrow⇒ try to understand difference between training and dev/test errors.\nMake the training data more similar or collect more data similar to dev/test set.\n\n\nArtificial data synthesis:\n\n&quot;the quick brown fox jumps over the lazy dog&quot; ⇐\\Leftarrow⇐ shortest sentence contains all A-Z letters in English.\nCreate manually data (combine 2 different types of data). However, BE CAREFUL if one of 2 data is much smaller to the other. It may be overfitting to the smaller!\n\n\n\nLearning from multiple tasks #\nTransfer learning #\n\n\nIDEA: already trained on 1 task (Task A) + don't have enough data on the current task (Task B) ⇒\\Rightarrow⇒ we can apply the trained network on the current one.\n\nTransfer learning. Image from the course.\n\n\nTo do transfer learning, delete the last layer of NN and it's weights and:\n\nOption 1: if you have a small data set - keep all the other weights as a fixed weights. Add a new last layer(-s) and initialize the new layer weights and feed the new data to the NN and learn the new weights.\nOption 2: if you have enough data you can retrain all the weights.\n\n\n\nPretraining = training on task A.\n\n\nFine-tuning = using pretrained weights + use new data to train task B.\n\n\nThis idea is useful because some of layers of trained NN contain helpful information for the new problem.\n\n\nTransfer learning makes sense when (e.g. from A to B):\n\nTask A and B have the same input X.\nYou have a lot more data for task A than task B.\nLow level features from A could be helpful for learning B.\n\n\n\nMulti-task learning #\n\n\n1 NN do several things at the same time and each of these tasks helps hopefully all of the other tasks!\n\n\nExample: Autonomous driving example ⇒\\Rightarrow⇒ Detect several things (not only 1) at the same time like: pedestrians, other cars, stop signs, traffic lights,...\n\nMulti-task learning. Image from the course.\n\n\nWe use Logistic Regression for the last layer. It's DIFFERENT from softmax regression because in this case, we need to determine more than 2 labels!\n\n\nIf there are some infos unclear in Y (e.g. don't know if there is a traffic light or not?), we consider only the rest and just ignore the unclear!\n\n\nMulti-task makes sense when (e.g. from A to B):\n\nTraining on a set of tasks that could benefit from having shred lover-level features.\nUsually: amount of data you have for each task is quite similar.\nCan train a big enough NN to do well on all the task.\n\n\n\nIn general (have ENOUGH DATA), multi-task gives better performances!\n\n\nOther remarks:\n\nMulti-task learning (usually) works good in object detection.\n(Usually) transfer learning is USED MORE OFTEN (an better) than multi task learning!\n\n\n\nEnd-to-end deep learning #\n\n\nThere have been some data processing system require multiple stages of processing. ⇒\\Rightarrow⇒ End-to-end does take all of them into 1 NN.\n\n\nExample: speech recognition from English to French: this case, end-to-end works better than separated problems because it has enough data!\n\nEnd-to-end learning. Image from the course.\n\n\nExample: auto open gate system: in this case, separated task is better end-to-end.\n\nDetermine the head.\nDetermine the name.\n\n\n\nWhen end-to-end works, it works very well!\n\n\nPros &amp; Cons:\n\nPros:\n\nLet the data speaks.\nLet hand-designing of components needed.\n\n\nCons:\n\nMay need a lot of data.\nExcludes potentially useful hand-designing components.\n\n\n\n\n\nIf having enough data ⇒\\Rightarrow⇒ can think of using end-to-end!\n\n\nAdvice: carefully choose what type of X→YX \\to YX→Y mapping ⇐\\Leftarrow⇐ depends on what tasks you can get data for!\n\n\n👉 Course 4 -- Structuring Machine Learning Projects.\n"},"/deeplearning-ai-course-3-autonomous-driving/":{"id":"/deeplearning-ai-course-3-autonomous-driving/","title":"Deep Learning Coursera - Bird recognition in the city of Peacetopia","keywords":"case study andrew ng","tags":["posts","MOOC","deeplearning.ai","Deep Learning"],"cat":"/img/cats/mooc.svg","content":"The content in this note is copied exactly from the course. It's really helpful to be a separated note.\n👉 Course 3 -- Structuring Machine Learning Projects.\n\n\nYou are just getting started on this project. What is the first thing you do? Assume each of the steps below would take about an equal amount of time (a few days).\n\nSpend a few days training a basic model and see what mistakes it makes.\n\n\nAs discussed in lecture, applied ML is a highly iterative process. If you train a basic model and carry out error analysis (see what mistakes it makes) it will help point you in more promising directions.\n\n\n\nYour goal is to detect road signs (stop sign, pedestrian crossing sign, construction ahead sign) and traffic signals (red and green lights) in images. The goal is to recognize which of these objects appear in each image. You plan to use a deep neural network with ReLU units in the hidden layers.\nFor the output layer, a softmax activation would be a good choice for the output layer because this is a multi-task learning problem. True/False?\n\n True\n False\n\n\nSoftmax would be a good choice if one and only one of the possibilities (stop sign, speed bump, pedestrian crossing, green light and red light) was present in each image.\n\n\n\nYou are carrying out error analysis and counting up what errors the algorithm makes. Which of these datasets do you think you should manually go through and carefully examine, one image at a time?\n\n 10,000 randomly chosen images\n 500 randomly chosen images\n 500 images on which the algorithm made a mistake\n 10,000 images on which the algorithm made a mistake\n\n\n\nAfter working on the data for several weeks, your team ends up with the following data:\n\n100,000 labeled images taken using the front-facing camera of your car.\n900,000 labeled images of roads downloaded from the internet.\n\nEach image’s labels precisely indicate the presence of any specific road signs and traffic signals or combinations of them. For example, y(i) = [1 0 0 1 0] means the image contains a stop sign and a red traffic light.\nBecause this is a multi-task learning problem, you need to have all your y(i) vectors fully labeled. If one example is equal to [0 ? 1 1 ?] then the learning algorithm will not be able to use that example. True/False?\n\n True\n False\n\n\nAs seen in the lecture on multi-task learning, you can compute the cost such that it is not influenced by the fact that some entries haven’t been labeled.\n\n\n\nThe distribution of data you care about contains images from your car’s front-facing camera; which comes from a different distribution than the images you were able to find and download off the internet. How should you split the dataset into train/dev/test sets?\n\n Mix all the 100,000 images with the 900,000 images you found online. Shuffle everything. Split the 1,000,000 images dataset into 600,000 for the training set, 200,000 for the dev set and 200,000 for the test set.\n Mix all the 100,000 images with the 900,000 images you found online. Shuffle everything. Split the 1,000,000 images dataset into 980,000 for the training set, 10,000 for the dev set and 10,000 for the test set.\n Choose the training set to be the 900,000 images from the internet along with 80,000 images from your car’s front-facing camera. The 20,000 remaining images will be split equally in dev and test sets.\n Choose the training set to be the 900,000 images from the internet along with 20,000 images from your car’s front-facing camera. The 80,000 remaining images will be split equally in dev and test sets.\n\n\nAs seen in lecture, it is important that your dev and test set have the closest possible distribution to “real”-data. It is also important for the training set to contain enough “real”-data to avoid having a data-mismatch problem.\n\n\n\nAssume you’ve finally chosen the following split between of the data:\n\nTraining\t940,000 images randomly picked from (900,000 internet images + 60,000 car’s front-facing camera images)\t8.8%\nTraining-Dev\t20,000 images randomly picked from (900,000 internet images + 60,000 car’s front-facing camera images)\t9.1%\nDev\t20,000 images from your car’s front-facing camera\t14.3%\nTest\t20,000 images from the car’s front-facing camera\t14.8%\n\nYou also know that human-level error on the road sign and traffic signals classification task is around 0.5%. Which of the following are True? (Check all that apply).\n\nYou have a large avoidable-bias problem because your training error is quite a bit higher than the human-level error.\nYou have a large data-mismatch problem because your model does a lot better on the training-dev set than on the dev set.\n\n\n\nBased on table from the previous question, a friend thinks that the training data distribution is much easier than the dev/test distribution. What do you think?\n\nThere’s insufficient information to tell if your friend is right or wrong.\n\n\nThe algorithm does better on the distribution of data it trained on. But you don’t know if it’s because it trained on that no distribution or if it really is easier. To get a better sense, measure human-level error separately on both distributions.\n\n\n\nYou decide to focus on the dev set and check by hand what are the errors due to. Here is a table summarizing your discoveries:\n\nOverall dev set error\t14.3%\nErrors due to incorrectly labeled data\t4.1%\nErrors due to foggy pictures\t8.0%\nErrors due to rain drops stuck on your car’s front-facing camera\t2.2%\nErrors due to other causes\t1.0%\n\nIn this table, 4.1%, 8.0%, etc.are a fraction of the total dev set (not just examples your algorithm mislabeled). I.e. about 8.0/14.3 = 56% of your errors are due to foggy pictures.\nThe results from this analysis implies that the team’s highest priority should be to bring more foggy pictures into the training set so as to address the 8.0% of errors in that category. True/False?\n\n False because this would depend on how easy it is to add this data and how much you think your team thinks it’ll help.\n True because it is the largest category of errors. As discussed in lecture, we should prioritize the largest category of error to avoid wasting the team’s time.\n True because it is greater than the other error categories added together (8.0 &gt; 4.1+2.2+1.0).\n False because data augmentation (synthesizing foggy images by clean/non-foggy images) is more efficient.\n\n\n\nYou can buy a specially designed windshield wiper that help wipe off some of the raindrops on the front-facing camera. Based on the table from the previous question, which of the following statements do you agree with?\n\n2.2% would be a reasonable estimate of the maximum amount this windshield wiper could improve performance.\n\n\nYou will probably not improve performance by more than 2.2% by solving the raindrops problem. If your dataset was infinitely big, 2.2% would be a perfect estimate of the improvement you can achieve by purchasing a specially designed windshield wiper that removes the raindrops.\n\n\n\nYou decide to use data augmentation to address foggy images. You find 1,000 pictures of fog off the internet, and “add” them to clean images to synthesize foggy days, like this:\nWhich of the following statements do you agree with? (Check all that apply.)\n\nSo long as the synthesized fog looks realistic to the human eye, you can be confident that the synthesized data is accurately capturing the distribution of real foggy images, since human vision is very accurate for the problem you’re solving.\n\n\nIf the synthesized images look realistic, then the model will just see them as if you had added useful data to identify road signs and traffic signals in a foggy weather. I will very likely help.\n\n\n\nAfter working further on the problem, you’ve decided to correct the incorrectly labeled data on the dev set. Which of these statements do you agree with? (Check all that apply).\n\nYou should not correct incorrectly labeled data in the training set as well so as to avoid your training set now being even more different from your dev set.\n\n\nDeep learning algorithms are quite robust to having slightly different train and dev distributions.\n\n\nYou should also correct the incorrectly labeled data in the test set, so that the dev and test sets continue to come from the same distribution\n\n\nBecause you want to make sure that your dev and test data come from the same distribution for your algorithm to make your team’s iterative development process is efficient.\n\n\n\nSo far your algorithm only recognizes red and green traffic lights. One of your colleagues in the startup is starting to work on recognizing a yellow traffic light. (Some countries call it an orange light rather than a yellow light; we’ll use the US convention of calling it yellow.) Images containing yellow lights are quite rare, and she doesn’t have enough data to build a good model. She hopes you can help her out using transfer learning.\nWhat do you tell your colleague?\n\nShe should try using weights pre-trained on your dataset, and fine-tuning further with the yellow-light dataset.\n\n\nYou have trained your model on a huge dataset, and she has a small dataset. Although your labels are different, the parameters of your model have been trained to recognize many characteristics of road and traffic images which will be useful for her problem. This is a perfect case for transfer learning, she can start with a model with the same architecture as yours, change what is after the last hidden layer and initialize it with your trained parameters.\n\n\n\nAnother colleague wants to use microphones placed outside the car to better hear if there’re other vehicles around you. For example, if there is a police vehicle behind you, you would be able to hear their siren. However, they don’t have much to train this audio system. How can you help?\n\nNeither transfer learning nor multi-task learning seems promising.\n\n\nThe problem he is trying to solve is quite different from yours. The different dataset structures make it probably impossible to use transfer learning or multi-task learning.\n\n\n\nTo recognize red and green lights, you have been using this approach:\n\n(A) Input an image (x) to a neural network and have it directly learn a mapping to make a prediction as to whether there’s a red light and/or green light (y).\n\nA teammate proposes a different, two-step approach:\n\n\n(B) In this two-step approach, you would first (i) detect the traffic light in the image (if any), then (ii) determine the color of the illuminated lamp in the traffic light.\nBetween these two, Approach B is more of an end-to-end approach because it has distinct steps for the input end and the output end. True/False?\n\n\n True\n\n\n False\n\n\n\n(A) is an end-to-end approach as it maps directly the input (x) to the output (y).\n\n\n\nApproach A (in the question above) tends to be more promising than approach B if you have a ________ (fill in the blank).\n\n Large training set\n Multi-task learning problem.\n Large bias problem.\n Problem with a high Bayes error.\n\n\nIn many fields, it has been observed that end-to-end learning works better in practice, but requires a large amount of data.\n\n\n\n"},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"id":"/deeplearning-ai-course-3-bird-recognition-peacetopia/","title":"Deep Learning Coursera - Bird recognition in the city of Peacetopia","keywords":"case study andrew ng","tags":["posts","MOOC","deeplearning.ai","Deep Learning"],"cat":"/img/cats/mooc.svg","content":"The content in this note is copied exactly from the course. It's really helpful to be a separated note.\n👉 Course 3 -- Structuring Machine Learning Projects.\nProblem Statement #\nThis example is adapted from a real production application, but with details disguised to protect confidentiality.\nYou are a famous researcher in the City of Peacetopia. The people of Peacetopia have a common characteristic: they are afraid of birds. To save them, you have to build an algorithm that will detect any bird flying over Peacetopia and alert the population.\nThe City Council gives you a dataset of 10,000,000 images of the sky above Peacetopia, taken from the city’s security cameras. They are labelled:\n\n\ny = 0: There is no bird on the image.\ny = 1: There is a bird on the image.\n\nYour goal is to build an algorithm able to classify new images taken by security cameras from Peacetopia.\nThere are a lot of decisions to make:\n\n\nWhat is the evaluation metric?\nHow do you structure your data into train/dev/test sets?\n\nMetric of success #\n⭐ The City Council tells you that they want an algorithm that\n\nHas high accuracy\nRuns quickly and takes only a short time to classify a new image.\nCan fit in a small amount of memory, so that it can run in a small processor that the city will attach to many different security cameras.\n\nNote: Having three evaluation metrics makes it harder for you to quickly choose between two different algorithms, and will slow down the speed with which your team can iterate.\n⭐ After further discussions, the city narrows down its criteria to:\n\n\n&quot;We need an algorithm that can let us know a bird is flying over Peacetopia as accurately as possible.&quot;\n&quot;We want the trained model to take no more than 10sec to classify a new image.”\n“We want the model to fit in 10MB of memory.”\n\n⭐ If you had the three following models, which one would you choose?\n\n\nTest Accuracy\t98%\nRuntime 9 sec\nMemory size 9MB\n\nAs soon as the runtime is less than 10 seconds you're good. So, you may simply maximize the test accuracy after you made sure the runtime is &lt;10sec.\n⭐ Based on the city’s requests: Accuracy is an optimizing metric; running time and memory size are a satisficing metrics.\nStructuring your data #\n⭐ Before implementing your algorithm, you need to split your data into train/dev/test sets.\n\n\nTrain 9,500,000\nDev 250,000\nTest 250,000\n\nAfter setting up your train/dev/test sets, the City Council comes across another 1,000,000 images, called the “citizens’ data”. Apparently the citizens of Peacetopia are so scared of birds that they volunteered to take pictures of the sky and label them, thus contributing these additional 1,000,000 images. These images are different from the distribution of images the City Council had originally given you, but you think it could help your algorithm.\nYou should add the citizens’ data to the training set\nSometimes we'll need to train the model on the data that is available, and its distribution may not be the same as the data that will occur in production. Also, adding training data that differs from the dev set may still help the model improve performance on the dev set. What matters is that the dev and test set have the same distribution.\n⭐ One member of the City Council knows a little about machine learning, and thinks you should add the 1,000,000 citizens’ data images to the test set. You object because:\n\n\nThe test set no longer reflects the distribution of data (security cameras) you most care about.\nThis would cause the dev and test set distributions to become different. This is a bad idea because you’re not aiming where you want to hit.\n\n⭐ You train a system, and its errors are as follows (error = 100%-Accuracy):\n\n\nTraining set error\t4.0%\nDev set error\t4.5%\n\nThis suggests that one good avenue for improving performance is to train a bigger network so as to drive down the 4.0% training error. Do you agree?\n\n\nNo, because there is insufficient information to tell.\n\n⭐ You ask a few people to label the dataset so as to find out what is human-level performance. You find the following levels of accuracy:\n\n\nBird watching expert #1\t0.3% error\nBird watching expert #2\t0.5% error\nNormal person #1 (not a bird watching expert)\t1.0% error\nNormal person #2 (not a bird watching expert)\t1.2% error\n\nIf your goal is to have “human-level performance” be a proxy (or estimate) for Bayes error, how would you define “human-level performance”?\n\n\n0.3% (accuracy of expert #1)\n\n⭐ A learning algorithm’s performance can be better human-level performance but it can never be better than Bayes error.\n⭐ You find that a team of ornithologists debating and discussing an image gets an even better 0.1% performance, so you define that as “human-level performance.” After working further on your algorithm, you end up with the following:\n\n\nHuman-level performance\t0.1%\nTraining set error\t2.0%\nDev set error\t2.1%\n\nBased on the evidence you have, which two of the following four options seem the most promising to try?\n\n\nTry decreasing regularization.\nTrain a bigger model to try to do better on the training set.\n\n⭐ You also evaluate your model on the test set, and find the following:\n\n\nHuman-level performance\t0.1%\nTraining set error\t2.0%\nDev set error\t2.1%\nTest set error\t7.0%\n\nWhat does this mean?\n\n\nYou should try to get a bigger dev set.\nYou have overfit to the dev set.\n\n⭐ After working on this project for a year, you finally achieve:\n\n\nHuman-level performance\t0.10%\nTraining set error\t0.05%\nDev set error\t0.05%\n\nWhat can you conclude?\n\n\nIt is now harder to measure avoidable bias, thus progress will be slower going forward.\nIf the test set is big enough for the 0,05% error estimate to be accurate, this implies Bayes error is ≤0.05\n\n⭐ It turns out Peacetopia has hired one of your competitors to build a system as well. Your system and your competitor both deliver systems with about the same running time and memory size. However, your system has higher accuracy! However, when Peacetopia tries out your and your competitor’s systems, they conclude they actually like your competitor’s system better, because even though you have higher overall accuracy, you have more false negatives (failing to raise an alarm when a bird is in the air). What should you do?\n\n\nRethink the appropriate metric for this task, and ask your team to tune to the new metric.\n\n⭐ You’ve handily beaten your competitor, and your system is now deployed in Peacetopia and is protecting the citizens from birds! But over the last few months, a new species of bird has been slowly migrating into the area, so the performance of your system slowly degrades because your data is being tested on a new type of data.\n\n\nUse the data you have to define a new evaluation metric (using a new dev/test set) taking into account the new species, and use that to drive further progress for your team.\n\n⭐ The City Council thinks that having more Cats in the city would help scare off birds. They are so happy with your work on the Bird detector that they also hire you to build a Cat detector. (Wow Cat detectors are just incredibly useful aren’t they.) Because of years of working on Cat detectors, you have such a huge dataset of 100,000,000 cat images that training on this data takes about two weeks. Which of the statements do you agree with?\n\n\nIf 100,000,000 examples is enough to build a good enough Cat detector, you might be better of training with just 10,000,000 examples to gain a ≈10x improvement in how quickly you can run experiments, even if each model performs a bit worse because it’s trained on less data.\nBuying faster computers could speed up your teams’ iteration speed and thus your team’s productivity.\nNeeding two weeks to train will limit the speed at which you can iterate.\n\n"},"/wasserstein-earth-mover-distance/":{"id":"/wasserstein-earth-mover-distance/","title":"Earth mover’s distance","keywords":"compare distribution CDF Earth mover's distance earth mover Wasserstein Distance Kolmogorov test ks test EMD","tags":["posts","Prob & Stats"],"cat":"/img/cats/stats.svg","content":"What (general)? #\n\nIn statistics, the earth mover's distance (EMD) is a measure of the distance between two probability distributions over a region D.[ref]\nIn stats or computer science, it's &quot;Earth mover's distance&quot;.\nIn maths, it's &quot;Wasserstein metric&quot;\nThe Wasserstein distance is the minimum cost of transporting mass in converting the data distribution q to the data distribution p.\n\nWhat (math way)? #\nThe idea borrowed from this. The first Wasserstein distance between the distributions uuu and vvv is:\nl1(u,v)=inf⁡π∈Γ(u,v)∫R×R∣x−y∣dπ(x,y)l_1 (u, v) = \\inf_{\\pi \\in \\Gamma (u, v)} \\int_{\\mathbb{R} \\times\n \\mathbb{R}} |x-y| \\mathrm{d} \\pi (x, y)\nl1​(u,v)=π∈Γ(u,v)inf​∫R×R​∣x−y∣dπ(x,y)\nwhere Γ(u,v)\\Gamma(u,v)Γ(u,v) is the set of (probability) distributions on R×R\\mathbb{R}\\times \\mathbb{R}R×R whose marginals are and on the first and second factors respectively.\nIf UUU and VVV are the respective CDFs of uuu and vvv, this distance also equals to:\nl1(u,v)=∫−∞+∞∣U−V∣l_1(u, v) = \\int_{-\\infty}^{+\\infty} |U-V|\nl1​(u,v)=∫−∞+∞​∣U−V∣\nExample of metric #\nSuppose we wanna move the blocks on the left to dotted-blocks on the right, we wanna find the &quot;energy&quot; (or metric) to do that.\nEnergy = Σ\\SigmaΣ weight of block x distance to move that block.\nSuppose that weight of each block is 1. All below figures are copied from this.\n\nThere are 2 ways to do that,\n\n2 ways of moving blocks from left to right.\nAbove example gives the same energies (424242) but there are usually different as below example,\n\nCoding #\nfrom scipy.stats import wasserstein_distance\n\narr1 = [1,2,3,4,5,6]arr2 = [1,2,3,4,5,6]wasserstein_distance(arr1, arr2)\n0.0# they are exactly the same!\n\n\narr1 = [1,2,3]arr2 = [4,5,6]wasserstein_distance(arr1, arr2)# 3.0000000000000004import seaborn as snssns.distplot(arr1, kde=False, hist_kws={\"histtype\": \"step\", \"linewidth\": 3, \"alpha\": 1, \"color\": \"b\"})sns.distplot(arr2, kde=False, hist_kws={\"histtype\": \"step\", \"linewidth\": 3, \"alpha\": 1, \"color\": \"r\"})\n\n\nReferences #\n\nWhat is an intuitive explanation of the Wasserstein distance?\nGAN — Wasserstein GAN &amp; WGAN-GP\nAn example of why we need to use EMD instead of Kolmogorov–Smirnov distance (video).\n\n"},"/data-visualization/":{"id":"/data-visualization/","title":"Data Visualization","keywords":"dtw dynamic time warping graph C library","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"👉 Note of Matplotlib extra\nDynamic Time Warping (DTW) #\nRef here,\nfrom dtaidistance import dtwfrom dtaidistance import dtw_visualisation as dtwvisimport numpy as nps1 = np.array([0., 0, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 0])s2 = np.array([0., 1, 2, 3, 1, 0, 0, 0, 2, 1, 0, 0, 0])path = dtw.warping_path(s1, s2)dtwvis.plot_warping(s1, s2, path, filename=\"warp.png\")\nIf meet err The compiled dtaidistance C library is not available.,\n\n\nTry to reinstall the lib from source.\n\n\nOr\npip install -v --force-reinstall --no-deps --no-binary dtaidistance dtaidistance\n\n\nIf you are running notebook, you have to restart the kernel!\n\n\n"},"/type-of-time-series/":{"id":"/type-of-time-series/","title":"Type of Time Series","keywords":"univariate time series multivariate time series","tags":["posts","Time Series"],"cat":"/img/cats/ts.svg","content":"Univariate vs Multivariate TS #\n\n\nUnivariate time series: Only one variable is varying over time.\n ``` bash\n # example of univariate dataset\n index Time value\n 0 2016-04-01 06:00:10 1\n 1 2016-04-01 06:00:20 2\n 2 2016-04-01 06:00:30 3\n ```\n\n\n\nMultivariate time series: Multiple variables are varying over time.\n ``` bash\n # example of multivariate dataset\n index Time value_1 value_2 value_3\n 0 2016-04-01 06:00:10 1 5 2\n 1 2016-04-01 06:00:20 2 9 8\n 2 2016-04-01 06:00:30 3 5 1\n ```\n\n\n"},"/data-structure/":{"id":"/data-structure/","title":"Data Structure","keywords":"HDF Hierarchical Data Format hdf5 hdf t-digest","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"Hierarchical Data Format (HDF) #\n\nDesigned to store and organize large amounts of data.\nStore multiple data files in a single data file!\n\nDifferent types of information.\nSelf describing (metadata included in the file)\n\n\nProperties[ref]:\n\nDatasets (numpy arrays): fast slicing, compression.\nGroup (dictionaries): nesting, POSIX path syntax.\nAttributrs (metadata): datasets/group, key-value.\n\n\nHDF5 is row based and really effient than csv for very large file size[ref].\nExtensions: .h5, .hdf, .hdf4, ...\nTool: HDFView\nExample[ref]:\n\n\nAn example HDF5 file structure which contains groups, datasets and associated metadata.\nimport h5pyf = h5py.File('mytestfile.hdf5', 'r') # read a file# h5py.File acts like Python dictdset = f['mydataset']dset.attrs # attribute\nt-digest #\nlater\n"},"/awesome-anomaly-detection-ts/":{"id":"/awesome-anomaly-detection-ts/","title":"Anomaly Detection for TS Resources","keywords":"resources material ad awesome collection time series pyodds adtk tool kit awesome","tags":["posts","Time Series"],"cat":"/img/cats/ts.svg","content":"This note contains good resources for Time Series Anomaly Detection problems.\nBook &amp; tutorials #\n\nPractical Machine Learning - A new look at Anomaly Detection - Ted Dunning &amp; Ellen Friedman -- clear explanation -- pdf\n\nLibraries #\n\nAnomaly Detection Tool Kit (ADTK) -- many examples and cases with codes -- docs -- github.\nPyODDS -- docs -- github\n\nOther resources #\n\nawesome-TS-anomaly-detection\nMachine Learning Awesome List - section &quot;Time Series Anomaly Detection&quot;.\nScitkit-learn -- Comparing anomaly detection algorithms for outlier detection on toy datasets\nawesome anomaly detection - section &quot;Time-series anomaly detection&quot;\n\n"},"/k-shape-clustering/":{"id":"/k-shape-clustering/","title":"K-Shape clustering","keywords":"clustering time series","tags":["posts","Machine Learning","Clustering"],"cat":"/img/cats/ml.svg","content":"What? #\nK-Shape clustering method is a method for clustering time series.\nThe main ideas of this algorithms are:\n\n\nThe distance measure is based on the cross-correlation of two time series.\nThe clustering process uses iterative approaches.\nIt is a raw-based method. It is fundamentally a variant of k-means with some interesting modification.\n\nDefine a distance between 2 time series.\nHow to average multiple time series.\n\n\n\nReferences #\n\n(article) k-Shape: Efficient and Accurate Clustering of Time Series\nRyan's blog -- K-Shape Clustering Algorithm\n\n"},"/data-ml-tools-resources/":{"id":"/data-ml-tools-resources/","title":"Resources for DS & ML & DL","keywords":"data science deep learing tools resources application good choice collection machine learning websites link url video dataset data frameworks","tags":["posts","Data Science"],"cat":"/img/cats/data-science.svg","content":"Services &amp; API #\n\nMapbox -- Precise location data and powerful developer tools to change the way we navigate the world.\nOpenStreetMap -- a map of the world, created by people like you and free to use under an open license.\nFoursquare -- the trusted location data.\n\nFrameworks #\n\nD3js (Data-Driven Documents)\nCaffe -- deep learning framework.\n\nPython libs #\n\nCSAPS -- a Python package for univariate, multivariate and n-dimensional grid data approximation using cubic smoothing splines. The package can be useful in practical engineering tasks for data approximation and smoothing.\ndaft -- a Python package that uses matplotlib to render pixel-perfect probabilistic graphical models for publication in a journal or on the internet.\n\nR libs #\nlater!\nTools #\n\nTensorFlow Playground\nObservale -- Observable is the magic notebook for exploring data and thinking with code.\nTravis-CI -- a hosted continuous integration service used to build and test software projects hosted at GitHub and Bitbucket.\n\n"},"/deeplearning-ai-tensorflow-course-1/":{"id":"/deeplearning-ai-tensorflow-course-1/","title":"TF 1 - Intro to TensorFlow for AI, ML, DL","keywords":"deep learning ai coursera tensorflow google project python mnist convolutional neural networks cnn andrew ng cnn convolution neural networks image generator real world images photos minist fashion Laurence Moroney fashion mnist optimizer loss metrics model sequential summary pooling convolution visualization MNIST layers flatten kernel size dense layer classification features extraction mycallback my callback on_epoch_end train test set pooling conv image filtering visualize convolutions and pooling real world images ImageGenerator ConvNet","tags":["posts","MOOC","deeplearning.ai","Deep Learning","TensorFlow"],"cat":"/img/cats/mooc.svg","content":"This is my note for the first course of TensorFlow in Practice Specialization given by deeplearning.ai and taught by Laurence Moroney on Coursera.\n👉 Check the codes on my Github.\n👉 Official notebooks on Github.\n👉 Go to course 2 - CNN in Tensorflow.\n👉 Go to course 3 - NLP in Tensorflow.\n👉 Go to course 4 - Sequences, Time Series and Prediction.\nBasic DL on MNIST #\nimport tensorflow as tf# stop the training with conditionclass myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs={}): # compare at the end of each epoch if(logs.get('accuracy') > 0.99): self.model.stop_training = Truemnist = tf.keras.datasets.mnist(x_train, y_train),(x_test, y_test) = mnist.load_data()x_train, x_test = x_train / 255.0, x_test / 255.0 # normalizecallbacks = myCallback() # define the callbackmodel = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), # Takes that square and # turns it into a 1 dim tf.keras.layers.Dense(512, activation=tf.nn.relu), tf.keras.layers.Dense(10, activation=tf.nn.softmax) # 10 outputs])model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\nComments (notebook):\n\n\nAdding more Neurons we have to do more calculations, slowing down the process, but get more accurate.\nThe first layer in your network should be the same shape as your data.\nThe number of neurons in the last layer should match the number of classes you are classifying for.\nExtra layers are often necessary.\nFlatten as the name implies, converts your multidimensional matrices (Batch.Size x Img.W x Img.H x Kernel.Size) to a nice single 2-dimensional matrix: (Batch.Size x (Img.W x Img.H x Kernel.Size)). During backpropagation it also converts back your delta of size (Batch.Size x (Img.W x Img.H x Kernel.Size)) to the original (Batch.Size x Img.W x Img.H x Kernel.Size).\nDense layer is of course the standard fully connected layer.\n\n\nCNN layers, cource of image.\nBasic DL on Fashion-MNIST #\n# the same as in MINST# different at below line of loading datamnist = tf.keras.datasets.fashion_mnist\nBasic CNN on Fashion-MNIST #\nimport tensorflow as tfmnist = tf.keras.datasets.fashion_mnistclass myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epochs, logs={}) : if(logs.get('accuracy') is not None and logs.get('accuracy') >= 0.998) : print('\\nReached 99.8% accuracy so cancelling training!') self.model.stop_training = True(training_images, training_labels), (test_images, test_labels) = mnist.load_data()# Why reshape?# The first convolution expects a single tensor containing everything,# so instead of 60000 28x28x1 items in a list, we have a single 4D list# that is 60000x28x28x1## training_images' shape (before reshape): (60000, 28, 28)# training_images' shape (after reshape): (60000, 28, 28, 1)# trainaing_labels' shape: (60000,)training_images=training_images.reshape(60000, 28, 28, 1)training_images=training_images / 255.0test_images = test_images.reshape(10000, 28, 28, 1)test_images=test_images/255.0model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Conv2D(64, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dense(10, activation='softmax')])model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])callbacks = myCallback()model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])test_loss = model.evaluate(test_images, test_labels)\nmodel.summary() # model detail\nModel: \"sequential_1\"_________________________________________________________________Layer (type) Output Shape Param #=================================================================conv2d (Conv2D) (None, 26, 26, 64) 640 # for every image, 64 convolution has been tried # 26 (=28-2) because we use 3x3 filter and we can't # count on edges, so the picture is 2 smaller on x and y. # if 5x5 filter => 4 smaller on x and y._________________________________________________________________max_pooling2d (MaxPooling2D) (None, 13, 13, 64) 0_________________________________________________________________conv2d_1 (Conv2D) (None, 11, 11, 64) 36928_________________________________________________________________max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64) 0_________________________________________________________________flatten_1 (Flatten) (None, 1600) 0_________________________________________________________________dense_2 (Dense) (None, 128) 204928_________________________________________________________________dense_3 (Dense) (None, 10) 1290=================================================================Total params: 243,786Trainable params: 243,786Non-trainable params: 0\nRefs:\n\n\nKernel in image processing: examples with images.\nPooling layer: non-linear down-sampling.\n\nMore?\n\n\n\nImage Filtering -- Lode's Computer Graphics Tutorial\n\n\nApplying Convolutions on top of our Deep neural network will make training =&gt; It depends on many factors. It might make your training faster or slower, and a poorly designed Convolutional layer may even be less efficient than a plain DNN!\n\n\nWhat is a Convolution? =&gt; A technique to isolate features in images\n\n\nWhat is a Pooling? =&gt; A technique to reduce the information in an image while maintaining features\n\n\nHow do Convolutions improve image recognition? =&gt; They isolate features in images\n\n\nAfter passing a 3x3 conv filter over a 28x28 image, how big will the output be? =&gt; 26x26\n\n7x7 to 5x5 (source)\n\n\nAfter max pooling a 26x26 image with a 2x2 filter, how big will the output be? =&gt; 13x13\n\n(source)\n\n\nVisualizing the Convolutions and Pooling #\nUsing layer API, something like below, check more in the notebook.\nimport matplotlib.pyplot as pltf, axarr = plt.subplots()from tensorflow.keras import modelslayer_outputs = [layer.output for layer in model.layers]activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)for x in range(0,4): f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x] axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno') axarr[0,x].grid(False) ...\nUsing real-world images #\nAn example of classifying horses and humans!\nImageGenerator #\n👉 Video explain ImageGenerator.\n# make images more used for training# (focus on object, split cleary objects, label images,...)# also help to augmenting data (rotate, skew, flip,...)from tensorflow.keras.preprocessing.image import ImageDataGeneratortrain_datagen = ImageDataGenerator(rescale=1./255) # normalize -> No need to convert images and then put in the training # do the scaling on the flytrain_generator = train_datagen.flow_from_directory( train_dir, # dir contains the dir containing your images # -> be careful! target_size=(300, 300), # images will be resized when loaded, genial! # because NN always needs that! # -> experimenting with diff sizes without # impacting your source data batch_size=128, class_mode=\"binary\" # 2 diff things)test_datagen = ImageDataGenerator(rescale=1./255) # normalizevalidation_generator = test_datagen.flow_from_directory( validation_dir, # dir contains the dir containing your images target_size=(300, 300), batch_size=32, class_mode=\"binary\")\nConvNet with ImageGenerator #\nMore docs:\n\n\nUnderstanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names\nOverview of mini-batch gradient descent\n\n"},"/r-installation/":{"id":"/r-installation/","title":"R Installation","keywords":"r jupyter notebook programming language install 101 windows linux ubuntu extension package lib library requirement LC_ALL utf8 UTF-8","tags":["posts","R Lang"],"cat":"/img/cats/r.svg","content":"Install R #\n👉 Home page.\nInstall a package in R #\n\n# directlyinstall.packages(\"slidify\")\n# from github repoinstall.packages(\"devtools\")devtools::install_github(\"twitter/AnomalyDetection\")library(AnomalyDetection)\n\nR with jupyter notebook #\n👉 Read this note.\nError #\n# installation of package ‘xml2’ had non-zero exit statussudo apt install libxml2-dev\n# cannot install packages# Setting LC_CTYPE failed, using \"C\"# (or something like that)# without root environnement# exit Rdefaults write org.R-project.R force.LANG en_US.UTF-8# start R again# with root (in a docker bash, for example)# start R by usingLC_ALL=C.UTF-8 R\n"},"/deeplearning-ai-tensorflow-course-2/":{"id":"/deeplearning-ai-tensorflow-course-2/","title":"TF 2 - CNN in TensorFlow","keywords":"deep learning ai coursera tensorflow google project python mnist convolutional neural networks cnn andrew ng cnn convolution neural networks image generator real world images photos minist fashion Laurence Moroney zip python gzip unzip transfer learning inception module network ImageDataGenerator RMSprop cat vs dog accuracy loss make a larger dataset dropout crop image scaling extract zip file using python image to np array plot accuracy and loss split shuffle data sequential model keras dense flatten conv2d max pooling generate data image augmentation human vs horse image generator transfer learning Inception GoogleNet network Dropout pre trained model multi class classification mnist rock paper scissors","tags":["posts","MOOC","deeplearning.ai","Deep Learning","TensorFlow"],"cat":"/img/cats/mooc.svg","content":"This is my note for the 2nd course of TensorFlow in Practice Specialization given by deeplearning.ai and taught by Laurence Moroney on Coursera.\n👉 Check the codes on my Github.\n👉 Official notebooks on Github.\n👉 Go to course 1 - Intro to TensorFlow for AI, ML, DL.\n👉 Go to course 3 - NLP in Tensorflow.\n👉 Go to course 4 - Sequences, Time Series and Prediction.\nLarger dataset #\n\n\nKaggle Dogs v Cats dataset - very famous dataset on Kaggle.\nCrop an image make the predict better!\nMake a larger dataset by rotating, scaling, cropping,...\n\nExtract zip file + view image #\n\n# extract zip fileimport zipfilelocal_zip = 'file.zip'zip_ref = zipfile.ZipFile(local_zip, 'r')zip_ref.extractall('/tmp')zip_ref.close()\n# show imageimport matplotlib.image as mpimgimport matplotlib.pyplot as pltimg = mpimg.imread(img_path)plt.imshow(img)plt.show()\n\nimage to np array #\nfrom keras.preprocessing import imagepath = './image.png'img = image.load_img(path, target_size=(150, 150))x = image.img_to_array(img)x = np.expand_dims(x, axis=0)images = np.vstack([x])classes = model.predict(images, batch_size=10)\nPlot loss and acc #\nhistory = model.fit(...)acc = history.history[ 'accuracy' ]val_acc = history.history[ 'val_accuracy' ]loss = history.history[ 'loss' ]val_loss = history.history['val_loss' ]\n\n# plot accuracyplt.plot ( epochs, acc )plt.plot ( epochs, val_acc )plt.title ('Training and validation acc')plt.figure()\n# plot loss functionplt.plot ( epochs, loss )plt.plot ( epochs, val_loss )plt.title ('Training and validation loss')\n\nCats vs dogs #\nos #\nbase_dir = '/tmp/cats-v-dogs'os.mkdir(base_dir)train_dir = os.path.join(base_dir, 'training')validation_dir = os.path.join(base_dir, 'testing')os.mkdir(train_dir)os.mkdir(validation_dir)\nos.listdir(DIRECTORY) # gives you a listing of the contents of that directoryos.path.getsize(PATH) # gives you the size of the filecopyfile(source, destination) # copies a file from source to destinationrandom.sample(list, len(list)) # shuffles a list\nSplit data #\nShuffle images and split/copy images to training/testing folder for each cat and dog.\ndef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE): lst_cat_imgs = os.listdir(SOURCE) lst_cat_imgs = random.sample(lst_cat_imgs, len(lst_cat_imgs)) for file in lst_cat_imgs[:int(SPLIT_SIZE*len(lst_cat_imgs))]: source_file = os.path.join(SOURCE, file) destination_file = os.path.join(TRAINING, file) if os.path.getsize(source_file) > 0: copyfile(source_file, destination_file) for file in lst_cat_imgs[int(SPLIT_SIZE*len(lst_cat_imgs)):]: source_file = os.path.join(SOURCE, file) destination_file = os.path.join(TESTING, file) if os.path.getsize(source_file) > 0: copyfile(source_file, destination_file)\nCAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"split_size = .9split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\nDefine model #\nmodel = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(32, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(64, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation='relu'), tf.keras.layers.Dense(1, activation='sigmoid')])model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\nGenerate data #\nTRAINING_DIR = \"/tmp/cats-v-dogs/training/\"train_datagen = ImageDataGenerator( rescale = 1.0/255. )train_generator = train_datagen.flow_from_directory(TRAINING_DIR, batch_size=10, class_mode='binary', target_size=(150, 150))# the same for validation# output: Found 2700 images belonging to 2 classes.\nTrain #\nhistory = model.fit_generator(train_generator, epochs=2, verbose=1, validation_data=validation_generator)\nImage Augmentation #\n👉 Notebook: Cats v Dogs using augmentation &amp; the final exercise (more data).\n👉 Notebook: Human vs Horse using augmentation.\n\n\nCreate multiple &quot;other&quot; images from original images without saving them to the memory + quickly.\nImage augmentation helps you avoid overfitting.\nMeaning of params, check this video.\nBroad set of images for BOTH training and testing sets!\nImageDataGenerator on TF.\n\n# The different from the code in the previous section!train_datagen = ImageDataGenerator( rescale=1./255, # rescale rotation_range=40, # rotate randomly between 0 &amp; 40 degrees (max 180) width_shift_range=0.2, # offset horizontally 20% height_shift_range=0.2, # offset vertically 20% shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest' # fill any pixel may been lost by the \"nearest\" ones)validation_datagen = ImageDataGenerator(rescale=1/255)\n\nAn illustration of image augmentation from apple.\nTransfer learning #\n👉 Notebook: Coding transfer learning from the inception mode. ➪ Video explains this notebook.\n👉 Notebook: Horses v Humans using callBack, Augmentation, transfer learning (final exercise).\n\n\nTransfer learning = Taking existing model that's trained on far more data + use the features that model learned.\n(Tensorflow tutorial) Transfer learning and fine-tuning\nInception/GoogLeNet network: Inception Modules are used in CNN to allow for more efficient computation and deeper Networks through a dimensionality reduction with stacked 1x1 convolutions. The modules were designed to solve the problem of computational expense, as well as overfitting, among other issues. The solution, in short, is to take multiple kernel filter sizes within the CNN, and rather than stacking them sequentially, ordering them to operate on the same level. [ref] Check more in Refereces 1, 2, 3.\nDropout: remove a random number of neurons in your NN. It works well because:\n\nneighboring neurons often end up with similar weights, which can lead to overfitting.\na neuron can over-weigh the input from a neuron in the previous layer\n\n\n\nfrom tensorflow.keras import layersfrom tensorflow.keras import Model# download snapshot of weightsfrom tensorflow.keras.applications.inception_v3 import InceptionV3local_weights_file = '/tmp/inception_v3_weights.h5'pre_trained_model = InceptionV3( input_shape = (150, 150, 3), include_top = False, # Inception v3 has a fully-connected # layer at the top -> False to ignore # it and get straight to the convolution. weights = None # don't wana use built-in weights)pre_trained_model.load_weights(local_weights_file) # but use the snapshot downloadedfor layer in pre_trained_model.layers: layer.trainable = False # lock pretrained layers # they're not going to be trained # with this code# pre_trained_model.summary() # DON'T DO THAT, IT'S HUGE!!!\n# By default, the output of the last layer will be 3x3 but we wanna# get more info, so we grap layer \"mixed7\" from inception and take its output# mixed7: output of a lot of conv that are 7x7last_layer = pre_trained_model.get_layer('mixed7')last_output = last_layer.output\nfrom tensorflow.keras.optimizers import RMSprop# Define a new modelx = layers.Flatten()(last_output) # Take the output (mixed7) from inception model # last_output: look like dense model # -> input of the new model # Starting by flatting the inputx = layers.Dense(1024, activation='relu')(x)x = layers.Dropout(0.2)(x) # randomly remove 20% of neurons (avoid overfitting)x = layers.Dense (1, activation='sigmoid')(x)model = Model(pre_trained_model.input, x)model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['accuracy'])\nMulti-class classification #\n👉 Notebook: Rock Paper Scissors.\n👉 Notebook: MNIST.\n\n\nRock-Paper-Scissors dataset (generated using CGI techniques)\n\nThe codes are quite the same as in the case of binary classification, the differences are\ntrain_generator = train_datagen.flow_from_directory( ... class_mode='categorical' # 'binary' for binary)\nmodel = tf.keras.models.Sequential([ ... tf.keras.layers.Dense(3, activation='softmax') # 'sigmoid' for binary])\nmodel.compile( loss='categorical_crossentropy' # 'binary_lossentropy' for binary)\nMore #\n\nApplying Convolutions on top of our Deep neural network will make training ➪ It depends on many factors. It might make your training faster or slower, and a poorly designed Convolutional layer may even be less efficient than a plain DNN!\n\nReferences #\n\nInception Network - Implementation Of GoogleNet In Keras\nResNet, AlexNet, VGGNet, Inception: Understanding various architectures of Convolutional Networks – CV-Tricks.com\nReview: GoogLeNet (Inception v1)— Winner of ILSVRC 2014 (Image Classification)\nTransfer learning and fine-tuning  -  TensorFlow Core\n\n"},"/deeplearning-ai-tensorflow-course-3/":{"id":"/deeplearning-ai-tensorflow-course-3/","title":"TF 3 - NLP in TensorFlow","keywords":"deep learning ai coursera tensorflow google project python natural language processing NLP letters sequences text sentiment RNN LSTM long short term memory Recurrent neural network sarcasm tokenizer imdb movie review embedding word embeddings GRU Gated Recurrent Unit layer conv character-based prediction Shakespeare poem","tags":["posts","MOOC","deeplearning.ai","Deep Learning","TensorFlow"],"cat":"/img/cats/mooc.svg","content":"This is my note for the 3rd course of TensorFlow in Practice Specialization given by deeplearning.ai and taught by Laurence Moroney on Coursera.\n👉 Check the codes on my Github.\n👉 Official notebooks on Github.\n👉 Go to course 1 - Intro to TensorFlow for AI, ML, DL.\n👉 Go to course 2 - CNN in TensorFlow.\n👉 Go to course 4 - Sequences, Time Series and Prediction.\nTokernizing + padding #\n👉 Notebook: Tokenizer basic examples.\n👉 Notebook: Sarcasm detection.\n\n\nA common simple character encoding is ASCII,\nWe can encode each word as a number (token) -- Tokenizer.\nTokenize words &gt; build all the words to make a corpus &gt; turn your sentences into lists of values based on these tokens. &gt; manipulate these lists (make the same length, for example)\n\nfrom tensorflow.keras.preprocessing.text import Tokenizersentences = [ 'i love my dog', 'I, love my cat', 'You love my dog so much!']tokenizer = Tokenizer(num_words = 100, oov_token=\"&lt;OOV>\") # num_words: max of words to be tokenized &amp; pick # the most common 100 words. # More words, more accuracy, more time to train # oov_token: replace unseen words by \"&lt;OOV>\"tokenizer.fit_on_texts(sentences) # fix texts based on tokens\n# indexing wordsword_index = tokenizer.word_indexprint(word_index)# {'&lt;OOV>': 1, 'love': 2, 'my': 3, 'i': 4, 'dog': 5, 'cat': 6, 'you': 7, 'so': 8, 'much': 9}# \"!\", \",\", capital, ... are removed\n👉 tf.keras.preprocessing.text.Tokenizer\n# encode sentencessequences = tokenizer.texts_to_sequences(sentences)print(sequences)# [[4, 2, 3, 5], [4, 2, 3, 6], [7, 2, 3, 5, 8, 9]]# if a word is not in the word index, it will be lost in the text_to_sequences()\n👉 tf.keras.preprocessing.sequence.pad_sequences\n# make encoded sentences equalfrom tensorflow.keras.preprocessing.sequence import pad_sequencespadded = pad_sequences(sequences, value=-1, maxlen=5, padding=\"post\", truncating=\"post\") # maxlen: max len of encoded sentence # value: value to be filld (default 0) # padding: add missing values at beginning or ending of sentence? # truncating: longer than maxlen? cut at beginning or ending?print(padded)# [[ 4 2 3 5 -1]# [ 4 2 3 6 -1]# [ 7 2 3 5 8]]\n👉 Sarcasm detection dataset.\n# read json textimport jsonwith open(\"/tmp/sarcasm.json\", 'r') as f: datastore = json.load(f)sentences = []labels = []urls = []for item in datastore: sentences.append(item['headline']) labels.append(item['is_sarcastic']) urls.append(item['article_link'])\nWord embeddings #\n👉 Embedding projector - visualization of high-dimensional data\n👉 Large Movie Review Dataset\nIMDB review dataset #\n👉 Notebook: Train IMDB review dataset.\n👉 Video explain the code.\n\n\nWord embeddings = the idea in which words and associated words are clustered as vectors in a multi-dimensional space. That allows words with similar meaning to have a similar representation.\nThe meaning of the words can come from labeling of the dataset.\n\nExample: &quot;dull&quot; and &quot;boring&quot; show up a lot in negative reviews =&gt; they have similar sentiments =&gt; they are close to each other in the sentence =&gt; thus their vector will be similar =&gt; NN train + learn these vectors + associating them with the labels to come up with what's called in embedding.\n\n\nThe purpose of embedding dimension is the number of dimensions for the vector representing the word encoding.\n\nimport tensorflow as tfprint(tf.__version__) # check version of tensorflow# If you are using tf1, you need below codetf.enable_eager_execution()\n# IMDB reviews datasetimport tensorflow_datasets as tfdsimdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)train_data, test_data = imdb['train'], imdb['test']for s,l in train_data: # \"s\" for sentences \"l\" for labels # The values for \"s\" and \"l\" are tensors # so we need to extracr their values training_sentences.append(s.numpy().decode('utf8')) training_labels.append(l.numpy())\n# Prepare for the NNvocab_size = 10000embedding_dim = 16 # embedding to dim 16max_length = 120 # of each sentencetrunc_type='post' # cut the last wordsoov_tok = \"&lt;OOV>\" # replace not-encoded words by thisfrom tensorflow.keras.preprocessing.text import Tokenizerfrom tensorflow.keras.preprocessing.sequence import pad_sequencestokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)tokenizer.fit_on_texts(training_sentences) # encoding the wordsword_index = tokenizer.word_index # list of word index (built based on training set) # there may be many oov_tok in test setsequences = tokenizer.texts_to_sequences(training_sentences) # apply on sentencespadded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type) # padding the sentences# apply to the test settesting_sequences = tokenizer.texts_to_sequences(testing_sentences)testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n# Simple NNmodel = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length), # The result of embedding will be a 2D array: # length of sentence x embedding_dim tf.keras.layers.Flatten(), # Alternatively (a little diff on speed and accuracy): # tf.keras.layers.GlobalAveragePooling1D() # average across the vectors to flatten it out tf.keras.layers.Dense(6, activation='relu'), tf.keras.layers.Dense(1, activation='sigmoid')])model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])model.summary()\n# Trainingmodel.fit(padded, training_labels_final, epochs=10, validation_data=(testing_padded, testing_labels_final))\n# the resulte = model.layers[0] # get the result of the embedding layersweights = e.get_weights()[0]print(weights.shape) # shape: (vocab_size, embedding_dim)\nIf you wanna visualize the result (in 3D) with Embedding projector,\nimport ioout_v = io.open('vecs.tsv', 'w', encoding='utf-8')out_m = io.open('meta.tsv', 'w', encoding='utf-8')for word_num in range(1, vocab_size): word = reverse_word_index[word_num] embeddings = weights[word_num] out_m.write(word + \"\\n\") out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")out_v.close()out_m.close()try: from google.colab import filesexcept ImportError: passelse: files.download('vecs.tsv') files.download('meta.tsv')\nSarcasm dataset #\n👉 Notebook: Train Sacarsm dataset.\n\nIn text data, it usually happens that the accuracy increase over the number of training but the loss increase sharply also. We can &quot;play&quot; with hyperparameter to see the effect.\n\n# Run this to ensure TensorFlow 2.x is usedtry: # %tensorflow_version only exists in Colab. %tensorflow_version 2.xexcept Exception: pass\nPre-tokenized datasets #\n👉 datasets/imdb_reviews.md at master · tensorflow/datasets\n👉 tfds.features.text.SubwordTextEncoder  |  TensorFlow Datasets\n👉 Notebook: Pre-tokenizer example.\n👉 Video exaplain the codes.\n\nThere are someones who did the work (tokenization) for you.\nTry on IMDB dataset that has been pre-tokenized.\nThe tokenization is done on subwords!\nThe sequence of words can be just important as their existence.\n\n# load imdb dataset from tensorflowimport tensorflow_datasets as tfdsimdb, info = tfds.load(\"imdb_reviews/subwords8k\", with_info=True, as_supervised=True)# extract train/test setstrain_data, test_data = imdb['train'], imdb['test']# take the tokernizertokenizer = info.features['text'].encoderprint(tokenizer.subwords)# ['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_',...\nsample_string = 'TensorFlow, from basics to mastery'tokenized_string = tokenizer.encode(sample_string)print ('Tokenized string is {}'.format(tokenized_string))# Tokenized string is [6307, 2327, 4043, 2120, 2, 48, 4249, 4429, 7, 2652, 8050]original_string = tokenizer.decode(tokenized_string)print ('The original string: {}'.format(original_string))# The original string: TensorFlow, from basics to mastery\n# take a look on tokenized string# case sensitive + punctuation maintainedfor ts in tokenized_string: print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))# 6307 ----> Ten# 2327 ----> sor# 4043 ----> Fl# ...\n\nThe code run quite long (4 minutes each epoch if using GPU on colab) because there are a lot of hyperparameters and sub-words.\nResult: 50% acc &amp; loss is decreasing but very small.\n\nBecause we are using sub-words, not for-words -&gt; they (sub-words) are nonsensical. -&gt; they are only when we put them together in sequences -&gt; learning from sequences would be a great way forward -&gt; RNN (Recurrent Neural Networks)\n\n\n\nSequence models #\n\nThe relative ordering, the sequence of words, matters for the meaning of the sentence .\nFor NN to take into account for the ordering of the words: RNN (Recurrent Neural Networks), LSTM (Long short-term memory).\nWhy not RNN but LSTM ? With RNN, the context is preserved from timstamp to timestamp BUT that may get lost in longer sentences =&gt; LSTM gets better because it has cell state.\nExample of using LSTM: &quot;I grew up in Ireland, I went to school and at school, they made me learn how to speak...&quot; =&gt; &quot;speak&quot; is the context and we go back to the beginning to catch &quot;Ireland&quot;, then the next word could be &quot;leanr how to speak Gaelic&quot;!\n\nRNN idea #\n👉 Note of the course of sequence model.\n\n\nThe usual NN, something like &quot;f(data, labels)=rules&quot; cannot take into account of sequences.\nAn example of using sequences: Fibonacci sequence =&gt; the result of current function is the input of next function itself,...\n\n\nRNN basic idea (source).\nLSTM idea #\n👉 (Video) Illustrated Guide to LSTM's and GRU's: A step by step explanation &amp; its article.\n\n\nSometimes, the sequence context leads to lose information like the example of &quot;Ireland&quot; and &quot;Gaelic&quot; before.\nLSTM has an additional pipeline called Cell State. It can pass through the network to impact it + help to keep context from earlier tokens relevance.\n\n\nLSTM basic idea (image from the course).\n# SINGLE LAYER LSTMmodel = tf.keras.Sequential([ tf.keras.layers.Embedding(tokenizer.vocab_size, 64), tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)), # 64: #oututs desired (but the result may be different) tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(1, activation='sigmoid')])\n👉 Notebook: IMDB Subwords 8K with Single Layer LSTM\n# MULTI PLAYER LSTMmodel = tf.keras.Sequential([ tf.keras.layers.Embedding(tokenizer.vocab_size, 64), tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)), # return_sequences=True: required if we wanna feed LSTM into another one # It ensures that the output of LSTM match the desired inputs of the next one tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(1, activation='sigmoid')])\n👉 Notebook: IMDB Subwords 8K with Multi Layer LSTM\n\n1 layer vs 2 layer LSTM accuracy after 50 epochs (image from the course). 2 layer is better (smoother) which makes us more confident about the model. The validation acc is sticked to 80% because we used 8000 sub-words taken from training set, so there may be many tokens from the test set that would be out of vocabulary.\nWith vs without LSTM #\n# WITHOUT LSTM (like previous section)model = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length), # tf.keras.layers.Flatten(), tf.keras.layers.GlobalmaxPooling1D(), # tf.keras.layers.Dense(6, activation='relu'), tf.keras.layers.Dense(1, activation='sigmoid')])\n# WITH LSTMmodel = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length), # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)), # tf.keras.layers.Dense(6, activation='relu'), tf.keras.layers.Dense(1, activation='sigmoid')])\n\nWith vs without LSTM (image from the course). With LSTM is really better but there is still overfitting here.\nUsing a ConvNet #\n👉 Video explains the dimension.\n👉 Notebook: IMDB Subwords 8K with 1D Convolutional Layer.\nmodel = tf.keras.Sequential([ tf.keras.layers.Embedding(tokenizer.vocab_size, 64), # tf.keras.layers.Conv1D(128, 5, activation='relu'), # tf.keras.layers.GlobalAveragePooling1D(), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(1, activation='sigmoid')])\n\nUsing Convolution network. (image from the course). It's really better but there is overfitting there.\nIMDB dataset #\n👉 Notebook: IMDB Reviews with GRU (and optional LSTM and Conv1D).\n👉 Video compares the results.\nTry with 3 different choices:\n\n\nSimple NN: 5s/epoch, 170K params, nice acc, overfitting.\nLSTM: 43s/epoch, 30K params, acc better, overfitting.\nGRU (Gated Recurrent Unit layer, a different type of RNN): 20s/epoch, 169K params, very good acc, overfitting.\nConv1D: 6s/epoch, 171K params, good acc, overfitting.\n\nRemark: With the texts, you'll probably get a bit more overfitting than you would have done with images. Because we have out of voca words in validation data.\nSequence models and literature #\nOne application of sequence models: read text then generate another look-alike text.\n👉 Notebook 1 &amp; explaining video.\n\nHow they predict a new word in the notebook? -&gt; Check this video.\n\ninput_sequences = []for line in corpus:\t# convert each sentence to list of numbers\ttoken_list = tokenizer.texts_to_sequences([line])[0]\t# convert each list to n-gram sequence\t# eg. from [1,2,3,4,5]\t# \t\tto [1,2], [1,2,3], [1,2,3,4], [1,2,3,4,5]\tfor i in range(1, len(token_list)):\t\tn_gram_sequence = token_list[:i+1]\t\tinput_sequences.append(n_gram_sequence)# pad sequences to the maximum length of all sentencesmax_sequence_len = max([len(x) for x in input_sequences])input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))# create predictors and label# [0,0,1,2] -> 2 is label# [0,1,2,3] -> 3 is label# [1,2,3,4] -> 4 is labelxs, labels = input_sequences[:,:-1],input_sequences[:,-1]# one-hot encoding the labels (classification problem)ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\nmodel = Sequential()model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))model.add(Bidirectional(LSTM(20))) # take only 20 units (bi-direction) to trainmodel.add(Dense(total_words, activation='softmax'))model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])history = model.fit(xs, ys, epochs=500, verbose=1)\nseed_text = \"Laurence went to dublin\"next_words = 100for _ in range(next_words):\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\t# \"went to dublin\" -> [134, 13, 59]\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\t# [0, 0, 0, 0, 0, 0, 0, 134, 13, 59]\tpredicted = model.predict_classes(token_list, verbose=0)\toutput_word = \"\"\t# revert an index back to the word\tfor word, index in tokenizer.word_index.items():\t\tif index == predicted:\t\t\toutput_word = word\t\t\tbreak\t# add predicted word to the seed text and make another prediction\tseed_text += \" \" + output_wordprint(seed_text)# all the words are predicted based on the probability# next one will be less certain than the previous# -> less meaningful\n\nUsing more words will help.\n\n👉 Notebook 3 (more data)\n# read from a filetokenizer = Tokenizer()data = open('/tmp/irish-lyrics-eof.txt').read()corpus = data.lower().split(\"\\n\")\nA little changes from the previous,\nmodel = Sequential()model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))model.add(Bidirectional(LSTM(150)))model.add(Dense(total_words, activation='softmax'))adam = Adam(lr=0.01) # customized optimizermodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')history = model.fit(xs, ys, epochs=100, verbose=1)\n\nDifferent convernges can create different poetry.\nIf we use one-hot for a very big corpus -&gt; take a lot of RAM -&gt; use character-based prediction -&gt; #unique characters is far less than #unique words. -&gt; notebook &quot;Text generation with RNN&quot;\n\n👉 Notebook Using LSTMs, see if you can write Shakespeare!\n"},"/deeplearning-ai-tensorflow-course-4/":{"id":"/deeplearning-ai-tensorflow-course-4/","title":"TF 4 - Sequences, Time Series and Prediction","keywords":"deep learning ai coursera tensorflow google project python sequences time series sunspot activities circle NASA RNN Autocorrelation autocorrelated time series trend seasonality lambda layer sequence to vector sequence to sequence univariate multivariate learning rate LSTM callback recurrent layer moving average differencing metric train test validation set windowed dataset loss function Huber","tags":["posts","MOOC","deeplearning.ai","Deep Learning","TensorFlow"],"cat":"/img/cats/mooc.svg","content":"This is my note for the 4th course of TensorFlow in Practice Specialization given by deeplearning.ai and taught by Laurence Moroney on Coursera.\n👉 Check the codes on my Github.\n👉 Official notebooks on Github.\n👉 Go to course 1 - Intro to TensorFlow for AI, ML, DL.\n👉 Go to course 2 - CNN in TensorFlow.\n👉 Go to course 3 - NLP in Tensorflow.\n\n\nSequence models: focus on time series (there are others) -- stock, weather,...\nAt the end, we wanna model sunspot actitivity cycles which is important to NASA and other space agencies.\nUsing RNN on time series data.\n\nSequences and prediction #\nTime Series #\n👉 Notebook: introduction to time series. + explaining video. =&gt; How to create synthetic time series data + plot them.\n\n\nTime series is everywhere: stock prices, weather focasts, historical trends (Moore's law),...\nUnivariate TS and Miltivariate TS.\nType of things can we do with ML over TS:\n\nAny thing has a time factor can be analysed using TS.\nPredicting a focasting (eg. birth &amp; death in Japan -&gt; predict future for retirement, immigration, impacts...).\nImputation: project back into the past.\nFill holes in the data.\nNomalies detecction (website attacks).\nSpot patterns (eg. speed recognition).\n\n\nCommon patterns in TS:\n\n\nTrend: a specific direcion that they're moving in.\n\n\n\nSeasonality: patterns repeat at predictable intervals (eg. active users for a website).\n\n\n\nCombinition of both trend and seasonality.\n\n\n\nStationary TS.\n\n\n\nAutocorrelated TS: a time series is linearly related to a lagged version of itself.. There is no trend, no seasonality.\n\n\n\nMultiple auto correlation.\n\n\n\nMay be trend + seasonality + autorrelation + noise.\n\n\n\nNon-stationary TS:\n\nIn this case, we base just on the later data to predict the future (not on the whole data).\n\n\n\n\nTrain / Validation / Test #\n\n\nFixed partitioning (this course focuses on) = splitting TS data into training period, validation period and test period.\n\n\nIf TS is seasonal, we want each period contains the whole number of seasons.\n\n\n\n\n\nWe can split + train + test to get a model and then re-train with the data containing also the test period so that the model is optimized! In that case, the test set comes from the future.\n\n\n\nRoll-forward partitioning: we start with a short training period and we gradually increase it (1 day at a time or 1 week at a time). At each iteration, we train the model on training period, use it to focast the following day/week in the validation period. = Fixed partitioning in a number of times!\n\n\n\nMetrics #\nFor evaluating models:\nerrors = forecasts - actual# Mean squared error (square to get rid of negative values)# Eg. Used if large errors are potentially dangerousmse = np.square(errors).mean()# Get back to the same scale to errorrmse = np.sqrt(mse)# Mean absolute error (his favorite)# this doesn't penalize large errs as much as mse does,# used if loss is proportional to the size of errmae = np.abs(errors).mean()# Mean abs percentage err# idea of the size of err compared to the valuesmape = np.abs(errors / x_valid).mean()\n# MAE with TFkeras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy()\nMoving average and differencing #\n👉 Notebook: Forecasting. + explaining video.\nMoving average: a simple forecasting method. Calculate the average of blue lines within a fixed &quot;averaging windows&quot;.\n\nThis can eliminate noises and doesn't anticipate trend or seasonality.\nDepend on the &quot;averaging window&quot;, it can give worse result than naive forecast.\n\n\nTake the average on each yellow window. MAE=7.14 (optimal is 4).\ndef moving_average_forecast(series, window_size): \"\"\"Forecasts the mean of the last few values. If window_size=1, then this is equivalent to naive forecast\"\"\" forecast = [] for time in range(len(series) - window_size): forecast.append(series[time:time + window_size].mean()) return np.array(forecast)\nDifferencing: remove the trend and seasonality from the TS. We study on the differences between points and their previous neighbor in period.\n\nLeft image: we find the differencing of original values, then we find the average (orange line). Right image: restore the trend and seasonality. MAE=5.8 (optimal is 4).\nAbove method still get the noises (because we add the differencing to the previous noise). If we remove past noise using moving average on that.\n\nSmoothing both past and present values. MAE=4.5 (optimal is 4).\nKeep in mind before using Deep Learning, sometimes simple approaches just work fine!\nDeep NN for Time Series #\nPreparing features and labels #\n\nWe need to split our TS data into features and labels so that we can use them in ML algos.\nIn this case: features=#values in TS, label=next_value.\n\nFeature: window size and train to predict next value.\nEx: 30 days of values as features and next value as label.\nOvertime, train ML to match 30 features to match a single label.\n\n\n\n👉 Notebook: Preparing features and labels.\n👉 Video explains how to split to features and labels from dataset.\ndef windowed_dataset(series, window_size, batch_size, shuffle_buffer): dataset = tf.data.Dataset.from_tensor_slices(series) dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True) dataset = dataset.flat_map(lambda window: window.batch(window_size + 1)) dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1])) dataset = dataset.batch(batch_size).prefetch(1) return dataset\nExplaine the codes# create a very simple datasetdataset = tf.data.Dataset.range(6)arr = [val.numpy() for val in dataset]print(arr)# [0, 1, 2, 3, 4, 5]\n# make equal (drop_remaninder) windowsdataset = dataset.window(5, shift=1, drop_remainder=True)dataset = dataset.flat_map(lambda window: window.batch(5)) # instead of val.numpy for each val in each windowfor window in dataset: print(window.numpy())# [0 1 2 3 4]# [1 2 3 4 5]\n# split the last value to be labeldataset = dataset.map(lambda window: (window[:-1], window[-1:]))# [0 1 2 3] [4]# [1 2 3 4] [5]\n# shuffledataset = dataset.shuffle(buffer_size=6)# construct batch of 2dataset = dataset.batch(2).prefetch(1)# x = [[1 2 3 4], [0 1 2 3]]# y = [[5], [4]]\n\nSequence bias #\nSequence bias is when the order of things can impact the selection of things. It's ok to shuffle!\nFeeding windowed datasets into NN #\n👉 Notebook: Single layer NN + video explains it.\n# Simple linear regression (1 layer NN)dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)l0 = tf.keras.layers.Dense(1, input_shape=[window_size])model = tf.keras.models.Sequential([l0])model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))model.fit(dataset,epochs=100,verbose=0)print(\"Layer weights {}\".format(l0.get_weights()))forecast = []for time in range(len(series) - window_size): forecast.append(model.predict(series[time:time + window_size][np.newaxis])) # np.newaxis: reshape X to input dimension that used by the modelforecast = forecast[split_time-window_size:]results = np.array(forecast)[:, 0, 0]\n👉 Notebook: DNN with TS + video explains it.\n# A way to choose an optimal learning ratelr_schedule = tf.keras.callbacks.LearningRateScheduler( lambda epoch: 1e-8 * 10**(epoch / 20))optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)model.compile(loss=\"mse\", optimizer=optimizer)history = model.fit(dataset, epochs=100, callbacks=[lr_schedule], verbose=0)\n\nlrs = 1e-8 * (10 ** (np.arange(100) / 20))plt.semilogx(lrs, history.history[\"loss\"])plt.axis([1e-8, 1e-3, 0, 300])\n\nLoss w.r.t different learning rates. We choose the lowest one, around 8e-6.\n\n👉 Notebook: DNN with synthetic TS.\nRNN for TS #\n\n\nRRN is a NN containing Recurrent layer.\nThe different from DNN is the input shape is 3 dimensional (batch_size x #time_step x dims_input_at each_timestep).\nRe-use 1 cell multiple times in different layers (in this course).\n\n\nIdea of how RNN works with TS data. The current location can be impacted more by the nearby locations.\nShape of input to RNN #\n👉 Video explains the dimensional and sequence-to-vector RNN.\n\n\nSuppose: window size of 30 time steps, batch size of 4: Shape will be 4x30x1 and the memory cell input will be 4x1 matrix.\nIf the memory cell comprises 3 neurons then the output matrix will be 4x3. Therefore, the full output of the layer will be 4x30x3.\nHiH_iHi​ is just a copy of YiY_iYi​.\nBelow figure: input and also output a sequence.\n\n\nDimension of input to RNN.\nSequence to vector RNN #\n\n\nSometimes, we want only input a sequence but not output. This called sequence-to-vector RNN. I.E., ignore all of the outputs except the last one!. In tf.keras, it's default setting!\n\n\nSequence to vector RNN.\n# Check the figure below as an illustrationmodel = tf.keras.models.Sequential([tf.keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]), # input_shape: # TF assumes that 1st dim is batch size -> any size at all -> no need to define # None -> number of time steps, None means RNN can handle sequence of any length # 1 -> univariate TStf.keras.layers.SimpleRNN(20), # if there is `return_sequences=True` -> sequence-to-sequence RNNtf.keras.layers.Dense(1),])\n\nIllustration with keras.\nLambda layer #\n👉 Video explains the use of lambda layer in RNN..\nmodel = tf.keras.models.Sequential([ tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), # expand to 1 dim (from 2) so that we have 3 dims: batch size x #timesteps x series dim input_shape=[None]), # can use any size of sequences tf.keras.layers.SimpleRNN(40, return_sequences=True), tf.keras.layers.SimpleRNN(40), tf.keras.layers.Dense(1), tf.keras.layers.Lambda(lambda x: x * 100.0) # default activation in RNN is tanh -> (-1, 1) -> scale to -100, 100])\nSimple RNN #\n\n\nLoss function Huber (wiki): less sensitive to outliers. =&gt; we use this because our data in this case get a little bit noisy!\n\n👉 Notebook: Simple RNN with a TS data + videos explains it.\nLSTM #\n👉 Notebook: LSTM with a TS data + videos explains it.\n# clear internal variablestf.keras.backend.clear_session()dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)model = tf.keras.models.Sequential([ tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[None]), # LSTM here tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)), tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)), tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)), # tf.keras.layers.Dense(1), tf.keras.layers.Lambda(lambda x: x * 100.0)])\n👉 Notebook: LSTM with synthetic TS.\nReal-world time series data #\n\n\nWe are going to predict the sunspot actitivity cycles (download dataset).\nCombine CNN + LSTM.\n\n👉 Andrew's video on Optimization Algo: Mini-batch gradient descent.\n👉 Notebook: Sunspot dataset with CNN+LSTM. + video explains it.\n👉 Notebook: Sunspot dataset with DNN only + explaining video.\n👉 Video explains train &amp; tune the model (how to choose suitable values for sizes)\n"},"/docker-wsl2-windows/":{"id":"/docker-wsl2-windows/","title":"WSL 2 on Windows","keywords":"wsl wsl2 windows subsystem linux windows terminal zsh oh my szh jekyll ruby bundle vscode","tags":["posts","MLOps","Windows"],"cat":"/img/cats/mlops.svg","content":"WSL on Windows #\n👉 Main tutorial.\n# Eanble Windows Subsystem for Linux# PowerShell as Admindism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart# Enable Virtual Machine Platform (for WSL2)dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart# restart required\n# Download and install WSL2 Linux kernel update package for x64 machineshttps://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi\n# Set WSL2 as default version# PowerShell as Adminwsl --set-default-version 2\n# Go to Windows Store# Choose a Linux Distro and install it\nLocation #\n\nThe C drive is located in /mnt/c/.\nThe Download folder is located in /mnt/c/Users/dinha/Downloads/.\nOpen current folder (in WSL2) with Windows Explorer: explorer.exe ..\n\nDependencies #\nsudo apt-get updatesudo apt-get install git-core curl wget fontconfig zlib1g-dev build-essential libssl-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libcurl4-openssl-dev software-properties-common libffi-dev\nWindows Terminal &amp; Zsh #\n👉 Install Windows Terminal + some things with this note.\nChange default setting theme to Linux Distro!\n# Install Zshsudo apt-get install zshzsh --version# make defaultsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"# exit all windows and reopen# check versionecho $SHELL # /usr/bin/zsh or similar\nContinue to this note with following remarks:\n\nYou have to install all the fonts suggested in that note (just for sure).\nYou have to install MS's cascadia-code font (download zip and install all files there manually). Then you choose from Windows Terminal or cmder the font face is Cascadia Code PL.\nThis article may be interesting also.\n\nJekyll on WSL2 #\nRemark: We should clone a new version from Github to the local (inside wsl) machine.\nsudo apt-get install -y ruby-full build-essential zlib1g-devwhich ruby# Make sure we don't use gem on Windows systemwhich gem # /usr/bin/rubysource ~/.zshrc# restart Windows Terminalsudo gem install bundler# cd to jekyll theme folderbundle install# continue as usualbundle exec jekyll build # 1st time after installingbundle exec jekyll servebundle exec jekyll serve -I\n# Troubleshoot: Could not find a JavaScript runtimesudo apt-get install libv8-devbundle update# install nodejscurl -sL https://deb.nodesource.com/setup_14.x | bash -sudo apt-get install -y nodejs\n# Troubleshoot: wsl2 jekyll auto generation windows# Clone a repo to wsl local, not clone by git on Windows!\nVSCode + WSL2 + jekyll #\n\nInstall extension Remote-WSL\nConnect via Debian instead! (&gt;&lt;SWL: Debian)\n\nWSL with cmder #\nSettings &gt; Startup &gt; Tasks &gt; +\n# for debianset PATH=\"%ConEmuBaseDirShort%\\wsl\";%PATH% &amp; wsl -d debian# for ubuntuset PATH=\"%ConEmuBaseDirShort%\\wsl\";%PATH% &amp; wsl -d ubuntu\nChoose font Cascadia Code in General &gt; Fonts.\n"},"/nodejs-npm/":{"id":"/nodejs-npm/","title":"NodeJS & NPM","keywords":"js javascript package management Node Package Manager","tags":["posts","JavaScript"],"cat":"/img/cats/js.svg","content":"Install NodeJS &amp; NPM #\nInstall NodeJS and NPM.\n\nWindows &amp; MacOS: download installer.\nLinux: this guide.\n\nUpdate to latest version?\n# npmnpm cache clean -f # clear the cache firstsudo npm install -g npm\n# nodesudo npm install -g nsudo n stable# refresh the shellsource ~/.zshrc # if using zshsource ~/.bashrc # is using bash\nCheck version?\nnpm -vnode -v\nShorthand #\n\n\ni: install\n-D: --save-dev (devDependencies)\n-P: --save-prod (default), --save\n-g: --global\n-f: --force\nls: list\n\n\nInstall package #\n👉 Official documentation.\nnpm install package_name # if it's in package.json, the indicated version will be installed # otherwise, the newsest version will be installednpm install --global package_name # global package\n# install all package in package.jsonnpm install\n# install + save to package.jsonnpm install --save package_name # save to package.jsonnpm install --save-dev package_name # save to package.json, in devDependenciesnpm install --no-save package_name # don't save\n# install with versionnpm install express@4.16.1\n# list all installed packages (current project only)ls node_modules\n# list all local (installed) packagesnpm list # -g for globel # or use \"ls\"npm list --depth=0 # without dependencies# Check the current version of a (installed) packagenpm list package_name # with \"-g\" for global# Check the latest (not current) version of a packagenpm view package_name version\nUpdate package #\n# which global packages need to be updated?npm outdated -g --depth=0# update all global packagesnpm update -g\n# update a packagenpm update package_name # -g for global\nRemove package #\nnpm uninstall package\n"},"/11ty-nunjucks/":{"id":"/11ty-nunjucks/","title":"11ty + Nunjucks","keywords":"create a website static web 11ty js Nunjucks mozilla template language liquid eleventy nextjs netlify google fonts bootstrap scss css layout web design ssg static site generator static website include template github pages frontmatter markdown code syntax highlight mathjax math markdown-it plugin editor incremental build nunjuck mozilla shortcodes","tags":["posts","Web Dev","Static Site Generators","11ty"],"cat":"/img/cats/web-dev.svg","content":"\nThis is not a tutorial to create an 11ty website, this's a note! You can find some very new and useful techniques on this note alongside the official documentation.\n\n\nThis note will be always updated!\n\nInstallation #\n👉 First, install nodejs.\n👉 Using this starter template or Google's high performance statrer theme (recommended).\n# Install dependenciesnpm install\nDepend on each theme, you should follow the installation step given in that theme.\nSetting up with Netlify #\nSometimes, 11ty takes too much time to build (especially on the task of optimizing images, on my site, it takes almost 10m). You shouldn't use branch master to build you site because every time you make a push, Netlify will rebuild your whole site. You should create and use a new branch, so-called prod instead.\nIdea 1 -- manually build but should not use many timesOn Netlify, go to Site settings &gt; Build &amp; deploy:\n\n\nBuild settings:\n\nBuild command: npm run build (depends on your site)\nPublish directory: _site (depends on your site)\nBuilds: Active builds\n\n\nDeploy contexts:\n\nProduction branch: prod (the same as the your created branch)\nDeploy previews: Don't deploy pull requests (you don't want someone pull request and it auto make a deploy)\nBranch deploys: Deploy only the production branch.\n\n\n\n\nThe weakness of Idea 1 is that you let netlify build again your whole site with its resources. That's why it takes too much time! Remember that, you have only 300 free minutes to build.\nIdea 2 -- build locally and push _site onlyYou should know that, even if you site contains only html files, netlify is able to make it live as usual.\n\n\nWorking mainly on branch _dev like in Idea 1.\n\n\nCreate a branch, so-called _site from dev. In this branch, delete all folders except _site, node_modules, .git, .gitignore.\n\n\nModify .gitignore (exclude all except _site folder to push to github),\n/*/*/!/_site/\n\n\nNow, we tell netlify build our site from branch _site (which contains html files only so it doesn't take time to build anything, it's really fast!)\n\nBuild settings:\n\nBase directory: Not set.\nBuild command: Not set.\nPublish directory: _site/\nBuilds: Active.\n\n\nDeploy context:\n\nProduction branch: site\nDeploy previews: Don’t deploy pull requests\nBranch deploys: Deploy only the production branch\n\n\n\n\n\n\nExample workflow with dinhanhthi.comFrom the main repo, I clone to 2 different folders\n|- dinhanhthi.com # &lt;- branch \"dev\"|- dat.com \t\t\t\t# &lt;- branch \"_site\"\nOn dat.com, I create a script called ud_site.sh which contains,\necho \"Start building site\"cd ../dinhanhthi.com/npm run buildcd ../dat.com/echo \"Start copying....\"cp -Rf ../dinhanhthi.com/_site/* _site/echo \"End copying\"git add .git commit -m \"Updated: `date +'%Y-%m-%d %H:%M:%S'`\"git push\nFor covenience, I create an alias in bash shell,\nalias update_dat='cd ~/git/dat.com &amp;&amp; sh ud_site.sh &amp;&amp; cd -1'\nFrom now, whenever I wanna build and deploy my site on netlify, I just run,\nupdate_dat\nI saved from 1h of building to 2m of building on netlify with this method!\n\nSCSS to CSS #\nIf you use rollup (like this site)\n# Folder's structurecss/main.scsscss/components/_fonts.scsscss/components/....css/main_input.js\n// package.json{ \"scripts\": { \"js-build\": \"rollup -c rollup.config.js\", }}\n\nimport scss from 'rollup-plugin-scss';export default [ { // plugin 1 }, { input: 'css/main_input.js', // where the input file containing import of main.scss output: { file: 'css/main.js', // intermediate file which can be translated to css/main.css format: 'esm' // still not know }, plugins: [ scss() // there are other configs ] }];\n\nIf you use parcel\n# installnpm i parcel-bundlernpm i npm-run-all -D\n# folder structure_assets/css/main.scss___________/_bootstrap.scss_______/js/main.js\n\n\n# main.scss@import \"./bootstrap\";\n# main.jsimport \"./../css/main.scss\";\n\n# package.json\"scripts\": { \"start\": \"npm-run-all --parallel dev:*\", \"build\": \"run-s prod:*\", \"dev:eleventy\": \"eleventy --serve\", \"dev:parcel\": \"parcel watch ./_assets/js/main.js --out-dir ./_site/assets\", \"prod:eleventy\": \"eleventy\", \"prod:parcel\": \"parcel build ./_assets/js/main.js --out-dir ./_site/assets\",},\n# runnpm start\n\nBootstrap + 11ty #\n👉 Bootstrap's homepage\n👉 How to Isolate Bootstrap CSS to Avoid Conflicts (using LESS) | Formden.com\n# installnpm i bootstrap jquery popper.js\nUsing alongside with section &quot;SCSS to CSS&quot;.\n\n# folder structure_assets/css/main.scss_______/vender/_bootstrap.scss\n// main.scss@import \"./vender/bootstrap\";\n\n// _bootstrap.scss// all components// @import \"./../../../node_modules/bootstrap/scss/bootstrap.scss\";// Required// check more: https://getbootstrap.com/docs/4.5/getting-started/theming/#importing@import \"./../../../node_modules/bootstrap/scss/functions\";@import \"./../../../node_modules/bootstrap/scss/variables\";@import \"./../../../node_modules/bootstrap/scss/mixins\";\nLayout #\n\nmkdir _includes/layoutstouch _includes/layouts/post.njk\n// create an aliasmodule.exports = function(eleventyConfig) { eleventyConfig.addLayoutAlias('post', 'layouts/post.njk');};\n# update changestouch .eleventy.js\n# then use---layout: post---\n\nIncludes #\nSplit layout into parts and include them in the main file.\n// in _includes/components/head.njk{% include \"components/head.njk\" %}// custom parameter{% set customClass = 'list-homepage' %}{% include \"postslist.njk\" %}// inside postlist.njk, just use {{ customClass }}\nTemplate inheritance #\nRead this tutorial.\n\n&lt;!-- _includes/layouts/base.njk -->&lt;body> &lt;header> &lt;/header>&lt;/body>\n&lt;!-- _includes/layouts/post.njk -->------{% extends \"layouts/base.njk\" %}{% block headerLogo%} &lt;!-- only appear on post layout -->{% endblock %}\n\nTemplating #\nPost's components #\n👉 Page variable components.\n// URL can be used in &lt;a href> to link to other templatesurl: \"/current/page/myFile/\",// For permalinks: inputPath filename minus template file extension (New in v0.3.4)fileSlug: \"myFile\",// For permalinks: inputPath minus template file extension (New in v0.9.0)filePathStem: \"/current/page/myFile\",// JS Date Object for current page (used to sort collections)date: new Date(),// The path to the original source file for the template// Note: this will include your input directory path!inputPath: \"./current/page/myFile.md\",// Depends on your output directory (the default is _site)// You probably won’t use this: `url` is better.outputPath: \"./_site/current/page/myFile/index.html\"templateContent: //the rendered content of this template. This does not include layout wrappers.data: // all data for this piece of content (includes any data inherited from layouts)// self-defined frontmatter tags can be found here\n\nFor ones who wanna get only the content (escape HTML tags and special characters) of the post:\n{{ page.templateContent | dump | safe | striptags(true) }}\n\nFrontmatter #\n\n---title: Title of the postdescription: description of the postdate: 2020-09-11layout: layouts/post.njk---\n---tags: - default# ortags: [tag 1, tag 2]---\n\nList of post #\nNormal,\n&lt;ul>{% for post in collections.posts %} &lt;li> &lt;a href=\"{{ post.url | url }}\"> {{ post.data.title }} &lt;/a> &lt;/li>{% endfor %}&lt;/ul>\n\nOther default variable (like post.url) can be found here. Note that, you can use page.templateContent for the content of a page in some collections (not tested yet but you can try![ref]).\n\nSort by title,\n&lt;!-- Create a new list -->{% set newPostList = [] %}{% for post in collections.posts %} {% set newPostList = (newPostList.push({title: post.data.title, url: post.url}), newPostList) %}{% endfor %}&lt;!-- list of post by alphabet -->&lt;ul>{% for post in newPostList|sort(attribute='title') %} &lt;li> &lt;a href=\"{{ post.url | url }}\"> {{ post.title }} &lt;/a> &lt;/li>{% endfor %}&lt;/ul>\nCustom js scripts #\n\n# Put scripts in# /src/main.js\n&lt;!-- in &lt;head> -->&lt;script async defer src=\"{{ '/js/min.js' | addHash }}\">&lt;/script>\n\nUsing rollupjs,\n// rollup.config.jsexport default [ { input: \"src/main.js\", output: [ { file: \"js/min.js\", format: \"iife\", sourcemap: true, plugins: [terser()], }, ], }];\nGoogle Fonts #\n\nPut fonts in fonts/ and use this tool to generate .woff, woff2 from Google Fonts. Be careful on the location will be used on your site.\nCopy and paste to css/main.scss.\nIf you have a problem with Content-Security-Policy, check this section.\n\nLast modified date #\n// .eleventy.jsconst { DateTime } = require(\"luxon\");module.exports = function (eleventyConfig) { eleventyConfig.addFilter(\"readableDate\", (dateObj) => { return DateTime.fromJSDate(dateObj, { zone: \"utc\" }).toFormat( \"dd LLL yyyy\" ); }); // https://html.spec.whatwg.org/multipage/common-microsyntaxes.html#valid-date-string eleventyConfig.addFilter(\"htmlDateString\", (dateObj) => { return DateTime.fromJSDate(dateObj, { zone: \"utc\" }).toFormat(\"dd-LL-yyyy\"); }); eleventyConfig.addFilter(\"sitemapDateTimeString\", (dateObj) => { const dt = DateTime.fromJSDate(dateObj, { zone: \"utc\" }); if (!dt.isValid) { return \"\"; } return dt.toISO(); });}\nLast modified date,\n{{ page.inputPath | lastModifiedDate | htmlDateString }}\nInsert code highlight #\nCode syntax highlight: Need this plugin. List of supported languages.\n\n# Highlight line 2``` js/2// lines of codes```\n# Highlight line 2 to 4``` js/2-4// lines of codes```\n# Highlight line 2, 4``` js/2,4// lines of codes```\n# Delete line 2 (red highlight)# and add line 4 (green highlight)``` js/4/2// lines of codes```\n\nInsert liquid / nunjuck code #\nInline code, put {% raw %} and {% endraw %} around the keyword.\nCode block,\n~~~ js {% raw %}// line of codes{% endraw %}~~~\nNext / Previous post #\n&lt;ul> {%- set nextPost = collections.posts | getNextCollectionItem(page) %} {%- if nextPost %}&lt;li>Next: &lt;a href=\"{{ nextPost.url | url }}\">{{ nextPost.data.title }}&lt;/a>&lt;/li>{% endif %} {%- set previousPost = collections.posts | getPreviousCollectionItem(page) %} {%- if previousPost %}&lt;li>Previous: &lt;a href=\"{{ previousPost.url | url }}\">{{ previousPost.data.title }}&lt;/a>&lt;/li>{% endif %}&lt;/ul>\nMath equations #\nKaTeX: using markdown-it-katex (use this version only),\n// .eleventy.jsconst markdownIt = require(\"markdown-it\");const markdownItKatex = require('@iktakahiro/markdown-it-katex');let markdownLibrary = markdownIt()markdownLibrary.use(markdownItKatex);\n&lt;!-- inside &lt;head> -->&lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css\">\nMathjax: using markdown-it-mathjax\n💡 Some tips: working with KaTeX\n\n# working$$\\dfrac{1}{2}$$\n# not working- Item\t$$\t\\dfrac{1}{2}\t$$- Item\n# working again- Item $$\\dfrac{1}{2}$$ # without \\n- Item\n\nFigures #\n\n# Insert normally,![description](/path/to/image){% enraw %}\n# With custom classes (using markdown-it-attrs)![](){:.custom-class}\n\nMarkdown #\nmarkdown-it &amp; its plugins #\nWe use markdown-it and its plugins.\n\nMy choices of useful plugins\n\nJust use npm i &lt;plugin-name&gt; --save-dev to install.\n// .eleventy.jsconst markdownIt = require(\"markdown-it\");module.exports = function (eleventyConfig) { let markdownLibrary = markdownIt({ html: true, // html tag inside source breaks: true, // use '\\n' as &lt;br> linkify: true, // Autoconvert URL-like text to links }) .use(require(\"markdown-it-anchor\"), { permalink: true, permalinkClass: \"direct-link\", permalinkSymbol: \"#\", }) .use(require('markdown-it-mark')) // ==mark== .use(require('markdown-it-attrs'), { // use {:} options leftDelimiter: '{:', rightDelimiter: '}' }) .use(require(\"markdown-it-emoji\")) // emoji .use(require(\"markdown-it-table-of-contents\")) // [[toc]] (no spaces) .use(require('@iktakahiro/markdown-it-katex')) // katex .use(require(\"markdown-it-task-lists\")) // tasks [x] .use(require('markdown-it-container'), 'success') // use `::: success` bock to create a custom div .use(require('markdown-it-kbd')) // [[Ctrl]] .use(require('markdown-it-footnote')) .use(require('@gerhobbelt/markdown-it-inline-text-color')) ; eleventyConfig.setLibrary(\"md\", markdownLibrary);}\n\n\n\nHow to use markdown-it's plugins in 11ty?\n\nBelow are an example of inserting 2 plugins,\n// .eleventy.js// An example of using pluginsconst markdownIt = require(\"markdown-it\");var markdownItp = require('markdown-it')();module.exports = function (eleventyConfig) { let markdownLibrary = markdownIt({ html: true, // html tag inside source breaks: true, // use '\\n' as &lt;br> linkify: true, // Autoconvert URL-like text to links }) .use(require(\"markdown-it-emoji\")) // emoji .use(require(\"markdown-it-table-of-contents\")) // [[toc]] (no spaces) ; eleventyConfig.setLibrary(\"md\", markdownLibrary);}\n\n\nCustom container #\nIf you wanna create an advanced custom container, use plugin markdown-it-container. For example, you want export something like,\n&lt;div class=\"hsbox\"> &lt;div class=\"hs__title\"> &lt;!-- Custom Title --> &lt;/div> &lt;div class=\"hs__content\"> &lt;!-- Custom markdown texts -->&lt;/div>\nJust by using,\n::: hsbox Custom TitleCustom markdown texts:::\nYou can put in .eleventy.js like,\n.use(require('markdown-it-container'), 'hsbox', { validate: function (params) { return params.trim().match(/^hsbox\\s+(.*)$/); }, render: function (tokens, idx) { var m = tokens[idx].info.trim().match(/^hsbox\\s+(.*)$/); if (tokens[idx].nesting === 1) { // opening tag return '&lt;div class=\"hsbox\">&lt;div class=\"hs__title\">' + markdownItp.renderInline(m[1]) + '&lt;/div>&lt;div class=\"hs__content\">'; } else { // closing tag return '&lt;/div>&lt;/div>'; } }})\nMarkdown inside .njk #\n\n// .eleventy.jsmodule.exports = function (eleventyConfig) { eleventyConfig.addPairedShortcode(\"markdown\", (content, inline = null) => { return inline ? markdownLibrary.renderInline(content) : markdownLibrary.render(content); });}\n{% markdown %}&lt;!-- html tags -->&lt;!-- no need spaces before/after -->{% endmarkdown %}\n\nHTML/nunjucks tags inside .md #\n\n&lt;!-- not working -->&lt;div> __abc__&lt;/div>\n&lt;!-- working -->&lt;div> __abc__&lt;/div>\n&lt;!-- not working -->&lt;div class=\"list-of\"> &lt;/div>\n&lt;!-- working -->&lt;div class=\"list-of\">&lt;/div>\n\nCustom block shortcodes #\n\n\nTo creata the same code block like above, i.e.,\n&lt;div class=\"hsbox\"> &lt;div class=\"hs__title\"> &lt;!-- Custom Title --> &lt;/div> &lt;div class=\"hs__content\"> &lt;!-- Custom markdown texts -->&lt;/div>\n\n\nJust by using,\n{% hsbox \"Custom Title\" %}&lt;!-- Custom markdown texts -->{% endhsbox %}\n\n\n// .eleventy.jsmodule.exports = function (eleventyConfig) { eleventyConfig.addPairedShortcode(\"hsbox\", (content, title) => { return '&lt;div class=\"hsbox\">&lt;div class=\"hs__title\">' + markdownLibrary.renderInline(title) + '&lt;/div>&lt;div class=\"hs__content\">' + markdownLibrary.render(content) + '&lt;/div>&lt;/div>'; });}\nCustom inline shortcodes #\nIf you wanna export something like,\n&lt;a href=\"custom-url\">ref&lt;/a>\nby using {% ref &quot;custom-url&quot; %} (&quot;&quot; is required). You can set,\n// .eleventy.jsmodule.exports = function (eleventyConfig) { eleventyConfig.addShortcode(\"ref\", function(url) { return '&lt;sup>&lt;a href=\"' + url + '\" rel=\"noopener noreferrer\" target=\"_blank\">[ref]&lt;/a>&lt;/sup>'; });}\nSearch #\nFor me, the best choice for search feature in 11ty is using Elasticlunr with some customizations.\nWhy not others?Based on the purpose of free, quick, full text search:\n\nWe don't choose Google's Programmable Search because: it contains ads, not index as we want, difficult to customize with personal theme,...\nWe don't choose paid options like Agolia because the free option contains very few units. It's absolutely not enough for your need. In case you still want to use it with less consumption, read this article.\n\n\nBecause your site becomes bigger in future, you cannot index the whole text of your site (every time you build). My idea is to create a custom frontmatter tag called &quot;keywords&quot; which contains all of the important keywords used to determine the content of your posts. Of course, the cons is that you have to put the keywords manually!!\nCheck this repository, I've pulled and modified from this one (The author takes so long to check my pull request ^^). My customization supports:\n\nIndex your customizable keywords.\nFix UX bugs in the main repo.\nHighlight found keywords in the search result.\nLimit the max number of texts in the result (show around the found keywords).\nAdapt to the newest version of 11ty.\n\nData files #\n// .eleventy.jsmodule.exports = function (eleventyConfig) { return { dir: { input: \".\", includes: \"_includes\", data: \"_data\", output: \"_site\", }, }}\nYou put all your data files (.js or .json) in _data, e.g.,\n\n// _data/dataUrls.json[ { \"name\": \"abc\", \"url\": \"http://abc.com\" }, { \"name\": \"xyz\", \"url\": \"http://xyz.com\" }]\n&lt;!-- in a .njk file -->{% for item in dataUrls %} {{ item.name }} {{ item.url }}{% endfor %}\n\nFor example, export a current year on site,\n\n// _data/helpers.jsmodule.exports = { currentYear() { const today = new Date(); return today.getFullYear(); }}\n&lt;!-- in a .njk file -->&lt;div>{{ helpers.currentYear() }}&lt;/div>\n\nWorking style #\nCustom environment #\nMore info, read official doc. For example, we only perform something differently on local.\n{ \"scripts\": { \"local-build\": \"ELEVENTY_ENV=local eleventy\" }}\nAn example of using in .eleventy.js,\n// .eleventy.jsmodule.exports = { environment: process.env.ELEVENTY_ENV};module.exports = function (eleventyConfig) { if (process.env.ELEVENTY_ENV == \"local\"){ // do something locally } else { // do something on server }}\nOr using in the template,\n\n// _data/myProject.jsmodule.exports = { environment: process.env.ELEVENTY_ENV};\n{% if myProject.environment == \"local\" %} &lt;style>{{ css | cssmin | safe }}&lt;/style>{% else %} &lt;style>{{ css | safe }}&lt;/style>{% endif %}\n\nIncremental build #\nIt's impossible for the current version (^0.11.0)! (Follow the main project).\nWeakness of 11ty:\n\n\nThere is some change in files, 11ty rebuilds the whole site. It's painful if we work with markdown files and save them regularly!\nCannot access the site while the building processing.\n\nIdea:\n\n\nBuild manually, e.g. npm run build-local to _site folder.\nCopy all files in _site to a so-called folder _live\nRun a custom server on folder _site (install npm i http-server -g first)\n\nAn example of scripts,\n{ \"scripts\": { \"local-build\": \"ELEVENTY_ENV=local eleventy &amp;&amp; mkdir -p _live &amp;&amp; cp -Rf _site/* _live/\", \"local-serve\": \"mkdir -p _live &amp;&amp; cp -Rf _site/* _live/ &amp;&amp; http-server _live\", }}\nErrors #\n# TypeError: Cannot read property 'type' of undefined# => Class comes before ![]() of an image!\n# EISDIR: illegal operation on a directory# Solution:# Delete _site/ and rebuild!\n# ENOTDIR: not a directory...# Solution:# Delete _site/ and rebuild!\nReferences #\n\n\nOfficial website.\nNunjucks Documentation\nMoving from WordPress to Eleventy\nFrom Jekyll to Eleventy - Webstoemp\nCreating an 11ty Plugin - SVG Embed Tool - bryanlrobinson.com\n\n"},"/tensorflow/":{"id":"/tensorflow/","title":"Tensorflow extra","keywords":"device gpu cuda nvidia graphical device torch deep learning neural network dell xps 7590 gpu install nvidia installation torch docker nvidia-docker nvidia-container-runtime packages","tags":["posts","Deep Learning"],"cat":"/img/cats/dl.svg","content":"Check if GPU available? #\n# check if GPU available?import tensorflow as tftf.config.list_physical_devices('GPU')\nInstallation with docker #\n👉 Official guide.\n👉 Docker &amp; GPU note.\nThe advantage of this method is that you only have to install GPU driver on the host machine.\nNote about docker versionCheck docker version: docker --version:\n\n&lt;19.03: requires nvidia-docker2 (check by nvidia-docker version) and --runtime=nvidia.\n&gt;=19.03: requires nvidia-container-toolkit (check by which nvidia-container-toolkit) and --gpus all.\n\nWithout docker-compose #\n👉 Different types of images for tensorflow.\n# pull the imagedocker pull tensorflow/tensorflow:latest-gpu-jupyter# run a containermkdir ~/Downloads/test/notebooksdocker run --name docker_thi_test -it --rm -v $(realpath ~/Downloads/test/notebooks):/tf/notebooks -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter\n# check if gpu available?nvidia-smi# check if tf2 working?docker exec -it docker_thi_test bashpython\nimport tensorflow as tftf.config.list_physical_devices('GPU')\nWith docker-compose? #\n👉 Read this note instead.\nOn Windows WSL2 #\nInstall directly on Linux (without docker) #\nOn my computer, Dell XPS 15 7590 - NVIDIA® GeForce® GTX 1650 Mobile.\n{:.alert.alert-danger}\nThis section is not complete, the guide is still not working!\nInstallation #\n👉 GPU support : TensorFlow\nThis guide is specific for:\npip show tensorflow # 2.3.1pip show tensorflow-gpu # 2.3.1nvidia-smi # NVIDIA-SMI 450.80.02 Driver Version: 450.80.02 CUDA Version: 11.0\n👉 PyTorch note.\n👉 Ubuntu note.\n👉 Linux note.\nCUDA Toolkit:\n\nIf you meet Existing package manager installation of the driver found, try this method to remove some already-installed packages before continuing.\nOr you can download cuda toolkit .run and then run\n\nsudo sh cuda_11.1.0_*.run --toolkit --silent --override\nErrors? #\n# Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\nNeed to install new cuda &amp; CUDNN libraries and tensorflow. (This note is for tensorflow==2.3.1 and CUDA 11.1). [ref]\n# update pathexport PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib\\ ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}# quickly test cuda versionnvcc --version\n"},"/docker-gpu/":{"id":"/docker-gpu/","title":"Docker + GPUs","keywords":"pybash tania rascia CI CD continuous integration deployment pipeline docker idea how to use airflow kubernetes k8s k apache container images dangling images vscode vsc visual studio code ssh container env environnement file variable nvidia docker runtime gpus tensorflow torch","tags":["posts","MLOps"],"cat":"/img/cats/mlops.svg","content":"👉 Note: Docker 101\n👉 Note: Wordpress Docker\n👉 Note: Airflow + Kubernetes 101\n👉 Note: Tensorflow extra\nWSL + Windows #\nMake WSL2 recognize GPU on Windows 10 👉 Check this tut.\nIf you meet error &quot;Your insider preview build settings need attention&quot;, restart many times don't solve the problem. 👉 Go to Account setting, then choose &quot;Verify&quot;.\nWith Tensorflow or PyTorch #\n👉 Official doc for TF + docker\n👉 My note for docker + TF.\n👉 An example of docker pytorch with gpu support.\nBasic installation #\nIt works perfectly on Pop!_OS 20.04,\nsudo apt updatesudo apt install -y nvidia-container-runtimesudo apt install -y nvidia-container-toolkitsudo apt install -y nvidia-cuda-toolkit# restard required\nCheck info #\n# verify that your computer has a graphic cardlspci -nn | grep '\\[03'\n# First, install drivers and checknvidia-smi# output: NVIDIA-SMI 450.80.02 Driver Version: 450.80.02 CUDA Version: 11.0# it's maximum CUDA version that your driver supports\n# check current version of cudanvcc --version# If there is not nvcc, it may be in /usr/local/cuda/bin/# Add this location to PATH# modify ~/.zshrc or ~/.bashrcexport PATH=/usr/local/cuda/bin:$PATH# You may need to installsudo apt install -y nvidia-cuda-toolkit\n# install and check nvidia-dockerdpkg -l | grep nvidia-docker# ornvidia-docker version\n# Verifying –gpus option under docker rundocker run --help | grep -i gpus# output: --gpus gpu-request GPU devices to add to the container ('all' to pass all GPUs)\n# Listing out GPU devicesdocker run -it --rm --gpus all ubuntu nvidia-smi -L# output: GPU 0: GeForce GTX 1650 (...)\n# Verifying again with nvidia-smidocker run -it --rm --gpus all ubuntu nvidia-smi\n# test a working setup container-toolkitdocker run --rm --gpus all nvidia/cuda nvidia-smi\n# test a working setup container-runtimedocker run --runtime=nvidia --rm nvidia/cuda nvidia-smi# Error response from daemon: Unknown runtime specified nvidia.# Search below for \"/etc/docker/daemon.json\"# Maybe it helps.\nInstall nvidia-docker2 #\nMore information (ref)\nThis package is the only docker-specific package of any of them. It takes the script associated with the nvidia-container-runtime and installs it into docker's /etc/docker/daemon.json file for you. This then allows you to run (for example) docker run --runtime=nvidia ... to automatically add GPU support to your containers. It also installs a wrapper script around the native docker CLI called nvidia-docker which lets you invoke docker without needing to specify --runtime=nvidia every single time. It also lets you set an environment variable on the host (NV_GPU) to specify which GPUs should be injected into a container.\n\n\n👉 Officicial guide to install.\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.listsudo apt-get updatesudo apt-get install -y nvidia-docker2# restart dockersudo systemctl restart docker\n# check versionnvidia-docker version\nDifference: nvidia-container-toolkit vs nvidia-container-runtime #\n👉 What's the difference between the lastest nvidia-docker and nvidia container runtime？\n\nIn this note, with Docker 19.03+ (docker --version), he says that nvidia-container-toolkit is used for --gpus (in docker run ...), nvidia-container-runtime is used for --runtime=nvidia (can also be used in docker-compose file).\n\n\nHowever, if you want to use Kubernetes with Docker 19.03, you actually need to continue using nvidia-docker2 because Kubernetes doesn't support passing GPU information down to docker through the --gpus flag yet. It still relies on the nvidia-container-runtime to pass GPU information down the stack via a set of environment variables.\n\n👉 Installation Guide — NVIDIA Cloud Native Technologies documentation\nUsing docker-compose? #\nPurpose?\n\n# instead of usingdocker run \\ --gpus all\\ --name docker_thi_test\\ --rm\\ -v abc:abc\\ -p 8888:8888\n# we use this with docker-compose.ymldocker-compose up\n\n# check version of docker-composedocker-compose --version\n# If \"version\" in docker-compose.yml &lt; 2.3# Modify: /etc/docker/daemon.json{ \"default-runtime\": \"nvidia\", \"runtimes\": { \"nvidia\": { \"path\": \"nvidia-container-runtime\", \"runtimeArgs\": [] } }}\n# restart our docker daemonsudo pkill -SIGHUP dockerd\n# If \"version\" in docker-compose.yml >=2.3# docker-compose.yml => able to use \"runtime\"version: '2.3' # MUST BE >=2.3 AND &lt;3services: testing: ports: - \"8000:8000\" runtime: nvidia volumes: - ./object_detection:/object_detection\n👉 Check more in my repo my-dockerfiles on Github.\nRun the test,\ndocker pull tensorflow/tensorflow:latest-gpu-jupytermkdir ~/Downloads/test/notebooks\nWithout using docker-compose.yml (tensorflow) (cf. this note for more)\ndocker run --name docker_thi_test -it --rm -v $(realpath ~/Downloads/test/notebooks):/tf/notebooks -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter\nWith docker-compose.yml?\n# ~/Download/test/DockerfileFROM tensorflow/tensorflow:latest-gpu-jupyter\n# ~/Download/test/docker-compose.ymlversion: '2'services: jupyter: container_name: 'docker_thi_test' build: . volumes: - ./notebooks:/tf/notebooks # notebook directory ports: - 8888:8888 # exposed port for jupyter environment: - NVIDIA_VISIBLE_DEVICES=0 # which gpu do you want to use for this container - PASSWORD=12345\nThen run,\ndocker-compose run --rm jupyter\nMake NVIDIA work in docker (Linux) #\n\nThis section is still working (on 26-Oct-2020) but it's old for newer methods.\n\nIdea: Using NVIDIA driver of the base machine, don't install anything in docker!\nDetail of steps\n\n\nFirst, maker sure your base machine has an NVIDIA driver.\n# list all gpuslspci -nn | grep '\\[03'# check nvidia &amp; cuda versionsnvidia-smi\n\n\nInstall nvidia-container-runtime\ncurl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add -distribution=$(. /etc/os-release;echo $ID$VERSION_ID)curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.listsudo apt-get updatesudo apt-get install nvidia-container-runtime\n\n\nNote that, we cannot use docker-compose.yml in this case!!!\n\n\nCreate an image img_datas with Dockerfile is\nFROM nvidia/cuda:10.2-baseRUN apt-get update &amp;&amp; \\\tapt-get -y upgrade &amp;&amp; \\\tapt-get install -y python3-pip python3-dev locales git# install dependenciesCOPY requirements.txt requirements.txtRUN python3 -m pip install --upgrade pip &amp;&amp; \\\tpython3 -m pip install -r requirements.txtCOPY . .# default commandCMD [ \"jupyter\", \"lab\", \"--no-browser\", \"--allow-root\", \"--ip=0.0.0.0\" ]\n\n\nCreate a container,\ndocker run --name docker_thi --gpus all -v /home/thi/folder_1/:/srv/folder_1/ -v /home/thi/folder_1/git/:/srv/folder_2 -dp 8888:8888 -w=\"/srv\" -it img_datas# -v: volumes# -w: working dir# --gpus all: using all gpus on base machine\n\n\nThis article is also very interesting and helpful in some cases.\n\nReferences #\n\nDifference between base, runtime and devel in Dockerfile of CUDA.\nDockerfile on Github of Tensorflow.\n\n"},"/for-me-only/":{"id":"/for-me-only/","title":"For me only","keywords":"for me only customize edit this site box font blocks","tags":["posts","Others","Static Site Generators","11ty"],"cat":"/img/cats/others.svg","content":"This post is for me only. It contains shortcodes to create this website.\n👉 11ty note.\nFrontmatter #\nlayout: post # or `page` or `base`title: \"For me only\"descriptopm: description of the posttags: [Others] # base: Project-based Learning, MOOC, Machine Learning, # Data Science, Deep Learning, Time Series, # NLP, MLOps, Python, R Lang, Linear Algebra, # Prob &amp; Stats, JavaScript, Web Dev, Algorithms # Skills, Othersicon: \"/img/header/customize.svg\" # can be \"customize.svg\" # if it's in /img/header/keywords: \"for me only customize edit this site box font blocks\" # used for searchingtoc: true # `false` to hide tocnotfull: true # if the post is not good enoughhide: true # if don't want to show it on index\nOther components #\n\nMark: ==Text==.\nKeyboard: [[Ctrl]].\nReference: {% ref &quot;url&quot; %} (mush have &quot;&quot;).\nInline text color: {color:red}text{color} (without space)\n{:.noindent} before a list, not indent a list.\n{:.indent} before a list, indent a list.\n{:target=&quot;_blank&quot;} after an url.\n\nInsert figures #\n# NORMAL WITH CUSTOM CLASS![description](/path/to/figure){:.img-full-100}# There are class .img-full-{number}# where, {number} are 30 to 100, step 5.\n# WITH DESCRIPTION![description](/path/){:.custom-class}__Description texts__\nBackground white #\n![Description](/path/to){:.bg-white}# with other classes?{:.bg-white .custom-class}\nDefault img path #\n{% assign img-url = '/img/post/python' %}\nInser codes #\n\n# Highlight line 2``` js/2// lines of codes```\n# Highlight line 2 to 4``` js/2-4// lines of codes```\n# Highlight line 2, 4``` js/2,4// lines of codes```\n\n# Delete line 2 (red highlight) and add line 4 (green highlight)``` js/4/2// lines of codes```\nRaw code #\n~~~ js {% raw %}# line of codes{% endraw %}~~~\nCode inside a list #\nFor problems with tab/spaces in markdown rendering.\n1. Item # below is a blank line ``` bash # codes with 2 spaces (as tab indented) ```2. Another item. ``` bash # code ```\nColumns #\nContent - figure / table #\nUsing class columns-2,\n&lt;div class=\"columns-2\" markdown=\"1\">&lt;div>Content containing markdown blocks&lt;/div>![Description](/path/to/figure){:.custom-class}&lt;/div>\nThere are also others: .columns-2.size-2-1 (1-2, 3-2, 2-3, 1-1).\nTwo cols list #\n&lt;div class=\"col-2-list\">&lt;!-- list (a line break above is required!) -->&lt;/div>\nCode &amp; output #\n\nEqual widths: ::: code-output-equal.\nFlexible widths: ::: code-output-flex.\n\nTwo columns #\n&lt;!-- flexible width -->::: col-2-flex\n&lt;!-- 2 equal colmuns -->&lt;div class=\"col-2-equal\">Content&lt;/div>&lt;!-- or use (not recommended) -->::: col-2-equalContent:::\nBoxes #\nHide / Show box #\n// The box must have a title::: hsbox Title NameContent:::\nOr using liquid tag,\n{% hsbox \"Long title\" %}# content{% endhsbox %}\nHSBox with indent #\n{% hsbox %}- Item 1- Item 2 &lt;div >&lt;div class=\"hsbox\">\t&lt;div class=\"hs__title\">\t\tMore detail\t&lt;/div>\t&lt;div class=\"hs__content\"> //code &lt;/div> &lt;/div> - Sub item.- Item{% endhsbox %}\nAlert boxes #\n\n// info::: infoContent:::\n// warning::: warningContent:::\n// danger::: dangerContent:::\n// success::: successContent:::\n\nMath #\nIf using with list and indent -&gt; DON'T break line in math formulas,\n\n# instead of- Item $$ \\dfrac{1}{2} $$- Item\n# use- Item $$\\dfrac{1}{2}$$ # ALl in 1 line- Item\n\nDev #\nLocally developing mode #\nWe can use a different config file (instead of .eleventy.js).\nnpm run eleventy --config=.eleventy.dev.js\nOther command lines can be found here or using npx @11ty/eleventy --help.\nPurgeCSS #\nBecare full on PurgeCSS,\n/*! purgecss start ignore */// css classes/*! purgecss end ignore */\nCustom tags / shortcodes #\nThe main guide is here.\n// In .eleventy.jsmodule.exports = function(eleventyConfig) {\televentyConfig.addShortcode(\"ref\", function(url) { return '&lt;a href=\"' + url + '\">[ref]&lt;/a'; });}\nUsage,\n{% ref https://dinhanhthi.com %}\nCustom classes #\nUsage,\n\n# paragraphA pragraph {:.custom-class}\n# image![](){:.custom-class}\n# table{:.custom-class}table\n# heading# Heading{:#heading-id}\n\nMulti-classes: {:.custom-1 .custom-2} (with spaces)!\nWe define CSS like that,\np.custom-class + table{}// andp.custom-class{display: none;}// instead oftable.custom-class{}\n.eleventy.dev.js vs .main.js #\nThe only difference is the line\n// comment out in .dev.jseleventyConfig.addPlugin(require(\"./_11ty/img-dim.js\"));\nBuilding index for search #\nIf there is new post / keywords in some old posts -&gt; remove line of pages/search-index.json.njk in .eleventyignore.\nUsing markdown inside njk #\nUsing {% markdown %}{% endmarkdown %} (no need spaces between content).\nOther vars of page #\nBesise page.url, there are others at here.\nErrors? #\n// Problem of \"Content-Security-Policy\" (CSP)// _data/csp.jsconst CSP = { regular: serialize([ // Inline CSS is allowed. [\"style-src\", SELF, \"https://fonts.googleapis.com/\", quote(\"unsafe-inline\")], [\"font-src\", SELF, \"https://fonts.gstatic.com/\"], ]),};// equivalent phrase (put in &lt;head>)&lt;meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self'; font-src 'self' https://fonts.gstatic.com/; style-src 'self' https://fonts.googleapis.com/ 'unsafe-inline';\">// quote() -> for '', e.g. 'self'// \"abc\" -> doesn't mean 'abc' in &lt;meta>\n"},"/reading/":{"id":"/reading/","title":"My reading list","keywords":"book reading goodreads","tags":["posts","Others","Collection"],"cat":"/img/cats/others.svg","content":"\nI like to read books in applied maths, sciences, biography, history and psychology. Check my activities on Goodreads (to-read books, comments, ratings,...) for more information.\n\n\n\n \n \n \n I'm reading\n \n \n Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems\n \n &mdash; Aurélien Géron.\n \n \n \n \n \n I'm reading\n \n \n Factfulness: Ten Reasons We&#39;re Wrong About the World – and Why Things Are Better Than You Think\n \n &mdash; Hans Rosling, Ola Rosling, Anna Rosling Rönnlund.\n \n \n \n \n \n \n my choice\n \n The Godfather\n \n &mdash; Mario Puzo.\n \n \n \n \n \n \n \n The ABC Murders\n \n &mdash; Agatha Christie.\n \n When Alice Asher is murdered in Andover, Hercule Poirot is already on to the clues. Alphabetically speaking, it&#39;s one down, twenty-five to go.\n \n \n \n \n \n \n Inside the Minds of Serial Killers: Why They Kill\n \n &mdash; Katherine Ramsland.\n \n \n \n \n \n \n \n The Boy in the Striped Pajamas\n \n &mdash; Jostein Gaarder.\n \n \n \n \n \n \n my choice\n \n Con đường Hồi giáo\n \n &mdash; Nguyễn Phương Mai.\n \n \n \n \n \n \n \n South of the Border, West of the Sun\n \n &mdash; Haruki Murakami.\n \n \n \n \n \n \n \n Think like a freak\n \n &mdash; Steven D. Levitt.\n \n The New York Times bestselling Freakonomics changed the way we see the world, exposing the hidden side of just about everything.\n \n \n \n \n \n \n Homo Deus: A Brief History of Tomorrow\n \n &mdash; Yuval Noah Harari.\n \n The next book of Harari after his Sapiens.\n \n \n \n \n \n \n Oxford thương yêu\n \n &mdash; Dương Thụy.\n \n \n \n \n \n \n my choice\n \n Sapiens: A Brief History of Humankind\n \n &mdash; Yuval Noah Harari.\n \n Go through the history of human from the first individuals to walk the earth to the radical.\n \n \n \n \n \n \n Tâm nguyện cuối cùng\n \n &mdash; Mi Lei.\n \n The newest detective novel from Mi Lei. This time, he focused heavily on the stories of each character. There are still twists but they&#39;re quite easy to guess.\n \n \n \n \n \n \n Hiệu ứng chim mồi\n \n &mdash; Quốc Khánh, Hạo Nhiên.\n \n With a simple and witty writing style, the authors show us some useful psychological techniques for business.\n \n \n \n \n \n \n Papillon\n \n &mdash; Henri Charrière.\n \n An awesome adventure of Charrière when he tried to escape from all prisons he is confined.\n \n \n \n \n \n \n Hắn và thằng bạn\n \n &mdash; Quốc Khánh, Hạo Nhiên.\n \n \n \n \n \n \n \n Edison as I know him\n \n &mdash; Henry Ford, Samuel Crowther.\n \n \n \n \n \n \n my choice\n \n To Kill a Mockingbird\n \n &mdash; Harper Lee.\n \n \n \n \n \n \n \n Predictably Irrational: The Hidden Forces That Shape Our Decisions\n \n &mdash; Dan Ariely.\n \n \n \n \n \n \n \n Blink: The Power of Thinking Without Thinking\n \n &mdash; Malcolm Gladwell.\n \n \n \n \n \n \n \n Bức xúc không làm ta vô can\n \n &mdash; Đặng Hoàng Giang.\n \n \n \n \n \n \n \n The Murder of Roger Ackroyd\n \n &mdash; Agatha Christie.\n \n \n \n \n \n \n \n Le Petit Nicolas\n \n &mdash; Sempé - Goscinny.\n \n \n \n \n \n \n \n When he comes, close your eyes\n \n &mdash; Ding Mo.\n \n \n \n \n \n \n my choice\n \n Einstein: His Life and Universe\n \n &mdash; Walter Isaacson.\n \n \n \n \n \n \n \n Man&#39;s Search for Meaning\n \n &mdash; Viktor Emil Frankl.\n \n \n \n \n \n \n my choice\n \n The Code Book: The Science of Secrecy from Ancient Egypt to Quantum Cryptography\n \n &mdash; Simon Singh.\n \n \n \n \n \n \n \n How to stop Worrying and start living\n \n &mdash; Dale Carnegie.\n \n \n \n \n \n \n \n Lần đầu thấy trăng\n \n &mdash; Võ Diệu Thanh.\n \n \n \n \n \n \n \n The Alchemist\n \n &mdash; Paulo Coelho.\n \n \n \n \n \n \n \n Letters to a young mathematician\n \n &mdash; Ian Stewart.\n \n \n \n \n \n \n my choice\n \n The Power of Habit: Why We Do What We Do in Life and Business\n \n &mdash; Charles Duhigg.\n \n \n \n \n \n \n \n Love and Math: The Heart of Hidden Reality\n \n &mdash; Edward Frenkel.\n \n \n \n \n \n \n \n The call of the wild\n \n &mdash; Jack London.\n \n \n \n \n \n \n \n White Fang\n \n &mdash; Jack London.\n \n \n \n \n \n \n \n The housekeeper and the professor\n \n &mdash; Yoko Ogawa.\n \n \n \n \n \n \n \n Harry Potter (7 books)\n \n &mdash; J.K. Rowling.\n \n \n \n"},"/useful-tools-data-science-machine-learning/":{"id":"/useful-tools-data-science-machine-learning/","title":"DS & ML tools & bookmarks","keywords":"graphviz data science tools dataframe huge data vaex linux app ubuntu pop os mac macos office online tools app applications pdf multi platform unix windows education chrome extension pluugin math","tags":["posts","Data Science","Machine Learning","Deep Learning","Collection","Linux"],"cat":"/img/cats/data-science.svg","content":"👉 Useful tools in other fields.\n👉 Web Dev tools.\n\nThis note will always be updated.\n\n\n\nGraphviz export\n\nDownload Graphviz here.\nIts online version.\n\n\nVaex -- Handle huge dataframe.\nReplicate -- Version control for machine learning.\nObservable -- Explore and visualize data with advanced notebooks.\nnbdev -- Create delightful python projects using Jupyter Notebooks.\nMapbox -- Maps and location for developers.\nFoursquare -- Put the most trusted, independent location data and technology platform to work for your business.\nidyll -- A toolkit for creating data-driven stories and explorable explanations.\n\n"},"/web-dev-tools/":{"id":"/web-dev-tools/","title":"Web Dev tools & bookmarks","keywords":"html character terms font ligatures useful tools frameworks javascript frameworks library plugins extensions dev tools application framework js java script bookmarks","tags":["posts","Web Dev","Collection","JavaScript"],"cat":"/img/cats/web-dev.svg","content":"👉 Useful tools for Data Science, Machine Learning.\n👉 Useful tools in other fields.\n\nThis note will always be updated.\n\nTools #\n\nHTML characters: copy &amp; paste HTML characters.\ngoogle-webfonts-helper -- A Hassle-Free Way to Self-Host Google Fonts -- giving us font files and font-face declarations based on the fonts, charsets, styles, and browser support you select.\nRegular Expression 101 -- rules and transform directly.\nDownload font pro.\nWebfont Generator\nappium -- Automation for Apps (used to testing UX on different devices, more exact than Browser Inspector)\nFontello -- make an icon as a font (there are also Awesomefont).\nWayback mahine -- an internet archive (to check old/dead websites).\nHappy Hues - Curated colors in context. -- Not sure what colors to use in your designs or where to use them? Happy Hues is a color palette inspiration site that acts as a real world example as to how the colors could be used in your design projects.\nJavaScript Event KeyCodes -- get the keycode of any key when you press.\nFacebook Sharing Debugger tool -- check if your urls display correctly or not on facebook.\nTiny helpers (github) -- A collection of free single-purpose online tools for web developers.\n\nFrameworks #\n\nMatter.js -- a 2D physics engine for the web.\nPlotly -- JavaScript Open Source Graphing Library\nD3.js -- a JavaScript library for manipulating documents based on data.\nJSXGraph -- JSXGraph is a cross-browser JavaScript library for interactive geometry, function plotting, charting, and data visualization in the web browser.\nStage.js -- 2D JavaScript library for cross-platform HTML5 game development.\nidyll -- A toolkit for creating data-driven stories and explorable explanations.\nQuill -- Your powerful rich text editor.\n\nBookmarks #\nLearning &amp; Coding platforms #\n\nThe Odin Project -- A full stack curriculum is free and supported by a passionate open source community.\n\n"}},"docInfo":{"/css-tips/":{"title":2,"keywords":53,"tags":3},"/good-repositories/":{"title":3,"keywords":3,"tags":3},"/setting-up-a-cafe-in-hcmc/":{"title":7,"keywords":37,"tags":4},"/confusion-matrix-and-f1-score/":{"title":4,"keywords":52,"tags":3},"/js-tips/":{"title":2,"keywords":23,"tags":2},"/random-forest/":{"title":2,"keywords":23,"tags":3},"/decision-tree-classifier/":{"title":3,"keywords":54,"tags":4},"/decision-tree-regression/":{"title":3,"keywords":20,"tags":3},"/computer-and-internet-tips/":{"title":3,"keywords":45,"tags":2},"/pep-8/":{"title":5,"keywords":24,"tags":2},"/python-classes-objects/":{"title":3,"keywords":44,"tags":2},"/python-docs-refs/":{"title":2,"keywords":8,"tags":2},"/python-functions/":{"title":2,"keywords":22,"tags":2},"/python-input-output/":{"title":3,"keywords":35,"tags":2},"/python-installation/":{"title":2,"keywords":48,"tags":2},"/python-list/":{"title":2,"keywords":37,"tags":2},"/python-tips/":{"title":2,"keywords":23,"tags":2},"/git/":{"title":1,"keywords":91,"tags":2},"/jupyter-notebook/":{"title":2,"keywords":72,"tags":2},"/python-with-sublime-text/":{"title":3,"keywords":9,"tags":2},"/jekyll-tips/":{"title":2,"keywords":106,"tags":7},"/web-design-tips/":{"title":3,"keywords":31,"tags":3},"/support-vector-machine/":{"title":4,"keywords":65,"tags":4},"/gambler-ruin-problem/":{"title":3,"keywords":4,"tags":3},"/dataset-collection/":{"title":2,"keywords":35,"tags":3},"/pipeline/":{"title":1,"keywords":34,"tags":3},"/principal-component-analysis/":{"title":4,"keywords":34,"tags":3},"/gitbook/":{"title":1,"keywords":0,"tags":3},"/python-matplotlib-tips/":{"title":2,"keywords":46,"tags":2},"/python-numpy-tips/":{"title":2,"keywords":43,"tags":2},"/small-projects-to-understand-concepts/":{"title":4,"keywords":34,"tags":5},"/k-means-clustering/":{"title":3,"keywords":45,"tags":4},"/js-101/":{"title":2,"keywords":31,"tags":2},"/python-pandas/":{"title":2,"keywords":65,"tags":2},"/data-aggregation/":{"title":2,"keywords":14,"tags":3},"/data-combining/":{"title":2,"keywords":13,"tags":3},"/data-preprocessing-cleaning/":{"title":3,"keywords":51,"tags":3},"/dataframe-overview/":{"title":2,"keywords":38,"tags":3},"/titanic-disaster/":{"title":3,"keywords":23,"tags":4},"/grid-search/":{"title":2,"keywords":8,"tags":3},"/regular-expression/":{"title":3,"keywords":2,"tags":2},"/gatsby-js/":{"title":2,"keywords":6,"tags":7},"/gatsby-images/":{"title":2,"keywords":8,"tags":7},"/pytorch/":{"title":2,"keywords":12,"tags":3},"/simple-autoencoder-ae/":{"title":3,"keywords":27,"tags":3},"/date-time-tips/":{"title":3,"keywords":70,"tags":3},"/dbscan-hdbscan-clustering/":{"title":3,"keywords":41,"tags":4},"/python-loop/":{"title":2,"keywords":7,"tags":2},"/good-applications/":{"title":4,"keywords":101,"tags":5},"/algorithm-1/":{"title":2,"keywords":19,"tags":2},"/docker/":{"title":2,"keywords":32,"tags":2},"/screen/":{"title":1,"keywords":25,"tags":3},"/fast-fourier-transform-fft/":{"title":4,"keywords":12,"tags":3},"/tsfresh/":{"title":1,"keywords":12,"tags":3},"/time-series-tips/":{"title":3,"keywords":41,"tags":3},"/linux-tips/":{"title":2,"keywords":154,"tags":3},"/visual-studio-code/":{"title":1,"keywords":43,"tags":2},"/pytest/":{"title":1,"keywords":12,"tags":2},"/wordpress-installation/":{"title":2,"keywords":37,"tags":4},"/bash-command-line/":{"title":1,"keywords":47,"tags":3},"/wordpress-101/":{"title":2,"keywords":14,"tags":4},"/python-exception/":{"title":2,"keywords":3,"tags":2},"/mean-shift/":{"title":3,"keywords":21,"tags":4},"/python-dictionary/":{"title":2,"keywords":6,"tags":2},"/python-json/":{"title":2,"keywords":6,"tags":2},"/deeplearning-ai-course-1/":{"title":4,"keywords":72,"tags":5},"/python-os-sys/":{"title":3,"keywords":5,"tags":2},"/airflow-k8s-101/":{"title":3,"keywords":5,"tags":2},"/python-tuple/":{"title":2,"keywords":0,"tags":2},"/KS-test/":{"title":2,"keywords":27,"tags":3},"/p-value/":{"title":2,"keywords":24,"tags":3},"/fresh-install-windows/":{"title":4,"keywords":11,"tags":5},"/fresh-installation-ubuntu/":{"title":4,"keywords":21,"tags":5},"/ssh/":{"title":1,"keywords":10,"tags":2},"/wordpress-docker/":{"title":2,"keywords":23,"tags":4},"/deeplearning-ai-course-2/":{"title":8,"keywords":131,"tags":5},"/sphinx-restructuredtext/":{"title":3,"keywords":20,"tags":2},"/terminal/":{"title":1,"keywords":18,"tags":3},"/deeplearning-ai-course-3/":{"title":5,"keywords":78,"tags":5},"/deeplearning-ai-course-3-autonomous-driving/":{"title":7,"keywords":4,"tags":5},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"title":7,"keywords":4,"tags":5},"/wasserstein-earth-mover-distance/":{"title":3,"keywords":15,"tags":3},"/data-visualization/":{"title":2,"keywords":7,"tags":3},"/type-of-time-series/":{"title":3,"keywords":6,"tags":3},"/data-structure/":{"title":2,"keywords":8,"tags":3},"/awesome-anomaly-detection-ts/":{"title":4,"keywords":12,"tags":3},"/k-shape-clustering/":{"title":3,"keywords":3,"tags":4},"/data-ml-tools-resources/":{"title":4,"keywords":19,"tags":3},"/deeplearning-ai-tensorflow-course-1/":{"title":7,"keywords":68,"tags":6},"/r-installation/":{"title":2,"keywords":19,"tags":3},"/deeplearning-ai-tensorflow-course-2/":{"title":4,"keywords":99,"tags":6},"/deeplearning-ai-tensorflow-course-3/":{"title":4,"keywords":44,"tags":6},"/deeplearning-ai-tensorflow-course-4/":{"title":6,"keywords":49,"tags":6},"/docker-wsl2-windows/":{"title":3,"keywords":14,"tags":3},"/nodejs-npm/":{"title":2,"keywords":7,"tags":2},"/11ty-nunjucks/":{"title":2,"keywords":47,"tags":7},"/tensorflow/":{"title":2,"keywords":26,"tags":3},"/docker-gpu/":{"title":2,"keywords":38,"tags":2},"/for-me-only/":{"title":0,"keywords":6,"tags":6},"/reading/":{"title":2,"keywords":3,"tags":3},"/useful-tools-data-science-machine-learning/":{"title":4,"keywords":30,"tags":9},"/web-dev-tools/":{"title":4,"keywords":21,"tags":5}},"length":102,"save":true},"index":{"title":{"root":{"1":{"0":{"1":{"docs":{"/js-101/":{"tf":1},"/gatsby-js/":{"tf":1},"/docker/":{"tf":1},"/wordpress-101/":{"tf":1},"/airflow-k8s-101/":{"tf":1}},"df":5},"docs":{"/fresh-install-windows/":{"tf":1}},"df":1},"1":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}},"docs":{"/algorithm-1/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":3},"2":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/docker-wsl2-windows/":{"tf":1}},"df":3},"3":{"docs":{"/python-with-sublime-text/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":3},"4":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1},"8":{"docs":{"/pep-8/":{"tf":1}},"df":1},"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/css-tips/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"f":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}},"h":{"docs":{},"df":0,"i":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":3}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1}},"df":1}}}}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}},"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/data-combining/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/k-means-clustering/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/mean-shift/":{"tf":1},"/k-shape-clustering/":{"tf":1}},"df":4}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/data-preprocessing-cleaning/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{"/css-tips/":{"tf":1},"/js-tips/":{"tf":1},"/python-tips/":{"tf":1},"/web-design-tips/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/pytorch/":{"tf":1},"/date-time-tips/":{"tf":1},"/time-series-tips/":{"tf":1},"/tensorflow/":{"tf":1}},"df":11}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/regular-expression/":{"tf":1}},"df":1}}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/python-exception/":{"tf":1}},"df":1}}}}},"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"/wasserstein-earth-mover-distance/":{"tf":1}},"df":1}}}}},"f":{"1":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1},"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/good-repositories/":{"tf":1}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/random-forest/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/python-functions/":{"tf":1}},"df":1}}}}}}},"f":{"docs":{},"df":0,"t":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1}},"df":1,"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{"/good-repositories/":{"tf":1}},"df":1}}},"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"/gitbook/":{"tf":1}},"df":1}}}}}},"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/pep-8/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/gambler-ruin-problem/":{"tf":1}},"df":1}}}},"t":{"docs":{},"df":0,"s":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1}},"df":2}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/grid-search/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"u":{"docs":{"/docker-gpu/":{"tf":1}},"df":1}}},"r":{"docs":{"/r-installation/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/good-repositories/":{"tf":1}},"df":1}}}}}}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/decision-tree-regression/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/regular-expression/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":2}}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/python-docs-refs/":{"tf":1}},"df":1}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}}}}}}}}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1},"/data-ml-tools-resources/":{"tf":1}},"df":2}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2}}}}}},"a":{"docs":{},"df":0,"d":{"docs":{"/reading/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"/random-forest/":{"tf":1}},"df":1}}}}},"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/gambler-ruin-problem/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1},"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/grid-search/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"i":{"docs":{"/time-series-tips/":{"tf":1},"/type-of-time-series/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":3}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/screen/":{"tf":1}},"df":1}}}}},"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"/pep-8/":{"tf":1}},"df":1}}},"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{"/good-applications/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-3/":{"tf":1},"/data-structure/":{"tf":1}},"df":2}}}}}}},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/python-with-sublime-text/":{"tf":1}},"df":1}}}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}}},"v":{"docs":{},"df":0,"m":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1}},"df":1}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"/simple-autoencoder-ae/":{"tf":1}},"df":1}}}},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"/mean-shift/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"/k-shape-clustering/":{"tf":1}},"df":1}}}},"y":{"docs":{"/python-os-sys/":{"tf":1}},"df":1},"s":{"docs":{},"df":0,"h":{"docs":{"/ssh/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"x":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}}}}},"u":{"docs":{},"df":0,"p":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1}},"df":1}}}}}}}}},"s":{"docs":{"/good-applications/":{"tf":1}},"df":1},"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{"/fresh-installation-ubuntu/":{"tf":1}},"df":1}}}}}},"h":{"docs":{},"df":0,"o":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1},"d":{"docs":{},"df":0,"b":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}}}}}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}}}}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"h":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}}}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/k-means-clustering/":{"tf":1},"/mean-shift/":{"tf":1}},"df":2}}},"l":{"docs":{"/deeplearning-ai-course-3/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":4},"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"’":{"docs":{"/wasserstein-earth-mover-distance/":{"tf":1}},"df":1}}}}}},"j":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/js-tips/":{"tf":1},"/js-101/":{"tf":1}},"df":2}}}}}}}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"y":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"k":{"docs":{},"df":0,"y":{"docs":{},"df":0,"l":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/python-json/":{"tf":1}},"df":1}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1}},"df":2}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"/web-design-tips/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1}},"df":1}}}},"v":{"docs":{"/web-dev-tools/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"/data-aggregation/":{"tf":1},"/data-combining/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/data-visualization/":{"tf":1},"/data-structure/":{"tf":1}},"df":6,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}}},"e":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/wasserstein-earth-mover-distance/":{"tf":1}},"df":1}}}}},"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/python-dictionary/":{"tf":1}},"df":1}}}}}}}}},"b":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/docker/":{"tf":1},"/wordpress-docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}}}},"l":{"docs":{"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":5},"n":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}},"s":{"docs":{"/data-ml-tools-resources/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":2}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1}},"df":2}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"p":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{"/date-time-tips/":{"tf":1},"/time-series-tips/":{"tf":1},"/type-of-time-series/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":4}}},"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{"/python-with-sublime-text/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{"/KS-test/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/terminal/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/tensorflow/":{"tf":1}},"df":4}}}}}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"/good-applications/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":3}}},"s":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1}},"df":1,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/tsfresh/":{"tf":1}},"df":1}}}}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"/python-tuple/":{"tf":1}},"df":1}},"n":{"docs":{},"df":0,"e":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"/type-of-time-series/":{"tf":1}},"df":1}}},"f":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":4}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}}}},"r":{"docs":{},"df":0,"o":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/python-input-output/":{"tf":1}},"df":1}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/python-installation/":{"tf":1},"/wordpress-installation/":{"tf":1},"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/r-installation/":{"tf":1}},"df":5}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"/gatsby-images/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}},"p":{"docs":{"/p-value/":{"tf":1}},"df":1,"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/pep-8/":{"tf":1},"/python-classes-objects/":{"tf":1},"/python-docs-refs/":{"tf":1},"/python-functions/":{"tf":1},"/python-input-output/":{"tf":1},"/python-installation/":{"tf":1},"/python-list/":{"tf":1},"/python-tips/":{"tf":1},"/regular-expression/":{"tf":1},"/python-loop/":{"tf":1},"/python-exception/":{"tf":1},"/python-dictionary/":{"tf":1},"/python-json/":{"tf":1},"/python-os-sys/":{"tf":1},"/python-tuple/":{"tf":1}},"df":15}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/pytorch/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/pytest/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"p":{"docs":{"/pep-8/":{"tf":1}},"df":1},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2}}}}}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"/gambler-ruin-problem/":{"tf":1}},"df":1}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/data-preprocessing-cleaning/":{"tf":1}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}}}}},"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/pipeline/":{"tf":1}},"df":1}}}}}},"c":{"docs":{},"df":0,"a":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"!":{"docs":{},"df":0,"_":{"docs":{},"df":0,"o":{"docs":{"/fresh-installation-ubuntu/":{"tf":1}},"df":1}}}}}},"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/python-input-output/":{"tf":1}},"df":1}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}}}}}}},"s":{"docs":{"/python-os-sys/":{"tf":1}},"df":1},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/python-list/":{"tf":1},"/reading/":{"tf":1}},"df":2}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"x":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"/python-loop/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2}}}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"j":{"docs":{"/nodejs-npm/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{"/python-numpy-tips/":{"tf":1}},"df":1}}},"n":{"docs":{},"df":0,"j":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}}}}},"n":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1},"l":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"m":{"docs":{"/nodejs-npm/":{"tf":1}},"df":1}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"b":{"docs":{"/web-design-tips/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":2}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"/good-applications/":{"tf":1}},"df":1},"d":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/wordpress-installation/":{"tf":1},"/wordpress-101/":{"tf":1},"/wordpress-docker/":{"tf":1}},"df":3}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/fresh-install-windows/":{"tf":1},"/docker-wsl2-windows/":{"tf":1}},"df":2}}}}},"s":{"docs":{},"df":0,"l":{"docs":{"/docker-wsl2-windows/":{"tf":1}},"df":1}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"/visual-studio-code/":{"tf":1}},"df":1}}}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"/p-value/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/data-visualization/":{"tf":1}},"df":1}}}}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1}},"df":1}}}}}},"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{"/data-aggregation/":{"tf":1}},"df":1}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"/simple-autoencoder-ae/":{"tf":1}},"df":1}}}}}}}},"e":{"docs":{"/simple-autoencoder-ae/":{"tf":1}},"df":1},"l":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{"/algorithm-1/":{"tf":1}},"df":1}}}}}}}},"i":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/airflow-k8s-101/":{"tf":1}},"df":1}}}}}}},"k":{"docs":{"/k-means-clustering/":{"tf":1},"/k-shape-clustering/":{"tf":1}},"df":2,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/airflow-k8s-101/":{"tf":1}},"df":1}}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"–":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"/KS-test/":{"tf":1}},"df":1}}}}}}}}}}}}}}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/bash-command-line/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"/useful-tools-data-science-machine-learning/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":2}}}}}}}}}},"keywords":{"root":{"0":{"docs":{"/python-pandas/":{"tf":1},"/date-time-tips/":{"tf":1}},"df":2},"1":{"0":{"1":{"docs":{"/r-installation/":{"tf":1}},"df":1},"docs":{"/computer-and-internet-tips/":{"tf":1},"/fresh-install-windows/":{"tf":1}},"df":2},"1":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}},"docs":{"/git/":{"tf":1},"/python-pandas/":{"tf":1}},"df":2},"2":{"docs":{"/python-list/":{"tf":1},"/python-tips/":{"tf":1},"/web-design-tips/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/KS-test/":{"tf":1}},"df":5},"3":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1},"4":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"5":{"docs":{"/css-tips/":{"tf":1}},"df":1},"7":{"5":{"9":{"0":{"docs":{"/tensorflow/":{"tf":1}},"df":1},"docs":{},"df":0},"docs":{},"df":0},"docs":{},"df":0},"8":{"0":{"docs":{"/pep-8/":{"tf":1}},"df":1},"6":{"0":{"1":{"docs":{"/date-time-tips/":{"tf":1}},"df":1},"docs":{},"df":0},"docs":{},"df":0},"docs":{"/pep-8/":{"tf":1.4142135623730951},"/r-installation/":{"tf":1}},"df":2},"9":{"9":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1},"docs":{},"df":0},"docs":{},"df":0,"l":{"2":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1},"docs":{"/deeplearning-ai-course-1/":{"tf":1.7320508075688772}},"df":1,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"/css-tips/":{"tf":1.4142135623730951},"/js-101/":{"tf":1},"/python-loop/":{"tf":1.4142135623730951}},"df":3}},"n":{"docs":{},"df":0,"g":{"docs":{"/python-input-output/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":2,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/python-classes-objects/":{"tf":1},"/git/":{"tf":1.7320508075688772},"/wordpress-installation/":{"tf":1.4142135623730951},"/wordpress-docker/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":5,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1},"/jekyll-tips/":{"tf":1},"/wordpress-installation/":{"tf":1.4142135623730951},"/wordpress-101/":{"tf":1}},"df":4}}}}}},"k":{"docs":{"/good-applications/":{"tf":1.4142135623730951}},"df":1}},"g":{"docs":{"/python-input-output/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-1/":{"tf":1.4142135623730951}},"df":1}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2}}}}}},"a":{"docs":{},"df":0,"d":{"docs":{"/web-design-tips/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2}},"s":{"docs":{},"df":0,"s":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":3,"i":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1.4142135623730951}},"df":1}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/python-list/":{"tf":2.23606797749979},"/jupyter-notebook/":{"tf":1},"/jekyll-tips/":{"tf":1.7320508075688772},"/web-design-tips/":{"tf":1},"/python-matplotlib-tips/":{"tf":1.7320508075688772},"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/dataframe-overview/":{"tf":1},"/algorithm-1/":{"tf":1},"/python-os-sys/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":12}},"n":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1,"k":{"docs":{"/js-tips/":{"tf":1.4142135623730951},"/data-ml-tools-resources/":{"tf":1}},"df":2},"e":{"2":{"docs":{},"df":0,"d":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}},"docs":{"/python-input-output/":{"tf":1.4142135623730951},"/python-matplotlib-tips/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1},"/ssh/":{"tf":1},"/terminal/":{"tf":1}},"df":5,"a":{"docs":{},"df":0,"r":{"docs":{"/support-vector-machine/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1}},"df":2}}},"u":{"docs":{},"df":0,"x":{"docs":{"/python-installation/":{"tf":1},"/linux-tips/":{"tf":1.4142135623730951},"/bash-command-line/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/terminal/":{"tf":1},"/r-installation/":{"tf":1},"/docker-wsl2-windows/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":8}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"/python-numpy-tips/":{"tf":1}},"df":1}}}},"g":{"docs":{},"df":0,"o":{"docs":{"/good-applications/":{"tf":1.4142135623730951}},"df":1}}},"b":{"docs":{"/r-installation/":{"tf":1}},"df":1,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/python-installation/":{"tf":1},"/data-visualization/":{"tf":1},"/r-installation/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":4}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/jekyll-tips/":{"tf":1.7320508075688772},"/11ty-nunjucks/":{"tf":1}},"df":2}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/web-design-tips/":{"tf":1.4142135623730951},"/visual-studio-code/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":3}}}}},"v":{"docs":{},"df":0,"e":{"docs":{"/visual-studio-code/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}}}},"y":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/pep-8/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":2}}},"e":{"docs":{},"df":0,"r":{"docs":{"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1.7320508075688772},"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1.4142135623730951}},"df":5}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"/python-functions/":{"tf":1},"/python-tips/":{"tf":1},"/data-aggregation/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":4}}},"p":{"docs":{"/wordpress-installation/":{"tf":1},"/wordpress-docker/":{"tf":1}},"df":2}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}},"r":{"docs":{},"df":0,"g":{"docs":{"/dataset-collection/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}}},"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/dataset-collection/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2}}},"z":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"/r-installation/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":3}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/data-ml-tools-resources/":{"tf":1}},"df":1,"n":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/random-forest/":{"tf":1},"/dataset-collection/":{"tf":1},"/pipeline/":{"tf":1},"/pytorch/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/good-applications/":{"tf":1.7320508075688772},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":2},"/data-ml-tools-resources/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.7320508075688772},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1.4142135623730951},"/tensorflow/":{"tf":1}},"df":16}},"k":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/python-classes-objects/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2}}},"n":{"docs":{"/python-list/":{"tf":1}},"df":1,"g":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"/python-list/":{"tf":1}},"df":1}}}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/python-matplotlib-tips/":{"tf":1.4142135623730951}},"df":1}}}},"f":{"docs":{},"df":0,"t":{"docs":{"/data-combining/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/visual-studio-code/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":2}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"r":{"docs":{},"df":0,"j":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}},"a":{"docs":{"/good-applications/":{"tf":1}},"df":1,"p":{"docs":{"/good-applications/":{"tf":1}},"df":1}}},"i":{"docs":{"/principal-component-analysis/":{"tf":1},"/k-means-clustering/":{"tf":1}},"df":2}},"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"/r-installation/":{"tf":1}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}}},"c":{"docs":{"/python-installation/":{"tf":1},"/jekyll-tips/":{"tf":1},"/support-vector-machine/":{"tf":1},"/data-visualization/":{"tf":1}},"df":4,"s":{"docs":{},"df":0,"s":{"docs":{"/css-tips/":{"tf":2},"/jekyll-tips/":{"tf":1},"/visual-studio-code/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":4},"v":{"docs":{"/python-pandas/":{"tf":1.4142135623730951},"/dataframe-overview/":{"tf":1},"/time-series-tips/":{"tf":1}},"df":3}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/css-tips/":{"tf":1},"/python-matplotlib-tips/":{"tf":1.4142135623730951}},"df":2}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"/web-design-tips/":{"tf":1.4142135623730951},"/python-pandas/":{"tf":1.7320508075688772},"/data-preprocessing-cleaning/":{"tf":2.23606797749979},"/dataframe-overview/":{"tf":1}},"df":4}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1},"/good-applications/":{"tf":1},"/awesome-anomaly-detection-ts/":{"tf":1},"/data-ml-tools-resources/":{"tf":1}},"df":4}}}}},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"l":{"docs":{"/linux-tips/":{"tf":1.4142135623730951}},"df":1}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1},"/jekyll-tips/":{"tf":1}},"df":2}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{"/titanic-disaster/":{"tf":1},"/docker/":{"tf":1},"/screen/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":4}}},"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/docker/":{"tf":1.4142135623730951},"/wordpress-docker/":{"tf":1},"/tensorflow/":{"tf":1},"/docker-gpu/":{"tf":1.4142135623730951}},"df":4}}}},"v":{"2":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}},"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1.4142135623730951},"/web-design-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/titanic-disaster/":{"tf":1},"/date-time-tips/":{"tf":1}},"df":5},"s":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":2},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1},"/support-vector-machine/":{"tf":1},"/js-101/":{"tf":1}},"df":4}},"a":{"docs":{"/python-installation/":{"tf":1.4142135623730951},"/jupyter-notebook/":{"tf":1.4142135623730951}},"df":2}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/git/":{"tf":1}},"df":2,"u":{"docs":{},"df":0,"r":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"m":{"docs":{"/python-tips/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1},"/python-matplotlib-tips/":{"tf":1}},"df":2,"o":{"docs":{},"df":0,"r":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}}},"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"/js-101/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"t":{"docs":{"/data-combining/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"n":{"docs":{"/data-combining/":{"tf":1}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/date-time-tips/":{"tf":null}},"df":1}}}}}}}}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/css-tips/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{"/python-numpy-tips/":{"tf":1},"/date-time-tips/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1}},"df":3,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"/git/":{"tf":1}},"df":1}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/p-value/":{"tf":1}},"df":1}}}}}},"o":{"docs":{},"df":0,"s":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1},"n":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/jekyll-tips/":{"tf":1},"/principal-component-analysis/":{"tf":1.4142135623730951},"/small-projects-to-understand-concepts/":{"tf":1},"/good-applications/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":5}}}},"u":{"docs":{},"df":0,"t":{"docs":{"/screen/":{"tf":1},"/linux-tips/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":3}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/visual-studio-code/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"l":{"docs":{"/visual-studio-code/":{"tf":1}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/python-input-output/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1.4142135623730951}},"df":1}},"a":{"docs":{"/python-pandas/":{"tf":1}},"df":1,"n":{"docs":{},"df":0,"d":{"docs":{"/jupyter-notebook/":{"tf":1},"/good-applications/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1},"/bash-command-line/":{"tf":1.4142135623730951},"/ssh/":{"tf":1},"/terminal/":{"tf":1}},"df":6,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/terminal/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"n":{"docs":{"/time-series-tips/":{"tf":1}},"df":1}}},"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/python-pandas/":{"tf":1},"/visual-studio-code/":{"tf":1}},"df":2}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/python-docs-refs/":{"tf":1}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":5}}}}},"p":{"docs":{},"df":0,"l":{"docs":{"/python-list/":{"tf":1},"/data-combining/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/visual-studio-code/":{"tf":1}},"df":4}},"n":{"docs":{},"df":0,"t":{"docs":{"/python-list/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/dataframe-overview/":{"tf":1}},"df":3}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/git/":{"tf":1}},"df":1}}}}},"c":{"docs":{},"df":0,"t":{"docs":{"/p-value/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":2,"l":{"docs":{},"df":0,"i":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}},"e":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}},"d":{"docs":{},"df":0,"e":{"docs":{"/pep-8/":{"tf":1.4142135623730951},"/jupyter-notebook/":{"tf":1},"/docker/":{"tf":1},"/visual-studio-code/":{"tf":1},"/wordpress-installation/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":7,"c":{"docs":{"/python-installation/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"i":{"docs":{"/python-list/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/linux-tips/":{"tf":1}},"df":3}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/principal-component-analysis/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1}},"df":2}}}},"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1},"/pep-8/":{"tf":1},"/js-101/":{"tf":1},"/regular-expression/":{"tf":1},"/visual-studio-code/":{"tf":1.7320508075688772},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":7,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}}}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/git/":{"tf":1.4142135623730951},"/jekyll-tips/":{"tf":1}},"df":3},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}}},"i":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/p-value/":{"tf":1}},"df":2,"l":{"docs":{},"df":0,"d":{"docs":{"/decision-tree-classifier/":{"tf":1},"/python-classes-objects/":{"tf":1}},"df":2}},"p":{"docs":{"/python-tips/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"i":{"docs":{"/random-forest/":{"tf":1},"/support-vector-machine/":{"tf":1}},"df":2},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":2}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"/python-functions/":{"tf":1.4142135623730951},"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/date-time-tips/":{"tf":1},"/linux-tips/":{"tf":1},"/pytest/":{"tf":1},"/bash-command-line/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1.4142135623730951}},"df":11,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1.7320508075688772}},"df":1}}}}},"a":{"docs":{},"df":0,"t":{"docs":{"/screen/":{"tf":1}},"df":1,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1},"/screen/":{"tf":1}},"df":2}}}}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{"/data-preprocessing-cleaning/":{"tf":1}},"df":1}},"i":{"docs":{},"df":0,"c":{"docs":{"/data-ml-tools-resources/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/algorithm-1/":{"tf":1}},"df":1}}}}}},"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/fresh-installation-ubuntu/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1},"r":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}},"c":{"docs":{},"df":0,"h":{"docs":{"/jekyll-tips/":{"tf":1.7320508075688772}},"df":1}},"t":{"docs":{"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/support-vector-machine/":{"tf":1},"/titanic-disaster/":{"tf":1}},"df":2,"i":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951}},"df":1}}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"e":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}}}}}},"i":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2,"t":{"docs":{},"df":0,"i":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/k-means-clustering/":{"tf":2},"/dbscan-hdbscan-clustering/":{"tf":2.23606797749979},"/k-shape-clustering/":{"tf":1}},"df":4}}}}},"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/random-forest/":{"tf":1},"/python-classes-objects/":{"tf":2},"/python-input-output/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":6,"i":{"docs":{},"df":0,"f":{"docs":{"/decision-tree-classifier/":{"tf":1.4142135623730951},"/decision-tree-regression/":{"tf":1},"/time-series-tips/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":6,"i":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/python-list/":{"tf":1},"/python-tips/":{"tf":1},"/jekyll-tips/":{"tf":1}},"df":3},"n":{"docs":{"/jekyll-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":3}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"/git/":{"tf":1.4142135623730951},"/wordpress-installation/":{"tf":1}},"df":2}}},"i":{"docs":{"/wordpress-docker/":{"tf":1.4142135623730951}},"df":1,"c":{"docs":{},"df":0,"k":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}},"p":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1}},"df":1}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1.7320508075688772}},"df":1},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/python-installation/":{"tf":1},"/python-pandas/":{"tf":1},"/linux-tips/":{"tf":1}},"df":3}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951},"/for-me-only/":{"tf":1}},"df":2,"i":{"docs":{},"df":0,"z":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}}}},"d":{"docs":{},"df":0,"a":{"docs":{"/pytorch/":{"tf":1},"/tensorflow/":{"tf":1}},"df":2}},"m":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"/KS-test/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/python-list/":{"tf":1},"/jekyll-tips/":{"tf":1},"/python-numpy-tips/":{"tf":1.4142135623730951},"/titanic-disaster/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/wordpress-installation/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":8}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,".":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"p":{"docs":{"/git/":{"tf":1}},"df":1}}}}}}}}}}}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/jekyll-tips/":{"tf":1},"/pipeline/":{"tf":1}},"df":2}},"p":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}},"m":{"docs":{},"df":0,"d":{"docs":{"/good-applications/":{"tf":1.4142135623730951},"/bash-command-line/":{"tf":1},"/terminal/":{"tf":1}},"df":3,"e":{"docs":{},"df":0,"r":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/good-applications/":{"tf":1.4142135623730951},"/bash-command-line/":{"tf":1},"/terminal/":{"tf":1}},"df":4}}},"a":{"docs":{},"df":0,"p":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"/jupyter-notebook/":{"tf":1.4142135623730951}},"df":1}}},"d":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2,"f":{"docs":{"/wasserstein-earth-mover-distance/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"u":{"docs":{"/bash-command-line/":{"tf":1}},"df":1}},"n":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2}}},"s":{"docs":{"/git/":{"tf":1}},"df":1,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/css-tips/":{"tf":1.4142135623730951},"/visual-studio-code/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":3}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/confusion-matrix-and-f1-score/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":4}}},"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1},"/pipeline/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1}},"df":3}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"e":{"docs":{"/js-101/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"/pipeline/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}},"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/good-applications/":{"tf":1.4142135623730951},"/screen/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1.4142135623730951}},"df":4,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/bash-command-line/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":2}}}}},"a":{"docs":{"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1}},"df":2,"s":{"docs":{},"df":0,"s":{"docs":{"/css-tips/":{"tf":1},"/web-design-tips/":{"tf":1}},"df":2}},"l":{"docs":{},"df":0,"e":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1},"m":{"docs":{},"df":0,"a":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}}}}}}}},"y":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1}},"df":2}}},"m":{"docs":{},"df":0,"e":{"docs":{"/python-classes-objects/":{"tf":1},"/KS-test/":{"tf":1}},"df":2},"p":{"docs":{},"df":0,"l":{"docs":{"/python-input-output/":{"tf":1},"/KS-test/":{"tf":1}},"df":2}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"/css-tips/":{"tf":1},"/pep-8/":{"tf":1},"/python-numpy-tips/":{"tf":1.4142135623730951},"/time-series-tips/":{"tf":1}},"df":4}},"m":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/support-vector-machine/":{"tf":1}},"df":2},"n":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1},"a":{"docs":{},"df":0,"l":{"docs":{"/js-101/":{"tf":1},"/regular-expression/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":3}}}},"e":{"docs":{},"df":0,"d":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1},"c":{"docs":{},"df":0,"h":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-classifier/":{"tf":1},"/algorithm-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":3}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}}}},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"x":{"docs":{"/sphinx-restructuredtext/":{"tf":1.4142135623730951}},"df":1}}}}},"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"/pep-8/":{"tf":1.4142135623730951},"/python-matplotlib-tips/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1.4142135623730951}},"df":3,".":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/css-tips/":{"tf":1.4142135623730951}},"df":1}}}}}}},"o":{"docs":{},"df":0,"p":{"docs":{"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1},"/screen/":{"tf":1}},"df":3},"r":{"docs":{},"df":0,"e":{"docs":{"/git/":{"tf":1}},"df":1}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/decision-tree-regression/":{"tf":1}},"df":1}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/dataset-collection/":{"tf":1},"/principal-component-analysis/":{"tf":1}},"df":2}}}}},"r":{"docs":{"/python-functions/":{"tf":1}},"df":1,"t":{"docs":{"/time-series-tips/":{"tf":1}},"df":1}},"g":{"docs":{},"df":0,"e":{"docs":{"/git/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"h":{"docs":{"/git/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"u":{"docs":{"/git/":{"tf":1}},"df":1},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/gambler-ruin-problem/":{"tf":1},"/KS-test/":{"tf":1},"/p-value/":{"tf":1}},"df":3}},"c":{"docs":{"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/11ty-nunjucks/":{"tf":1.7320508075688772}},"df":3}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/js-101/":{"tf":1}},"df":1}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/python-input-output/":{"tf":1.4142135623730951},"/js-101/":{"tf":1},"/date-time-tips/":{"tf":1.4142135623730951}},"df":3}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/python-input-output/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":2}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}},"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{"/pipeline/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"p":{"docs":{"/python-numpy-tips/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/date-time-tips/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":4}},"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1}},"df":2,"o":{"docs":{"/docker/":{"tf":1},"/visual-studio-code/":{"tf":1},"/wordpress-installation/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":4}}}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}},"p":{"docs":{"/python-loop/":{"tf":1}},"df":1}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"r":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1}},"df":1}}}}},"b":{"docs":{"/decision-tree-classifier/":{"tf":1},"/git/":{"tf":1}},"df":2,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"/git/":{"tf":1}},"df":1}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/python-with-sublime-text/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"/docker-wsl2-windows/":{"tf":1}},"df":1}}}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/python-classes-objects/":{"tf":1.4142135623730951}},"df":1}}},"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}},"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"/linux-tips/":{"tf":1.4142135623730951}},"df":1}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}},"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"/screen/":{"tf":1}},"df":1}}}}}},"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1}}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}}}}},"h":{"docs":{"/bash-command-line/":{"tf":1}},"df":1,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{"/screen/":{"tf":1}},"df":1}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1},"/linux-tips/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":3}},"o":{"docs":{},"df":0,"d":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"n":{"docs":{"/linux-tips/":{"tf":1}},"df":1},"s":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}},"w":{"docs":{"/jekyll-tips/":{"tf":1},"/dataframe-overview/":{"tf":1}},"df":2},"t":{"docs":{"/linux-tips/":{"tf":1}},"df":1}},"a":{"1":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1},"docs":{"/jupyter-notebook/":{"tf":1}},"df":1,"n":{"docs":{},"df":0,"k":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}},"p":{"docs":{},"df":0,"e":{"docs":{"/dataframe-overview/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1}},"df":2}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}}}}}}},"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/screen/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/k-means-clustering/":{"tf":1}},"df":2}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}}}}}},"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/jekyll-tips/":{"tf":1},"/mean-shift/":{"tf":1}},"df":3}}},"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}}},"t":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/pipeline/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/date-time-tips/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":8,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/js-101/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"f":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/principal-component-analysis/":{"tf":1},"/python-pandas/":{"tf":1.4142135623730951},"/tsfresh/":{"tf":1}},"df":3}}}},"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/jupyter-notebook/":{"tf":1},"/linux-tips/":{"tf":1},"/visual-studio-code/":{"tf":1.4142135623730951},"/ssh/":{"tf":1}},"df":4}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{"/principal-component-analysis/":{"tf":1},"/k-means-clustering/":{"tf":1}},"df":2}}}},"i":{"docs":{"/python-pandas/":{"tf":1},"/date-time-tips/":{"tf":1},"/time-series-tips/":{"tf":1.7320508075688772},"/type-of-time-series/":{"tf":1.4142135623730951},"/awesome-anomaly-detection-ts/":{"tf":1},"/k-shape-clustering/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1.4142135623730951}},"df":7,"a":{"docs":{},"df":0,"l":{"docs":{"/python-json/":{"tf":1}},"df":1}}}},"p":{"docs":{"/python-pandas/":{"tf":1}},"df":1,"a":{"docs":{},"df":0,"r":{"docs":{"/web-design-tips/":{"tf":1},"/python-pandas/":{"tf":1}},"df":2}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/pipeline/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":4}},"c":{"docs":{"/algorithm-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":2}},"df":3}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}}}}}},"h":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/screen/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"k":{"docs":{"/mean-shift/":{"tf":1}},"df":1}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/decision-tree-regression/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/algorithm-1/":{"tf":1},"/p-value/":{"tf":1}},"df":4}}}},"d":{"docs":{},"df":0,"r":{"docs":{"/decision-tree-regression/":{"tf":1}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1},"r":{"docs":{},"df":0,"t":{"docs":{"/python-list/":{"tf":1},"/jekyll-tips/":{"tf":1},"/date-time-tips/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/python-dictionary/":{"tf":1}},"df":5}},"f":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1},"/good-applications/":{"tf":1},"/fresh-install-windows/":{"tf":1}},"df":3,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/good-applications/":{"tf":1}},"df":1}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"x":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}}},"l":{"docs":{},"df":0,"v":{"docs":{"/grid-search/":{"tf":1}},"df":1}}},"y":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/python-classes-objects/":{"tf":1.4142135623730951}},"df":1}},"x":{"docs":{"/jekyll-tips/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":2}}},"c":{"docs":{"/linux-tips/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"/python-tips/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/python-with-sublime-text/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":4}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"/web-design-tips/":{"tf":1},"/visual-studio-code/":{"tf":1}},"df":2}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}}},"s":{"docs":{},"df":0,"l":{"docs":{"/python-installation/":{"tf":1}},"df":1},"h":{"docs":{"/python-installation/":{"tf":1},"/git/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/docker/":{"tf":1},"/linux-tips/":{"tf":1},"/visual-studio-code/":{"tf":1},"/ssh/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":8},"g":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"/python-list/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/algorithm-1/":{"tf":1}},"df":3}},"d":{"docs":{},"df":0,"e":{"docs":{"/algorithm-1/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"w":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"/python-tips/":{"tf":1}},"df":1}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/js-101/":{"tf":1}},"df":1}}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"/jupyter-notebook/":{"tf":1.4142135623730951},"/data-combining/":{"tf":1.4142135623730951},"/good-applications/":{"tf":1.4142135623730951}},"df":3}},"t":{"docs":{},"df":0,"e":{"docs":{"/jekyll-tips/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/for-me-only/":{"tf":1}},"df":3}},"g":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/support-vector-machine/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":3}}}},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"/p-value/":{"tf":1}},"df":1}}}}}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":2,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{"/pipeline/":{"tf":1},"/date-time-tips/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":3}}},"z":{"docs":{},"df":0,"e":{"docs":{"/time-series-tips/":{"tf":1},"/linux-tips/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":3}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}},"v":{"docs":{},"df":0,"m":{"docs":{"/pipeline/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1}},"df":2}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"/KS-test/":{"tf":1}},"df":1}}}}}},"z":{"docs":{},"df":0,"h":{"docs":{"/docker-wsl2-windows/":{"tf":1}},"df":1}}},"t":{"docs":{"/date-time-tips/":{"tf":1},"/data-structure/":{"tf":1}},"df":2,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"/css-tips/":{"tf":1},"/computer-and-internet-tips/":{"tf":1},"/good-applications/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1},"/awesome-anomaly-detection-ts/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1.4142135623730951},"/web-dev-tools/":{"tf":1.4142135623730951}},"df":8}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}}},"p":{"docs":{"/js-tips/":{"tf":1},"/python-classes-objects/":{"tf":1}},"df":2},"n":{"docs":{},"df":0,"i":{"docs":{"/random-forest/":{"tf":1}},"df":1}},"c":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1},"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"v":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/pytorch/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/tensorflow/":{"tf":1.4142135623730951},"/docker-gpu/":{"tf":1}},"df":4}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/python-pandas/":{"tf":1.4142135623730951},"/algorithm-1/":{"tf":1}},"df":4}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/good-applications/":{"tf":1.4142135623730951}},"df":1}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"/good-applications/":{"tf":1}},"df":1}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{"/pipeline/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1.7320508075688772},"/deeplearning-ai-course-3/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":6}},"s":{"docs":{},"df":0,"h":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"e":{"docs":{"/random-forest/":{"tf":1.4142135623730951},"/decision-tree-classifier/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":3},"n":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}},"i":{"docs":{"/data-preprocessing-cleaning/":{"tf":1},"/python-exception/":{"tf":1}},"df":2,"c":{"docs":{},"df":0,"k":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1.4142135623730951},"/python-functions/":{"tf":1},"/python-numpy-tips/":{"tf":1}},"df":3}}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1},"/wordpress-installation/":{"tf":1},"/wordpress-101/":{"tf":1.4142135623730951},"/11ty-nunjucks/":{"tf":1.4142135623730951}},"df":4}}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}}}}},"x":{"docs":{},"df":0,"t":{"docs":{"/python-input-output/":{"tf":1},"/python-with-sublime-text/":{"tf":1},"/support-vector-machine/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":5}},"r":{"docs":{},"df":0,"m":{"docs":{"/web-design-tips/":{"tf":1},"/time-series-tips/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":4,"i":{"docs":{},"df":0,"n":{"docs":{"/good-applications/":{"tf":1.7320508075688772},"/screen/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1},"/bash-command-line/":{"tf":1.4142135623730951},"/terminal/":{"tf":1.7320508075688772},"/docker-wsl2-windows/":{"tf":1}},"df":6,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"/time-series-tips/":{"tf":1}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"/pipeline/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/pytest/":{"tf":1},"/KS-test/":{"tf":1.4142135623730951},"/p-value/":{"tf":2},"/deeplearning-ai-course-2/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":10,"n":{"docs":{},"df":0,"g":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":6}}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"/decision-tree-classifier/":{"tf":1},"/pipeline/":{"tf":1},"/grid-search/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1.7320508075688772}},"df":4}},"r":{"docs":{},"df":0,"n":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{"/decision-tree-classifier/":{"tf":1},"/support-vector-machine/":{"tf":1},"/principal-component-analysis/":{"tf":1}},"df":3}},"p":{"docs":{"/python-tips/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":2},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/grid-search/":{"tf":1}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{"/date-time-tips/":{"tf":1.4142135623730951},"/dbscan-hdbscan-clustering/":{"tf":1},"/good-applications/":{"tf":1},"/time-series-tips/":{"tf":2},"/deeplearning-ai-course-2/":{"tf":1},"/data-visualization/":{"tf":1},"/type-of-time-series/":{"tf":1.4142135623730951},"/awesome-anomaly-detection-ts/":{"tf":1},"/k-shape-clustering/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1.4142135623730951}},"df":10,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"6":{"4":{"docs":{"/date-time-tips/":{"tf":1}},"df":1},"docs":{},"df":0},"docs":{"/date-time-tips/":{"tf":2}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{"/date-time-tips/":{"tf":1.4142135623730951},"/time-series-tips/":{"tf":1}},"df":2}}}}}}}},"a":{"docs":{},"df":0,"b":{"docs":{"/pep-8/":{"tf":1}},"df":1,"l":{"docs":{"/jupyter-notebook/":{"tf":1},"/data-aggregation/":{"tf":1.4142135623730951}},"df":2},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/python-with-sublime-text/":{"tf":1}},"df":1}}},"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}}},"g":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1}},"df":2},"s":{"docs":{},"df":0,"k":{"docs":{"/pipeline/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2}},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2}},"h":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}},"l":{"docs":{},"df":0,"s":{"docs":{},"df":0,"/":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"l":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}}}},"w":{"docs":{},"df":0,"o":{"docs":{"/git/":{"tf":1},"/web-design-tips/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/KS-test/":{"tf":1}},"df":4},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"/python-with-sublime-text/":{"tf":1},"/wordpress-installation/":{"tf":1},"/wordpress-101/":{"tf":1.4142135623730951},"/sphinx-restructuredtext/":{"tf":1}},"df":4}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/data-preprocessing-cleaning/":{"tf":1}},"df":1}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/tsfresh/":{"tf":1}},"df":1}}}}}}},"f":{"1":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1},"2":{"docs":{"/linux-tips/":{"tf":1}},"df":1},"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1}},"df":1,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}},"s":{"docs":{},"df":0,"h":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/good-applications/":{"tf":1}},"df":2}}},"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"/pipeline/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"/css-tips/":{"tf":1},"/computer-and-internet-tips/":{"tf":1},"/python-classes-objects/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1.7320508075688772},"/bash-command-line/":{"tf":1}},"df":5}}},"i":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1},"/web-design-tips/":{"tf":1.7320508075688772},"/visual-studio-code/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/for-me-only/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":6,"a":{"docs":{},"df":0,"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"/css-tips/":{"tf":1}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"m":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{"/pep-8/":{"tf":1},"/date-time-tips/":{"tf":1.4142135623730951},"/sphinx-restructuredtext/":{"tf":1},"/data-structure/":{"tf":1}},"df":4}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/git/":{"tf":1.4142135623730951},"/deeplearning-ai-course-1/":{"tf":1}},"df":2}}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/titanic-disaster/":{"tf":1},"/grid-search/":{"tf":1}},"df":2}}}},"c":{"docs":{},"df":0,"u":{"docs":{"/web-design-tips/":{"tf":1}},"df":1}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"d":{"docs":{"/pytest/":{"tf":1}},"df":1}}},"x":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{"/css-tips/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}},"q":{"docs":{"/date-time-tips/":{"tf":1}},"df":1,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/date-time-tips/":{"tf":1.4142135623730951},"/fast-fourier-transform-fft/":{"tf":1}},"df":2}}}}}},"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/web-dev-tools/":{"tf":1.7320508075688772}},"df":3}}}}}}},"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/css-tips/":{"tf":1},"/python-functions/":{"tf":2},"/python-list/":{"tf":1},"/python-tips/":{"tf":1},"/jupyter-notebook/":{"tf":1.4142135623730951},"/support-vector-machine/":{"tf":1},"/js-101/":{"tf":1},"/data-aggregation/":{"tf":1},"/mean-shift/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/KS-test/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":12}}}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/computer-and-internet-tips/":{"tf":1},"/python-classes-objects/":{"tf":1},"/python-pandas/":{"tf":1.4142135623730951},"/titanic-disaster/":{"tf":1},"/docker/":{"tf":1},"/linux-tips/":{"tf":2.8284271247461903},"/bash-command-line/":{"tf":1.7320508075688772},"/python-os-sys/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":11,"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}}}}},"l":{"docs":{"/data-preprocessing-cleaning/":{"tf":1.4142135623730951}},"df":1,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/data-preprocessing-cleaning/":{"tf":1}},"df":1}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1}}}},"x":{"docs":{"/js-tips/":{"tf":1}},"df":1,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/pytest/":{"tf":1}},"df":1}}}},"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"/web-design-tips/":{"tf":1}},"df":1}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}}}}}}}}}}}},"n":{"docs":{},"df":0,"d":{"docs":{"/time-series-tips/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2},"e":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{"/time-series-tips/":{"tf":1}},"df":1},"s":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}},"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/python-pandas/":{"tf":1.4142135623730951},"/algorithm-1/":{"tf":1}},"df":4}},"s":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1.4142135623730951}},"df":1,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{"/random-forest/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"r":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"l":{"docs":{"/git/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"l":{"docs":{"/git/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2}},"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/git/":{"tf":1}},"df":1}}},"e":{"docs":{"/support-vector-machine/":{"tf":1.4142135623730951},"/dataset-collection/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1.4142135623730951}},"df":3}},"k":{"docs":{},"df":0,"e":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/random-forest/":{"tf":1.4142135623730951},"/decision-tree-classifier/":{"tf":1},"/principal-component-analysis/":{"tf":1.4142135623730951},"/dataframe-overview/":{"tf":1},"/titanic-disaster/":{"tf":1},"/tsfresh/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":7}}}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/git/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"d":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951}},"df":1}}},"f":{"docs":{},"df":0,"t":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"p":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}},"u":{"docs":{},"df":0,"i":{"docs":{"/css-tips/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":2},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}}}}}}}}}}}}},"x":{"docs":{"/date-time-tips/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":2},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"y":{"docs":{"/good-applications/":{"tf":1}},"df":1}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/type-of-time-series/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/random-forest/":{"tf":1}},"df":1}}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"/python-functions/":{"tf":1}},"df":1}}}},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"/bash-command-line/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}},"r":{"docs":{},"df":0,"l":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/wordpress-101/":{"tf":1},"/data-ml-tools-resources/":{"tf":1}},"df":3}},"s":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/jekyll-tips/":{"tf":1},"/date-time-tips/":{"tf":1},"/good-applications/":{"tf":1},"/docker/":{"tf":1},"/tsfresh/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/docker-gpu/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":9,"e":{"docs":{},"df":0,"r":{"docs":{"/date-time-tips/":{"tf":1},"/linux-tips/":{"tf":1.4142135623730951}},"df":2}}},"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{"/python-installation/":{"tf":1},"/linux-tips/":{"tf":1.4142135623730951},"/bash-command-line/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/terminal/":{"tf":1},"/r-installation/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":7}}}}},"p":{"docs":{"/principal-component-analysis/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1}},"df":2}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1}},"df":2}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"/git/":{"tf":1}},"df":1}}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}},"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}},"t":{"docs":{},"df":0,"c":{"docs":{"/date-time-tips/":{"tf":1}},"df":1},"f":{"8":{"docs":{"/r-installation/":{"tf":1}},"df":1},"docs":{"/r-installation/":{"tf":1}},"df":1}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":2.6457513110645907}},"df":3}}}}},"p":{"docs":{},"df":0,"h":{"docs":{"/deeplearning-ai-course-1/":{"tf":1},"/data-visualization/":{"tf":1}},"df":2,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":3}}},"i":{"docs":{},"df":0,"c":{"docs":{"/git/":{"tf":1},"/pytorch/":{"tf":1},"/linux-tips/":{"tf":1},"/tensorflow/":{"tf":1}},"df":4}}}},"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{"/python-matplotlib-tips/":{"tf":1},"/algorithm-1/":{"tf":1}},"df":2,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/pipeline/":{"tf":1}},"df":1,"c":{"docs":{},"df":0,"v":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}}}}}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{"/data-aggregation/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1}},"df":2,"b":{"docs":{},"df":0,"i":{"docs":{"/data-aggregation/":{"tf":1}},"df":1}}}}},"u":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"p":{"docs":{"/css-tips/":{"tf":1}},"df":1}},"i":{"docs":{"/git/":{"tf":1.4142135623730951}},"df":1,"d":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"k":{"docs":{"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/terminal/":{"tf":1}},"df":4}}},"i":{"docs":{},"df":0,"t":{"docs":{"/good-repositories/":{"tf":1},"/git/":{"tf":2}},"df":2,"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{"/good-repositories/":{"tf":1},"/git/":{"tf":1.4142135623730951},"/jekyll-tips/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":5}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{"/git/":{"tf":1}},"df":1}}},"k":{"docs":{"/git/":{"tf":1}},"df":1,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/git/":{"tf":1}},"df":1}}}}}}},"n":{"docs":{},"df":0,"i":{"docs":{"/decision-tree-classifier/":{"tf":1.4142135623730951}},"df":1}},"f":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"y":{"docs":{},"df":0,".":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,".":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"y":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}}}},"m":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/dataset-collection/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.7320508075688772},"/11ty-nunjucks/":{"tf":1}},"df":5}}},"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/js-101/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/computer-and-internet-tips/":{"tf":1.4142135623730951},"/web-design-tips/":{"tf":1.4142135623730951},"/dataset-collection/":{"tf":1.4142135623730951},"/small-projects-to-understand-concepts/":{"tf":1},"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":13,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}}}}},"d":{"docs":{"/data-ml-tools-resources/":{"tf":1}},"df":1,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/reading/":{"tf":1}},"df":1}}}}}},"l":{"docs":{},"df":0,"f":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/good-applications/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}}}}},"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/decision-tree-classifier/":{"tf":1.4142135623730951}},"df":1}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}}},"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}},"p":{"docs":{"/time-series-tips/":{"tf":1.4142135623730951}},"df":1},"t":{"docs":{},"df":0,"e":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}},"é":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/git/":{"tf":1}},"df":1}}}}},"c":{"docs":{},"df":0,"f":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"u":{"docs":{"/pytorch/":{"tf":1},"/tensorflow/":{"tf":1.4142135623730951},"/docker-gpu/":{"tf":1}},"df":3}},"n":{"docs":{},"df":0,"u":{"docs":{"/screen/":{"tf":1}},"df":1},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"/linux-tips/":{"tf":1.4142135623730951}},"df":1}}}},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}}},"d":{"docs":{"/git/":{"tf":1},"/KS-test/":{"tf":1}},"df":2,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{"/date-time-tips/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"/css-tips/":{"tf":1.4142135623730951},"/pipeline/":{"tf":1},"/data-aggregation/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/date-time-tips/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1}},"df":6,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}},"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/dataframe-overview/":{"tf":1},"/algorithm-1/":{"tf":1},"/linux-tips/":{"tf":1},"/KS-test/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1.4142135623730951},"/wasserstein-earth-mover-distance/":{"tf":1}},"df":6}}}},"o":{"docs":{"/linux-tips/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/k-means-clustering/":{"tf":1},"/mean-shift/":{"tf":1},"/KS-test/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1.4142135623730951}},"df":4}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"/python-input-output/":{"tf":1.7320508075688772},"/jupyter-notebook/":{"tf":1},"/data-combining/":{"tf":1}},"df":3,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"b":{"docs":{},"df":0,"y":{"docs":{},"df":0,"_":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}}}}}}}}}}}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/git/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"v":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}}},"k":{"docs":{"/linux-tips/":{"tf":1.4142135623730951}},"df":1}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}}}}},"t":{"docs":{"/python-numpy-tips/":{"tf":1},"/python-dictionary/":{"tf":1}},"df":2,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/good-applications/":{"tf":1},"/python-dictionary/":{"tf":1}},"df":4}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/linux-tips/":{"tf":1},"/wordpress-101/":{"tf":1},"/python-os-sys/":{"tf":1}},"df":4}}},"l":{"docs":{},"df":0,"i":{"docs":{"/js-101/":{"tf":1}},"df":1}}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/k-means-clustering/":{"tf":1}},"df":3}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/data-structure/":{"tf":1}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}}}}}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1.4142135623730951},"/confusion-matrix-and-f1-score/":{"tf":1},"/dataset-collection/":{"tf":1.4142135623730951},"/principal-component-analysis/":{"tf":1.4142135623730951},"/small-projects-to-understand-concepts/":{"tf":1},"/k-means-clustering/":{"tf":1},"/python-pandas/":{"tf":2},"/data-preprocessing-cleaning/":{"tf":1},"/titanic-disaster/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1.7320508075688772},"/data-structure/":{"tf":1},"/data-ml-tools-resources/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951},"/useful-tools-data-science-machine-learning/":{"tf":1.4142135623730951}},"df":16,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"/python-input-output/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/python-pandas/":{"tf":1.4142135623730951},"/data-aggregation/":{"tf":1},"/data-combining/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/date-time-tips/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":9}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":2.449489742783178},"/dataframe-overview/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":5}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/simple-autoencoder-ae/":{"tf":1}},"df":1}}}}},".":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"/wordpress-installation/":{"tf":1.4142135623730951}},"df":1}}}},"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/date-time-tips/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}}}}}},"y":{"docs":{"/date-time-tips/":{"tf":1}},"df":1},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2}}}},"e":{"docs":{},"df":0,"v":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":3,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/computer-and-internet-tips/":{"tf":1}},"df":2}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-regression/":{"tf":1}},"df":1}},"c":{"docs":{"/pytorch/":{"tf":1.4142135623730951},"/tensorflow/":{"tf":1.4142135623730951}},"df":2}}},"f":{"docs":{"/python-functions/":{"tf":1}},"df":1,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"/js-tips/":{"tf":1},"/computer-and-internet-tips/":{"tf":1.4142135623730951}},"df":2}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/python-input-output/":{"tf":1},"/js-101/":{"tf":1}},"df":2}}}}},"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"/random-forest/":{"tf":1}},"df":1},"m":{"docs":{"/python-input-output/":{"tf":1}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{"/python-functions/":{"tf":1}},"df":1},"d":{"docs":{"/simple-autoencoder-ae/":{"tf":1.4142135623730951}},"df":1}},"a":{"docs":{},"df":0,"y":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}},"l":{"docs":{"/python-tips/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"t":{"docs":{"/python-tips/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1}},"df":4}},"t":{"docs":{},"df":0,"a":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}},"l":{"docs":{"/tensorflow/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"k":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"/git/":{"tf":1}},"df":1}}}},"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1},"/wordpress-101/":{"tf":1}},"df":2}},"b":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1.7320508075688772}},"df":2}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/js-101/":{"tf":1}},"df":1}}}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/python-json/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1.7320508075688772},"/simple-autoencoder-ae/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/time-series-tips/":{"tf":1.4142135623730951}},"df":4}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/screen/":{"tf":1}},"df":1}}}},"a":{"docs":{},"df":0,"l":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}},"n":{"docs":{},"df":0,"s":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/dataframe-overview/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1.4142135623730951},"/mean-shift/":{"tf":1.7320508075688772},"/KS-test/":{"tf":1}},"df":4}}}}},"e":{"docs":{},"df":0,"p":{"docs":{"/pytorch/":{"tf":1},"/good-applications/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":2},"/deeplearning-ai-course-3/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1},"/tensorflow/":{"tf":1}},"df":11,"l":{"docs":{"/good-applications/":{"tf":1.4142135623730951}},"df":1}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"y":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"/deeplearning-ai-course-1/":{"tf":1.4142135623730951}},"df":1}}},"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/fresh-installation-ubuntu/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{"/good-applications/":{"tf":1}},"df":1,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/computer-and-internet-tips/":{"tf":1.4142135623730951},"/web-design-tips/":{"tf":1},"/good-applications/":{"tf":1.7320508075688772},"/linux-tips/":{"tf":1.7320508075688772},"/bash-command-line/":{"tf":1}},"df":5}}}}}},"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/python-docs-refs/":{"tf":1},"/python-input-output/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1}},"df":3}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"/python-input-output/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1.4142135623730951}},"df":2}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/jupyter-notebook/":{"tf":1.4142135623730951},"/docker/":{"tf":1},"/airflow-k8s-101/":{"tf":1},"/wordpress-docker/":{"tf":2},"/tensorflow/":{"tf":1.4142135623730951},"/docker-gpu/":{"tf":1.4142135623730951}},"df":6}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}},"t":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1},"g":{"docs":{"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}}}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}}},"w":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1},"/data-visualization/":{"tf":1}},"df":2}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1},"/linux-tips/":{"tf":1.7320508075688772}},"df":2}}},"o":{"docs":{},"df":0,"p":{"docs":{"/data-preprocessing-cleaning/":{"tf":1.7320508075688772},"/titanic-disaster/":{"tf":1},"/good-applications/":{"tf":1}},"df":3,"n":{"docs":{},"df":0,"a":{"docs":{"/data-preprocessing-cleaning/":{"tf":1}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2}}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1}},"df":2}}}},"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}},"f":{"docs":{"/python-pandas/":{"tf":1}},"df":1,"t":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}},"b":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}}}}},"y":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1},"/data-visualization/":{"tf":1}},"df":2}}}},"l":{"docs":{"/linux-tips/":{"tf":1}},"df":1},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/css-tips/":{"tf":1.4142135623730951}},"df":1}}},"r":{"docs":{},"df":0,"n":{"docs":{"/python-input-output/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1}},"df":2},"p":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1},"/data-visualization/":{"tf":1}},"df":2}},"l":{"docs":{},"df":0,"k":{"docs":{"/gambler-ruin-problem/":{"tf":1}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{"/simple-autoencoder-ae/":{"tf":1},"/fast-fourier-transform-fft/":{"tf":1}},"df":2}},"m":{"docs":{},"df":0,"p":{"docs":{"/wordpress-installation/":{"tf":1},"/wordpress-docker/":{"tf":1}},"df":2,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/wasserstein-earth-mover-distance/":{"tf":1}},"df":1}}}}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/python-input-output/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":2,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/css-tips/":{"tf":1.4142135623730951},"/wordpress-installation/":{"tf":1},"/wordpress-docker/":{"tf":1.4142135623730951}},"df":3}}}}}},"k":{"docs":{"/pipeline/":{"tf":1},"/screen/":{"tf":1},"/tsfresh/":{"tf":1}},"df":3,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1},"o":{"docs":{},"df":0,"w":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/python-installation/":{"tf":1},"/algorithm-1/":{"tf":1},"/time-series-tips/":{"tf":1},"/linux-tips/":{"tf":1.4142135623730951},"/bash-command-line/":{"tf":1.4142135623730951},"/fresh-install-windows/":{"tf":1},"/terminal/":{"tf":1},"/r-installation/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1},"/docker-wsl2-windows/":{"tf":1.4142135623730951},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":12}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"p":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"d":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"/python-pandas/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"/pep-8/":{"tf":1}},"df":1}}}},"n":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"/python-input-output/":{"tf":1}},"df":1,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/python-functions/":{"tf":1}},"df":1}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"/python-pandas/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"b":{"docs":{"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/mean-shift/":{"tf":1},"/11ty-nunjucks/":{"tf":1.4142135623730951}},"df":4,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/web-design-tips/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/wordpress-installation/":{"tf":1.4142135623730951},"/wordpress-101/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/11ty-nunjucks/":{"tf":1.4142135623730951}},"df":6}}}},"l":{"docs":{},"df":0,"l":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1.4142135623730951}},"df":1}}}}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/linux-tips/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":2}}},"p":{"docs":{"/wordpress-installation/":{"tf":1},"/wordpress-docker/":{"tf":1}},"df":2},"w":{"docs":{},"df":0,"w":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"l":{"2":{"docs":{"/docker-wsl2-windows/":{"tf":1}},"df":1},"docs":{"/docker-wsl2-windows/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"/css-tips/":{"tf":1},"/awesome-anomaly-detection-ts/":{"tf":1.4142135623730951}},"df":2}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{"/css-tips/":{"tf":1},"/web-design-tips/":{"tf":1},"/visual-studio-code/":{"tf":1}},"df":3,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/js-tips/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/wordpress-docker/":{"tf":1}},"df":4}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{"/web-design-tips/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"/simple-autoencoder-ae/":{"tf":1}},"df":1}}}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1.4142135623730951}},"df":1}}}}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{"/wordpress-101/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"é":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}}}},"g":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}}}}},"p":{"docs":{},"df":0,"p":{"docs":{"/computer-and-internet-tips/":{"tf":1.4142135623730951},"/good-applications/":{"tf":1},"/wordpress-installation/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1.4142135623730951}},"df":4,"l":{"docs":{},"df":0,"i":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/data-aggregation/":{"tf":1}},"df":2,"c":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1},"/good-applications/":{"tf":1},"/fresh-install-windows/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":6}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/docker/":{"tf":1},"/airflow-k8s-101/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3,"e":{"2":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1},"docs":{},"df":0}}}}},"d":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1}},"df":1,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":2}}}}}}},"d":{"docs":{"/python-list/":{"tf":1},"/python-pandas/":{"tf":1},"/linux-tips/":{"tf":1},"/visual-studio-code/":{"tf":1},"/python-os-sys/":{"tf":1}},"df":5,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/jupyter-notebook/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":3}}}}},"a":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1},"p":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}},"t":{"docs":{},"df":0,"k":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1}},"df":1}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2}}}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/python-classes-objects/":{"tf":1},"/python-list/":{"tf":1},"/linux-tips/":{"tf":1},"/python-dictionary/":{"tf":1}},"df":4}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"/python-installation/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":5}}}},"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/p-value/":{"tf":1}},"df":1}}}},"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/random-forest/":{"tf":1},"/support-vector-machine/":{"tf":1}},"df":2}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/python-input-output/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"a":{"docs":{"/git/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":2,"s":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}},"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{"/pipeline/":{"tf":1},"/principal-component-analysis/":{"tf":1},"/algorithm-1/":{"tf":1},"/time-series-tips/":{"tf":1},"/pytest/":{"tf":1},"/mean-shift/":{"tf":1}},"df":6}}}}}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/js-tips/":{"tf":1}},"df":1}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"/python-classes-objects/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"/simple-autoencoder-ae/":{"tf":1},"/time-series-tips/":{"tf":1}},"df":2}}}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"/python-installation/":{"tf":1},"/python-with-sublime-text/":{"tf":1}},"df":2}}}}},"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2}}}}},"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"/support-vector-machine/":{"tf":1},"/k-means-clustering/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":9},"j":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}},"i":{"docs":{},"df":0,"m":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/js-tips/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/python-list/":{"tf":1}},"df":1}},"y":{"docs":{"/python-numpy-tips/":{"tf":2},"/js-101/":{"tf":1},"/python-pandas/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":4}}},"g":{"docs":{"/python-functions/":{"tf":1}},"df":1,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/python-functions/":{"tf":1}},"df":1}}}}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/python-numpy-tips/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/k-means-clustering/":{"tf":1}},"df":1}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}}}}}},"b":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-regression/":{"tf":1}},"df":1}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}}}},"c":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}}}},"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}}},"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/python-classes-objects/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}}}}}}}}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/screen/":{"tf":1}},"df":1}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/pytest/":{"tf":1}},"df":1}}}}}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"i":{"docs":{"/python-installation/":{"tf":1}},"df":1}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"/jupyter-notebook/":{"tf":1.4142135623730951},"/js-101/":{"tf":1}},"df":2}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"/python-installation/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{},"df":0,"m":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"/time-series-tips/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":3}}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}},"i":{"docs":{"/dataset-collection/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":5,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/docker/":{"tf":1},"/airflow-k8s-101/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3}}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"/fresh-installation-ubuntu/":{"tf":1}},"df":1}}}}},"x":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1},"g":{"docs":{},"df":0,"g":{"docs":{"/data-aggregation/":{"tf":1}},"df":1,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}}}},"e":{"docs":{"/simple-autoencoder-ae/":{"tf":1}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/css-tips/":{"tf":1},"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1}},"df":3}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"/python-functions/":{"tf":1},"/pytest/":{"tf":1}},"df":2}}}},"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}}},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"/random-forest/":{"tf":1}},"df":1}}},"u":{"docs":{"/decision-tree-classifier/":{"tf":1},"/support-vector-machine/":{"tf":1},"/principal-component-analysis/":{"tf":1}},"df":3},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{"/computer-and-internet-tips/":{"tf":1.7320508075688772},"/good-applications/":{"tf":1},"/tsfresh/":{"tf":1},"/data-ml-tools-resources/":{"tf":1}},"df":4,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}}}}}},"m":{"docs":{"/git/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1.4142135623730951},"/bash-command-line/":{"tf":1}},"df":3},"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/principal-component-analysis/":{"tf":1},"/dataframe-overview/":{"tf":1},"/docker/":{"tf":1},"/visual-studio-code/":{"tf":1},"/wordpress-installation/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/docker-gpu/":{"tf":1}},"df":7}},"z":{"docs":{},"df":0,"l":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"s":{"docs":{"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2}}}}}}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/screen/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2}}}}}},"s":{"docs":{"/python-classes-objects/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2,"c":{"docs":{"/docker/":{"tf":1},"/visual-studio-code/":{"tf":1},"/wordpress-installation/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":4,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"/docker/":{"tf":1},"/visual-studio-code/":{"tf":1},"/docker-wsl2-windows/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":4}}}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1.4142135623730951},"/data-preprocessing-cleaning/":{"tf":1.4142135623730951},"/dataframe-overview/":{"tf":1.7320508075688772},"/KS-test/":{"tf":1},"/p-value/":{"tf":1}},"df":6,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{"/pipeline/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":4}}},"r":{"docs":{},"df":0,"i":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"/python-tips/":{"tf":1.7320508075688772},"/jupyter-notebook/":{"tf":1},"/jekyll-tips/":{"tf":1},"/js-101/":{"tf":1},"/titanic-disaster/":{"tf":1},"/docker/":{"tf":1},"/bash-command-line/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":8}},"n":{"docs":{},"df":0,"c":{"docs":{"/principal-component-analysis/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":3}}}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"/support-vector-machine/":{"tf":1},"/principal-component-analysis/":{"tf":1}},"df":2}}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"x":{"docs":{"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":1}}},"n":{"docs":{"/linux-tips/":{"tf":1}},"df":1},"p":{"docs":{},"df":0,"n":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}}}},"p":{"docs":{"/KS-test/":{"tf":1},"/p-value/":{"tf":1}},"df":2,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{"/css-tips/":{"tf":1}},"df":1}}}}},"x":{"docs":{"/css-tips/":{"tf":1}},"df":1},"i":{"docs":{},"df":0,"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/css-tips/":{"tf":1}},"df":1}}},"n":{"docs":{},"df":0,"g":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"p":{"docs":{"/python-installation/":{"tf":1.7320508075688772},"/jupyter-notebook/":{"tf":1.4142135623730951}},"df":2,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1},"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3}}}}},"l":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1},"v":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"/data-aggregation/":{"tf":1}},"df":1,"_":{"docs":{},"df":0,"t":{"docs":{"/data-aggregation/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"/css-tips/":{"tf":1},"/dataframe-overview/":{"tf":1}},"df":2}}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/linux-tips/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":2}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-course-3/":{"tf":1.4142135623730951}},"df":1}}}}},"p":{"8":{"docs":{"/pep-8/":{"tf":1.4142135623730951}},"df":1},"docs":{"/pep-8/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"/css-tips/":{"tf":1},"/support-vector-machine/":{"tf":1},"/r-installation/":{"tf":1}},"df":3}}}},"u":{"docs":{},"df":0,"d":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951}},"df":1}}},"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"/support-vector-machine/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/grid-search/":{"tf":1},"/time-series-tips/":{"tf":1},"/linux-tips/":{"tf":1},"/p-value/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1.7320508075688772}},"df":7}}},"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"/gambler-ruin-problem/":{"tf":1},"/mean-shift/":{"tf":1},"/KS-test/":{"tf":1}},"df":3}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/pipeline/":{"tf":1.4142135623730951},"/dataframe-overview/":{"tf":1},"/linux-tips/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":5}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/principal-component-analysis/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":5}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/fast-fourier-transform-fft/":{"tf":1}},"df":1}}}},"a":{"docs":{},"df":0,"g":{"docs":{"/deeplearning-ai-course-1/":{"tf":1.4142135623730951}},"df":1}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1.4142135623730951}},"df":1}},"n":{"docs":{},"df":0,"t":{"docs":{"/python-input-output/":{"tf":1},"/bash-command-line/":{"tf":1.4142135623730951}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{"/good-applications/":{"tf":1}},"df":1},"n":{"docs":{},"df":0,"v":{"docs":{"/bash-command-line/":{"tf":1}},"df":1}}}},"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"/small-projects-to-understand-concepts/":{"tf":1}},"df":1}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/ssh/":{"tf":1}},"df":1}}}},"e":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1,"p":{"docs":{"/git/":{"tf":1}},"df":1,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/python-pandas/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1}},"df":3}}}}}}},"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1.4142135623730951}},"df":1}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":3}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/js-tips/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"/python-docs-refs/":{"tf":1},"/js-101/":{"tf":1}},"df":2}}}}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"t":{"docs":{"/jekyll-tips/":{"tf":1.7320508075688772},"/wordpress-101/":{"tf":1}},"df":2}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/bash-command-line/":{"tf":1},"/terminal/":{"tf":1}},"df":3}}}}}}},"p":{"docs":{"/python-list/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":3,"o":{"docs":{"/fresh-installation-ubuntu/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}},"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/python-matplotlib-tips/":{"tf":1},"/k-means-clustering/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1.7320508075688772},"/mean-shift/":{"tf":1}},"df":4}}},"o":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1.7320508075688772},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}},"e":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"/js-tips/":{"tf":1},"/jekyll-tips/":{"tf":1},"/web-design-tips/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":4}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1.4142135623730951},"/pipeline/":{"tf":1.4142135623730951},"/grid-search/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":4,"r":{"docs":{"/decision-tree-classifier/":{"tf":1},"/mean-shift/":{"tf":1}},"df":2}}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"s":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/k-means-clustering/":{"tf":1},"/linux-tips/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":3}}}},"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}}},"h":{"docs":{"/linux-tips/":{"tf":1.7320508075688772},"/visual-studio-code/":{"tf":1},"/python-os-sys/":{"tf":1}},"df":3}},"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"/python-classes-objects/":{"tf":1},"/python-installation/":{"tf":1.4142135623730951},"/jupyter-notebook/":{"tf":1},"/r-installation/":{"tf":1},"/nodejs-npm/":{"tf":1.4142135623730951},"/tensorflow/":{"tf":1}},"df":6}}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}}}}},"m":{"docs":{"/k-means-clustering/":{"tf":1}},"df":1},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"/data-combining/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/date-time-tips/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":5,"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}}},"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{"/js-tips/":{"tf":1},"/jekyll-tips/":{"tf":1.4142135623730951},"/good-applications/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":5}}},"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1},"/fast-fourier-transform-fft/":{"tf":1}},"df":2}}},"p":{"docs":{"/wordpress-installation/":{"tf":1.7320508075688772}},"df":1,"m":{"docs":{},"df":0,"y":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}},"t":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"/python-docs-refs/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":2}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"u":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951},"/visual-studio-code/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":4}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"t":{"docs":{"/python-matplotlib-tips/":{"tf":2.23606797749979},"/dataframe-overview/":{"tf":1},"/algorithm-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":4}},"t":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}}}}},"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/pep-8/":{"tf":1.4142135623730951},"/python-docs-refs/":{"tf":1},"/python-list/":{"tf":1},"/python-tips/":{"tf":1},"/python-with-sublime-text/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/python-loop/":{"tf":1},"/algorithm-1/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.7320508075688772},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":13,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"/visual-studio-code/":{"tf":1}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/pytorch/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1}},"df":2}}}}},"g":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/git/":{"tf":1.4142135623730951}},"df":1}},"l":{"docs":{},"df":0,"l":{"docs":{"/git/":{"tf":1.4142135623730951}},"df":1}},"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"/ssh/":{"tf":1}},"df":1}}}}},"c":{"docs":{},"df":0,"a":{"docs":{"/pipeline/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1}},"df":2}},"d":{"docs":{},"df":0,"f":{"docs":{"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1},"/mean-shift/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":4}},"n":{"docs":{},"df":0,"g":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"a":{"docs":{"/linux-tips/":{"tf":1.4142135623730951}},"df":1}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1},"/python-list/":{"tf":1.7320508075688772},"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/python-dictionary/":{"tf":1}},"df":5,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/linux-tips/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}}}}},"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/k-means-clustering/":{"tf":1}},"df":2}}},"i":{"docs":{},"df":0,"f":{"docs":{"/python-tips/":{"tf":1}},"df":1}}},"m":{"docs":{"/css-tips/":{"tf":1}},"df":1,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/python-classes-objects/":{"tf":1},"/python-numpy-tips/":{"tf":1}},"df":2}}},"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"i":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}},"d":{"docs":{"/wasserstein-earth-mover-distance/":{"tf":1}},"df":1},"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1.4142135623730951}},"df":1}}}},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/decision-tree-regression/":{"tf":1.4142135623730951},"/python-functions/":{"tf":1},"/python-input-output/":{"tf":1},"/python-installation/":{"tf":1},"/linux-tips/":{"tf":1},"/pytest/":{"tf":1},"/python-exception/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":9}},"n":{"docs":{},"df":0,"o":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{"/js-tips/":{"tf":1},"/jekyll-tips/":{"tf":1}},"df":2}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"/random-forest/":{"tf":1}},"df":1}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{"/random-forest/":{"tf":1},"/decision-tree-classifier/":{"tf":1}},"df":2}}}}},"v":{"docs":{"/python-installation/":{"tf":1},"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1}},"df":2,"n":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/bash-command-line/":{"tf":1}},"df":1}}}}}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"/simple-autoencoder-ae/":{"tf":1.4142135623730951}},"df":1}}},"d":{"docs":{"/time-series-tips/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1.4142135623730951}},"df":2}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/js-tips/":{"tf":1}},"df":1},"l":{"docs":{},"df":0,"i":{"docs":{"/python-numpy-tips/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}},"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"/decision-tree-regression/":{"tf":1},"/python-input-output/":{"tf":1}},"df":2}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/visual-studio-code/":{"tf":1.4142135623730951},"/r-installation/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":6}}},"r":{"docs":{},"df":0,"a":{"docs":{"/visual-studio-code/":{"tf":1}},"df":1,"c":{"docs":{},"df":0,"t":{"docs":{"/tsfresh/":{"tf":1},"/linux-tips/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":4}}}}},"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/data-preprocessing-cleaning/":{"tf":1},"/python-exception/":{"tf":1}},"df":2}}}},"i":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/web-design-tips/":{"tf":1},"/visual-studio-code/":{"tf":1.4142135623730951}},"df":2}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/support-vector-machine/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":2}}}}},"r":{"docs":{},"df":0,"t":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"_":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"_":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{"/linux-tips/":{"tf":1}},"df":1},"d":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"d":{"docs":{},"df":0,"g":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1},"i":{"docs":{},"df":0,"t":{"docs":{"/for-me-only/":{"tf":1}},"df":1,"o":{"docs":{},"df":0,"r":{"docs":{"/git/":{"tf":1},"/bash-command-line/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":3}}}},"u":{"docs":{},"df":0,"c":{"docs":{"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}},"c":{"docs":{},"df":0,"h":{"docs":{"/python-list/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/time-series-tips/":{"tf":1}},"df":3}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"/KS-test/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1.4142135623730951}},"df":2}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/python-numpy-tips/":{"tf":1}},"df":1}}}},"c":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/js-101/":{"tf":1}},"df":1}}}}}}}}},"s":{"6":{"docs":{"/js-101/":{"tf":1}},"df":1},"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/dataframe-overview/":{"tf":1},"/mean-shift/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1}},"df":3}}}}},"h":{"0":{"docs":{"/KS-test/":{"tf":1}},"df":1},"docs":{},"df":0,"t":{"docs":{},"df":0,"m":{"docs":{},"df":0,"l":{"docs":{"/css-tips/":{"tf":1},"/jekyll-tips/":{"tf":1.4142135623730951},"/web-dev-tools/":{"tf":1}},"df":3}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/css-tips/":{"tf":1},"/git/":{"tf":1}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{"/js-tips/":{"tf":1}},"df":1}}},"t":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}}}}},"l":{"docs":{},"df":0,"p":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"/web-design-tips/":{"tf":1}},"df":1}}}}},"o":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1,"u":{"docs":{},"df":0,"s":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1.4142135623730951}},"df":1},"r":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/js-tips/":{"tf":1}},"df":1}}},"t":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"y":{"docs":{"/jupyter-notebook/":{"tf":1.4142135623730951},"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1}},"df":3}}}},"m":{"docs":{},"df":0,"e":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{"/screen/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"s":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}},"c":{"docs":{},"df":0,"m":{"docs":{},"df":0,"c":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}},"a":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}},"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/python-tips/":{"tf":1}},"df":1}}},"b":{"docs":{"/dataset-collection/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/good-applications/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{},"df":0,"h":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"g":{"docs":{},"df":0,"e":{"docs":{"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"/jekyll-tips/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":2}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}}},"d":{"docs":{},"df":0,"e":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/data-structure/":{"tf":1}},"df":1}}}}}}},"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"d":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/k-means-clustering/":{"tf":1}},"df":1}}}}}}},"l":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}}}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/grid-search/":{"tf":1}},"df":1,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1.7320508075688772}},"df":2}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{"/KS-test/":{"tf":1},"/p-value/":{"tf":1.4142135623730951}},"df":2}}}}}}},"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}},"d":{"docs":{},"df":0,"b":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}}}}},"f":{"5":{"docs":{"/data-structure/":{"tf":1}},"df":1},"docs":{"/data-structure/":{"tf":1.4142135623730951}},"df":1}}},"r":{"docs":{"/r-installation/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/css-tips/":{"tf":1},"/python-docs-refs/":{"tf":1},"/jekyll-tips/":{"tf":1},"/screen/":{"tf":1},"/tsfresh/":{"tf":1}},"df":5}}},"m":{"docs":{"/css-tips/":{"tf":1}},"df":1,"o":{"docs":{},"df":0,"v":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/python-list/":{"tf":1},"/git/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1.7320508075688772},"/ssh/":{"tf":1}},"df":8},"t":{"docs":{"/git/":{"tf":2},"/jupyter-notebook/":{"tf":1},"/screen/":{"tf":1},"/linux-tips/":{"tf":1},"/visual-studio-code/":{"tf":1}},"df":5}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}},"p":{"docs":{},"df":0,"o":{"docs":{"/git/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/good-repositories/":{"tf":1},"/git/":{"tf":1.4142135623730951}},"df":2}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/python-list/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":2}}}}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1.4142135623730951}},"df":1}},"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/pep-8/":{"tf":1},"/jupyter-notebook/":{"tf":1}},"df":2}}}}},"g":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1,"i":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":3}}}},"r":{"docs":{},"df":0,"d":{"docs":{"/good-applications/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2}}},"i":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}}},"l":{"docs":{"/random-forest/":{"tf":1},"/python-classes-objects/":{"tf":1}},"df":2,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/js-tips/":{"tf":1}},"df":1}}},"u":{"docs":{"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1.4142135623730951}},"df":2},"a":{"docs":{},"df":0,"x":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/decision-tree-classifier/":{"tf":1.4142135623730951},"/decision-tree-regression/":{"tf":1},"/time-series-tips/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":4}}}},"e":{"docs":{},"df":0,"x":{"docs":{"/web-design-tips/":{"tf":1},"/visual-studio-code/":{"tf":1.4142135623730951}},"df":2}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1,"r":{"docs":{"/web-design-tips/":{"tf":1},"/support-vector-machine/":{"tf":1},"/visual-studio-code/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1.7320508075688772}},"df":4}}}}},"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-regression/":{"tf":1},"/principal-component-analysis/":{"tf":1}},"df":2}}}},"a":{"docs":{},"df":0,"d":{"docs":{"/python-classes-objects/":{"tf":1},"/python-pandas/":{"tf":1},"/time-series-tips/":{"tf":1},"/reading/":{"tf":1}},"df":4,"_":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{},"df":0,"v":{"docs":{"/python-pandas/":{"tf":1},"/time-series-tips/":{"tf":1}},"df":2}}}},"e":{"docs":{},"df":0,"r":{"docs":{"/linux-tips/":{"tf":1}},"df":1}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}}}}}},"c":{"docs":{},"df":0,"t":{"docs":{"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1}},"df":2}},"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/screen/":{"tf":1}},"df":1}}}}},"l":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"/python-installation/":{"tf":1}},"df":1},"e":{"docs":{},"df":0,"w":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"/python-list/":{"tf":1},"/python-pandas/":{"tf":1}},"df":2}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/python-tips/":{"tf":1.4142135623730951},"/git/":{"tf":1},"/fresh-install-windows/":{"tf":1}},"df":3,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{"/data-preprocessing-cleaning/":{"tf":1}},"df":1}}}}}}}},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/git/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{"/visual-studio-code/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1}},"df":2}}}}}}}}}}}}},"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{"/date-time-tips/":{"tf":1.4142135623730951}},"df":1}}}},"i":{"docs":{},"df":0,"z":{"docs":{"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"/pytest/":{"tf":1},"/mean-shift/":{"tf":1.4142135623730951}},"df":2}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1},"/data-ml-tools-resources/":{"tf":1}},"df":2}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"/git/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1}},"df":3}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{},"df":0,"r":{"docs":{"/r-installation/":{"tf":1}},"df":1}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/p-value/":{"tf":1}},"df":1}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/fresh-install-windows/":{"tf":1}},"df":1}}}}}}},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{"/css-tips/":{"tf":1},"/jekyll-tips/":{"tf":1},"/docker-wsl2-windows/":{"tf":1}},"df":3}},"n":{"docs":{"/jupyter-notebook/":{"tf":1},"/jekyll-tips/":{"tf":1},"/linux-tips/":{"tf":1},"/wordpress-installation/":{"tf":1}},"df":4,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"/tensorflow/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2}}}},"l":{"docs":{},"df":0,"e":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}},"s":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"c":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1.4142135623730951}},"df":1,"k":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}},"o":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-classifier/":{"tf":1},"/jupyter-notebook/":{"tf":1}},"df":2}},"u":{"docs":{},"df":0,"g":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}},"w":{"docs":{"/python-pandas/":{"tf":1.7320508075688772},"/data-preprocessing-cleaning/":{"tf":1}},"df":2},"l":{"docs":{},"df":0,"l":{"docs":{"/algorithm-1/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"/random-forest/":{"tf":1},"/python-list/":{"tf":1},"/gambler-ruin-problem/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/titanic-disaster/":{"tf":1},"/grid-search/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":7}}},"g":{"docs":{"/python-numpy-tips/":{"tf":1.4142135623730951},"/small-projects-to-understand-concepts/":{"tf":1}},"df":2}},"r":{"docs":{"/bash-command-line/":{"tf":1}},"df":1,"g":{"docs":{"/python-functions/":{"tf":1}},"df":1}},"i":{"docs":{},"df":0,"s":{"docs":{"/python-functions/":{"tf":1}},"df":1}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2}}}},"m":{"docs":{"/bash-command-line/":{"tf":1}},"df":1},"t":{"docs":{},"df":0,"e":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}},"b":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1,"f":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}},"/":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"/data-combining/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"i":{"docs":{"/good-applications/":{"tf":1}},"df":1},"t":{"docs":{"/visual-studio-code/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1}},"df":2},"a":{"docs":{"/ssh/":{"tf":1}},"df":1}},"m":{"docs":{},"df":0,"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}}}},"n":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}},"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/python-input-output/":{"tf":1},"/python-list/":{"tf":1},"/python-numpy-tips/":{"tf":1.4142135623730951},"/k-means-clustering/":{"tf":1},"/date-time-tips/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":7,"f":{"docs":{"/css-tips/":{"tf":1}},"df":1}}}},"p":{"docs":{},"df":0,"i":{"docs":{"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/date-time-tips/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1}},"df":6},"y":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}},"l":{"docs":{},"df":0,"l":{"docs":{"/python-numpy-tips/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1.4142135623730951},"/KS-test/":{"tf":1},"/p-value/":{"tf":1}},"df":5,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"/p-value/":{"tf":1}},"df":1}}}}},"n":{"docs":{},"df":0,"j":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"/11ty-nunjucks/":{"tf":1.4142135623730951}},"df":1}}}}}},"e":{"docs":{},"df":0,"g":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1},"w":{"docs":{"/python-installation/":{"tf":1},"/visual-studio-code/":{"tf":1}},"df":2,"s":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{"/python-docs-refs/":{"tf":1}},"df":1}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"/python-list/":{"tf":1},"/jekyll-tips/":{"tf":1}},"df":2}},"t":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"/dataset-collection/":{"tf":1},"/pytorch/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":2},"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":2},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/tensorflow/":{"tf":1}},"df":9}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}}}},"e":{"docs":{},"df":0,"d":{"docs":{"/data-preprocessing-cleaning/":{"tf":1},"/fresh-install-windows/":{"tf":1}},"df":2}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/pytorch/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-course-2/":{"tf":1.7320508075688772},"/deeplearning-ai-tensorflow-course-1/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/tensorflow/":{"tf":1}},"df":8}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}}}}}}}}}},"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"j":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"p":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":2}},"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"/js-tips/":{"tf":1}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{"/pep-8/":{"tf":1},"/jekyll-tips/":{"tf":1},"/pipeline/":{"tf":1.4142135623730951},"/python-pandas/":{"tf":1.4142135623730951},"/pytest/":{"tf":1},"/wordpress-101/":{"tf":1}},"df":6}},"n":{"docs":{"/python-numpy-tips/":{"tf":1.7320508075688772},"/data-preprocessing-cleaning/":{"tf":1.7320508075688772},"/dataframe-overview/":{"tf":1}},"df":3,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}}}}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}},"s":{"docs":{},"df":0,"a":{"docs":{"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"/decision-tree-classifier/":{"tf":2.23606797749979},"/nodejs-npm/":{"tf":1}},"df":2}},"n":{"docs":{"/decision-tree-classifier/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/mean-shift/":{"tf":1}},"df":3,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"p":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/python-functions/":{"tf":1},"/js-101/":{"tf":1},"/python-json/":{"tf":1}},"df":3}},"e":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/r-installation/":{"tf":1}},"df":4}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"/git/":{"tf":1}},"df":1,"e":{"2":{"docs":{"/git/":{"tf":1}},"df":1},"docs":{},"df":0}}}}}}},"i":{"docs":{},"df":0,"s":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-course-2/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"g":{"docs":{"/support-vector-machine/":{"tf":1},"/k-means-clustering/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":9},"p":{"docs":{"/date-time-tips/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{"/pytorch/":{"tf":1},"/tensorflow/":{"tf":2},"/docker-gpu/":{"tf":1}},"df":3}}}}},"n":{"docs":{"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1.4142135623730951}},"df":2},"i":{"docs":{},"df":0,"l":{"docs":{"/tsfresh/":{"tf":1}},"df":1}}},"m":{"docs":{"/git/":{"tf":1}},"df":1,"i":{"docs":{},"df":0,"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/css-tips/":{"tf":1}},"df":1}}},"n":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1},"/time-series-tips/":{"tf":1}},"df":2,"h":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1},"u":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}},"i":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1,"m":{"docs":{"/linux-tips/":{"tf":1}},"df":1},"s":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}},"s":{"docs":{},"df":0,"s":{"docs":{"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/titanic-disaster/":{"tf":1}},"df":3},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/deeplearning-ai-course-3/":{"tf":1.4142135623730951}},"df":1}}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}}},"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/wordpress-docker/":{"tf":1.4142135623730951}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/decision-tree-regression/":{"tf":1.4142135623730951},"/principal-component-analysis/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1.4142135623730951},"/k-means-clustering/":{"tf":1.4142135623730951},"/data-preprocessing-cleaning/":{"tf":1}},"df":6}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/python-classes-objects/":{"tf":1.4142135623730951},"/k-means-clustering/":{"tf":1.4142135623730951},"/linux-tips/":{"tf":1}},"df":4}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"/deeplearning-ai-course-3/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":3}}}},"r":{"docs":{},"df":0,"g":{"docs":{"/git/":{"tf":1},"/data-combining/":{"tf":1}},"df":2},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"/k-means-clustering/":{"tf":2}},"df":1}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/k-means-clustering/":{"tf":1.4142135623730951}},"df":1}}}},"l":{"docs":{},"df":0,"t":{"docs":{"/data-aggregation/":{"tf":1}},"df":1}},"g":{"docs":{},"df":0,"a":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}}}},"a":{"docs":{},"df":0,"c":{"docs":{"/python-installation/":{"tf":1},"/bash-command-line/":{"tf":1},"/terminal/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":4,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/data-ml-tools-resources/":{"tf":1}},"df":6}}},"o":{"docs":{"/bash-command-line/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":2}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"k":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{"/jupyter-notebook/":{"tf":1},"/jekyll-tips/":{"tf":1},"/visual-studio-code/":{"tf":1},"/11ty-nunjucks/":{"tf":1.4142135623730951}},"df":4,"=":{"docs":{},"df":0,"\"":{"1":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"docs":{},"df":0}}}}}},"e":{"docs":{},"df":0,"r":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/support-vector-machine/":{"tf":2}},"df":1}}}},"t":{"docs":{},"df":0,"h":{"docs":{"/11ty-nunjucks/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":2,"j":{"docs":{},"df":0,"a":{"docs":{},"df":0,"x":{"docs":{"/js-tips/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":2}}}},"e":{"docs":{"/good-applications/":{"tf":1}},"df":1,"r":{"docs":{},"df":0,"i":{"docs":{"/python-docs-refs/":{"tf":1},"/awesome-anomaly-detection-ts/":{"tf":1}},"df":2}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{"/python-installation/":{"tf":1}},"df":1}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"/principal-component-analysis/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1}},"df":2}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{"/linux-tips/":{"tf":1.7320508075688772}},"df":1}}}},"e":{"docs":{"/decision-tree-regression/":{"tf":1}},"df":1},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"/computer-and-internet-tips/":{"tf":1},"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1},"/nodejs-npm/":{"tf":1.4142135623730951}},"df":4},"v":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}},"i":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}},"p":{"docs":{"/python-list/":{"tf":1}},"df":1},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/git/":{"tf":1}},"df":1}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}},"x":{"docs":{"/time-series-tips/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}},"k":{"docs":{},"df":0,"e":{"docs":{"/data-preprocessing-cleaning/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2,"_":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/pipeline/":{"tf":1}},"df":1}}}}}}}}}},"m":{"docs":{},"df":0,"p":{"docs":{"/wordpress-installation/":{"tf":1},"/wordpress-docker/":{"tf":1}},"df":2}}},"s":{"docs":{},"df":0,"e":{"docs":{"/decision-tree-regression/":{"tf":1}},"df":1}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/python-input-output/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":5,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/python-input-output/":{"tf":1.4142135623730951},"/jupyter-notebook/":{"tf":1}},"df":2}}},"p":{"docs":{},"df":0,"l":{"docs":{"/pipeline/":{"tf":1.4142135623730951},"/python-matplotlib-tips/":{"tf":1},"/bash-command-line/":{"tf":1},"/p-value/":{"tf":2}},"df":4,"i":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1},"e":{"docs":{},"df":0,"x":{"docs":{"/screen/":{"tf":1}},"df":1},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/p-value/":{"tf":1}},"df":1}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/type-of-time-series/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{"/python-list/":{"tf":1}},"df":1}}},"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{"/principal-component-analysis/":{"tf":1}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"/python-installation/":{"tf":1},"/git/":{"tf":1},"/dataset-collection/":{"tf":1},"/linux-tips/":{"tf":1},"/pytest/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":6}},"e":{"docs":{"/k-means-clustering/":{"tf":1.4142135623730951},"/mean-shift/":{"tf":1}},"df":2,"l":{"docs":{"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":5}}},"r":{"docs":{},"df":0,"e":{"docs":{"/python-list/":{"tf":1}},"df":1},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"y":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":2}}}}},"v":{"docs":{},"df":0,"i":{"docs":{"/good-applications/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":2},"e":{"docs":{"/linux-tips/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":2,"r":{"docs":{"/wasserstein-earth-mover-distance/":{"tf":1}},"df":1,"'":{"docs":{"/KS-test/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1}},"df":2}}}},"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"n":{"docs":{"/time-series-tips/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1,"u":{"docs":{},"df":0,"m":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}},"z":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"/11ty-nunjucks/":{"tf":1.4142135623730951}},"df":1}}}}}},"p":{"3":{"docs":{"/linux-tips/":{"tf":1}},"df":1},"docs":{},"df":0},"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"q":{"docs":{},"df":0,"l":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1}}}}}}}}},"l":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1.7320508075688772},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2}}}}},"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"m":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/python-list/":{"tf":1},"/python-pandas/":{"tf":1.4142135623730951},"/data-preprocessing-cleaning/":{"tf":1.7320508075688772},"/date-time-tips/":{"tf":1}},"df":5},"n":{"docs":{},"df":0,"t":{"docs":{"/pep-8/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}}}},"f":{"docs":{},"df":0,"o":{"docs":{"/python-input-output/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/date-time-tips/":{"tf":1},"/wordpress-101/":{"tf":1.4142135623730951}},"df":4,"r":{"docs":{},"df":0,"m":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}},"t":{"docs":{"/python-list/":{"tf":1},"/python-numpy-tips/":{"tf":1}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"t":{"docs":{"/good-applications/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/python-list/":{"tf":1}},"df":1}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"/simple-autoencoder-ae/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/screen/":{"tf":1}},"df":1}}}}},"g":{"docs":{"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1}},"df":2,"r":{"docs":{"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":2}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"/wordpress-installation/":{"tf":1}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}},"l":{"docs":{"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/tsfresh/":{"tf":1},"/linux-tips/":{"tf":1.4142135623730951},"/visual-studio-code/":{"tf":1.4142135623730951},"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/wordpress-docker/":{"tf":1},"/r-installation/":{"tf":1},"/tensorflow/":{"tf":1.4142135623730951}},"df":10}}},"i":{"docs":{},"df":0,"d":{"docs":{"/python-tips/":{"tf":1}},"df":1}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/js-101/":{"tf":1}},"df":1}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/gatsby-images/":{"tf":1}},"df":1}}}},"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}},"u":{"docs":{},"df":0,"d":{"docs":{"/jekyll-tips/":{"tf":1.7320508075688772},"/11ty-nunjucks/":{"tf":1}},"df":2}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}}}}},"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/11ty-nunjucks/":{"tf":1}},"df":1}}}}}}},"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/python-functions/":{"tf":1},"/web-design-tips/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/python-pandas/":{"tf":1},"/good-applications/":{"tf":1},"/time-series-tips/":{"tf":1},"/linux-tips/":{"tf":1}},"df":8}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/python-numpy-tips/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":2.6457513110645907}},"df":3}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/python-pandas/":{"tf":1}},"df":1},"v":{"docs":{"/time-series-tips/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/data-combining/":{"tf":1}},"df":1}}},"j":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}},"i":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1},"m":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/random-forest/":{"tf":1}},"df":1}}}}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"/random-forest/":{"tf":1},"/python-classes-objects/":{"tf":1.4142135623730951},"/dataframe-overview/":{"tf":1}},"df":3,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/python-installation/":{"tf":1},"/pytest/":{"tf":1}},"df":2}}}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1},"t":{"docs":{"/titanic-disaster/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2}}}},"a":{"docs":{},"df":0,"g":{"docs":{"/dataset-collection/":{"tf":1},"/principal-component-analysis/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/gatsby-images/":{"tf":1},"/good-applications/":{"tf":1.7320508075688772},"/docker/":{"tf":1.4142135623730951},"/deeplearning-ai-course-1/":{"tf":1},"/wordpress-docker/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":2},"/deeplearning-ai-tensorflow-course-2/":{"tf":2.449489742783178},"/docker-gpu/":{"tf":1.4142135623730951}},"df":12,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1}}}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}}}}}}}}}}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/python-matplotlib-tips/":{"tf":1.4142135623730951},"/small-projects-to-understand-concepts/":{"tf":1},"/algorithm-1/":{"tf":1}},"df":3}}}},"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/python-matplotlib-tips/":{"tf":1}},"df":1}}}},"d":{"docs":{},"df":0,"b":{"docs":{"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":1}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/decision-tree-classifier/":{"tf":1},"/js-101/":{"tf":1},"/python-loop/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1}},"df":4,"m":{"2":{"docs":{"/good-applications/":{"tf":1}},"df":1},"docs":{},"df":0}}}},"d":{"3":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1},"docs":{"/python-with-sublime-text/":{"tf":1}},"df":1,"e":{"docs":{},"df":0,"a":{"docs":{"/simple-autoencoder-ae/":{"tf":1},"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3}},"m":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}}}},"i":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}},"p":{"docs":{"/linux-tips/":{"tf":1},"/bash-command-line/":{"tf":1}},"df":2,"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/python-pandas/":{"tf":1}},"df":1,"s":{"docs":{},"df":0,"t":{"docs":{"/python-numpy-tips/":{"tf":1}},"df":1}}}},"o":{"docs":{"/date-time-tips/":{"tf":1},"/linux-tips/":{"tf":1.4142135623730951}},"df":2,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1}},"df":1}}}}}}}},"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}},"r":{"docs":{"/python-loop/":{"tf":1}},"df":1}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"g":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}}}},"o":{"docs":{"/linux-tips/":{"tf":1}},"df":1}},"j":{"docs":{},"df":0,"s":{"docs":{"/js-tips/":{"tf":1},"/jekyll-tips/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/nodejs-npm/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":7,"o":{"docs":{},"df":0,"n":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/js-101/":{"tf":1},"/python-json/":{"tf":1}},"df":3}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"y":{"docs":{},"df":0,"t":{"docs":{"/python-installation/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/r-installation/":{"tf":1}},"df":4}}},"m":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}},"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{"/web-dev-tools/":{"tf":1}},"df":1,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951},"/js-101/":{"tf":1},"/python-json/":{"tf":1},"/nodejs-npm/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":5}}}}}}}},"k":{"docs":{},"df":0,"e":{"docs":{"/support-vector-machine/":{"tf":1},"/principal-component-analysis/":{"tf":1}},"df":2}}},"e":{"docs":{},"df":0,"k":{"docs":{},"df":0,"y":{"docs":{},"df":0,"l":{"docs":{"/jekyll-tips/":{"tf":2.23606797749979},"/docker-wsl2-windows/":{"tf":1}},"df":2}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"i":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/good-applications/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1}},"df":1}}}}}}}}},"v":{"docs":{},"df":0,"p":{"docs":{},"df":0,"n":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}},"r":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/js-101/":{"tf":1}},"df":2}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}},"m":{"docs":{"/deeplearning-ai-course-2/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":3,"a":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"u":{"docs":{},"df":0,"t":{"docs":{"/good-applications/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1}},"df":2,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/support-vector-machine/":{"tf":1},"/k-means-clustering/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1.4142135623730951}},"df":3}}}},"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"/jupyter-notebook/":{"tf":1},"/python-pandas/":{"tf":1},"/titanic-disaster/":{"tf":1}},"df":3}}},"e":{"docs":{},"df":0,"r":{"docs":{"/data-combining/":{"tf":1}},"df":1}}},"r":{"docs":{"/git/":{"tf":1}},"df":1}},"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/python-classes-objects/":{"tf":1},"/python-installation/":{"tf":1},"/js-101/":{"tf":1.4142135623730951},"/python-json/":{"tf":1}},"df":4}}}}},"s":{"docs":{"/linux-tips/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1.4142135623730951},"/terminal/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":4,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/jupyter-notebook/":{"tf":1}},"df":1}}}}},"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}},"x":{"docs":{"/terminal/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951}},"df":1}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}}}},"n":{"docs":{"/wordpress-docker/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":2,"c":{"docs":{"/pipeline/":{"tf":1}},"df":1},"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"_":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":1}}}}}}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":1}}}},"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/k-means-clustering/":{"tf":1}},"df":1}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"/python-pandas/":{"tf":1}},"df":1}}}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/date-time-tips/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{},"df":0,"c":{"docs":{"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":1}}}},"w":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{"/linux-tips/":{"tf":1}},"df":1}}}}}}}},"h":{"docs":{"/docker-wsl2-windows/":{"tf":1}},"df":1}},"k":{"3":{"8":{"0":{"docs":{"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2},"docs":{},"df":0},"docs":{},"df":0},"8":{"docs":{"/docker/":{"tf":1},"/airflow-k8s-101/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3},"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1.4142135623730951},"/k-means-clustering/":{"tf":3},"/docker/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":5,"o":{"docs":{},"df":0,"o":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1},"l":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"/KS-test/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1}},"df":2}}}}}}}}},"e":{"docs":{},"df":0,"y":{"docs":{"/git/":{"tf":1},"/python-dictionary/":{"tf":1},"/ssh/":{"tf":1.4142135623730951}},"df":3,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/js-tips/":{"tf":1},"/good-applications/":{"tf":1},"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":4}}}}},"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}}},"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}},"e":{"docs":{},"df":0,"l":{"docs":{"/support-vector-machine/":{"tf":2.23606797749979},"/dataframe-overview/":{"tf":1},"/mean-shift/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1}},"df":4}}},"a":{"docs":{"/deeplearning-ai-tensorflow-course-2/":{"tf":1}},"df":1}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{"/python-functions/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951}},"df":1}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1},"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"/docker/":{"tf":1},"/airflow-k8s-101/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":3}}}}}}},"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}},"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/k-means-clustering/":{"tf":1.4142135623730951}},"df":1}}}},"d":{"docs":{},"df":0,"e":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"/linux-tips/":{"tf":1}},"df":1}},"t":{"docs":{"/awesome-anomaly-detection-ts/":{"tf":1}},"df":1}},"s":{"docs":{"/KS-test/":{"tf":1.4142135623730951},"/wasserstein-earth-mover-distance/":{"tf":1}},"df":2}},"b":{"docs":{"/git/":{"tf":1}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1}},"df":1}},"c":{"docs":{},"df":0,"k":{"docs":{"/js-tips/":{"tf":1}},"df":1,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/good-applications/":{"tf":1}},"df":1}}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}},"u":{"docs":{},"df":0,"p":{"docs":{"/wordpress-docker/":{"tf":1}},"df":1}}}},"g":{"docs":{"/random-forest/":{"tf":1}},"df":1},"s":{"docs":{},"df":0,"e":{"docs":{"/python-installation/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1.4142135623730951},"/deeplearning-ai-tensorflow-course-3/":{"tf":1}},"df":4},"i":{"docs":{},"df":0,"c":{"docs":{"/support-vector-machine/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":3}},"h":{"docs":{"/bash-command-line/":{"tf":1},"/terminal/":{"tf":1}},"df":2}},"d":{"docs":{},"df":0,"g":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}},"r":{"docs":{"/dataframe-overview/":{"tf":1}},"df":1},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/algorithm-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":2.23606797749979}},"df":2}}},"b":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/random-forest/":{"tf":1}},"df":2},"c":{"docs":{},"df":0,"k":{"docs":{"/jekyll-tips/":{"tf":1.4142135623730951},"/js-101/":{"tf":1},"/bash-command-line/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/for-me-only/":{"tf":1}},"df":5}}},"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}}},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"/linux-tips/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2}}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/js-tips/":{"tf":1}},"df":1}}}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"/python-with-sublime-text/":{"tf":1},"/jekyll-tips/":{"tf":1.4142135623730951},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":5}}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/time-series-tips/":{"tf":1.7320508075688772}},"df":1}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{"/docker-wsl2-windows/":{"tf":1}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"/decision-tree-classifier/":{"tf":1},"/git/":{"tf":1.7320508075688772}},"df":2}}},"u":{"docs":{},"df":0,"n":{"docs":{"/tsfresh/":{"tf":1}},"df":1}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"/decision-tree-classifier/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/computer-and-internet-tips/":{"tf":1.4142135623730951},"/js-101/":{"tf":1}},"df":2}}},"n":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"k":{"docs":{"/python-input-output/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1}},"df":2}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,".":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"/computer-and-internet-tips/":{"tf":1}},"df":1}}}},"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"s":{"docs":{},"df":0,"t":{"docs":{"/time-series-tips/":{"tf":1}},"df":1}}}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}}}}}}},"n":{"docs":{"/linux-tips/":{"tf":1}},"df":1,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-1/":{"tf":1}},"df":1}}}},"a":{"docs":{"/deeplearning-ai-course-2/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1.4142135623730951}},"df":2}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/pep-8/":{"tf":1}},"df":1,"f":{"docs":{},"df":0,"i":{"docs":{"/pep-8/":{"tf":1}},"df":1}}}}}},"y":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}},"t":{"docs":{},"df":0,"a":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"/k-means-clustering/":{"tf":1},"/mean-shift/":{"tf":1}},"df":2}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"/pipeline/":{"tf":1}},"df":1}},"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{"/algorithm-1/":{"tf":1}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"/jekyll-tips/":{"tf":1},"/11ty-nunjucks/":{"tf":1}},"df":2}}}}}},"k":{"docs":{"/linux-tips/":{"tf":1},"/reading/":{"tf":1}},"df":2,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"/linux-tips/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":2}}}}}},"x":{"docs":{"/jekyll-tips/":{"tf":1},"/for-me-only/":{"tf":1}},"df":2},"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/dbscan-hdbscan-clustering/":{"tf":1}},"df":1}}}}}},"z":{"docs":{"/wordpress-docker/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1}},"df":2,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"/js-tips/":{"tf":1},"/jekyll-tips/":{"tf":1}},"df":2}}},"i":{"docs":{},"df":0,"p":{"docs":{"/bash-command-line/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1.4142135623730951}},"df":2}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}},"s":{"docs":{},"df":0,"h":{"docs":{"/terminal/":{"tf":1},"/docker-wsl2-windows/":{"tf":1}},"df":2}}},"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"u":{"docs":{"/random-forest/":{"tf":1}},"df":1}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/random-forest/":{"tf":1}},"df":1}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{"/linux-tips/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"q":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}},"_":{"docs":{},"df":0,"_":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"_":{"docs":{},"df":0,"_":{"docs":{},"df":0,".":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{"/python-classes-objects/":{"tf":1}},"df":1}}}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"_":{"docs":{"/python-tips/":{"tf":1}},"df":1}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"_":{"docs":{},"df":0,"_":{"docs":{"/python-tips/":{"tf":1}},"df":1}}}}}},"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"_":{"docs":{},"df":0,"_":{"docs":{"/python-tips/":{"tf":1}},"df":1}}}}}}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"_":{"docs":{},"df":0,"_":{"docs":{"/sphinx-restructuredtext/":{"tf":1}},"df":1}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"l":{"docs":{"/python-installation/":{"tf":1}},"df":1}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"/git/":{"tf":1},"/linux-tips/":{"tf":1}},"df":2},"c":{"docs":{},"df":0,"k":{"docs":{"/jekyll-tips/":{"tf":1},"/good-applications/":{"tf":1},"/screen/":{"tf":1},"/bash-command-line/":{"tf":1.4142135623730951},"/deeplearning-ai-course-3/":{"tf":1}},"df":5,"l":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-3/":{"tf":1}},"df":1}}}}},"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/support-vector-machine/":{"tf":1}},"df":1}}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{"/dataset-collection/":{"tf":1}},"df":1}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/good-applications/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"x":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"/support-vector-machine/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1}},"df":2}},"d":{"docs":{},"df":0,"m":{"docs":{"/good-applications/":{"tf":1}},"df":1}},"p":{"docs":{"/fresh-installation-ubuntu/":{"tf":1},"/tensorflow/":{"tf":1}},"df":2},"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/deeplearning-ai-course-2/":{"tf":1}},"df":1}}}}}}}},"tags":{"root":{"1":{"1":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"/11ty-nunjucks/":{"tf":1},"/for-me-only/":{"tf":1}},"df":2}}},"docs":{},"df":0},"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"/css-tips/":{"tf":1},"/good-repositories/":{"tf":1},"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/confusion-matrix-and-f1-score/":{"tf":1},"/js-tips/":{"tf":1},"/random-forest/":{"tf":1},"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1},"/computer-and-internet-tips/":{"tf":1},"/pep-8/":{"tf":1},"/python-classes-objects/":{"tf":1},"/python-docs-refs/":{"tf":1},"/python-functions/":{"tf":1},"/python-input-output/":{"tf":1},"/python-installation/":{"tf":1},"/python-list/":{"tf":1},"/python-tips/":{"tf":1},"/git/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/python-with-sublime-text/":{"tf":1},"/jekyll-tips/":{"tf":1},"/web-design-tips/":{"tf":1},"/support-vector-machine/":{"tf":1},"/gambler-ruin-problem/":{"tf":1},"/dataset-collection/":{"tf":1},"/pipeline/":{"tf":1},"/principal-component-analysis/":{"tf":1},"/gitbook/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/k-means-clustering/":{"tf":1},"/js-101/":{"tf":1},"/python-pandas/":{"tf":1},"/data-aggregation/":{"tf":1},"/data-combining/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/titanic-disaster/":{"tf":1},"/grid-search/":{"tf":1},"/regular-expression/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/pytorch/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/date-time-tips/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/python-loop/":{"tf":1},"/good-applications/":{"tf":1},"/algorithm-1/":{"tf":1},"/docker/":{"tf":1},"/screen/":{"tf":1},"/fast-fourier-transform-fft/":{"tf":1},"/tsfresh/":{"tf":1},"/time-series-tips/":{"tf":1},"/linux-tips/":{"tf":1},"/visual-studio-code/":{"tf":1},"/pytest/":{"tf":1},"/wordpress-installation/":{"tf":1},"/bash-command-line/":{"tf":1},"/wordpress-101/":{"tf":1},"/python-exception/":{"tf":1},"/mean-shift/":{"tf":1},"/python-dictionary/":{"tf":1},"/python-json/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/python-os-sys/":{"tf":1},"/airflow-k8s-101/":{"tf":1},"/python-tuple/":{"tf":1},"/KS-test/":{"tf":1},"/p-value/":{"tf":1},"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/ssh/":{"tf":1},"/wordpress-docker/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1},"/terminal/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1},"/data-visualization/":{"tf":1},"/type-of-time-series/":{"tf":1},"/data-structure/":{"tf":1},"/awesome-anomaly-detection-ts/":{"tf":1},"/k-shape-clustering/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/r-installation/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1},"/docker-wsl2-windows/":{"tf":1},"/nodejs-npm/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/tensorflow/":{"tf":1},"/docker-gpu/":{"tf":1},"/for-me-only/":{"tf":1},"/reading/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":102}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/titanic-disaster/":{"tf":1}},"df":3}}}},"b":{"docs":{"/gambler-ruin-problem/":{"tf":1},"/KS-test/":{"tf":1},"/p-value/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1}},"df":4}}},"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"/pep-8/":{"tf":1},"/python-classes-objects/":{"tf":1},"/python-docs-refs/":{"tf":1},"/python-functions/":{"tf":1},"/python-input-output/":{"tf":1},"/python-installation/":{"tf":1},"/python-list/":{"tf":1},"/python-tips/":{"tf":1},"/python-matplotlib-tips/":{"tf":1},"/python-numpy-tips/":{"tf":1},"/python-pandas/":{"tf":1},"/regular-expression/":{"tf":1},"/python-loop/":{"tf":1},"/pytest/":{"tf":1},"/python-exception/":{"tf":1},"/python-dictionary/":{"tf":1},"/python-json/":{"tf":1},"/python-os-sys/":{"tf":1},"/python-tuple/":{"tf":1},"/sphinx-restructuredtext/":{"tf":1}},"df":20}}}}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"b":{"docs":{"/css-tips/":{"tf":1},"/jekyll-tips/":{"tf":1},"/web-design-tips/":{"tf":1},"/gitbook/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/wordpress-installation/":{"tf":1},"/wordpress-101/":{"tf":1},"/wordpress-docker/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":11}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/good-applications/":{"tf":1},"/fresh-install-windows/":{"tf":1},"/docker-wsl2-windows/":{"tf":1}},"df":3}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"/wordpress-installation/":{"tf":1},"/wordpress-101/":{"tf":1},"/wordpress-docker/":{"tf":1}},"df":3}}}}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{"/css-tips/":{"tf":1},"/jekyll-tips/":{"tf":1},"/web-design-tips/":{"tf":1},"/gitbook/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/wordpress-installation/":{"tf":1},"/wordpress-101/":{"tf":1},"/wordpress-docker/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":11},"e":{"docs":{},"df":0,"p":{"docs":{"/pytorch/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1},"/tensorflow/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":13,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,".":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":9}}}}}}}}}}}}}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"/dataset-collection/":{"tf":1},"/data-aggregation/":{"tf":1},"/data-combining/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/data-visualization/":{"tf":1},"/data-structure/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":9}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/good-repositories/":{"tf":1},"/computer-and-internet-tips/":{"tf":1},"/good-applications/":{"tf":1},"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/for-me-only/":{"tf":1},"/reading/":{"tf":1}},"df":7}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"/good-repositories/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/good-applications/":{"tf":1},"/reading/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":6}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{"/decision-tree-classifier/":{"tf":1},"/support-vector-machine/":{"tf":1}},"df":2}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/k-means-clustering/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/mean-shift/":{"tf":1},"/k-shape-clustering/":{"tf":1}},"df":4}}}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/titanic-disaster/":{"tf":1}},"df":3}}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"/setting-up-a-cafe-in-hcmc/":{"tf":1},"/confusion-matrix-and-f1-score/":{"tf":1},"/random-forest/":{"tf":1},"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1},"/support-vector-machine/":{"tf":1},"/pipeline/":{"tf":1},"/principal-component-analysis/":{"tf":1},"/small-projects-to-understand-concepts/":{"tf":1},"/k-means-clustering/":{"tf":1},"/titanic-disaster/":{"tf":1},"/grid-search/":{"tf":1},"/pytorch/":{"tf":1},"/simple-autoencoder-ae/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/mean-shift/":{"tf":1},"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1},"/k-shape-clustering/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1},"/tensorflow/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1.4142135623730951}},"df":28}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"x":{"docs":{"/good-applications/":{"tf":1},"/screen/":{"tf":1},"/linux-tips/":{"tf":1},"/bash-command-line/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1},"/terminal/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":7}}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"/r-installation/":{"tf":1}},"df":1}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"/confusion-matrix-and-f1-score/":{"tf":1},"/random-forest/":{"tf":1},"/decision-tree-classifier/":{"tf":1},"/decision-tree-regression/":{"tf":1},"/support-vector-machine/":{"tf":1},"/pipeline/":{"tf":1},"/principal-component-analysis/":{"tf":1},"/k-means-clustering/":{"tf":1},"/grid-search/":{"tf":1},"/dbscan-hdbscan-clustering/":{"tf":1},"/mean-shift/":{"tf":1},"/k-shape-clustering/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":13}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{"/docker/":{"tf":1},"/airflow-k8s-101/":{"tf":1},"/docker-wsl2-windows/":{"tf":1},"/docker-gpu/":{"tf":1}},"df":4}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{"/deeplearning-ai-course-1/":{"tf":1},"/deeplearning-ai-course-2/":{"tf":1},"/deeplearning-ai-course-3/":{"tf":1},"/deeplearning-ai-course-3-autonomous-driving/":{"tf":1},"/deeplearning-ai-course-3-bird-recognition-peacetopia/":{"tf":1},"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":9}}}},"j":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"/js-tips/":{"tf":1},"/js-101/":{"tf":1},"/nodejs-npm/":{"tf":1},"/web-dev-tools/":{"tf":1}},"df":4}}}}}}}}},"e":{"docs":{},"df":0,"k":{"docs":{},"df":0,"y":{"docs":{},"df":0,"l":{"docs":{"/jekyll-tips/":{"tf":1}},"df":1}}}}},"s":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"/git/":{"tf":1},"/jupyter-notebook/":{"tf":1},"/python-with-sublime-text/":{"tf":1},"/screen/":{"tf":1},"/linux-tips/":{"tf":1},"/visual-studio-code/":{"tf":1},"/bash-command-line/":{"tf":1},"/ssh/":{"tf":1},"/terminal/":{"tf":1}},"df":9}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"/gambler-ruin-problem/":{"tf":1},"/KS-test/":{"tf":1},"/p-value/":{"tf":1},"/wasserstein-earth-mover-distance/":{"tf":1}},"df":4,"i":{"docs":{},"df":0,"c":{"docs":{"/jekyll-tips/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/for-me-only/":{"tf":1}},"df":5}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"/jekyll-tips/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/for-me-only/":{"tf":1}},"df":5}}},"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"/dataset-collection/":{"tf":1},"/data-aggregation/":{"tf":1},"/data-combining/":{"tf":1},"/data-preprocessing-cleaning/":{"tf":1},"/dataframe-overview/":{"tf":1},"/data-visualization/":{"tf":1},"/data-structure/":{"tf":1},"/data-ml-tools-resources/":{"tf":1},"/useful-tools-data-science-machine-learning/":{"tf":1}},"df":9}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{"/date-time-tips/":{"tf":1},"/fast-fourier-transform-fft/":{"tf":1},"/tsfresh/":{"tf":1},"/time-series-tips/":{"tf":1},"/type-of-time-series/":{"tf":1},"/awesome-anomaly-detection-ts/":{"tf":1}},"df":6}}}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"/jekyll-tips/":{"tf":1},"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1},"/11ty-nunjucks/":{"tf":1},"/for-me-only/":{"tf":1}},"df":5}}}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{},"df":0,"b":{"docs":{},"df":0,"y":{"docs":{},"df":0,"j":{"docs":{"/gatsby-js/":{"tf":1},"/gatsby-images/":{"tf":1}},"df":2}}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"/date-time-tips/":{"tf":1},"/fast-fourier-transform-fft/":{"tf":1},"/tsfresh/":{"tf":1},"/time-series-tips/":{"tf":1},"/type-of-time-series/":{"tf":1},"/awesome-anomaly-detection-ts/":{"tf":1}},"df":6}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"/deeplearning-ai-tensorflow-course-1/":{"tf":1},"/deeplearning-ai-tensorflow-course-2/":{"tf":1},"/deeplearning-ai-tensorflow-course-3/":{"tf":1},"/deeplearning-ai-tensorflow-course-4/":{"tf":1}},"df":4}}}}}}}}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{"/algorithm-1/":{"tf":1}},"df":1}}}}}}}}},"f":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"/fresh-install-windows/":{"tf":1},"/fresh-installation-ubuntu/":{"tf":1}},"df":2}}}}}},"r":{"docs":{"/r-installation/":{"tf":1}},"df":1}}}},"pipeline":["trimmer","stopWordFilter","stemmer"]}